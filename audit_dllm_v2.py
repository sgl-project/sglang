import os
import re
import asyncio
from openai import AsyncOpenAI

# ================= âš¡ï¸ é…ç½®åŒºåŸŸ =================
# å¡«å…¥ä½ ä¹‹å‰éªŒè¯æˆåŠŸçš„é…ç½®
REMOTE_HOST = "https://api.agentify.top/v1" 
API_KEY = "sk-MzagDUFUavhiE1ieVOHk5V1KAy7eXF0ZXfnn6IkPRwb9185P"
MODEL_NAME = "openai/gpt-oss-120b" 

client = AsyncOpenAI(base_url=REMOTE_HOST, api_key=API_KEY)

# ================= ğŸ” çŒæ€è§„åˆ™ (Fingerprints) =================
# é’ˆå¯¹ LLaDA Block Diffusion çš„ç‰¹å®šæ¼æ´æŒ‡çº¹
RULES = {
    "UNSYNC_RANDOM": {
        "pattern": r"torch\.rand(n|_like)?\(",
        "context": 10,
        "desc": "Unsynchronized random sampling in TP mode"
    },
    "CAUSAL_MASK_REUSE": {
        "pattern": r"torch\.tril\(",
        "context": 8,
        "desc": "Incorrect Causal Mask used for Block Diffusion (Rectangular needed)"
    },
    "KV_CACHE_APPEND": {
        "pattern": r"(kv_cache|k_cache|v_cache).*(\.append|cat\()",
        "context": 12,
        "desc": "Incorrect KV Cache append during re-masking (Should overwrite)"
    },
    "UNSAFE_DIVISION": {
        "pattern": r"\/.*sigma",  # æŸ¥æ‰¾é™¤ä»¥ sigma çš„æ“ä½œ
        "context": 5,
        "desc": "Potential Division by Zero (missing epsilon)"
    }
}

# é”å®šç›®æ ‡ç›®å½• (dLLM æ ¸å¿ƒåŒº)
TARGET_DIRS = [
    "python/sglang/srt/models",
    "python/sglang/srt/layers/attention",
    "python/sglang/srt/managers"
]

async def analyze_snippet(sem, file_path, line_num, code_snippet, rule_key):
    async with sem:
        # æ„é€ æå…¶å…·ä½“çš„ Prompt
        prompt = f"""
        You are a Senior AI Systems Engineer auditing SGLang's new Diffusion Model (LLaDA) implementation.
        
        **Context**: 
        - File: `{file_path}` (Line {line_num})
        - Issue Type: {RULES[rule_key]['desc']}
        - Architecture: LLaDA uses Block Diffusion (Bidirectional Attention within blocks) and requires Tensor Parallel (TP) consistency.
        
        **Code Snippet**:
        ```python
        {code_snippet}
        ```
        
        **Task**: 
        Analyze ONLY this snippet. 
        1. If this is `torch.rand`, is there a `generator` argument derived from a TP-synchronized seed?
        2. If this is `torch.tril`, is it being used for `attention_mask`? If so, it breaks LLaDA.
        3. If this is `kv_cache.append`, is it inside a diffusion loop where it should overwrite instead?
        
        **Output**:
        - If BUG: Start with "[CONFIRMED BUG]". Explain why briefly.
        - If SAFE: Start with "[SAFE]".
        """

        try:
            res = await client.chat.completions.create(
                model=MODEL_NAME,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
            )
            return res.choices[0].message.content
        except:
            return None

def extract_snippets(file_path):
    """æ³•åŒ»çº§åˆ‡ç‰‡ï¼šåªæå–å‘½ä¸­è§„åˆ™çš„ä»£ç æ®µ"""
    snippets = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except: return []

    # åªæ‰«æåŒ…å« diffusion/llada çš„æ–‡ä»¶ï¼Œæˆ–è€…æ ¸å¿ƒ layers
    content = "".join(lines).lower()
    if "diffusion" not in content and "llada" not in content and "layer" not in file_path:
        return []

    for i, line in enumerate(lines):
        for rule_key, rule in RULES.items():
            if re.search(rule['pattern'], line):
                # æå–ä¸Šä¸‹æ–‡
                start = max(0, i - rule['context'])
                end = min(len(lines), i + rule['context'] + 1)
                snippet = "".join(lines[start:end])
                snippets.append((i + 1, snippet, rule_key))
                break # ä¸€è¡ŒåªæŠ¥ä¸€æ¬¡
    return snippets

async def main():
    report_file = "DLLM_V2_AUDIT_REPORT.md"
    print(f"ğŸš€ SGLang dLLM Audit V2.0 (Fingerprint-Based)...")
    
    all_snippets = []
    # 1. æ‰«ææ–‡ä»¶
    for d in TARGET_DIRS:
        for root, _, files in os.walk(d):
            for file in files:
                if file.endswith(".py"):
                    path = os.path.join(root, file)
                    hits = extract_snippets(path)
                    for hit in hits:
                        all_snippets.append((path, *hit))

    print(f"ğŸ” æå–åˆ° {len(all_snippets)} ä¸ªå¯ç–‘ä»£ç ç‰‡æ®µã€‚å¼€å§‹ AI ä¼šè¯Š...")

    if not all_snippets:
        print("âš ï¸ æœªå‘ç°å¯ç–‘ç‰‡æ®µã€‚å¯èƒ½ç›®å½•ä¸å¯¹æˆ–ä»£ç å·²æ›´æ–°ã€‚")
        return

    sem = asyncio.Semaphore(10) # å¹¶å‘ 10
    
    # === ğŸ”´ åˆ é™¤åŸæ¥çš„ task_map å¤æ‚é€»è¾‘ï¼Œç›´æ¥ç”¨ä¸‹é¢è¿™ä¸€è¡Œ ===
    tasks = [analyze_snippet(sem, p, l, s, r) for p, l, s, r in all_snippets]
    
    # å¹¶å‘æ‰§è¡Œå¹¶æ”¶é›†ç»“æœ
    results = await asyncio.gather(*tasks)

    # 3. å†™å…¥æŠ¥å‘Š
    with open(report_file, "w", encoding="utf-8") as f:
        f.write(f"# Audit Report (Total Checked: {len(results)})\n\n")
        
        for i, analysis in enumerate(results):
            # è¿™é‡Œçš„ i å’Œ all_snippets çš„ç´¢å¼•æ˜¯ä¸€ä¸€å¯¹åº”çš„
            if analysis and "[CONFIRMED BUG]" in analysis:
                path, line, snippet, rule = all_snippets[i]
                print(f"ğŸ”¥ [å®é”¤] {path}:{line} - {rule}")
                f.write(f"## ğŸš¨ {rule} in `{path}` : {line}\n")
                f.write(f"```python\n{snippet}\n```\n")
                f.write(f"> {analysis}\n\n---\n")

    print(f"\nâœ… å®¡è®¡ç»“æŸï¼è¯·æŸ¥çœ‹ {report_file}")
    
if __name__ == "__main__":
    asyncio.run(main())