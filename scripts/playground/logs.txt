devuser@7ed22f68dd76:/sgl-workspace/sglang$ python3 scripts/playground/bench_speculative.py --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --tp-size 8 --trust-remote-code --batch-size 8 --steps 3 4 5 6 --topk 1 2 3 4 --num_draft_tokens 4 6 8 12 --speculative-algorithm EAGLE --dataset-path /shared/junmingc/converted_prompts.txt
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:36:24.171000 124365 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:36:24.171000 124365 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
Loaded 180 prompts from /shared/junmingc/converted_prompts.txt
Start i=0: batch_size=8, steps=3, topk=1, num_draft_tokens=4
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-draft-tokens 4 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:36:29.791000 124619 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:36:29.791000 124619 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 06:36:30] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=189107614, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=3, speculative_eagle_topk=1, speculative_num_draft_tokens=4, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:36:30] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:36:38.858000 124897 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:36:38.858000 124897 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:36:39.053000 124898 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:36:39.053000 124898 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:36:39.101000 124899 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:36:39.101000 124899 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:36:39.223000 124896 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:36:39.223000 124896 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:36:39.224000 124902 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:36:39.224000 124902 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:36:39.232000 124895 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:36:39.232000 124895 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:36:39.272000 124903 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:36:39.272000 124903 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:36:39.274000 124900 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:36:39.274000 124900 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:36:39.337000 124901 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:36:39.337000 124901 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:36:39 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 06:36:39 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:36:39 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:36:41 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:36:44 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 06:36:46 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 06:36:46 TP0] Detected fp8 checkpoint.
[2025-09-13 06:36:46 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 28/1024 [00:00<00:03, 255.81it/s]
Loading safetensors checkpoint shards:   5% Completed | 54/1024 [00:00<00:12, 75.84it/s]
Loading safetensors checkpoint shards:   7% Completed | 68/1024 [00:00<00:15, 62.55it/s]
Loading safetensors checkpoint shards:   8% Completed | 78/1024 [00:01<00:15, 60.53it/s]
Loading safetensors checkpoint shards:   8% Completed | 87/1024 [00:01<00:14, 62.67it/s]
Loading safetensors checkpoint shards:   9% Completed | 95/1024 [00:01<00:17, 53.66it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:02<00:29, 31.15it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:02<00:27, 33.53it/s]
Loading safetensors checkpoint shards:  11% Completed | 113/1024 [00:02<00:27, 33.23it/s]
Loading safetensors checkpoint shards:  12% Completed | 119/1024 [00:02<00:25, 36.06it/s]
Loading safetensors checkpoint shards:  12% Completed | 124/1024 [00:02<00:24, 37.26it/s]
Loading safetensors checkpoint shards:  13% Completed | 129/1024 [00:02<00:23, 38.62it/s]
Loading safetensors checkpoint shards:  13% Completed | 134/1024 [00:02<00:23, 37.90it/s]
Loading safetensors checkpoint shards:  14% Completed | 140/1024 [00:02<00:20, 42.19it/s]
Loading safetensors checkpoint shards:  14% Completed | 145/1024 [00:03<00:20, 42.84it/s]
Loading safetensors checkpoint shards:  15% Completed | 150/1024 [00:03<00:19, 43.73it/s]
Loading safetensors checkpoint shards:  15% Completed | 155/1024 [00:03<00:19, 44.27it/s]
Loading safetensors checkpoint shards:  16% Completed | 161/1024 [00:03<00:18, 45.86it/s]
Loading safetensors checkpoint shards:  16% Completed | 166/1024 [00:03<00:19, 44.28it/s]
Loading safetensors checkpoint shards:  17% Completed | 172/1024 [00:03<00:18, 46.24it/s]
Loading safetensors checkpoint shards:  17% Completed | 177/1024 [00:03<00:18, 46.15it/s]
Loading safetensors checkpoint shards:  18% Completed | 182/1024 [00:03<00:18, 46.58it/s]
Loading safetensors checkpoint shards:  18% Completed | 187/1024 [00:03<00:18, 45.85it/s]
Loading safetensors checkpoint shards:  19% Completed | 192/1024 [00:04<00:18, 45.57it/s]
Loading safetensors checkpoint shards:  19% Completed | 198/1024 [00:04<00:17, 47.24it/s]
Loading safetensors checkpoint shards:  20% Completed | 203/1024 [00:04<00:18, 44.99it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:04<00:17, 46.50it/s]
Loading safetensors checkpoint shards:  21% Completed | 214/1024 [00:04<00:17, 45.61it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:04<00:17, 45.78it/s]
Loading safetensors checkpoint shards:  22% Completed | 224/1024 [00:04<00:17, 45.25it/s]
Loading safetensors checkpoint shards:  22% Completed | 229/1024 [00:04<00:17, 45.42it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:04<00:17, 45.44it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:05<00:16, 46.97it/s]
Loading safetensors checkpoint shards:  24% Completed | 245/1024 [00:05<00:16, 46.62it/s]
Loading safetensors checkpoint shards:  25% Completed | 251/1024 [00:05<00:15, 48.34it/s]
Loading safetensors checkpoint shards:  25% Completed | 256/1024 [00:05<00:16, 47.26it/s]
Loading safetensors checkpoint shards:  26% Completed | 262/1024 [00:05<00:15, 48.17it/s]
Loading safetensors checkpoint shards:  26% Completed | 267/1024 [00:05<00:15, 47.51it/s]
Loading safetensors checkpoint shards:  27% Completed | 273/1024 [00:05<00:15, 48.91it/s]
Loading safetensors checkpoint shards:  27% Completed | 278/1024 [00:05<00:15, 46.65it/s]
Loading safetensors checkpoint shards:  28% Completed | 284/1024 [00:06<00:15, 48.02it/s]
Loading safetensors checkpoint shards:  28% Completed | 289/1024 [00:06<00:30, 24.13it/s]
Loading safetensors checkpoint shards:  29% Completed | 294/1024 [00:06<00:26, 27.98it/s]
Loading safetensors checkpoint shards:  29% Completed | 299/1024 [00:06<00:23, 31.18it/s]
Loading safetensors checkpoint shards:  30% Completed | 305/1024 [00:06<00:20, 35.45it/s]
Loading safetensors checkpoint shards:  30% Completed | 310/1024 [00:06<00:19, 36.69it/s]
Loading safetensors checkpoint shards:  31% Completed | 316/1024 [00:07<00:17, 40.37it/s]
Loading safetensors checkpoint shards:  31% Completed | 321/1024 [00:07<00:17, 40.93it/s]
Loading safetensors checkpoint shards:  32% Completed | 327/1024 [00:07<00:15, 44.16it/s]
Loading safetensors checkpoint shards:  32% Completed | 332/1024 [00:07<00:15, 44.77it/s]
Loading safetensors checkpoint shards:  33% Completed | 338/1024 [00:07<00:14, 45.92it/s]
Loading safetensors checkpoint shards:  33% Completed | 343/1024 [00:07<00:15, 45.31it/s]
Loading safetensors checkpoint shards:  34% Completed | 348/1024 [00:07<00:15, 44.48it/s]
Loading safetensors checkpoint shards:  34% Completed | 353/1024 [00:07<00:15, 44.01it/s]
Loading safetensors checkpoint shards:  35% Completed | 358/1024 [00:07<00:15, 44.10it/s]
Loading safetensors checkpoint shards:  35% Completed | 363/1024 [00:08<00:14, 45.08it/s]
Loading safetensors checkpoint shards:  36% Completed | 368/1024 [00:08<00:14, 44.64it/s]
Loading safetensors checkpoint shards:  37% Completed | 374/1024 [00:08<00:14, 46.25it/s]
Loading safetensors checkpoint shards:  37% Completed | 379/1024 [00:08<00:14, 44.61it/s]
Loading safetensors checkpoint shards:  38% Completed | 384/1024 [00:08<00:13, 45.89it/s]
Loading safetensors checkpoint shards:  38% Completed | 389/1024 [00:08<00:14, 44.19it/s]
Loading safetensors checkpoint shards:  38% Completed | 394/1024 [00:08<00:14, 44.48it/s]
Loading safetensors checkpoint shards:  39% Completed | 399/1024 [00:08<00:14, 41.99it/s]
Loading safetensors checkpoint shards:  39% Completed | 404/1024 [00:09<00:14, 43.36it/s]
Loading safetensors checkpoint shards:  40% Completed | 409/1024 [00:09<00:14, 42.43it/s]
Loading safetensors checkpoint shards:  40% Completed | 414/1024 [00:09<00:14, 42.34it/s]
Loading safetensors checkpoint shards:  41% Completed | 419/1024 [00:09<00:14, 42.95it/s]
Loading safetensors checkpoint shards:  41% Completed | 424/1024 [00:09<00:14, 42.73it/s]
Loading safetensors checkpoint shards:  42% Completed | 429/1024 [00:09<00:13, 44.56it/s]
Loading safetensors checkpoint shards:  42% Completed | 434/1024 [00:09<00:13, 42.36it/s]
Loading safetensors checkpoint shards:  43% Completed | 439/1024 [00:09<00:13, 43.92it/s]
Loading safetensors checkpoint shards:  43% Completed | 444/1024 [00:09<00:13, 43.19it/s]
Loading safetensors checkpoint shards:  44% Completed | 449/1024 [00:10<00:13, 42.93it/s]
Loading safetensors checkpoint shards:  44% Completed | 454/1024 [00:10<00:13, 41.82it/s]
Loading safetensors checkpoint shards:  45% Completed | 459/1024 [00:10<00:13, 42.81it/s]
Loading safetensors checkpoint shards:  45% Completed | 464/1024 [00:10<00:13, 40.24it/s]
Loading safetensors checkpoint shards:  46% Completed | 469/1024 [00:10<00:14, 38.71it/s]
Loading safetensors checkpoint shards:  46% Completed | 474/1024 [00:10<00:13, 41.47it/s]
Loading safetensors checkpoint shards:  47% Completed | 479/1024 [00:10<00:13, 39.33it/s]
Loading safetensors checkpoint shards:  47% Completed | 484/1024 [00:10<00:13, 40.32it/s]
Loading safetensors checkpoint shards:  48% Completed | 489/1024 [00:11<00:13, 38.71it/s]
Loading safetensors checkpoint shards:  48% Completed | 494/1024 [00:11<00:13, 39.97it/s]
Loading safetensors checkpoint shards:  49% Completed | 499/1024 [00:11<00:13, 39.98it/s]
Loading safetensors checkpoint shards:  49% Completed | 504/1024 [00:11<00:12, 41.31it/s]
Loading safetensors checkpoint shards:  50% Completed | 509/1024 [00:11<00:12, 40.23it/s]
Loading safetensors checkpoint shards:  50% Completed | 514/1024 [00:11<00:12, 39.27it/s]
Loading safetensors checkpoint shards:  51% Completed | 519/1024 [00:11<00:12, 39.22it/s]
Loading safetensors checkpoint shards:  51% Completed | 523/1024 [00:11<00:13, 38.19it/s]
Loading safetensors checkpoint shards:  52% Completed | 528/1024 [00:12<00:12, 39.27it/s]
Loading safetensors checkpoint shards:  52% Completed | 532/1024 [00:12<00:12, 38.64it/s]
Loading safetensors checkpoint shards:  52% Completed | 536/1024 [00:12<00:27, 17.93it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:12<00:22, 21.90it/s]
Loading safetensors checkpoint shards:  53% Completed | 545/1024 [00:12<00:19, 24.80it/s]
Loading safetensors checkpoint shards:  54% Completed | 550/1024 [00:13<00:16, 29.11it/s]
Loading safetensors checkpoint shards:  54% Completed | 554/1024 [00:13<00:14, 31.40it/s]
Loading safetensors checkpoint shards:  54% Completed | 558/1024 [00:13<00:14, 32.20it/s]
Loading safetensors checkpoint shards:  55% Completed | 563/1024 [00:13<00:12, 36.24it/s]
Loading safetensors checkpoint shards:  55% Completed | 568/1024 [00:13<00:12, 37.59it/s]
Loading safetensors checkpoint shards:  56% Completed | 574/1024 [00:13<00:11, 39.89it/s]
Loading safetensors checkpoint shards:  57% Completed | 579/1024 [00:13<00:10, 40.71it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:13<00:09, 44.65it/s]
Loading safetensors checkpoint shards:  58% Completed | 590/1024 [00:13<00:10, 42.89it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:14<00:09, 45.08it/s]
Loading safetensors checkpoint shards:  59% Completed | 601/1024 [00:14<00:09, 45.10it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:14<00:09, 46.35it/s]
Loading safetensors checkpoint shards:  60% Completed | 614/1024 [00:14<00:07, 52.95it/s]
Loading safetensors checkpoint shards:  61% Completed | 623/1024 [00:14<00:06, 62.16it/s]
Loading safetensors checkpoint shards:  62% Completed | 630/1024 [00:14<00:06, 63.92it/s]
Loading safetensors checkpoint shards:  62% Completed | 637/1024 [00:14<00:05, 65.06it/s]
Loading safetensors checkpoint shards:  63% Completed | 645/1024 [00:14<00:05, 64.54it/s]
Loading safetensors checkpoint shards:  64% Completed | 653/1024 [00:14<00:05, 68.41it/s]
Loading safetensors checkpoint shards:  64% Completed | 660/1024 [00:15<00:05, 66.99it/s]
Loading safetensors checkpoint shards:  65% Completed | 667/1024 [00:15<00:05, 66.34it/s]
Loading safetensors checkpoint shards:  66% Completed | 676/1024 [00:15<00:04, 69.73it/s]
Loading safetensors checkpoint shards:  67% Completed | 684/1024 [00:15<00:04, 70.32it/s]
Loading safetensors checkpoint shards:  68% Completed | 693/1024 [00:15<00:04, 73.67it/s]
Loading safetensors checkpoint shards:  68% Completed | 701/1024 [00:15<00:04, 71.88it/s]
Loading safetensors checkpoint shards:  69% Completed | 709/1024 [00:15<00:04, 71.59it/s]
Loading safetensors checkpoint shards:  70% Completed | 717/1024 [00:15<00:05, 56.10it/s]
Loading safetensors checkpoint shards:  71% Completed | 724/1024 [00:16<00:06, 48.60it/s]
Loading safetensors checkpoint shards:  71% Completed | 730/1024 [00:16<00:06, 44.36it/s]
Loading safetensors checkpoint shards:  72% Completed | 735/1024 [00:16<00:06, 41.42it/s]
Loading safetensors checkpoint shards:  72% Completed | 740/1024 [00:16<00:08, 34.84it/s]
Loading safetensors checkpoint shards:  73% Completed | 744/1024 [00:16<00:08, 32.74it/s]
Loading safetensors checkpoint shards:  73% Completed | 748/1024 [00:16<00:08, 33.03it/s]
Loading safetensors checkpoint shards:  73% Completed | 752/1024 [00:17<00:08, 30.66it/s]
Loading safetensors checkpoint shards:  74% Completed | 756/1024 [00:17<00:09, 28.55it/s]
Loading safetensors checkpoint shards:  74% Completed | 759/1024 [00:17<00:10, 25.87it/s]
Loading safetensors checkpoint shards:  74% Completed | 762/1024 [00:17<00:10, 25.64it/s]
Loading safetensors checkpoint shards:  75% Completed | 765/1024 [00:17<00:10, 23.65it/s]
Loading safetensors checkpoint shards:  75% Completed | 768/1024 [00:18<00:22, 11.28it/s]
Loading safetensors checkpoint shards:  75% Completed | 770/1024 [00:18<00:20, 12.34it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:18<00:19, 12.91it/s]
Loading safetensors checkpoint shards:  76% Completed | 774/1024 [00:18<00:18, 13.82it/s]
Loading safetensors checkpoint shards:  76% Completed | 776/1024 [00:18<00:17, 14.32it/s]
Loading safetensors checkpoint shards:  76% Completed | 778/1024 [00:18<00:16, 15.09it/s]
Loading safetensors checkpoint shards:  76% Completed | 781/1024 [00:19<00:13, 17.79it/s]
Loading safetensors checkpoint shards:  77% Completed | 785/1024 [00:19<00:10, 22.21it/s]
Loading safetensors checkpoint shards:  77% Completed | 789/1024 [00:19<00:09, 25.25it/s]
Loading safetensors checkpoint shards:  77% Completed | 793/1024 [00:19<00:08, 27.91it/s]
Loading safetensors checkpoint shards:  78% Completed | 797/1024 [00:19<00:07, 30.24it/s]
Loading safetensors checkpoint shards:  78% Completed | 801/1024 [00:19<00:06, 31.91it/s]
Loading safetensors checkpoint shards:  79% Completed | 805/1024 [00:19<00:06, 32.85it/s]
Loading safetensors checkpoint shards:  79% Completed | 809/1024 [00:19<00:06, 33.62it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:19<00:06, 34.56it/s]
Loading safetensors checkpoint shards:  80% Completed | 817/1024 [00:20<00:06, 34.49it/s]
Loading safetensors checkpoint shards:  80% Completed | 821/1024 [00:20<00:05, 34.83it/s]
Loading safetensors checkpoint shards:  81% Completed | 825/1024 [00:20<00:05, 35.86it/s]
Loading safetensors checkpoint shards:  81% Completed | 829/1024 [00:20<00:05, 37.01it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:20<00:05, 37.53it/s]
Loading safetensors checkpoint shards:  82% Completed | 837/1024 [00:20<00:04, 37.84it/s]
Loading safetensors checkpoint shards:  82% Completed | 841/1024 [00:20<00:04, 38.17it/s]
Loading safetensors checkpoint shards:  83% Completed | 845/1024 [00:20<00:04, 37.01it/s]
Loading safetensors checkpoint shards:  83% Completed | 849/1024 [00:20<00:04, 36.97it/s]
Loading safetensors checkpoint shards:  83% Completed | 853/1024 [00:21<00:04, 37.33it/s]
Loading safetensors checkpoint shards:  84% Completed | 858/1024 [00:21<00:04, 37.45it/s]
Loading safetensors checkpoint shards:  84% Completed | 862/1024 [00:21<00:04, 37.95it/s]
Loading safetensors checkpoint shards:  85% Completed | 866/1024 [00:21<00:04, 38.13it/s]
Loading safetensors checkpoint shards:  85% Completed | 870/1024 [00:21<00:04, 37.90it/s]
Loading safetensors checkpoint shards:  85% Completed | 874/1024 [00:21<00:04, 36.72it/s]
Loading safetensors checkpoint shards:  86% Completed | 878/1024 [00:21<00:03, 37.44it/s]
Loading safetensors checkpoint shards:  86% Completed | 882/1024 [00:21<00:03, 37.84it/s]
Loading safetensors checkpoint shards:  87% Completed | 886/1024 [00:21<00:03, 38.11it/s]
Loading safetensors checkpoint shards:  87% Completed | 890/1024 [00:22<00:03, 37.33it/s]
Loading safetensors checkpoint shards:  87% Completed | 894/1024 [00:22<00:03, 37.46it/s]
Loading safetensors checkpoint shards:  88% Completed | 898/1024 [00:22<00:03, 37.55it/s]
Loading safetensors checkpoint shards:  88% Completed | 902/1024 [00:22<00:03, 37.65it/s]
Loading safetensors checkpoint shards:  88% Completed | 906/1024 [00:22<00:03, 38.05it/s]
Loading safetensors checkpoint shards:  89% Completed | 910/1024 [00:22<00:02, 38.53it/s]
Loading safetensors checkpoint shards:  89% Completed | 915/1024 [00:22<00:02, 39.89it/s]
Loading safetensors checkpoint shards:  90% Completed | 919/1024 [00:22<00:02, 39.24it/s]
Loading safetensors checkpoint shards:  90% Completed | 923/1024 [00:22<00:02, 38.95it/s]
Loading safetensors checkpoint shards:  91% Completed | 927/1024 [00:23<00:02, 38.05it/s]
Loading safetensors checkpoint shards:  91% Completed | 931/1024 [00:23<00:02, 36.76it/s]
Loading safetensors checkpoint shards:  91% Completed | 935/1024 [00:23<00:02, 37.02it/s]
Loading safetensors checkpoint shards:  92% Completed | 939/1024 [00:23<00:02, 37.35it/s]
Loading safetensors checkpoint shards:  92% Completed | 943/1024 [00:23<00:02, 37.74it/s]
Loading safetensors checkpoint shards:  92% Completed | 947/1024 [00:23<00:02, 36.91it/s]
Loading safetensors checkpoint shards:  93% Completed | 951/1024 [00:23<00:01, 37.33it/s]
Loading safetensors checkpoint shards:  93% Completed | 955/1024 [00:23<00:01, 37.79it/s]
Loading safetensors checkpoint shards:  94% Completed | 959/1024 [00:23<00:01, 37.82it/s]
Loading safetensors checkpoint shards:  94% Completed | 963/1024 [00:23<00:01, 36.94it/s]
Loading safetensors checkpoint shards:  94% Completed | 967/1024 [00:24<00:01, 37.10it/s]
Loading safetensors checkpoint shards:  95% Completed | 971/1024 [00:24<00:01, 35.65it/s]
Loading safetensors checkpoint shards:  95% Completed | 975/1024 [00:24<00:01, 35.92it/s]
Loading safetensors checkpoint shards:  96% Completed | 979/1024 [00:24<00:01, 36.61it/s]
Loading safetensors checkpoint shards:  97% Completed | 993/1024 [00:24<00:00, 65.52it/s]
Loading safetensors checkpoint shards:  98% Completed | 1001/1024 [00:24<00:00, 67.18it/s]
Loading safetensors checkpoint shards:  99% Completed | 1010/1024 [00:24<00:00, 72.19it/s]
Loading safetensors checkpoint shards: 100% Completed | 1021/1024 [00:24<00:00, 82.67it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:24<00:00, 41.21it/s]

[2025-09-13 06:37:11 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 06:37:14 TP3] KV Cache is allocated. #tokens: 620113, KV size: 40.58 GB
[2025-09-13 06:37:14 TP2] KV Cache is allocated. #tokens: 620113, KV size: 40.58 GB
[2025-09-13 06:37:14 TP1] KV Cache is allocated. #tokens: 620113, KV size: 40.58 GB
[2025-09-13 06:37:14 TP5] KV Cache is allocated. #tokens: 620113, KV size: 40.58 GB
[2025-09-13 06:37:14 TP7] KV Cache is allocated. #tokens: 620113, KV size: 40.58 GB
[2025-09-13 06:37:14 TP4] KV Cache is allocated. #tokens: 620113, KV size: 40.58 GB
[2025-09-13 06:37:14 TP6] KV Cache is allocated. #tokens: 620113, KV size: 40.58 GB
[2025-09-13 06:37:14 TP0] KV Cache is allocated. #tokens: 620113, KV size: 40.58 GB
[2025-09-13 06:37:14 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 06:37:14 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 06:37:14 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.53 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 06:37:15 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:37:15 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 06:37:15 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:37:15 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:37:15 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:37:15 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:37:15 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:37:16 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:37:16 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 24952.38it/s]
[2025-09-13 06:37:16 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:37:16 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26490.61it/s]
[2025-09-13 06:37:17 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:37:17 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28052.70it/s]
[2025-09-13 06:37:17 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:37:17 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27692.23it/s]
[2025-09-13 06:37:18 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:37:18 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28211.88it/s]
[2025-09-13 06:37:18 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.25 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  2.00it/s][2025-09-13 06:37:21 TP6] Registering 984 cuda graph addresses
[2025-09-13 06:37:21 TP4] Registering 984 cuda graph addresses
[2025-09-13 06:37:21 TP7] Registering 984 cuda graph addresses
[2025-09-13 06:37:21 TP5] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.25 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.18it/s]
[2025-09-13 06:37:21 TP2] Registering 984 cuda graph addresses
[2025-09-13 06:37:21 TP3] Registering 984 cuda graph addresses
[2025-09-13 06:37:21 TP0] Registering 984 cuda graph addresses
[2025-09-13 06:37:21 TP1] Registering 984 cuda graph addresses
[2025-09-13 06:37:21 TP0] Capture cuda graph end. Time elapsed: 7.44 s. mem usage=0.34 GB. avail mem=17.23 GB.
[2025-09-13 06:37:22 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 06:37:22 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:37:22 TP0] Init torch distributed begin.
[2025-09-13 06:37:22 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 06:37:22 TP0] Load weight begin. avail mem=17.23 GB
[2025-09-13 06:37:22 TP0] Detected fp8 checkpoint.
[2025-09-13 06:37:22 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 177.25it/s]
Loading safetensors checkpoint shards:   5% Completed | 48/1024 [00:00<00:03, 247.70it/s]
Loading safetensors checkpoint shards:  11% Completed | 109/1024 [00:00<00:02, 412.03it/s]
Loading safetensors checkpoint shards:  17% Completed | 172/1024 [00:00<00:01, 496.92it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:00<00:01, 539.10it/s]
Loading safetensors checkpoint shards:  29% Completed | 297/1024 [00:00<00:01, 568.73it/s]
Loading safetensors checkpoint shards:  35% Completed | 359/1024 [00:00<00:01, 585.19it/s]
Loading safetensors checkpoint shards:  41% Completed | 422/1024 [00:00<00:01, 598.39it/s]
Loading safetensors checkpoint shards:  47% Completed | 485/1024 [00:00<00:00, 608.19it/s]
Loading safetensors checkpoint shards:  53% Completed | 547/1024 [00:01<00:00, 609.46it/s]
Loading safetensors checkpoint shards:  60% Completed | 610/1024 [00:01<00:00, 614.83it/s]
Loading safetensors checkpoint shards:  66% Completed | 672/1024 [00:01<00:00, 606.19it/s]
Loading safetensors checkpoint shards:  72% Completed | 733/1024 [00:01<00:00, 600.20it/s]
Loading safetensors checkpoint shards:  78% Completed | 794/1024 [00:01<00:00, 594.76it/s]
Loading safetensors checkpoint shards:  83% Completed | 854/1024 [00:01<00:00, 593.41it/s]
Loading safetensors checkpoint shards:  89% Completed | 914/1024 [00:01<00:00, 589.21it/s]
Loading safetensors checkpoint shards:  95% Completed | 973/1024 [00:01<00:00, 581.37it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:01<00:00, 519.95it/s]

[2025-09-13 06:37:24 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.24 GB, mem usage=1.98 GB.
[2025-09-13 06:37:24 TP7] KV Cache is allocated. #tokens: 620113, KV size: 0.67 GB
[2025-09-13 06:37:24 TP2] KV Cache is allocated. #tokens: 620113, KV size: 0.67 GB
[2025-09-13 06:37:24 TP4] KV Cache is allocated. #tokens: 620113, KV size: 0.67 GB
[2025-09-13 06:37:24 TP6] KV Cache is allocated. #tokens: 620113, KV size: 0.67 GB
[2025-09-13 06:37:24 TP5] KV Cache is allocated. #tokens: 620113, KV size: 0.67 GB
[2025-09-13 06:37:24 TP3] KV Cache is allocated. #tokens: 620113, KV size: 0.67 GB
[2025-09-13 06:37:24 TP0] KV Cache is allocated. #tokens: 620113, KV size: 0.67 GB
[2025-09-13 06:37:24 TP0] Memory pool end. avail mem=14.58 GB
[2025-09-13 06:37:24 TP1] KV Cache is allocated. #tokens: 620113, KV size: 0.67 GB
[2025-09-13 06:37:24 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.97 GB
[2025-09-13 06:37:24 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.97 GB
[2025-09-13 06:37:24 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.97 GB
[2025-09-13 06:37:24 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.97 GB
[2025-09-13 06:37:24 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.01 GB
[2025-09-13 06:37:24 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.97 GB
[2025-09-13 06:37:24 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.20 GB
[2025-09-13 06:37:24 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.97 GB
Capturing batches (bs=1 avail_mem=14.83 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:01<00:00,  6.02it/s][2025-09-13 06:37:28 TP6] Registering 48 cuda graph addresses
[2025-09-13 06:37:28 TP5] Registering 48 cuda graph addresses
[2025-09-13 06:37:28 TP2] Registering 48 cuda graph addresses
[2025-09-13 06:37:28 TP3] Registering 48 cuda graph addresses
[2025-09-13 06:37:28 TP4] Registering 48 cuda graph addresses
[2025-09-13 06:37:28 TP7] Registering 48 cuda graph addresses
[2025-09-13 06:37:28 TP1] Registering 48 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.83 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:02<00:00,  3.49it/s]
[2025-09-13 06:37:28 TP0] Registering 48 cuda graph addresses
[2025-09-13 06:37:28 TP6] Capture draft cuda graph end. Time elapsed: 3.17 s. mem usage=0.18 GB. avail mem=14.79 GB.
[2025-09-13 06:37:28 TP1] Capture draft cuda graph end. Time elapsed: 3.16 s. mem usage=0.18 GB. avail mem=14.79 GB.
[2025-09-13 06:37:28 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 06:37:28 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 06:37:28 TP0] Capture draft cuda graph end. Time elapsed: 3.17 s. mem usage=0.18 GB. avail mem=14.83 GB.
[2025-09-13 06:37:28 TP5] Capture draft cuda graph end. Time elapsed: 3.17 s. mem usage=0.18 GB. avail mem=14.79 GB.
[2025-09-13 06:37:28 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 06:37:28 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.83 GB
[2025-09-13 06:37:28 TP2] Capture draft cuda graph end. Time elapsed: 3.17 s. mem usage=0.18 GB. avail mem=14.79 GB.
[2025-09-13 06:37:28 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 06:37:28 TP7] Capture draft cuda graph end. Time elapsed: 3.16 s. mem usage=0.18 GB. avail mem=15.02 GB.
[2025-09-13 06:37:28 TP3] Capture draft cuda graph end. Time elapsed: 3.16 s. mem usage=0.18 GB. avail mem=14.79 GB.
[2025-09-13 06:37:28 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.02 GB
[2025-09-13 06:37:28 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 06:37:28 TP4] Capture draft cuda graph end. Time elapsed: 3.17 s. mem usage=0.18 GB. avail mem=14.79 GB.
[2025-09-13 06:37:28 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
Capturing batches (bs=1 avail_mem=14.66 GB):  62%|█████████████████████████████████████████████████████▊                                | 5/8 [00:00<00:00, 46.19it/s][2025-09-13 06:37:29 TP2] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.66 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 48.41it/s]
[2025-09-13 06:37:29 TP7] Registering 24 cuda graph addresses
[2025-09-13 06:37:29 TP3] Registering 24 cuda graph addresses
[2025-09-13 06:37:29 TP6] Registering 24 cuda graph addresses
[2025-09-13 06:37:29 TP1] Registering 24 cuda graph addresses
[2025-09-13 06:37:29 TP5] Registering 24 cuda graph addresses
[2025-09-13 06:37:29 TP4] Registering 24 cuda graph addresses
[2025-09-13 06:37:29 TP0] Registering 24 cuda graph addresses
[2025-09-13 06:37:29 TP1] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.17 GB. avail mem=14.62 GB.
[2025-09-13 06:37:29 TP6] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.17 GB. avail mem=14.62 GB.
[2025-09-13 06:37:29 TP2] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.17 GB. avail mem=14.62 GB.
[2025-09-13 06:37:29 TP5] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.17 GB. avail mem=14.62 GB.
[2025-09-13 06:37:29 TP0] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.17 GB. avail mem=14.66 GB.
[2025-09-13 06:37:29 TP0] max_total_num_tokens=620113, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.66 GB
[2025-09-13 06:37:29 TP4] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.17 GB. avail mem=14.62 GB.
[2025-09-13 06:37:29 TP7] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.17 GB. avail mem=14.85 GB.
[2025-09-13 06:37:29 TP3] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.17 GB. avail mem=14.62 GB.
[2025-09-13 06:37:29] INFO:     Started server process [124619]
[2025-09-13 06:37:29] INFO:     Waiting for application startup.
[2025-09-13 06:37:29] INFO:     Application startup complete.
[2025-09-13 06:37:29] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 06:37:30] INFO:     127.0.0.1:34092 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 06:37:30 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:37:30 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:37:30 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28110.80it/s]
[2025-09-13 06:37:31] INFO:     127.0.0.1:34108 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:31] The server is fired up and ready to roll!
[2025-09-13 06:37:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:37:35] INFO:     127.0.0.1:34122 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:37:35] INFO:     127.0.0.1:34134 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:35 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 06:37:37] INFO:     127.0.0.1:34136 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:37] INFO:     127.0.0.1:34142 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:37:37] INFO:     127.0.0.1:34144 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:37] INFO:     127.0.0.1:34152 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:37] INFO:     127.0.0.1:34166 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:37] INFO:     127.0.0.1:34172 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:37] INFO:     127.0.0.1:34186 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:37] INFO:     127.0.0.1:34190 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:37 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 06:37:37 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:37:37 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:37:37 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:37:37 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:37:37 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:37:37 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:37:37 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:37:37 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:37:37 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 06:37:38 TP0] Decode batch. #running-req: 8, #token: 14473, token usage: 0.02, accept len: 2.64, cuda graph: True, gen throughput (token/s): 62.90, #queue-req: 0, 
[2025-09-13 06:37:39 TP0] Decode batch. #running-req: 8, #token: 15383, token usage: 0.02, accept len: 2.84, cuda graph: True, gen throughput (token/s): 842.11, #queue-req: 0, 
[2025-09-13 06:37:40 TP0] Decode batch. #running-req: 8, #token: 16344, token usage: 0.03, accept len: 3.00, cuda graph: True, gen throughput (token/s): 881.79, #queue-req: 0, 
[2025-09-13 06:37:41 TP0] Decode batch. #running-req: 8, #token: 17267, token usage: 0.03, accept len: 2.88, cuda graph: True, gen throughput (token/s): 850.84, #queue-req: 0, 
 62%|█████████████████████████████████████████████████████████████████████████████████▉                                                 | 5/8 [00:05<00:01,  1.62it/s][2025-09-13 06:37:42 TP0] Decode batch. #running-req: 3, #token: 2175, token usage: 0.00, accept len: 3.06, cuda graph: True, gen throughput (token/s): 716.39, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.39it/s]
[2025-09-13 06:37:42] INFO:     127.0.0.1:58704 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  5.76      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4081      
Request throughput (req/s):              1.39      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         710.84    
Total token throughput (tok/s):          710.84    
Concurrency:                             7.48      
Accept length:                           2.89      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5391.13   
Median E2E Latency (ms):                 5457.77   
---------------Time to First Token----------------
Mean TTFT (ms):                          600.22    
Median TTFT (ms):                        712.48    
P99 TTFT (ms):                           713.12    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.38      
Median ITL (ms):                         6.85      
P95 ITL (ms):                            25.17     
P99 ITL (ms):                            27.34     
Max ITL (ms):                            633.20    
==================================================
[2025-09-13 06:37:42] INFO:     127.0.0.1:58718 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:37:42] INFO:     127.0.0.1:58720 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 06:37:44] INFO:     127.0.0.1:58724 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:44] INFO:     127.0.0.1:58738 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:37:44] INFO:     127.0.0.1:58748 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:44] INFO:     127.0.0.1:58756 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:44] INFO:     127.0.0.1:58758 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:44] INFO:     127.0.0.1:58774 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:44] INFO:     127.0.0.1:58788 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:44] INFO:     127.0.0.1:58798 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:44 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 06:37:44 TP0] Decode batch. #running-req: 8, #token: 14347, token usage: 0.02, accept len: 2.56, cuda graph: True, gen throughput (token/s): 214.92, #queue-req: 0, 
[2025-09-13 06:37:46 TP0] Decode batch. #running-req: 8, #token: 15277, token usage: 0.02, accept len: 2.91, cuda graph: True, gen throughput (token/s): 860.50, #queue-req: 0, 
[2025-09-13 06:37:47 TP0] Decode batch. #running-req: 8, #token: 16229, token usage: 0.03, accept len: 2.98, cuda graph: True, gen throughput (token/s): 874.06, #queue-req: 0, 
[2025-09-13 06:37:48 TP0] Decode batch. #running-req: 8, #token: 17143, token usage: 0.03, accept len: 2.86, cuda graph: True, gen throughput (token/s): 846.51, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:05,  4.34s/it][2025-09-13 06:37:48] INFO:     127.0.0.1:40020 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:48 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:28,  2.02s/it][2025-09-13 06:37:48] INFO:     127.0.0.1:40032 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:48 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:16,  1.31s/it][2025-09-13 06:37:49] INFO:     127.0.0.1:40042 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:49 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.16it/s][2025-09-13 06:37:49] INFO:     127.0.0.1:40046 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:49 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:37:49 TP0] Decode batch. #running-req: 8, #token: 13630, token usage: 0.02, accept len: 3.03, cuda graph: True, gen throughput (token/s): 590.07, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:07,  1.49it/s][2025-09-13 06:37:49] INFO:     127.0.0.1:40056 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:49 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.85it/s][2025-09-13 06:37:50] INFO:     127.0.0.1:40068 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:50 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:04,  2.21it/s][2025-09-13 06:37:50] INFO:     127.0.0.1:40082 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:50] INFO:     127.0.0.1:40096 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:37:50 TP0] Prefill batch. #new-seq: 2, #new-token: 6010, #cached-token: 1737, token usage: 0.01, #running-req: 6, #queue-req: 0, 
[2025-09-13 06:37:51 TP0] Decode batch. #running-req: 8, #token: 14399, token usage: 0.02, accept len: 2.65, cuda graph: True, gen throughput (token/s): 496.11, #queue-req: 0, 
[2025-09-13 06:37:52 TP0] Decode batch. #running-req: 8, #token: 15313, token usage: 0.02, accept len: 2.86, cuda graph: True, gen throughput (token/s): 840.39, #queue-req: 0, 
[2025-09-13 06:37:53 TP0] Decode batch. #running-req: 8, #token: 16343, token usage: 0.03, accept len: 3.22, cuda graph: True, gen throughput (token/s): 940.27, #queue-req: 0, 
 56%|█████████████████████████████████████████████████████████████████████████▏                                                        | 9/16 [00:09<00:07,  1.08s/it][2025-09-13 06:37:54 TP0] Decode batch. #running-req: 7, #token: 14783, token usage: 0.02, accept len: 3.27, cuda graph: True, gen throughput (token/s): 914.69, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.42it/s]
[2025-09-13 06:37:55] INFO:     127.0.0.1:40112 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.28     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8140      
Request throughput (req/s):              1.42      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         726.50    
Total token throughput (tok/s):          726.50    
Concurrency:                             7.59      
Accept length:                           2.92      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5351.34   
Median E2E Latency (ms):                 5213.68   
---------------Time to First Token----------------
Mean TTFT (ms):                          236.48    
Median TTFT (ms):                        281.25    
P99 TTFT (ms):                           339.22    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.01     
Median ITL (ms):                         6.85      
P95 ITL (ms):                            26.91     
P99 ITL (ms):                            41.91     
Max ITL (ms):                            340.72    
==================================================
[2025-09-13 06:37:55] INFO:     127.0.0.1:40128 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=0: batch_size=8, steps=3, topk=1, num_draft_tokens=4, speed=108.10 token/s, step_time=27.04 ms
Start i=1: batch_size=8, steps=3, topk=2, num_draft_tokens=4
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 3 --speculative-eagle-topk 2 --speculative-num-draft-tokens 4 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:38:06.332000 130049 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:38:06.332000 130049 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 06:38:06] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=128866420, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=3, speculative_eagle_topk=2, speculative_num_draft_tokens=4, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:38:07] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:38:15.400000 130268 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:38:15.400000 130268 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:38:15.635000 130265 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:38:15.635000 130265 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:38:15.693000 130263 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:38:15.693000 130263 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:38:15.764000 130261 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:38:15.764000 130261 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:38:15.789000 130267 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:38:15.789000 130267 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:38:15.938000 130262 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:38:15.938000 130262 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:38:15.958000 130264 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:38:15.958000 130264 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 06:38:16.083000 130260 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:38:16.083000 130260 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:38:16.167000 130266 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:38:16.167000 130266 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:38:16 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 06:38:16 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:38:16 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:38:18 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:38:21 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 06:38:22 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 06:38:22 TP0] Detected fp8 checkpoint.
[2025-09-13 06:38:22 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:04, 238.18it/s]
Loading safetensors checkpoint shards:   5% Completed | 50/1024 [00:00<00:17, 56.47it/s]
Loading safetensors checkpoint shards:   6% Completed | 62/1024 [00:01<00:19, 48.57it/s]
Loading safetensors checkpoint shards:   7% Completed | 71/1024 [00:01<00:20, 46.10it/s]
Loading safetensors checkpoint shards:   8% Completed | 78/1024 [00:01<00:22, 42.77it/s]
Loading safetensors checkpoint shards:   8% Completed | 84/1024 [00:01<00:21, 42.77it/s]
Loading safetensors checkpoint shards:   9% Completed | 89/1024 [00:01<00:22, 40.79it/s]
Loading safetensors checkpoint shards:   9% Completed | 94/1024 [00:01<00:23, 38.78it/s]
Loading safetensors checkpoint shards:  10% Completed | 99/1024 [00:02<00:23, 38.98it/s]
Loading safetensors checkpoint shards:  10% Completed | 104/1024 [00:02<00:22, 40.84it/s]
Loading safetensors checkpoint shards:  11% Completed | 109/1024 [00:02<00:22, 39.90it/s]
Loading safetensors checkpoint shards:  11% Completed | 114/1024 [00:02<00:22, 39.96it/s]
Loading safetensors checkpoint shards:  12% Completed | 119/1024 [00:02<00:21, 41.37it/s]
Loading safetensors checkpoint shards:  12% Completed | 124/1024 [00:03<00:39, 22.86it/s]
Loading safetensors checkpoint shards:  13% Completed | 129/1024 [00:03<00:33, 26.97it/s]
Loading safetensors checkpoint shards:  13% Completed | 133/1024 [00:03<00:31, 28.07it/s]
Loading safetensors checkpoint shards:  14% Completed | 139/1024 [00:03<00:26, 32.88it/s]
Loading safetensors checkpoint shards:  14% Completed | 143/1024 [00:03<00:25, 34.00it/s]
Loading safetensors checkpoint shards:  14% Completed | 147/1024 [00:03<00:25, 34.77it/s]
Loading safetensors checkpoint shards:  15% Completed | 152/1024 [00:03<00:23, 37.21it/s]
Loading safetensors checkpoint shards:  15% Completed | 157/1024 [00:03<00:21, 40.09it/s]
Loading safetensors checkpoint shards:  16% Completed | 162/1024 [00:03<00:21, 39.54it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:04<00:22, 38.40it/s]
Loading safetensors checkpoint shards:  17% Completed | 172/1024 [00:04<00:21, 40.39it/s]
Loading safetensors checkpoint shards:  17% Completed | 177/1024 [00:04<00:20, 40.40it/s]
Loading safetensors checkpoint shards:  18% Completed | 182/1024 [00:04<00:20, 40.85it/s]
Loading safetensors checkpoint shards:  18% Completed | 187/1024 [00:04<00:21, 39.84it/s]
Loading safetensors checkpoint shards:  19% Completed | 192/1024 [00:04<00:20, 39.76it/s]
Loading safetensors checkpoint shards:  19% Completed | 197/1024 [00:04<00:20, 41.15it/s]
Loading safetensors checkpoint shards:  20% Completed | 202/1024 [00:04<00:20, 40.61it/s]
Loading safetensors checkpoint shards:  20% Completed | 207/1024 [00:05<00:20, 40.42it/s]
Loading safetensors checkpoint shards:  21% Completed | 212/1024 [00:05<00:20, 39.79it/s]
Loading safetensors checkpoint shards:  21% Completed | 217/1024 [00:05<00:19, 41.49it/s]
Loading safetensors checkpoint shards:  22% Completed | 222/1024 [00:05<00:20, 39.62it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:05<00:20, 39.37it/s]
Loading safetensors checkpoint shards:  23% Completed | 231/1024 [00:05<00:20, 38.32it/s]
Loading safetensors checkpoint shards:  23% Completed | 235/1024 [00:05<00:21, 36.82it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:05<00:20, 38.88it/s]
Loading safetensors checkpoint shards:  24% Completed | 244/1024 [00:06<00:20, 39.00it/s]
Loading safetensors checkpoint shards:  24% Completed | 250/1024 [00:06<00:17, 44.67it/s]
Loading safetensors checkpoint shards:  25% Completed | 255/1024 [00:06<00:18, 42.48it/s]
Loading safetensors checkpoint shards:  26% Completed | 262/1024 [00:06<00:15, 47.77it/s]
Loading safetensors checkpoint shards:  26% Completed | 267/1024 [00:06<00:15, 48.30it/s]
Loading safetensors checkpoint shards:  27% Completed | 272/1024 [00:06<00:15, 48.04it/s]
Loading safetensors checkpoint shards:  27% Completed | 277/1024 [00:06<00:16, 46.06it/s]
Loading safetensors checkpoint shards:  28% Completed | 283/1024 [00:06<00:14, 49.45it/s]
Loading safetensors checkpoint shards:  28% Completed | 288/1024 [00:06<00:14, 49.40it/s]
Loading safetensors checkpoint shards:  29% Completed | 294/1024 [00:07<00:14, 49.66it/s]
Loading safetensors checkpoint shards:  29% Completed | 299/1024 [00:07<00:14, 48.64it/s]
Loading safetensors checkpoint shards:  30% Completed | 305/1024 [00:07<00:14, 50.13it/s]
Loading safetensors checkpoint shards:  30% Completed | 311/1024 [00:07<00:30, 23.13it/s]
Loading safetensors checkpoint shards:  31% Completed | 315/1024 [00:07<00:27, 25.52it/s]
Loading safetensors checkpoint shards:  31% Completed | 321/1024 [00:08<00:23, 29.78it/s]
Loading safetensors checkpoint shards:  32% Completed | 328/1024 [00:08<00:19, 36.09it/s]
Loading safetensors checkpoint shards:  33% Completed | 334/1024 [00:08<00:17, 38.74it/s]
Loading safetensors checkpoint shards:  33% Completed | 340/1024 [00:08<00:15, 42.87it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:08<00:14, 45.63it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:08<00:12, 52.53it/s]
Loading safetensors checkpoint shards:  35% Completed | 361/1024 [00:08<00:12, 55.17it/s]
Loading safetensors checkpoint shards:  36% Completed | 367/1024 [00:08<00:12, 51.08it/s]
Loading safetensors checkpoint shards:  37% Completed | 374/1024 [00:09<00:12, 52.34it/s]
Loading safetensors checkpoint shards:  37% Completed | 380/1024 [00:09<00:13, 48.92it/s]
Loading safetensors checkpoint shards:  38% Completed | 386/1024 [00:09<00:12, 50.25it/s]
Loading safetensors checkpoint shards:  38% Completed | 392/1024 [00:09<00:12, 50.09it/s]
Loading safetensors checkpoint shards:  39% Completed | 398/1024 [00:09<00:12, 51.43it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:09<00:10, 58.66it/s]
Loading safetensors checkpoint shards:  40% Completed | 413/1024 [00:09<00:10, 60.34it/s]
Loading safetensors checkpoint shards:  41% Completed | 420/1024 [00:09<00:09, 62.61it/s]
Loading safetensors checkpoint shards:  42% Completed | 427/1024 [00:09<00:09, 63.02it/s]
Loading safetensors checkpoint shards:  42% Completed | 434/1024 [00:10<00:09, 63.71it/s]
Loading safetensors checkpoint shards:  43% Completed | 441/1024 [00:10<00:08, 65.10it/s]
Loading safetensors checkpoint shards:  44% Completed | 449/1024 [00:10<00:08, 68.38it/s]
Loading safetensors checkpoint shards:  45% Completed | 456/1024 [00:10<00:08, 64.93it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:10<00:09, 61.89it/s]
Loading safetensors checkpoint shards:  46% Completed | 472/1024 [00:10<00:08, 66.80it/s]
Loading safetensors checkpoint shards:  47% Completed | 480/1024 [00:11<00:17, 31.90it/s]
Loading safetensors checkpoint shards:  48% Completed | 487/1024 [00:11<00:14, 36.76it/s]
Loading safetensors checkpoint shards:  48% Completed | 493/1024 [00:11<00:13, 40.53it/s]
Loading safetensors checkpoint shards:  49% Completed | 500/1024 [00:11<00:11, 44.92it/s]
Loading safetensors checkpoint shards:  49% Completed | 506/1024 [00:11<00:10, 47.89it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:11<00:09, 52.94it/s]
Loading safetensors checkpoint shards:  51% Completed | 520/1024 [00:11<00:09, 55.42it/s]
Loading safetensors checkpoint shards:  51% Completed | 527/1024 [00:11<00:08, 57.08it/s]
Loading safetensors checkpoint shards:  52% Completed | 534/1024 [00:12<00:08, 57.89it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:12<00:08, 59.40it/s]
Loading safetensors checkpoint shards:  54% Completed | 549/1024 [00:12<00:07, 63.80it/s]
Loading safetensors checkpoint shards:  54% Completed | 556/1024 [00:12<00:07, 63.27it/s]
Loading safetensors checkpoint shards:  55% Completed | 563/1024 [00:12<00:07, 63.38it/s]
Loading safetensors checkpoint shards:  56% Completed | 570/1024 [00:12<00:07, 64.07it/s]
Loading safetensors checkpoint shards:  56% Completed | 577/1024 [00:12<00:07, 56.62it/s]
Loading safetensors checkpoint shards:  57% Completed | 583/1024 [00:12<00:07, 56.94it/s]
Loading safetensors checkpoint shards:  58% Completed | 589/1024 [00:12<00:08, 53.65it/s]
Loading safetensors checkpoint shards:  58% Completed | 595/1024 [00:13<00:08, 48.23it/s]
Loading safetensors checkpoint shards:  59% Completed | 600/1024 [00:13<00:09, 45.86it/s]
Loading safetensors checkpoint shards:  59% Completed | 605/1024 [00:13<00:09, 44.77it/s]
Loading safetensors checkpoint shards:  60% Completed | 610/1024 [00:13<00:11, 37.53it/s]
Loading safetensors checkpoint shards:  60% Completed | 614/1024 [00:13<00:11, 36.67it/s]
Loading safetensors checkpoint shards:  60% Completed | 618/1024 [00:13<00:10, 36.92it/s]
Loading safetensors checkpoint shards:  61% Completed | 622/1024 [00:13<00:12, 33.36it/s]
Loading safetensors checkpoint shards:  61% Completed | 626/1024 [00:14<00:12, 32.32it/s]
Loading safetensors checkpoint shards:  62% Completed | 630/1024 [00:14<00:13, 29.76it/s]
Loading safetensors checkpoint shards:  62% Completed | 634/1024 [00:14<00:12, 30.80it/s]
Loading safetensors checkpoint shards:  62% Completed | 638/1024 [00:14<00:13, 29.54it/s]
Loading safetensors checkpoint shards:  63% Completed | 643/1024 [00:14<00:11, 33.93it/s]
Loading safetensors checkpoint shards:  63% Completed | 647/1024 [00:14<00:11, 31.95it/s]
Loading safetensors checkpoint shards:  64% Completed | 651/1024 [00:14<00:11, 33.25it/s]
Loading safetensors checkpoint shards:  64% Completed | 655/1024 [00:14<00:11, 33.24it/s]
Loading safetensors checkpoint shards:  64% Completed | 660/1024 [00:15<00:10, 35.15it/s]
Loading safetensors checkpoint shards:  65% Completed | 664/1024 [00:15<00:10, 34.14it/s]
Loading safetensors checkpoint shards:  65% Completed | 669/1024 [00:15<00:09, 36.51it/s]
Loading safetensors checkpoint shards:  66% Completed | 673/1024 [00:15<00:10, 32.68it/s]
Loading safetensors checkpoint shards:  66% Completed | 678/1024 [00:15<00:10, 34.41it/s]
Loading safetensors checkpoint shards:  67% Completed | 682/1024 [00:16<00:21, 15.79it/s]
Loading safetensors checkpoint shards:  67% Completed | 685/1024 [00:16<00:19, 17.01it/s]
Loading safetensors checkpoint shards:  67% Completed | 688/1024 [00:16<00:18, 17.70it/s]
Loading safetensors checkpoint shards:  67% Completed | 691/1024 [00:16<00:19, 17.45it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:16<00:17, 18.84it/s]
Loading safetensors checkpoint shards:  68% Completed | 697/1024 [00:17<00:18, 17.86it/s]
Loading safetensors checkpoint shards:  68% Completed | 700/1024 [00:17<00:17, 18.17it/s]
Loading safetensors checkpoint shards:  69% Completed | 703/1024 [00:17<00:15, 20.25it/s]
Loading safetensors checkpoint shards:  69% Completed | 708/1024 [00:17<00:12, 25.76it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:17<00:09, 32.80it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:17<00:08, 36.81it/s]
Loading safetensors checkpoint shards:  71% Completed | 724/1024 [00:17<00:07, 39.01it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:17<00:07, 39.80it/s]
Loading safetensors checkpoint shards:  72% Completed | 734/1024 [00:17<00:07, 37.46it/s]
Loading safetensors checkpoint shards:  72% Completed | 738/1024 [00:18<00:07, 37.32it/s]
Loading safetensors checkpoint shards:  72% Completed | 742/1024 [00:18<00:08, 34.39it/s]
Loading safetensors checkpoint shards:  73% Completed | 746/1024 [00:18<00:08, 32.99it/s]
Loading safetensors checkpoint shards:  73% Completed | 751/1024 [00:18<00:07, 35.36it/s]
Loading safetensors checkpoint shards:  74% Completed | 756/1024 [00:18<00:06, 38.98it/s]
Loading safetensors checkpoint shards:  74% Completed | 761/1024 [00:18<00:06, 40.19it/s]
Loading safetensors checkpoint shards:  75% Completed | 766/1024 [00:18<00:06, 39.38it/s]
Loading safetensors checkpoint shards:  75% Completed | 771/1024 [00:18<00:06, 38.87it/s]
Loading safetensors checkpoint shards:  76% Completed | 775/1024 [00:19<00:07, 35.45it/s]
Loading safetensors checkpoint shards:  76% Completed | 779/1024 [00:19<00:07, 31.33it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:19<00:09, 26.17it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:19<00:09, 26.17it/s]
Loading safetensors checkpoint shards:  77% Completed | 791/1024 [00:19<00:08, 27.76it/s]
Loading safetensors checkpoint shards:  78% Completed | 796/1024 [00:19<00:07, 32.09it/s]
Loading safetensors checkpoint shards:  78% Completed | 801/1024 [00:19<00:06, 36.31it/s]
Loading safetensors checkpoint shards:  79% Completed | 806/1024 [00:20<00:05, 38.89it/s]
Loading safetensors checkpoint shards:  79% Completed | 811/1024 [00:20<00:05, 39.53it/s]
Loading safetensors checkpoint shards:  80% Completed | 816/1024 [00:20<00:05, 38.25it/s]
Loading safetensors checkpoint shards:  80% Completed | 820/1024 [00:20<00:05, 35.64it/s]
Loading safetensors checkpoint shards:  80% Completed | 824/1024 [00:20<00:06, 32.54it/s]
Loading safetensors checkpoint shards:  81% Completed | 828/1024 [00:20<00:05, 32.92it/s]
Loading safetensors checkpoint shards:  81% Completed | 832/1024 [00:20<00:05, 33.82it/s]
Loading safetensors checkpoint shards:  82% Completed | 837/1024 [00:20<00:05, 36.65it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:21<00:04, 38.39it/s]
Loading safetensors checkpoint shards:  83% Completed | 846/1024 [00:21<00:04, 38.67it/s]
Loading safetensors checkpoint shards:  83% Completed | 851/1024 [00:21<00:04, 39.17it/s]
Loading safetensors checkpoint shards:  83% Completed | 855/1024 [00:21<00:04, 39.14it/s]
Loading safetensors checkpoint shards:  84% Completed | 860/1024 [00:21<00:03, 41.57it/s]
Loading safetensors checkpoint shards:  84% Completed | 865/1024 [00:21<00:03, 42.82it/s]
Loading safetensors checkpoint shards:  85% Completed | 870/1024 [00:21<00:03, 41.94it/s]
Loading safetensors checkpoint shards:  85% Completed | 875/1024 [00:21<00:03, 43.39it/s]
Loading safetensors checkpoint shards:  86% Completed | 880/1024 [00:21<00:03, 43.29it/s]
Loading safetensors checkpoint shards:  86% Completed | 885/1024 [00:22<00:03, 41.70it/s]
Loading safetensors checkpoint shards:  87% Completed | 890/1024 [00:22<00:03, 37.49it/s]
Loading safetensors checkpoint shards:  87% Completed | 894/1024 [00:22<00:03, 36.56it/s]
Loading safetensors checkpoint shards:  88% Completed | 898/1024 [00:22<00:03, 35.46it/s]
Loading safetensors checkpoint shards:  88% Completed | 902/1024 [00:22<00:03, 30.53it/s]
Loading safetensors checkpoint shards:  88% Completed | 906/1024 [00:22<00:04, 23.68it/s]
Loading safetensors checkpoint shards:  89% Completed | 909/1024 [00:23<00:04, 23.66it/s]
Loading safetensors checkpoint shards:  89% Completed | 913/1024 [00:23<00:04, 25.24it/s]
Loading safetensors checkpoint shards:  89% Completed | 916/1024 [00:23<00:09, 11.73it/s]
Loading safetensors checkpoint shards:  90% Completed | 920/1024 [00:23<00:06, 15.03it/s]
Loading safetensors checkpoint shards:  90% Completed | 925/1024 [00:24<00:05, 19.62it/s]
Loading safetensors checkpoint shards:  91% Completed | 930/1024 [00:24<00:03, 23.75it/s]
Loading safetensors checkpoint shards:  91% Completed | 936/1024 [00:24<00:03, 29.09it/s]
Loading safetensors checkpoint shards:  92% Completed | 941/1024 [00:24<00:02, 32.33it/s]
Loading safetensors checkpoint shards:  92% Completed | 945/1024 [00:24<00:02, 34.02it/s]
Loading safetensors checkpoint shards:  93% Completed | 950/1024 [00:24<00:01, 37.29it/s]
Loading safetensors checkpoint shards:  93% Completed | 956/1024 [00:24<00:01, 42.79it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:24<00:01, 42.40it/s]
Loading safetensors checkpoint shards:  94% Completed | 966/1024 [00:25<00:01, 41.72it/s]
Loading safetensors checkpoint shards:  95% Completed | 971/1024 [00:25<00:01, 41.45it/s]
Loading safetensors checkpoint shards:  95% Completed | 976/1024 [00:25<00:01, 38.27it/s]
Loading safetensors checkpoint shards:  96% Completed | 980/1024 [00:25<00:01, 35.18it/s]
Loading safetensors checkpoint shards:  96% Completed | 986/1024 [00:25<00:00, 39.67it/s]
Loading safetensors checkpoint shards:  97% Completed | 993/1024 [00:25<00:00, 46.01it/s]
Loading safetensors checkpoint shards:  98% Completed | 1003/1024 [00:25<00:00, 57.03it/s]
Loading safetensors checkpoint shards:  99% Completed | 1014/1024 [00:25<00:00, 65.70it/s]
Loading safetensors checkpoint shards: 100% Completed | 1022/1024 [00:26<00:00, 68.38it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:26<00:00, 39.30it/s]

[2025-09-13 06:38:50 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 06:38:50 TP0] KV Cache is allocated. #tokens: 620137, KV size: 40.59 GB
[2025-09-13 06:38:50 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 06:38:50 TP6] KV Cache is allocated. #tokens: 620137, KV size: 40.59 GB
[2025-09-13 06:38:50 TP2] KV Cache is allocated. #tokens: 620137, KV size: 40.59 GB
[2025-09-13 06:38:50 TP4] KV Cache is allocated. #tokens: 620137, KV size: 40.59 GB
[2025-09-13 06:38:50 TP1] KV Cache is allocated. #tokens: 620137, KV size: 40.59 GB
[2025-09-13 06:38:50 TP7] KV Cache is allocated. #tokens: 620137, KV size: 40.59 GB
[2025-09-13 06:38:50 TP3] KV Cache is allocated. #tokens: 620137, KV size: 40.59 GB
[2025-09-13 06:38:50 TP5] KV Cache is allocated. #tokens: 620137, KV size: 40.59 GB
[2025-09-13 06:38:50 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 06:38:51 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.53 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 06:38:52 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:38:52 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 06:38:52 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:38:52 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:38:52 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:38:52 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:38:52 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:38:52 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:38:52 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26386.97it/s]
[2025-09-13 06:38:52 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:38:52 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27436.32it/s]
[2025-09-13 06:38:53 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:38:53 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 29072.20it/s]
[2025-09-13 06:38:53 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:38:53 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28418.68it/s]
[2025-09-13 06:38:54 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:38:54 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 29046.08it/s]
[2025-09-13 06:38:55 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.22 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.13it/s]
[2025-09-13 06:38:58 TP5] Registering 984 cuda graph addresses
[2025-09-13 06:38:58 TP0] Registering 984 cuda graph addresses
[2025-09-13 06:38:58 TP2] Registering 984 cuda graph addresses
[2025-09-13 06:38:58 TP4] Registering 984 cuda graph addresses
[2025-09-13 06:38:58 TP7] Registering 984 cuda graph addresses
[2025-09-13 06:38:58 TP3] Registering 984 cuda graph addresses
[2025-09-13 06:38:58 TP6] Registering 984 cuda graph addresses
[2025-09-13 06:38:58 TP1] Registering 984 cuda graph addresses
[2025-09-13 06:38:58 TP0] Capture cuda graph end. Time elapsed: 7.82 s. mem usage=0.36 GB. avail mem=17.20 GB.
[2025-09-13 06:38:58 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 06:38:58 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:38:58 TP0] Init torch distributed begin.
[2025-09-13 06:38:58 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 06:38:58 TP0] Load weight begin. avail mem=17.20 GB
[2025-09-13 06:38:58 TP0] Detected fp8 checkpoint.
[2025-09-13 06:38:58 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 173.17it/s]
Loading safetensors checkpoint shards:   4% Completed | 45/1024 [00:00<00:04, 227.75it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:00<00:02, 402.66it/s]
Loading safetensors checkpoint shards:  17% Completed | 169/1024 [00:00<00:01, 484.83it/s]
Loading safetensors checkpoint shards:  23% Completed | 231/1024 [00:00<00:01, 530.61it/s]
Loading safetensors checkpoint shards:  29% Completed | 294/1024 [00:00<00:01, 561.07it/s]
Loading safetensors checkpoint shards:  35% Completed | 355/1024 [00:00<00:01, 576.06it/s]
Loading safetensors checkpoint shards:  41% Completed | 418/1024 [00:00<00:01, 592.13it/s]
Loading safetensors checkpoint shards:  47% Completed | 480/1024 [00:00<00:00, 600.09it/s]
Loading safetensors checkpoint shards:  53% Completed | 542/1024 [00:01<00:00, 605.95it/s]
Loading safetensors checkpoint shards:  59% Completed | 605/1024 [00:01<00:00, 611.92it/s]
Loading safetensors checkpoint shards:  65% Completed | 667/1024 [00:01<00:00, 601.04it/s]
Loading safetensors checkpoint shards:  71% Completed | 728/1024 [00:01<00:00, 592.07it/s]
Loading safetensors checkpoint shards:  77% Completed | 788/1024 [00:01<00:00, 585.89it/s]
Loading safetensors checkpoint shards:  83% Completed | 847/1024 [00:01<00:00, 583.44it/s]
Loading safetensors checkpoint shards:  88% Completed | 906/1024 [00:01<00:00, 579.52it/s]
Loading safetensors checkpoint shards:  94% Completed | 964/1024 [00:01<00:00, 578.39it/s]
Loading safetensors checkpoint shards: 100% Completed | 1022/1024 [00:02<00:00, 391.58it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 511.08it/s]

[2025-09-13 06:39:01 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.21 GB, mem usage=1.99 GB.
[2025-09-13 06:39:01 TP0] KV Cache is allocated. #tokens: 620137, KV size: 0.67 GB
[2025-09-13 06:39:01 TP0] Memory pool end. avail mem=14.54 GB
[2025-09-13 06:39:01 TP3] KV Cache is allocated. #tokens: 620137, KV size: 0.67 GB
[2025-09-13 06:39:01 TP2] KV Cache is allocated. #tokens: 620137, KV size: 0.67 GB
[2025-09-13 06:39:01 TP4] KV Cache is allocated. #tokens: 620137, KV size: 0.67 GB
[2025-09-13 06:39:01 TP7] KV Cache is allocated. #tokens: 620137, KV size: 0.67 GB
[2025-09-13 06:39:01 TP5] KV Cache is allocated. #tokens: 620137, KV size: 0.67 GB
[2025-09-13 06:39:01 TP6] KV Cache is allocated. #tokens: 620137, KV size: 0.67 GB
[2025-09-13 06:39:01 TP1] KV Cache is allocated. #tokens: 620137, KV size: 0.67 GB
[2025-09-13 06:39:01 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:39:01 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:39:01 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:39:01 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:39:01 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 06:39:01 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.17 GB
[2025-09-13 06:39:01 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:39:01 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
Capturing batches (bs=1 avail_mem=14.72 GB):  62%|█████████████████████████████████████████████████████▊                                | 5/8 [00:03<00:01,  2.43it/s][2025-09-13 06:39:07 TP3] Registering 48 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.72 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.52it/s]
[2025-09-13 06:39:07 TP0] Registering 48 cuda graph addresses
[2025-09-13 06:39:07 TP2] Registering 48 cuda graph addresses
[2025-09-13 06:39:07 TP4] Registering 48 cuda graph addresses
[2025-09-13 06:39:07 TP6] Registering 48 cuda graph addresses
[2025-09-13 06:39:07 TP1] Registering 48 cuda graph addresses
[2025-09-13 06:39:07 TP7] Registering 48 cuda graph addresses
[2025-09-13 06:39:07 TP5] Registering 48 cuda graph addresses
[2025-09-13 06:39:07 TP2] Capture draft cuda graph end. Time elapsed: 6.00 s. mem usage=0.26 GB. avail mem=14.67 GB.
[2025-09-13 06:39:07 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.67 GB
[2025-09-13 06:39:07 TP7] Capture draft cuda graph end. Time elapsed: 5.96 s. mem usage=0.26 GB. avail mem=14.91 GB.
[2025-09-13 06:39:07 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 06:39:07 TP6] Capture draft cuda graph end. Time elapsed: 6.00 s. mem usage=0.26 GB. avail mem=14.67 GB.
[2025-09-13 06:39:07 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.67 GB
[2025-09-13 06:39:07 TP4] Capture draft cuda graph end. Time elapsed: 6.00 s. mem usage=0.26 GB. avail mem=14.67 GB.
[2025-09-13 06:39:07 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.67 GB
[2025-09-13 06:39:07 TP0] Capture draft cuda graph end. Time elapsed: 5.96 s. mem usage=0.26 GB. avail mem=14.71 GB.
[2025-09-13 06:39:07 TP5] Capture draft cuda graph end. Time elapsed: 5.95 s. mem usage=0.26 GB. avail mem=14.67 GB.
[2025-09-13 06:39:07 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.67 GB
[2025-09-13 06:39:07 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.71 GB
[2025-09-13 06:39:07 TP1] Capture draft cuda graph end. Time elapsed: 5.96 s. mem usage=0.26 GB. avail mem=14.67 GB.
[2025-09-13 06:39:07 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.67 GB
[2025-09-13 06:39:07 TP3] Capture draft cuda graph end. Time elapsed: 5.95 s. mem usage=0.26 GB. avail mem=14.67 GB.
[2025-09-13 06:39:07 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.67 GB
Capturing batches (bs=1 avail_mem=14.53 GB):  25%|█████████████████████▌                                                                | 2/8 [00:00<00:00, 18.42it/s][2025-09-13 06:39:08 TP6] Registering 24 cuda graph addresses
[2025-09-13 06:39:08 TP1] Registering 24 cuda graph addresses
[2025-09-13 06:39:08 TP4] Registering 24 cuda graph addresses
[2025-09-13 06:39:08 TP5] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.53 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 41.83it/s][2025-09-13 06:39:08 TP2] Registering 24 cuda graph addresses
[2025-09-13 06:39:08 TP7] Registering 24 cuda graph addresses
[2025-09-13 06:39:08 TP3] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.53 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 38.17it/s]
[2025-09-13 06:39:08 TP0] Registering 24 cuda graph addresses
[2025-09-13 06:39:08 TP1] Capture draft extend cuda graph end. Time elapsed: 1.00 s. mem usage=0.19 GB. avail mem=14.48 GB.
[2025-09-13 06:39:08 TP3] Capture draft extend cuda graph end. Time elapsed: 1.01 s. mem usage=0.19 GB. avail mem=14.48 GB.
[2025-09-13 06:39:08 TP6] Capture draft extend cuda graph end. Time elapsed: 1.01 s. mem usage=0.19 GB. avail mem=14.48 GB.
[2025-09-13 06:39:08 TP4] Capture draft extend cuda graph end. Time elapsed: 1.01 s. mem usage=0.19 GB. avail mem=14.48 GB.
[2025-09-13 06:39:08 TP2] Capture draft extend cuda graph end. Time elapsed: 1.01 s. mem usage=0.19 GB. avail mem=14.48 GB.
[2025-09-13 06:39:08 TP0] Capture draft extend cuda graph end. Time elapsed: 1.01 s. mem usage=0.19 GB. avail mem=14.52 GB.
[2025-09-13 06:39:08 TP5] Capture draft extend cuda graph end. Time elapsed: 1.01 s. mem usage=0.19 GB. avail mem=14.48 GB.
[2025-09-13 06:39:08 TP7] Capture draft extend cuda graph end. Time elapsed: 1.01 s. mem usage=0.19 GB. avail mem=14.72 GB.
[2025-09-13 06:39:08 TP0] max_total_num_tokens=620137, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.52 GB
[2025-09-13 06:39:09] INFO:     Started server process [130049]
[2025-09-13 06:39:09] INFO:     Waiting for application startup.
[2025-09-13 06:39:09] INFO:     Application startup complete.
[2025-09-13 06:39:09] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 06:39:10] INFO:     127.0.0.1:60052 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 06:39:10 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:39:10 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:39:10 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup:  88%|██████████████████████████████████████████████████████████████████████████████████████████▍            | 14378/16384 [00:00<00:00, 30249.87it/s][2025-09-13 06:39:10] INFO:     127.0.0.1:60070 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 29148.46it/s]
[2025-09-13 06:39:11] INFO:     127.0.0.1:60064 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:11] The server is fired up and ready to roll!
[2025-09-13 06:39:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:39:21] INFO:     127.0.0.1:46586 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:39:21] INFO:     127.0.0.1:46596 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:21 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 06:39:23] INFO:     127.0.0.1:46604 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:23] INFO:     127.0.0.1:46612 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:39:23] INFO:     127.0.0.1:46626 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:23] INFO:     127.0.0.1:46642 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:23] INFO:     127.0.0.1:46644 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:23] INFO:     127.0.0.1:46660 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:23] INFO:     127.0.0.1:46674 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:23] INFO:     127.0.0.1:46676 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:23 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 06:39:24 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:39:24 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:39:24 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:39:24 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:39:24 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:39:24 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:39:24 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:39:24 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:39:24 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 06:39:24 TP0] Decode batch. #running-req: 8, #token: 14458, token usage: 0.02, accept len: 2.58, cuda graph: True, gen throughput (token/s): 34.95, #queue-req: 0, 
[2025-09-13 06:39:26 TP0] Decode batch. #running-req: 8, #token: 15391, token usage: 0.02, accept len: 2.92, cuda graph: True, gen throughput (token/s): 815.89, #queue-req: 0, 
[2025-09-13 06:39:27 TP0] Decode batch. #running-req: 8, #token: 16396, token usage: 0.03, accept len: 3.14, cuda graph: True, gen throughput (token/s): 871.59, #queue-req: 0, 
[2025-09-13 06:39:28 TP0] Decode batch. #running-req: 8, #token: 17393, token usage: 0.03, accept len: 3.12, cuda graph: True, gen throughput (token/s): 863.55, #queue-req: 0, 
 62%|█████████████████████████████████████████████████████████████████████████████████▉                                                 | 5/8 [00:05<00:01,  1.51it/s][2025-09-13 06:39:29 TP0] Decode batch. #running-req: 1, #token: 1490, token usage: 0.00, accept len: 3.11, cuda graph: True, gen throughput (token/s): 611.90, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.33it/s]
[2025-09-13 06:39:29] INFO:     127.0.0.1:36264 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.01      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4075      
Request throughput (req/s):              1.33      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         681.86    
Total token throughput (tok/s):          681.86    
Concurrency:                             7.35      
Accept length:                           2.99      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5520.44   
Median E2E Latency (ms):                 5571.39   
---------------Time to First Token----------------
Mean TTFT (ms):                          624.10    
Median TTFT (ms):                        735.95    
P99 TTFT (ms):                           736.48    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.58      
Median ITL (ms):                         7.23      
P95 ITL (ms):                            14.85     
P99 ITL (ms):                            28.91     
Max ITL (ms):                            630.72    
==================================================
[2025-09-13 06:39:29] INFO:     127.0.0.1:36266 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:39:29] INFO:     127.0.0.1:36268 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 06:39:30] INFO:     127.0.0.1:36274 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:30] INFO:     127.0.0.1:36286 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:30 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:39:30] INFO:     127.0.0.1:36294 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:30] INFO:     127.0.0.1:36302 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:30] INFO:     127.0.0.1:36306 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:30] INFO:     127.0.0.1:36308 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:30] INFO:     127.0.0.1:36310 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:30] INFO:     127.0.0.1:36324 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:30 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 06:39:31 TP0] Decode batch. #running-req: 8, #token: 14298, token usage: 0.02, accept len: 2.53, cuda graph: True, gen throughput (token/s): 191.62, #queue-req: 0, 
[2025-09-13 06:39:32 TP0] Decode batch. #running-req: 8, #token: 15217, token usage: 0.02, accept len: 2.87, cuda graph: True, gen throughput (token/s): 810.90, #queue-req: 0, 
[2025-09-13 06:39:33 TP0] Decode batch. #running-req: 8, #token: 16214, token usage: 0.03, accept len: 3.12, cuda graph: True, gen throughput (token/s): 864.78, #queue-req: 0, 
[2025-09-13 06:39:34 TP0] Decode batch. #running-req: 8, #token: 17212, token usage: 0.03, accept len: 3.12, cuda graph: True, gen throughput (token/s): 869.00, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:08,  4.54s/it][2025-09-13 06:39:35] INFO:     127.0.0.1:36326 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:35 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:05<00:30,  2.19s/it][2025-09-13 06:39:35] INFO:     127.0.0.1:36338 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:39:35] INFO:     127.0.0.1:36350 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:36 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:11,  1.01it/s][2025-09-13 06:39:36] INFO:     127.0.0.1:36364 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:36 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:08,  1.29it/s][2025-09-13 06:39:36] INFO:     127.0.0.1:36368 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:36] INFO:     127.0.0.1:36384 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:36 TP0] Prefill batch. #new-seq: 2, #new-token: 3259, #cached-token: 1724, token usage: 0.01, #running-req: 6, #queue-req: 0, 
[2025-09-13 06:39:37 TP0] Decode batch. #running-req: 8, #token: 8238, token usage: 0.01, accept len: 2.99, cuda graph: True, gen throughput (token/s): 464.54, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:04,  2.07it/s][2025-09-13 06:39:37] INFO:     127.0.0.1:36396 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:04,  1.87it/s][2025-09-13 06:39:37] INFO:     127.0.0.1:36400 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:39:37 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:39:38 TP0] Decode batch. #running-req: 8, #token: 14461, token usage: 0.02, accept len: 2.68, cuda graph: True, gen throughput (token/s): 575.40, #queue-req: 0, 
[2025-09-13 06:39:39 TP0] Decode batch. #running-req: 8, #token: 15351, token usage: 0.02, accept len: 2.78, cuda graph: True, gen throughput (token/s): 779.44, #queue-req: 0, 
[2025-09-13 06:39:40 TP0] Decode batch. #running-req: 8, #token: 16303, token usage: 0.03, accept len: 2.98, cuda graph: True, gen throughput (token/s): 827.96, #queue-req: 0, 
 56%|█████████████████████████████████████████████████████████████████████████▏                                                        | 9/16 [00:10<00:10,  1.47s/it][2025-09-13 06:39:41 TP0] Decode batch. #running-req: 5, #token: 10016, token usage: 0.02, accept len: 3.20, cuda graph: True, gen throughput (token/s): 867.84, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.36it/s]
[2025-09-13 06:39:42] INFO:     127.0.0.1:42632 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.78     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8102      
Request throughput (req/s):              1.36      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         695.43    
Total token throughput (tok/s):          695.43    
Concurrency:                             7.68      
Accept length:                           2.95      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5655.73   
Median E2E Latency (ms):                 5578.61   
---------------Time to First Token----------------
Mean TTFT (ms):                          237.29    
Median TTFT (ms):                        271.72    
P99 TTFT (ms):                           345.70    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.60     
Median ITL (ms):                         7.21      
P95 ITL (ms):                            28.33     
P99 ITL (ms):                            65.76     
Max ITL (ms):                            263.05    
==================================================
[2025-09-13 06:39:42] INFO:     127.0.0.1:42648 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=1: batch_size=8, steps=3, topk=2, num_draft_tokens=4, speed=103.19 token/s, step_time=28.61 ms
Start i=2: batch_size=8, steps=3, topk=2, num_draft_tokens=6
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 3 --speculative-eagle-topk 2 --speculative-num-draft-tokens 6 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:39:53.420000 135285 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:39:53.420000 135285 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 06:39:53] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=94771682, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=3, speculative_eagle_topk=2, speculative_num_draft_tokens=6, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:39:54] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:40:02.523000 135526 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:40:02.523000 135526 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:40:02.636000 135528 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:40:02.636000 135528 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 06:40:02.771000 135520 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:40:02.771000 135520 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:40:02.837000 135521 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:40:02.837000 135521 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:40:03.110000 135523 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:40:03.110000 135523 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:40:03.157000 135525 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:40:03.157000 135525 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:40:03.157000 135522 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:40:03.157000 135522 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:40:03.218000 135524 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:40:03.218000 135524 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:40:03.218000 135527 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:40:03.218000 135527 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:40:03 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 06:40:03 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:40:03 TP0] Init torch distributed begin.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:40:04 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:40:08 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 06:40:09 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 06:40:09 TP0] Detected fp8 checkpoint.
[2025-09-13 06:40:10 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:04, 225.77it/s]
Loading safetensors checkpoint shards:   5% Completed | 49/1024 [00:00<00:16, 60.22it/s]
Loading safetensors checkpoint shards:   6% Completed | 61/1024 [00:00<00:17, 55.01it/s]
Loading safetensors checkpoint shards:   7% Completed | 70/1024 [00:01<00:17, 54.28it/s]
Loading safetensors checkpoint shards:   8% Completed | 78/1024 [00:01<00:17, 52.69it/s]
Loading safetensors checkpoint shards:   8% Completed | 85/1024 [00:01<00:17, 53.90it/s]
Loading safetensors checkpoint shards:   9% Completed | 92/1024 [00:01<00:17, 53.82it/s]
Loading safetensors checkpoint shards:  10% Completed | 98/1024 [00:01<00:17, 54.10it/s]
Loading safetensors checkpoint shards:  10% Completed | 105/1024 [00:01<00:16, 56.52it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:31, 29.12it/s]
Loading safetensors checkpoint shards:  11% Completed | 116/1024 [00:02<00:28, 31.42it/s]
Loading safetensors checkpoint shards:  12% Completed | 121/1024 [00:02<00:27, 33.31it/s]
Loading safetensors checkpoint shards:  12% Completed | 126/1024 [00:02<00:24, 36.37it/s]
Loading safetensors checkpoint shards:  13% Completed | 131/1024 [00:02<00:22, 38.92it/s]
Loading safetensors checkpoint shards:  13% Completed | 136/1024 [00:02<00:21, 40.51it/s]
Loading safetensors checkpoint shards:  14% Completed | 143/1024 [00:02<00:18, 46.99it/s]
Loading safetensors checkpoint shards:  15% Completed | 149/1024 [00:03<00:17, 49.60it/s]
Loading safetensors checkpoint shards:  15% Completed | 155/1024 [00:03<00:17, 50.17it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:03<00:14, 59.15it/s]
Loading safetensors checkpoint shards:  17% Completed | 173/1024 [00:03<00:12, 65.70it/s]
Loading safetensors checkpoint shards:  18% Completed | 181/1024 [00:03<00:12, 69.03it/s]
Loading safetensors checkpoint shards:  18% Completed | 189/1024 [00:03<00:11, 70.99it/s]
Loading safetensors checkpoint shards:  19% Completed | 197/1024 [00:03<00:11, 73.14it/s]
Loading safetensors checkpoint shards:  20% Completed | 205/1024 [00:03<00:11, 74.45it/s]
Loading safetensors checkpoint shards:  21% Completed | 213/1024 [00:03<00:11, 68.46it/s]
Loading safetensors checkpoint shards:  21% Completed | 220/1024 [00:04<00:13, 60.25it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:04<00:14, 56.34it/s]
Loading safetensors checkpoint shards:  23% Completed | 233/1024 [00:04<00:14, 53.05it/s]
Loading safetensors checkpoint shards:  23% Completed | 239/1024 [00:04<00:15, 50.93it/s]
Loading safetensors checkpoint shards:  24% Completed | 245/1024 [00:04<00:15, 51.45it/s]
Loading safetensors checkpoint shards:  25% Completed | 251/1024 [00:05<00:27, 27.84it/s]
Loading safetensors checkpoint shards:  25% Completed | 256/1024 [00:05<00:25, 30.16it/s]
Loading safetensors checkpoint shards:  25% Completed | 261/1024 [00:05<00:22, 33.25it/s]
Loading safetensors checkpoint shards:  26% Completed | 266/1024 [00:05<00:21, 35.43it/s]
Loading safetensors checkpoint shards:  27% Completed | 272/1024 [00:05<00:19, 39.10it/s]
Loading safetensors checkpoint shards:  27% Completed | 277/1024 [00:05<00:18, 39.61it/s]
Loading safetensors checkpoint shards:  28% Completed | 284/1024 [00:05<00:15, 46.75it/s]
Loading safetensors checkpoint shards:  28% Completed | 290/1024 [00:05<00:15, 48.56it/s]
Loading safetensors checkpoint shards:  29% Completed | 297/1024 [00:06<00:13, 52.92it/s]
Loading safetensors checkpoint shards:  30% Completed | 303/1024 [00:06<00:14, 50.18it/s]
Loading safetensors checkpoint shards:  30% Completed | 309/1024 [00:06<00:15, 47.06it/s]
Loading safetensors checkpoint shards:  31% Completed | 314/1024 [00:06<00:16, 42.05it/s]
Loading safetensors checkpoint shards:  31% Completed | 319/1024 [00:06<00:16, 42.75it/s]
Loading safetensors checkpoint shards:  32% Completed | 324/1024 [00:06<00:18, 38.86it/s]
Loading safetensors checkpoint shards:  32% Completed | 330/1024 [00:06<00:15, 43.51it/s]
Loading safetensors checkpoint shards:  33% Completed | 335/1024 [00:06<00:15, 43.75it/s]
Loading safetensors checkpoint shards:  33% Completed | 340/1024 [00:07<00:15, 44.33it/s]
Loading safetensors checkpoint shards:  34% Completed | 345/1024 [00:07<00:15, 44.17it/s]
Loading safetensors checkpoint shards:  34% Completed | 351/1024 [00:07<00:14, 46.08it/s]
Loading safetensors checkpoint shards:  35% Completed | 356/1024 [00:07<00:15, 43.69it/s]
Loading safetensors checkpoint shards:  35% Completed | 361/1024 [00:07<00:15, 43.43it/s]
Loading safetensors checkpoint shards:  36% Completed | 366/1024 [00:07<00:15, 41.89it/s]
Loading safetensors checkpoint shards:  36% Completed | 371/1024 [00:07<00:15, 42.79it/s]
Loading safetensors checkpoint shards:  37% Completed | 376/1024 [00:07<00:16, 39.37it/s]
Loading safetensors checkpoint shards:  37% Completed | 381/1024 [00:08<00:16, 39.40it/s]
Loading safetensors checkpoint shards:  38% Completed | 386/1024 [00:08<00:16, 39.82it/s]
Loading safetensors checkpoint shards:  38% Completed | 391/1024 [00:08<00:17, 36.54it/s]
Loading safetensors checkpoint shards:  39% Completed | 395/1024 [00:08<00:17, 36.15it/s]
Loading safetensors checkpoint shards:  39% Completed | 399/1024 [00:08<00:17, 35.50it/s]
Loading safetensors checkpoint shards:  40% Completed | 405/1024 [00:08<00:15, 39.91it/s]
Loading safetensors checkpoint shards:  40% Completed | 410/1024 [00:08<00:14, 41.87it/s]
Loading safetensors checkpoint shards:  41% Completed | 415/1024 [00:09<00:32, 18.91it/s]
Loading safetensors checkpoint shards:  41% Completed | 419/1024 [00:09<00:29, 20.86it/s]
Loading safetensors checkpoint shards:  41% Completed | 424/1024 [00:09<00:24, 24.77it/s]
Loading safetensors checkpoint shards:  42% Completed | 429/1024 [00:09<00:20, 28.92it/s]
Loading safetensors checkpoint shards:  42% Completed | 433/1024 [00:09<00:21, 28.07it/s]
Loading safetensors checkpoint shards:  43% Completed | 437/1024 [00:10<00:19, 29.64it/s]
Loading safetensors checkpoint shards:  43% Completed | 441/1024 [00:10<00:19, 29.41it/s]
Loading safetensors checkpoint shards:  43% Completed | 445/1024 [00:10<00:18, 30.59it/s]
Loading safetensors checkpoint shards:  44% Completed | 449/1024 [00:10<00:18, 30.49it/s]
Loading safetensors checkpoint shards:  44% Completed | 453/1024 [00:10<00:19, 29.80it/s]
Loading safetensors checkpoint shards:  45% Completed | 457/1024 [00:10<00:18, 31.06it/s]
Loading safetensors checkpoint shards:  45% Completed | 461/1024 [00:10<00:20, 26.82it/s]
Loading safetensors checkpoint shards:  45% Completed | 464/1024 [00:10<00:22, 25.29it/s]
Loading safetensors checkpoint shards:  46% Completed | 467/1024 [00:11<00:22, 24.37it/s]
Loading safetensors checkpoint shards:  46% Completed | 472/1024 [00:11<00:18, 29.46it/s]
Loading safetensors checkpoint shards:  46% Completed | 476/1024 [00:11<00:17, 30.94it/s]
Loading safetensors checkpoint shards:  47% Completed | 481/1024 [00:11<00:15, 34.53it/s]
Loading safetensors checkpoint shards:  47% Completed | 486/1024 [00:11<00:14, 38.39it/s]
Loading safetensors checkpoint shards:  48% Completed | 491/1024 [00:11<00:13, 38.24it/s]
Loading safetensors checkpoint shards:  49% Completed | 498/1024 [00:11<00:11, 46.28it/s]
Loading safetensors checkpoint shards:  49% Completed | 504/1024 [00:11<00:10, 49.55it/s]
Loading safetensors checkpoint shards:  50% Completed | 510/1024 [00:12<00:09, 51.58it/s]
Loading safetensors checkpoint shards:  50% Completed | 517/1024 [00:12<00:09, 54.71it/s]
Loading safetensors checkpoint shards:  51% Completed | 523/1024 [00:12<00:09, 52.62it/s]
Loading safetensors checkpoint shards:  52% Completed | 532/1024 [00:12<00:07, 62.47it/s]
Loading safetensors checkpoint shards:  53% Completed | 542/1024 [00:12<00:06, 71.73it/s]
Loading safetensors checkpoint shards:  54% Completed | 552/1024 [00:12<00:06, 77.43it/s]
Loading safetensors checkpoint shards:  55% Completed | 560/1024 [00:12<00:06, 75.11it/s]
Loading safetensors checkpoint shards:  55% Completed | 568/1024 [00:12<00:07, 59.60it/s]
Loading safetensors checkpoint shards:  56% Completed | 575/1024 [00:13<00:08, 50.12it/s]
Loading safetensors checkpoint shards:  57% Completed | 581/1024 [00:13<00:09, 45.55it/s]
Loading safetensors checkpoint shards:  57% Completed | 586/1024 [00:13<00:09, 45.13it/s]
Loading safetensors checkpoint shards:  58% Completed | 591/1024 [00:13<00:10, 42.09it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:13<00:10, 40.89it/s]
Loading safetensors checkpoint shards:  59% Completed | 601/1024 [00:13<00:10, 40.01it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:13<00:10, 39.57it/s]
Loading safetensors checkpoint shards:  60% Completed | 611/1024 [00:14<00:23, 17.76it/s]
Loading safetensors checkpoint shards:  60% Completed | 615/1024 [00:14<00:20, 20.00it/s]
Loading safetensors checkpoint shards:  60% Completed | 619/1024 [00:14<00:18, 22.42it/s]
Loading safetensors checkpoint shards:  61% Completed | 623/1024 [00:14<00:17, 23.45it/s]
Loading safetensors checkpoint shards:  61% Completed | 627/1024 [00:15<00:15, 25.74it/s]
Loading safetensors checkpoint shards:  62% Completed | 631/1024 [00:15<00:14, 26.28it/s]
Loading safetensors checkpoint shards:  62% Completed | 635/1024 [00:15<00:14, 26.34it/s]
Loading safetensors checkpoint shards:  62% Completed | 639/1024 [00:15<00:13, 28.09it/s]
Loading safetensors checkpoint shards:  63% Completed | 643/1024 [00:15<00:13, 29.22it/s]
Loading safetensors checkpoint shards:  63% Completed | 647/1024 [00:15<00:13, 28.53it/s]
Loading safetensors checkpoint shards:  64% Completed | 651/1024 [00:15<00:12, 30.01it/s]
Loading safetensors checkpoint shards:  64% Completed | 655/1024 [00:16<00:12, 29.89it/s]
Loading safetensors checkpoint shards:  64% Completed | 659/1024 [00:16<00:11, 31.95it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:16<00:10, 33.57it/s]
Loading safetensors checkpoint shards:  65% Completed | 667/1024 [00:16<00:10, 35.11it/s]
Loading safetensors checkpoint shards:  66% Completed | 672/1024 [00:16<00:09, 37.02it/s]
Loading safetensors checkpoint shards:  66% Completed | 676/1024 [00:16<00:09, 37.39it/s]
Loading safetensors checkpoint shards:  67% Completed | 681/1024 [00:16<00:08, 38.28it/s]
Loading safetensors checkpoint shards:  67% Completed | 686/1024 [00:16<00:08, 39.40it/s]
Loading safetensors checkpoint shards:  67% Completed | 691/1024 [00:16<00:08, 40.10it/s]
Loading safetensors checkpoint shards:  68% Completed | 696/1024 [00:17<00:07, 41.87it/s]
Loading safetensors checkpoint shards:  68% Completed | 701/1024 [00:17<00:08, 39.97it/s]
Loading safetensors checkpoint shards:  69% Completed | 706/1024 [00:17<00:08, 39.63it/s]
Loading safetensors checkpoint shards:  69% Completed | 710/1024 [00:17<00:08, 39.05it/s]
Loading safetensors checkpoint shards:  70% Completed | 715/1024 [00:17<00:07, 39.23it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:17<00:07, 38.35it/s]
Loading safetensors checkpoint shards:  71% Completed | 723/1024 [00:17<00:07, 38.61it/s]
Loading safetensors checkpoint shards:  71% Completed | 727/1024 [00:17<00:07, 38.84it/s]
Loading safetensors checkpoint shards:  71% Completed | 731/1024 [00:17<00:07, 38.90it/s]
Loading safetensors checkpoint shards:  72% Completed | 735/1024 [00:18<00:07, 38.26it/s]
Loading safetensors checkpoint shards:  72% Completed | 739/1024 [00:18<00:07, 38.02it/s]
Loading safetensors checkpoint shards:  73% Completed | 743/1024 [00:18<00:07, 38.04it/s]
Loading safetensors checkpoint shards:  73% Completed | 747/1024 [00:18<00:07, 36.49it/s]
Loading safetensors checkpoint shards:  73% Completed | 751/1024 [00:18<00:07, 35.95it/s]
Loading safetensors checkpoint shards:  74% Completed | 755/1024 [00:18<00:07, 36.26it/s]
Loading safetensors checkpoint shards:  74% Completed | 759/1024 [00:18<00:07, 36.15it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:18<00:07, 36.48it/s]
Loading safetensors checkpoint shards:  75% Completed | 767/1024 [00:18<00:07, 36.70it/s]
Loading safetensors checkpoint shards:  75% Completed | 771/1024 [00:19<00:06, 36.27it/s]
Loading safetensors checkpoint shards:  76% Completed | 775/1024 [00:19<00:07, 35.31it/s]
Loading safetensors checkpoint shards:  76% Completed | 779/1024 [00:19<00:06, 35.07it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:19<00:06, 35.35it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:19<00:06, 34.37it/s]
Loading safetensors checkpoint shards:  77% Completed | 791/1024 [00:19<00:06, 35.17it/s]
Loading safetensors checkpoint shards:  78% Completed | 795/1024 [00:19<00:06, 35.53it/s]
Loading safetensors checkpoint shards:  78% Completed | 799/1024 [00:19<00:06, 35.92it/s]
Loading safetensors checkpoint shards:  79% Completed | 804/1024 [00:19<00:05, 36.89it/s]
Loading safetensors checkpoint shards:  79% Completed | 808/1024 [00:20<00:05, 36.50it/s]
Loading safetensors checkpoint shards:  79% Completed | 812/1024 [00:20<00:05, 36.11it/s]
Loading safetensors checkpoint shards:  80% Completed | 816/1024 [00:20<00:05, 34.93it/s]
Loading safetensors checkpoint shards:  80% Completed | 820/1024 [00:20<00:05, 34.67it/s]
Loading safetensors checkpoint shards:  80% Completed | 824/1024 [00:20<00:05, 35.15it/s]
Loading safetensors checkpoint shards:  81% Completed | 828/1024 [00:20<00:05, 35.28it/s]
Loading safetensors checkpoint shards:  81% Completed | 832/1024 [00:20<00:05, 36.16it/s]
Loading safetensors checkpoint shards:  82% Completed | 836/1024 [00:20<00:05, 36.52it/s]
Loading safetensors checkpoint shards:  82% Completed | 840/1024 [00:20<00:05, 36.39it/s]
Loading safetensors checkpoint shards:  82% Completed | 844/1024 [00:21<00:05, 35.26it/s]
Loading safetensors checkpoint shards:  83% Completed | 848/1024 [00:21<00:04, 35.76it/s]
Loading safetensors checkpoint shards:  83% Completed | 852/1024 [00:21<00:04, 36.11it/s]
Loading safetensors checkpoint shards:  84% Completed | 856/1024 [00:21<00:04, 36.59it/s]
Loading safetensors checkpoint shards:  84% Completed | 860/1024 [00:21<00:04, 35.65it/s]
Loading safetensors checkpoint shards:  84% Completed | 864/1024 [00:21<00:04, 35.74it/s]
Loading safetensors checkpoint shards:  85% Completed | 868/1024 [00:21<00:04, 35.78it/s]
Loading safetensors checkpoint shards:  85% Completed | 872/1024 [00:21<00:04, 36.04it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:21<00:04, 35.03it/s]
Loading safetensors checkpoint shards:  86% Completed | 880/1024 [00:22<00:04, 35.18it/s]
Loading safetensors checkpoint shards:  86% Completed | 884/1024 [00:22<00:03, 36.12it/s]
Loading safetensors checkpoint shards:  87% Completed | 888/1024 [00:22<00:03, 36.71it/s]
Loading safetensors checkpoint shards:  87% Completed | 892/1024 [00:22<00:03, 36.02it/s]
Loading safetensors checkpoint shards:  88% Completed | 896/1024 [00:22<00:03, 36.30it/s]
Loading safetensors checkpoint shards:  88% Completed | 900/1024 [00:23<00:09, 13.17it/s]
Loading safetensors checkpoint shards:  88% Completed | 904/1024 [00:23<00:07, 16.15it/s]
Loading safetensors checkpoint shards:  89% Completed | 908/1024 [00:23<00:05, 19.38it/s]
Loading safetensors checkpoint shards:  89% Completed | 912/1024 [00:23<00:04, 22.59it/s]
Loading safetensors checkpoint shards:  90% Completed | 917/1024 [00:23<00:04, 26.61it/s]
Loading safetensors checkpoint shards:  90% Completed | 921/1024 [00:23<00:03, 28.82it/s]
Loading safetensors checkpoint shards:  90% Completed | 925/1024 [00:23<00:03, 30.69it/s]
Loading safetensors checkpoint shards:  91% Completed | 929/1024 [00:24<00:02, 32.21it/s]
Loading safetensors checkpoint shards:  91% Completed | 933/1024 [00:24<00:02, 32.66it/s]
Loading safetensors checkpoint shards:  92% Completed | 937/1024 [00:24<00:02, 33.99it/s]
Loading safetensors checkpoint shards:  92% Completed | 941/1024 [00:24<00:02, 34.85it/s]
Loading safetensors checkpoint shards:  92% Completed | 945/1024 [00:24<00:02, 34.34it/s]
Loading safetensors checkpoint shards:  93% Completed | 949/1024 [00:24<00:02, 35.21it/s]
Loading safetensors checkpoint shards:  93% Completed | 953/1024 [00:24<00:02, 35.16it/s]
Loading safetensors checkpoint shards:  93% Completed | 957/1024 [00:24<00:01, 35.56it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:24<00:01, 34.44it/s]
Loading safetensors checkpoint shards:  94% Completed | 965/1024 [00:25<00:01, 35.44it/s]
Loading safetensors checkpoint shards:  95% Completed | 969/1024 [00:25<00:01, 35.60it/s]
Loading safetensors checkpoint shards:  95% Completed | 973/1024 [00:25<00:01, 35.24it/s]
Loading safetensors checkpoint shards:  95% Completed | 977/1024 [00:25<00:01, 36.50it/s]
Loading safetensors checkpoint shards:  96% Completed | 981/1024 [00:25<00:01, 37.01it/s]
Loading safetensors checkpoint shards:  99% Completed | 1009/1024 [00:25<00:00, 104.55it/s]
Loading safetensors checkpoint shards: 100% Completed | 1020/1024 [00:25<00:00, 93.50it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 39.60it/s]

[2025-09-13 06:40:36 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 06:40:37 TP6] KV Cache is allocated. #tokens: 620153, KV size: 40.59 GB
[2025-09-13 06:40:37 TP3] KV Cache is allocated. #tokens: 620153, KV size: 40.59 GB
[2025-09-13 06:40:37 TP2] KV Cache is allocated. #tokens: 620153, KV size: 40.59 GB
[2025-09-13 06:40:37 TP0] KV Cache is allocated. #tokens: 620153, KV size: 40.59 GB
[2025-09-13 06:40:37 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 06:40:37 TP1] KV Cache is allocated. #tokens: 620153, KV size: 40.59 GB
[2025-09-13 06:40:37 TP7] KV Cache is allocated. #tokens: 620153, KV size: 40.59 GB
[2025-09-13 06:40:37 TP5] KV Cache is allocated. #tokens: 620153, KV size: 40.59 GB
[2025-09-13 06:40:37 TP4] KV Cache is allocated. #tokens: 620153, KV size: 40.59 GB
[2025-09-13 06:40:37 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 06:40:38 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.52 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 06:40:39 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:40:39 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 06:40:39 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:40:39 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:40:39 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:40:39 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:40:39 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:40:39 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:40:39 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25862.92it/s]
[2025-09-13 06:40:39 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:40:39 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26362.29it/s]
[2025-09-13 06:40:40 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:40:40 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28104.55it/s]
[2025-09-13 06:40:41 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:40:41 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28288.99it/s]
[2025-09-13 06:40:41 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:40:41 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 29174.40it/s]
[2025-09-13 06:40:42 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.23 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:07<00:00,  1.59it/s][2025-09-13 06:40:46 TP2] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.23 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.02it/s]
[2025-09-13 06:40:46 TP1] Registering 984 cuda graph addresses
[2025-09-13 06:40:46 TP0] Registering 984 cuda graph addresses
[2025-09-13 06:40:46 TP7] Registering 984 cuda graph addresses
[2025-09-13 06:40:46 TP5] Registering 984 cuda graph addresses
[2025-09-13 06:40:46 TP6] Registering 984 cuda graph addresses
[2025-09-13 06:40:46 TP4] Registering 984 cuda graph addresses
[2025-09-13 06:40:46 TP3] Registering 984 cuda graph addresses
[2025-09-13 06:40:46 TP0] Capture cuda graph end. Time elapsed: 8.51 s. mem usage=0.35 GB. avail mem=17.21 GB.
[2025-09-13 06:40:46 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 06:40:46 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:40:46 TP0] Init torch distributed begin.
[2025-09-13 06:40:46 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 06:40:46 TP0] Load weight begin. avail mem=17.21 GB
[2025-09-13 06:40:46 TP0] Detected fp8 checkpoint.
[2025-09-13 06:40:46 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 19/1024 [00:00<00:05, 176.92it/s]
Loading safetensors checkpoint shards:   5% Completed | 48/1024 [00:00<00:04, 240.48it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:00<00:02, 399.09it/s]
Loading safetensors checkpoint shards:  16% Completed | 168/1024 [00:00<00:01, 475.35it/s]
Loading safetensors checkpoint shards:  22% Completed | 228/1024 [00:00<00:01, 516.89it/s]
Loading safetensors checkpoint shards:  28% Completed | 287/1024 [00:00<00:01, 540.04it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:00<00:01, 553.28it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:00<00:01, 567.10it/s]
Loading safetensors checkpoint shards:  45% Completed | 465/1024 [00:00<00:00, 572.42it/s]
Loading safetensors checkpoint shards:  51% Completed | 525/1024 [00:01<00:00, 579.57it/s]
Loading safetensors checkpoint shards:  57% Completed | 586/1024 [00:01<00:00, 588.70it/s]
Loading safetensors checkpoint shards:  63% Completed | 645/1024 [00:01<00:00, 584.88it/s]
Loading safetensors checkpoint shards:  69% Completed | 704/1024 [00:01<00:00, 576.96it/s]
Loading safetensors checkpoint shards:  74% Completed | 762/1024 [00:01<00:00, 569.31it/s]
Loading safetensors checkpoint shards:  80% Completed | 819/1024 [00:01<00:00, 566.12it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:01<00:00, 562.59it/s]
Loading safetensors checkpoint shards:  91% Completed | 933/1024 [00:01<00:00, 564.69it/s]
Loading safetensors checkpoint shards:  97% Completed | 990/1024 [00:01<00:00, 498.48it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 493.11it/s]

[2025-09-13 06:40:49 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.22 GB, mem usage=1.99 GB.
[2025-09-13 06:40:49 TP6] KV Cache is allocated. #tokens: 620153, KV size: 0.67 GB
[2025-09-13 06:40:49 TP7] KV Cache is allocated. #tokens: 620153, KV size: 0.67 GB
[2025-09-13 06:40:49 TP3] KV Cache is allocated. #tokens: 620153, KV size: 0.67 GB
[2025-09-13 06:40:49 TP5] KV Cache is allocated. #tokens: 620153, KV size: 0.67 GB
[2025-09-13 06:40:49 TP1] KV Cache is allocated. #tokens: 620153, KV size: 0.67 GB
[2025-09-13 06:40:49 TP0] KV Cache is allocated. #tokens: 620153, KV size: 0.67 GB
[2025-09-13 06:40:49 TP4] KV Cache is allocated. #tokens: 620153, KV size: 0.67 GB
[2025-09-13 06:40:49 TP0] Memory pool end. avail mem=14.55 GB
[2025-09-13 06:40:49 TP2] KV Cache is allocated. #tokens: 620153, KV size: 0.67 GB
[2025-09-13 06:40:49 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:40:49 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:40:49 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.18 GB
[2025-09-13 06:40:49 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:40:49 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:40:49 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:40:49 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.99 GB
[2025-09-13 06:40:49 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
Capturing batches (bs=1 avail_mem=14.72 GB):  62%|█████████████████████████████████████████████████████▊                                | 5/8 [00:03<00:01,  2.30it/s][2025-09-13 06:40:55 TP1] Registering 48 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.72 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.72it/s][2025-09-13 06:40:55 TP6] Registering 48 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.72 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.43it/s]
[2025-09-13 06:40:55 TP7] Registering 48 cuda graph addresses
[2025-09-13 06:40:55 TP0] Registering 48 cuda graph addresses
[2025-09-13 06:40:55 TP2] Registering 48 cuda graph addresses
[2025-09-13 06:40:55 TP4] Registering 48 cuda graph addresses
[2025-09-13 06:40:55 TP5] Registering 48 cuda graph addresses
[2025-09-13 06:40:55 TP3] Registering 48 cuda graph addresses
[2025-09-13 06:40:55 TP2] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.26 GB. avail mem=14.68 GB.
[2025-09-13 06:40:55 TP3] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.26 GB. avail mem=14.68 GB.
[2025-09-13 06:40:55 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.68 GB
[2025-09-13 06:40:55 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.68 GB
[2025-09-13 06:40:55 TP4] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.26 GB. avail mem=14.68 GB.
[2025-09-13 06:40:55 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.68 GB
[2025-09-13 06:40:55 TP5] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.26 GB. avail mem=14.68 GB.
[2025-09-13 06:40:55 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.68 GB
[2025-09-13 06:40:55 TP1] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.26 GB. avail mem=14.68 GB.
[2025-09-13 06:40:55 TP7] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.26 GB. avail mem=14.92 GB.
[2025-09-13 06:40:55 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.92 GB
[2025-09-13 06:40:55 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.68 GB
[2025-09-13 06:40:55 TP0] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.26 GB. avail mem=14.72 GB.
[2025-09-13 06:40:55 TP6] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.26 GB. avail mem=14.68 GB.
[2025-09-13 06:40:55 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.68 GB
[2025-09-13 06:40:55 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.72 GB
Capturing batches (bs=1 avail_mem=14.53 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:00<00:00, 27.19it/s][2025-09-13 06:40:56 TP7] Registering 24 cuda graph addresses
[2025-09-13 06:40:56 TP1] Registering 24 cuda graph addresses
[2025-09-13 06:40:56 TP5] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.53 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 23.48it/s][2025-09-13 06:40:56 TP3] Registering 24 cuda graph addresses

[2025-09-13 06:40:56 TP2] Registering 24 cuda graph addresses
[2025-09-13 06:40:56 TP6] Registering 24 cuda graph addresses
[2025-09-13 06:40:56 TP4] Registering 24 cuda graph addresses
[2025-09-13 06:40:56 TP0] Registering 24 cuda graph addresses
[2025-09-13 06:40:56 TP1] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.19 GB. avail mem=14.49 GB.
[2025-09-13 06:40:56 TP3] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.19 GB. avail mem=14.49 GB.
[2025-09-13 06:40:56 TP5] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.19 GB. avail mem=14.49 GB.
[2025-09-13 06:40:56 TP0] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.19 GB. avail mem=14.53 GB.
[2025-09-13 06:40:56 TP0] max_total_num_tokens=620153, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.53 GB
[2025-09-13 06:40:56 TP7] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.19 GB. avail mem=14.73 GB.
[2025-09-13 06:40:56 TP4] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.19 GB. avail mem=14.49 GB.
[2025-09-13 06:40:56 TP2] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.19 GB. avail mem=14.49 GB.
[2025-09-13 06:40:56 TP6] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.19 GB. avail mem=14.49 GB.
[2025-09-13 06:40:57] INFO:     Started server process [135285]
[2025-09-13 06:40:57] INFO:     Waiting for application startup.
[2025-09-13 06:40:57] INFO:     Application startup complete.
[2025-09-13 06:40:57] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 06:40:57] INFO:     127.0.0.1:39124 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 06:40:58] INFO:     127.0.0.1:44730 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 06:40:58 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:40:58 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:40:58 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27867.46it/s]
[2025-09-13 06:41:00] INFO:     127.0.0.1:44746 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:00] The server is fired up and ready to roll!
[2025-09-13 06:41:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:41:08] INFO:     127.0.0.1:44750 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:41:09] INFO:     127.0.0.1:55142 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:09 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 06:41:10] INFO:     127.0.0.1:55150 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:10] INFO:     127.0.0.1:55152 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:41:10] INFO:     127.0.0.1:55158 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:10] INFO:     127.0.0.1:55172 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:10] INFO:     127.0.0.1:55178 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:10] INFO:     127.0.0.1:55194 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:10] INFO:     127.0.0.1:55206 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:10] INFO:     127.0.0.1:55216 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:10 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 06:41:11 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:41:11 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:41:11 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:41:11 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:41:11 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:41:11 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:41:11 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:41:11 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:41:11 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 06:41:12 TP0] Decode batch. #running-req: 8, #token: 14543, token usage: 0.02, accept len: 2.95, cuda graph: True, gen throughput (token/s): 42.83, #queue-req: 0, 
[2025-09-13 06:41:13 TP0] Decode batch. #running-req: 8, #token: 15549, token usage: 0.03, accept len: 3.14, cuda graph: True, gen throughput (token/s): 846.15, #queue-req: 0, 
[2025-09-13 06:41:14 TP0] Decode batch. #running-req: 8, #token: 16615, token usage: 0.03, accept len: 3.33, cuda graph: True, gen throughput (token/s): 873.65, #queue-req: 0, 
[2025-09-13 06:41:15 TP0] Decode batch. #running-req: 8, #token: 17096, token usage: 0.03, accept len: 3.42, cuda graph: True, gen throughput (token/s): 892.73, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.23it/s]
[2025-09-13 06:41:17] INFO:     127.0.0.1:55228 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.50      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4091      
Request throughput (req/s):              1.23      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         630.34    
Total token throughput (tok/s):          630.34    
Concurrency:                             7.08      
Accept length:                           3.23      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5752.13   
Median E2E Latency (ms):                 5667.12   
---------------Time to First Token----------------
Mean TTFT (ms):                          611.37    
Median TTFT (ms):                        722.71    
P99 TTFT (ms):                           723.14    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.06     
Median ITL (ms):                         7.64      
P95 ITL (ms):                            15.31     
P99 ITL (ms):                            59.23     
Max ITL (ms):                            833.91    
==================================================
[2025-09-13 06:41:17] INFO:     127.0.0.1:55232 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:41:17] INFO:     127.0.0.1:55238 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:41:17 TP0] Decode batch. #running-req: 1, #token: 4667, token usage: 0.01, accept len: 2.99, cuda graph: True, gen throughput (token/s): 219.51, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 06:41:18] INFO:     127.0.0.1:49380 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:18] INFO:     127.0.0.1:49396 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:41:18] INFO:     127.0.0.1:49404 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:18] INFO:     127.0.0.1:49414 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:18] INFO:     127.0.0.1:49430 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:18] INFO:     127.0.0.1:49444 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:18] INFO:     127.0.0.1:49448 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:18] INFO:     127.0.0.1:49452 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:18 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 06:41:19 TP0] Decode batch. #running-req: 8, #token: 14642, token usage: 0.02, accept len: 3.02, cuda graph: True, gen throughput (token/s): 314.37, #queue-req: 0, 
[2025-09-13 06:41:20 TP0] Decode batch. #running-req: 8, #token: 15654, token usage: 0.03, accept len: 3.16, cuda graph: True, gen throughput (token/s): 846.16, #queue-req: 0, 
[2025-09-13 06:41:22 TP0] Decode batch. #running-req: 8, #token: 16721, token usage: 0.03, accept len: 3.33, cuda graph: True, gen throughput (token/s): 879.84, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:10,  4.70s/it][2025-09-13 06:41:23] INFO:     127.0.0.1:49456 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:23 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:41:23 TP0] Decode batch. #running-req: 8, #token: 17996, token usage: 0.03, accept len: 3.41, cuda graph: True, gen throughput (token/s): 702.17, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:05<00:31,  2.26s/it][2025-09-13 06:41:23] INFO:     127.0.0.1:49470 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:17,  1.32s/it][2025-09-13 06:41:23] INFO:     127.0.0.1:49476 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:23] INFO:     127.0.0.1:49480 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:23] INFO:     127.0.0.1:49494 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:23 TP0] Prefill batch. #new-seq: 3, #new-token: 3226, #cached-token: 2590, token usage: 0.02, #running-req: 5, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.94it/s][2025-09-13 06:41:24] INFO:     127.0.0.1:49500 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:24 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:41:24] INFO:     127.0.0.1:49502 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:03,  2.03it/s][2025-09-13 06:41:25] INFO:     127.0.0.1:49510 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:41:25 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:41:25 TP0] Decode batch. #running-req: 8, #token: 14192, token usage: 0.02, accept len: 2.95, cuda graph: True, gen throughput (token/s): 472.12, #queue-req: 0, 
[2025-09-13 06:41:26 TP0] Decode batch. #running-req: 8, #token: 15176, token usage: 0.02, accept len: 3.08, cuda graph: True, gen throughput (token/s): 842.02, #queue-req: 0, 
[2025-09-13 06:41:27 TP0] Decode batch. #running-req: 8, #token: 16328, token usage: 0.03, accept len: 3.60, cuda graph: True, gen throughput (token/s): 958.89, #queue-req: 0, 
 75%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                | 12/16 [00:10<00:02,  1.71it/s][2025-09-13 06:41:29 TP0] Decode batch. #running-req: 4, #token: 11302, token usage: 0.02, accept len: 3.59, cuda graph: True, gen throughput (token/s): 877.51, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.44it/s]
[2025-09-13 06:41:29] INFO:     127.0.0.1:42664 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.12     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8113      
Request throughput (req/s):              1.44      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         736.83    
Total token throughput (tok/s):          736.83    
Concurrency:                             7.73      
Accept length:                           3.25      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5372.46   
Median E2E Latency (ms):                 5400.60   
---------------Time to First Token----------------
Mean TTFT (ms):                          285.25    
Median TTFT (ms):                        274.60    
P99 TTFT (ms):                           391.25    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.96      
Median ITL (ms):                         7.58      
P95 ITL (ms):                            15.28     
P99 ITL (ms):                            55.10     
Max ITL (ms):                            295.76    
==================================================
[2025-09-13 06:41:29] INFO:     127.0.0.1:42672 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=2: batch_size=8, steps=3, topk=2, num_draft_tokens=6, speed=108.70 token/s, step_time=29.90 ms
Start i=3: batch_size=8, steps=3, topk=3, num_draft_tokens=4
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 3 --speculative-eagle-topk 3 --speculative-num-draft-tokens 4 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:41:40.410000 141861 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:41:40.410000 141861 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 06:41:40] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=318512681, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=3, speculative_eagle_topk=3, speculative_num_draft_tokens=4, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:41:41] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:41:49.549000 142074 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:41:49.549000 142074 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:41:49.642000 142076 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:41:49.642000 142076 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:41:49.833000 142069 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:41:49.833000 142069 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 06:41:49.899000 142072 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:41:49.899000 142072 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:41:49.928000 142077 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:41:49.928000 142077 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:41:49.955000 142070 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:41:49.955000 142070 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 06:41:50.096000 142073 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:41:50.096000 142073 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:41:50.106000 142075 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:41:50.106000 142075 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:41:50.113000 142071 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:41:50.113000 142071 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:41:50 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 06:41:50 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:41:50 TP0] Init torch distributed begin.
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:41:52 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:41:55 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 06:41:56 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 06:41:56 TP0] Detected fp8 checkpoint.
[2025-09-13 06:41:57 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 29/1024 [00:00<00:03, 265.90it/s]
Loading safetensors checkpoint shards:   5% Completed | 56/1024 [00:00<00:09, 107.22it/s]
Loading safetensors checkpoint shards:   7% Completed | 72/1024 [00:00<00:13, 72.32it/s]
Loading safetensors checkpoint shards:   8% Completed | 83/1024 [00:01<00:16, 57.64it/s]
Loading safetensors checkpoint shards:   9% Completed | 91/1024 [00:01<00:19, 48.47it/s]
Loading safetensors checkpoint shards:   9% Completed | 97/1024 [00:01<00:22, 41.17it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:02<00:37, 24.63it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:02<00:33, 27.04it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:32, 28.53it/s]
Loading safetensors checkpoint shards:  11% Completed | 116/1024 [00:02<00:28, 31.89it/s]
Loading safetensors checkpoint shards:  12% Completed | 121/1024 [00:02<00:26, 34.33it/s]
Loading safetensors checkpoint shards:  12% Completed | 126/1024 [00:02<00:23, 37.49it/s]
Loading safetensors checkpoint shards:  13% Completed | 131/1024 [00:02<00:23, 38.80it/s]
Loading safetensors checkpoint shards:  13% Completed | 136/1024 [00:03<00:23, 38.11it/s]
Loading safetensors checkpoint shards:  14% Completed | 142/1024 [00:03<00:21, 41.89it/s]
Loading safetensors checkpoint shards:  14% Completed | 147/1024 [00:03<00:20, 42.56it/s]
Loading safetensors checkpoint shards:  15% Completed | 152/1024 [00:03<00:20, 43.07it/s]
Loading safetensors checkpoint shards:  15% Completed | 157/1024 [00:03<00:20, 42.87it/s]
Loading safetensors checkpoint shards:  16% Completed | 163/1024 [00:03<00:18, 45.48it/s]
Loading safetensors checkpoint shards:  16% Completed | 168/1024 [00:03<00:20, 42.72it/s]
Loading safetensors checkpoint shards:  17% Completed | 173/1024 [00:03<00:19, 44.48it/s]
Loading safetensors checkpoint shards:  17% Completed | 178/1024 [00:03<00:19, 44.25it/s]
Loading safetensors checkpoint shards:  18% Completed | 183/1024 [00:04<00:18, 44.72it/s]
Loading safetensors checkpoint shards:  18% Completed | 188/1024 [00:04<00:18, 44.10it/s]
Loading safetensors checkpoint shards:  19% Completed | 194/1024 [00:04<00:17, 48.31it/s]
Loading safetensors checkpoint shards:  19% Completed | 199/1024 [00:04<00:17, 47.87it/s]
Loading safetensors checkpoint shards:  20% Completed | 204/1024 [00:04<00:17, 47.94it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:04<00:17, 46.23it/s]
Loading safetensors checkpoint shards:  21% Completed | 214/1024 [00:04<00:17, 45.86it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:04<00:17, 45.31it/s]
Loading safetensors checkpoint shards:  22% Completed | 224/1024 [00:04<00:17, 45.35it/s]
Loading safetensors checkpoint shards:  22% Completed | 229/1024 [00:05<00:17, 45.44it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:05<00:17, 45.69it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:05<00:15, 49.62it/s]
Loading safetensors checkpoint shards:  24% Completed | 245/1024 [00:05<00:16, 48.07it/s]
Loading safetensors checkpoint shards:  25% Completed | 251/1024 [00:05<00:16, 47.49it/s]
Loading safetensors checkpoint shards:  25% Completed | 256/1024 [00:05<00:16, 45.69it/s]
Loading safetensors checkpoint shards:  26% Completed | 262/1024 [00:05<00:15, 47.70it/s]
Loading safetensors checkpoint shards:  26% Completed | 267/1024 [00:05<00:16, 44.95it/s]
Loading safetensors checkpoint shards:  27% Completed | 273/1024 [00:06<00:16, 45.32it/s]
Loading safetensors checkpoint shards:  27% Completed | 278/1024 [00:06<00:17, 41.79it/s]
Loading safetensors checkpoint shards:  28% Completed | 283/1024 [00:06<00:17, 42.51it/s]
Loading safetensors checkpoint shards:  28% Completed | 288/1024 [00:06<00:17, 41.40it/s]
Loading safetensors checkpoint shards:  29% Completed | 293/1024 [00:06<00:17, 41.45it/s]
Loading safetensors checkpoint shards:  29% Completed | 298/1024 [00:07<00:35, 20.45it/s]
Loading safetensors checkpoint shards:  30% Completed | 303/1024 [00:07<00:29, 24.04it/s]
Loading safetensors checkpoint shards:  30% Completed | 308/1024 [00:07<00:25, 28.01it/s]
Loading safetensors checkpoint shards:  30% Completed | 312/1024 [00:07<00:23, 30.14it/s]
Loading safetensors checkpoint shards:  31% Completed | 317/1024 [00:07<00:21, 33.28it/s]
Loading safetensors checkpoint shards:  31% Completed | 321/1024 [00:07<00:20, 33.80it/s]
Loading safetensors checkpoint shards:  32% Completed | 325/1024 [00:07<00:20, 34.94it/s]
Loading safetensors checkpoint shards:  32% Completed | 330/1024 [00:07<00:18, 38.11it/s]
Loading safetensors checkpoint shards:  33% Completed | 335/1024 [00:07<00:17, 39.24it/s]
Loading safetensors checkpoint shards:  33% Completed | 340/1024 [00:08<00:16, 41.26it/s]
Loading safetensors checkpoint shards:  34% Completed | 345/1024 [00:08<00:17, 39.24it/s]
Loading safetensors checkpoint shards:  34% Completed | 350/1024 [00:08<00:16, 40.70it/s]
Loading safetensors checkpoint shards:  35% Completed | 355/1024 [00:08<00:16, 40.32it/s]
Loading safetensors checkpoint shards:  35% Completed | 360/1024 [00:08<00:15, 42.12it/s]
Loading safetensors checkpoint shards:  36% Completed | 365/1024 [00:08<00:15, 41.36it/s]
Loading safetensors checkpoint shards:  36% Completed | 370/1024 [00:08<00:15, 41.64it/s]
Loading safetensors checkpoint shards:  37% Completed | 376/1024 [00:08<00:14, 44.38it/s]
Loading safetensors checkpoint shards:  37% Completed | 381/1024 [00:09<00:15, 42.28it/s]
Loading safetensors checkpoint shards:  38% Completed | 386/1024 [00:09<00:14, 44.21it/s]
Loading safetensors checkpoint shards:  38% Completed | 391/1024 [00:09<00:14, 43.32it/s]
Loading safetensors checkpoint shards:  39% Completed | 396/1024 [00:09<00:14, 44.33it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:09<00:14, 43.65it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:09<00:13, 44.34it/s]
Loading safetensors checkpoint shards:  40% Completed | 411/1024 [00:09<00:14, 43.14it/s]
Loading safetensors checkpoint shards:  41% Completed | 416/1024 [00:09<00:14, 42.65it/s]
Loading safetensors checkpoint shards:  41% Completed | 421/1024 [00:09<00:15, 39.19it/s]
Loading safetensors checkpoint shards:  42% Completed | 425/1024 [00:10<00:15, 38.58it/s]
Loading safetensors checkpoint shards:  42% Completed | 430/1024 [00:10<00:14, 40.01it/s]
Loading safetensors checkpoint shards:  42% Completed | 435/1024 [00:10<00:15, 38.14it/s]
Loading safetensors checkpoint shards:  43% Completed | 440/1024 [00:10<00:14, 39.53it/s]
Loading safetensors checkpoint shards:  43% Completed | 444/1024 [00:10<00:14, 39.36it/s]
Loading safetensors checkpoint shards:  44% Completed | 448/1024 [00:10<00:14, 39.46it/s]
Loading safetensors checkpoint shards:  44% Completed | 452/1024 [00:10<00:14, 39.00it/s]
Loading safetensors checkpoint shards:  45% Completed | 456/1024 [00:10<00:14, 38.13it/s]
Loading safetensors checkpoint shards:  45% Completed | 461/1024 [00:11<00:14, 39.66it/s]
Loading safetensors checkpoint shards:  45% Completed | 465/1024 [00:11<00:14, 37.69it/s]
Loading safetensors checkpoint shards:  46% Completed | 469/1024 [00:11<00:14, 37.12it/s]
Loading safetensors checkpoint shards:  46% Completed | 475/1024 [00:11<00:13, 41.13it/s]
Loading safetensors checkpoint shards:  47% Completed | 480/1024 [00:11<00:13, 40.47it/s]
Loading safetensors checkpoint shards:  47% Completed | 485/1024 [00:11<00:12, 41.70it/s]
Loading safetensors checkpoint shards:  48% Completed | 490/1024 [00:11<00:13, 39.41it/s]
Loading safetensors checkpoint shards:  48% Completed | 495/1024 [00:11<00:12, 41.29it/s]
Loading safetensors checkpoint shards:  49% Completed | 500/1024 [00:11<00:12, 41.64it/s]
Loading safetensors checkpoint shards:  49% Completed | 505/1024 [00:12<00:12, 41.06it/s]
Loading safetensors checkpoint shards:  50% Completed | 510/1024 [00:12<00:12, 40.90it/s]
Loading safetensors checkpoint shards:  50% Completed | 516/1024 [00:12<00:11, 45.80it/s]
Loading safetensors checkpoint shards:  51% Completed | 521/1024 [00:12<00:11, 44.94it/s]
Loading safetensors checkpoint shards:  52% Completed | 528/1024 [00:12<00:09, 50.53it/s]
Loading safetensors checkpoint shards:  52% Completed | 534/1024 [00:13<00:22, 21.95it/s]
Loading safetensors checkpoint shards:  53% Completed | 540/1024 [00:13<00:18, 26.81it/s]
Loading safetensors checkpoint shards:  53% Completed | 545/1024 [00:13<00:15, 30.36it/s]
Loading safetensors checkpoint shards:  54% Completed | 553/1024 [00:13<00:12, 38.80it/s]
Loading safetensors checkpoint shards:  55% Completed | 559/1024 [00:13<00:10, 42.70it/s]
Loading safetensors checkpoint shards:  55% Completed | 565/1024 [00:13<00:10, 44.61it/s]
Loading safetensors checkpoint shards:  56% Completed | 571/1024 [00:13<00:09, 48.14it/s]
Loading safetensors checkpoint shards:  56% Completed | 577/1024 [00:13<00:10, 44.16it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:14<00:08, 51.75it/s]
Loading safetensors checkpoint shards:  58% Completed | 591/1024 [00:14<00:08, 53.58it/s]
Loading safetensors checkpoint shards:  58% Completed | 598/1024 [00:14<00:07, 56.52it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:14<00:07, 59.36it/s]
Loading safetensors checkpoint shards:  60% Completed | 613/1024 [00:14<00:07, 58.10it/s]
Loading safetensors checkpoint shards:  60% Completed | 619/1024 [00:14<00:07, 56.25it/s]
Loading safetensors checkpoint shards:  61% Completed | 625/1024 [00:14<00:08, 49.58it/s]
Loading safetensors checkpoint shards:  62% Completed | 631/1024 [00:14<00:08, 45.83it/s]
Loading safetensors checkpoint shards:  62% Completed | 636/1024 [00:15<00:08, 44.80it/s]
Loading safetensors checkpoint shards:  63% Completed | 641/1024 [00:15<00:08, 43.46it/s]
Loading safetensors checkpoint shards:  63% Completed | 646/1024 [00:15<00:09, 41.69it/s]
Loading safetensors checkpoint shards:  64% Completed | 652/1024 [00:15<00:08, 43.65it/s]
Loading safetensors checkpoint shards:  64% Completed | 657/1024 [00:15<00:08, 43.62it/s]
Loading safetensors checkpoint shards:  65% Completed | 662/1024 [00:15<00:08, 42.49it/s]
Loading safetensors checkpoint shards:  65% Completed | 668/1024 [00:15<00:07, 46.93it/s]
Loading safetensors checkpoint shards:  66% Completed | 674/1024 [00:15<00:06, 50.01it/s]
Loading safetensors checkpoint shards:  66% Completed | 680/1024 [00:16<00:07, 48.79it/s]
Loading safetensors checkpoint shards:  67% Completed | 686/1024 [00:16<00:06, 51.48it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:16<00:05, 56.68it/s]
Loading safetensors checkpoint shards:  68% Completed | 700/1024 [00:16<00:05, 56.64it/s]
Loading safetensors checkpoint shards:  69% Completed | 706/1024 [00:16<00:05, 56.70it/s]
Loading safetensors checkpoint shards:  70% Completed | 712/1024 [00:16<00:05, 56.61it/s]
Loading safetensors checkpoint shards:  70% Completed | 718/1024 [00:16<00:05, 57.47it/s]
Loading safetensors checkpoint shards:  71% Completed | 725/1024 [00:16<00:05, 58.92it/s]
Loading safetensors checkpoint shards:  71% Completed | 731/1024 [00:16<00:05, 53.42it/s]
Loading safetensors checkpoint shards:  72% Completed | 737/1024 [00:17<00:05, 53.84it/s]
Loading safetensors checkpoint shards:  73% Completed | 743/1024 [00:17<00:12, 22.24it/s]
Loading safetensors checkpoint shards:  73% Completed | 750/1024 [00:17<00:09, 28.55it/s]
Loading safetensors checkpoint shards:  74% Completed | 757/1024 [00:17<00:07, 35.15it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:18<00:06, 39.73it/s]
Loading safetensors checkpoint shards:  75% Completed | 771/1024 [00:18<00:05, 47.19it/s]
Loading safetensors checkpoint shards:  76% Completed | 778/1024 [00:18<00:04, 51.65it/s]
Loading safetensors checkpoint shards:  77% Completed | 785/1024 [00:18<00:04, 53.41it/s]
Loading safetensors checkpoint shards:  77% Completed | 793/1024 [00:18<00:03, 58.59it/s]
Loading safetensors checkpoint shards:  78% Completed | 801/1024 [00:18<00:03, 63.40it/s]
Loading safetensors checkpoint shards:  79% Completed | 808/1024 [00:18<00:03, 61.29it/s]
Loading safetensors checkpoint shards:  80% Completed | 815/1024 [00:18<00:03, 59.82it/s]
Loading safetensors checkpoint shards:  80% Completed | 822/1024 [00:18<00:03, 55.34it/s]
Loading safetensors checkpoint shards:  81% Completed | 828/1024 [00:19<00:03, 55.21it/s]
Loading safetensors checkpoint shards:  81% Completed | 834/1024 [00:19<00:03, 56.35it/s]
Loading safetensors checkpoint shards:  82% Completed | 841/1024 [00:19<00:03, 58.07it/s]
Loading safetensors checkpoint shards:  83% Completed | 847/1024 [00:19<00:03, 55.48it/s]
Loading safetensors checkpoint shards:  83% Completed | 853/1024 [00:19<00:03, 53.66it/s]
Loading safetensors checkpoint shards:  84% Completed | 859/1024 [00:19<00:03, 50.45it/s]
Loading safetensors checkpoint shards:  84% Completed | 865/1024 [00:19<00:03, 50.03it/s]
Loading safetensors checkpoint shards:  85% Completed | 871/1024 [00:19<00:03, 47.87it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:20<00:03, 46.88it/s]
Loading safetensors checkpoint shards:  86% Completed | 882/1024 [00:20<00:02, 47.52it/s]
Loading safetensors checkpoint shards:  87% Completed | 887/1024 [00:20<00:02, 46.48it/s]
Loading safetensors checkpoint shards:  87% Completed | 892/1024 [00:20<00:03, 43.21it/s]
Loading safetensors checkpoint shards:  88% Completed | 897/1024 [00:20<00:02, 43.48it/s]
Loading safetensors checkpoint shards:  88% Completed | 902/1024 [00:20<00:02, 44.82it/s]
Loading safetensors checkpoint shards:  89% Completed | 907/1024 [00:20<00:02, 46.04it/s]
Loading safetensors checkpoint shards:  89% Completed | 913/1024 [00:20<00:02, 47.80it/s]
Loading safetensors checkpoint shards:  90% Completed | 919/1024 [00:20<00:02, 49.48it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:21<00:02, 47.89it/s]
Loading safetensors checkpoint shards:  91% Completed | 929/1024 [00:21<00:01, 47.87it/s]
Loading safetensors checkpoint shards:  91% Completed | 934/1024 [00:21<00:01, 46.12it/s]
Loading safetensors checkpoint shards:  92% Completed | 939/1024 [00:21<00:01, 46.42it/s]
Loading safetensors checkpoint shards:  92% Completed | 944/1024 [00:21<00:01, 45.88it/s]
Loading safetensors checkpoint shards:  93% Completed | 950/1024 [00:21<00:01, 49.35it/s]
Loading safetensors checkpoint shards:  93% Completed | 956/1024 [00:21<00:01, 49.56it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:21<00:01, 47.57it/s]
Loading safetensors checkpoint shards:  94% Completed | 966/1024 [00:21<00:01, 48.08it/s]
Loading safetensors checkpoint shards:  95% Completed | 972/1024 [00:22<00:03, 16.82it/s]
Loading safetensors checkpoint shards:  95% Completed | 977/1024 [00:22<00:02, 20.52it/s]
Loading safetensors checkpoint shards:  96% Completed | 981/1024 [00:22<00:01, 23.10it/s]
Loading safetensors checkpoint shards:  97% Completed | 989/1024 [00:23<00:01, 32.50it/s]
Loading safetensors checkpoint shards:  97% Completed | 998/1024 [00:23<00:00, 42.86it/s]
Loading safetensors checkpoint shards:  98% Completed | 1008/1024 [00:23<00:00, 53.13it/s]
Loading safetensors checkpoint shards:  99% Completed | 1015/1024 [00:23<00:00, 55.79it/s]
Loading safetensors checkpoint shards: 100% Completed | 1022/1024 [00:23<00:00, 56.68it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:23<00:00, 43.47it/s]

[2025-09-13 06:42:24 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 06:42:24 TP1] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 06:42:24 TP6] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 06:42:24 TP0] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 06:42:24 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 06:42:24 TP7] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 06:42:24 TP2] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 06:42:24 TP4] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 06:42:24 TP3] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 06:42:24 TP5] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 06:42:24 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 06:42:24 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.53 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 06:42:25 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:42:25 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 06:42:25 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:42:25 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:42:25 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:42:26 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:42:26 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:42:26 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:42:26 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25265.40it/s]
[2025-09-13 06:42:26 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:42:26 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25289.80it/s]
[2025-09-13 06:42:27 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:42:27 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26111.47it/s]
[2025-09-13 06:42:27 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:42:27 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26690.28it/s]
[2025-09-13 06:42:28 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:42:28 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27890.25it/s]
[2025-09-13 06:42:29 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.22 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.87it/s][2025-09-13 06:42:32 TP7] Registering 984 cuda graph addresses
[2025-09-13 06:42:32 TP4] Registering 984 cuda graph addresses
[2025-09-13 06:42:32 TP3] Registering 984 cuda graph addresses
[2025-09-13 06:42:32 TP2] Registering 984 cuda graph addresses
[2025-09-13 06:42:32 TP5] Registering 984 cuda graph addresses
[2025-09-13 06:42:32 TP6] Registering 984 cuda graph addresses
[2025-09-13 06:42:32 TP1] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.22 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.11it/s]
[2025-09-13 06:42:32 TP0] Registering 984 cuda graph addresses
[2025-09-13 06:42:32 TP0] Capture cuda graph end. Time elapsed: 7.87 s. mem usage=0.36 GB. avail mem=17.20 GB.
[2025-09-13 06:42:32 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 06:42:32 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:42:32 TP0] Init torch distributed begin.
[2025-09-13 06:42:32 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 06:42:32 TP0] Load weight begin. avail mem=17.20 GB
[2025-09-13 06:42:32 TP0] Detected fp8 checkpoint.
[2025-09-13 06:42:32 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 172.40it/s]
Loading safetensors checkpoint shards:   4% Completed | 44/1024 [00:00<00:04, 221.00it/s]
Loading safetensors checkpoint shards:  10% Completed | 106/1024 [00:00<00:02, 399.45it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:00<00:01, 469.38it/s]
Loading safetensors checkpoint shards:  22% Completed | 223/1024 [00:00<00:01, 512.17it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:00<00:01, 545.89it/s]
Loading safetensors checkpoint shards:  33% Completed | 343/1024 [00:00<00:01, 556.29it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:00<00:01, 561.16it/s]
Loading safetensors checkpoint shards:  45% Completed | 461/1024 [00:00<00:00, 570.30it/s]
Loading safetensors checkpoint shards:  51% Completed | 521/1024 [00:01<00:00, 577.59it/s]
Loading safetensors checkpoint shards:  57% Completed | 579/1024 [00:01<00:00, 557.08it/s]
Loading safetensors checkpoint shards:  62% Completed | 640/1024 [00:01<00:00, 571.07it/s]
Loading safetensors checkpoint shards:  68% Completed | 698/1024 [00:01<00:00, 571.27it/s]
Loading safetensors checkpoint shards:  74% Completed | 756/1024 [00:01<00:00, 571.53it/s]
Loading safetensors checkpoint shards:  79% Completed | 814/1024 [00:01<00:00, 562.90it/s]
Loading safetensors checkpoint shards:  85% Completed | 873/1024 [00:01<00:00, 568.95it/s]
Loading safetensors checkpoint shards:  91% Completed | 932/1024 [00:01<00:00, 572.70it/s]
Loading safetensors checkpoint shards:  97% Completed | 990/1024 [00:01<00:00, 501.73it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 495.21it/s]

[2025-09-13 06:42:35 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.21 GB, mem usage=1.99 GB.
[2025-09-13 06:42:35 TP7] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 06:42:35 TP5] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 06:42:35 TP3] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 06:42:35 TP0] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 06:42:35 TP2] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 06:42:35 TP4] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 06:42:35 TP1] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 06:42:35 TP0] Memory pool end. avail mem=14.54 GB
[2025-09-13 06:42:35 TP6] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 06:42:35 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:42:35 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 06:42:35 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:42:35 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:42:35 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:42:35 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:42:35 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:42:35 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.17 GB
Capturing batches (bs=1 avail_mem=14.66 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:03<00:00,  3.91it/s][2025-09-13 06:42:41 TP2] Registering 48 cuda graph addresses
[2025-09-13 06:42:41 TP5] Registering 48 cuda graph addresses
[2025-09-13 06:42:41 TP4] Registering 48 cuda graph addresses
[2025-09-13 06:42:41 TP3] Registering 48 cuda graph addresses
[2025-09-13 06:42:41 TP7] Registering 48 cuda graph addresses
[2025-09-13 06:42:41 TP1] Registering 48 cuda graph addresses
[2025-09-13 06:42:41 TP6] Registering 48 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.66 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.49it/s]
[2025-09-13 06:42:41 TP0] Registering 48 cuda graph addresses
[2025-09-13 06:42:41 TP5] Capture draft cuda graph end. Time elapsed: 6.23 s. mem usage=0.31 GB. avail mem=14.62 GB.
[2025-09-13 06:42:41 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.62 GB
[2025-09-13 06:42:41 TP1] Capture draft cuda graph end. Time elapsed: 6.23 s. mem usage=0.31 GB. avail mem=14.62 GB.
[2025-09-13 06:42:41 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.62 GB
[2025-09-13 06:42:41 TP7] Capture draft cuda graph end. Time elapsed: 6.23 s. mem usage=0.31 GB. avail mem=14.86 GB.
[2025-09-13 06:42:41 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.86 GB
[2025-09-13 06:42:41 TP2] Capture draft cuda graph end. Time elapsed: 6.23 s. mem usage=0.31 GB. avail mem=14.62 GB.
[2025-09-13 06:42:41 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.62 GB
[2025-09-13 06:42:41 TP3] Capture draft cuda graph end. Time elapsed: 6.23 s. mem usage=0.31 GB. avail mem=14.62 GB.
[2025-09-13 06:42:41 TP4] Capture draft cuda graph end. Time elapsed: 6.23 s. mem usage=0.31 GB. avail mem=14.62 GB.
[2025-09-13 06:42:41 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.62 GB
[2025-09-13 06:42:41 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.62 GB
[2025-09-13 06:42:41 TP6] Capture draft cuda graph end. Time elapsed: 6.23 s. mem usage=0.31 GB. avail mem=14.62 GB.
[2025-09-13 06:42:41 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.62 GB
[2025-09-13 06:42:41 TP0] Capture draft cuda graph end. Time elapsed: 6.23 s. mem usage=0.31 GB. avail mem=14.66 GB.
[2025-09-13 06:42:41 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.66 GB
Capturing batches (bs=1 avail_mem=14.47 GB):  50%|███████████████████████████████████████████                                           | 4/8 [00:00<00:00, 39.25it/s][2025-09-13 06:42:42 TP2] Registering 24 cuda graph addresses
[2025-09-13 06:42:42 TP7] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.47 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 44.04it/s]
[2025-09-13 06:42:42 TP1] Registering 24 cuda graph addresses
[2025-09-13 06:42:42 TP3] Registering 24 cuda graph addresses
[2025-09-13 06:42:42 TP4] Registering 24 cuda graph addresses
[2025-09-13 06:42:42 TP5] Registering 24 cuda graph addresses
[2025-09-13 06:42:42 TP0] Registering 24 cuda graph addresses
[2025-09-13 06:42:42 TP6] Registering 24 cuda graph addresses
[2025-09-13 06:42:42 TP6] Capture draft extend cuda graph end. Time elapsed: 1.07 s. mem usage=0.19 GB. avail mem=14.43 GB.
[2025-09-13 06:42:42 TP3] Capture draft extend cuda graph end. Time elapsed: 1.07 s. mem usage=0.19 GB. avail mem=14.43 GB.
[2025-09-13 06:42:42 TP7] Capture draft extend cuda graph end. Time elapsed: 1.07 s. mem usage=0.19 GB. avail mem=14.67 GB.
[2025-09-13 06:42:42 TP4] Capture draft extend cuda graph end. Time elapsed: 1.07 s. mem usage=0.19 GB. avail mem=14.43 GB.
[2025-09-13 06:42:42 TP1] Capture draft extend cuda graph end. Time elapsed: 1.07 s. mem usage=0.19 GB. avail mem=14.43 GB.
[2025-09-13 06:42:42 TP2] Capture draft extend cuda graph end. Time elapsed: 1.07 s. mem usage=0.19 GB. avail mem=14.43 GB.
[2025-09-13 06:42:42 TP0] Capture draft extend cuda graph end. Time elapsed: 1.07 s. mem usage=0.19 GB. avail mem=14.47 GB.
[2025-09-13 06:42:42 TP5] Capture draft extend cuda graph end. Time elapsed: 1.08 s. mem usage=0.19 GB. avail mem=14.43 GB.
[2025-09-13 06:42:42 TP0] max_total_num_tokens=620161, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.47 GB
[2025-09-13 06:42:43] INFO:     Started server process [141861]
[2025-09-13 06:42:43] INFO:     Waiting for application startup.
[2025-09-13 06:42:43] INFO:     Application startup complete.
[2025-09-13 06:42:43] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 06:42:44] INFO:     127.0.0.1:33818 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 06:42:44 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:42:44 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:42:44 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup:  47%|████████████████████████████████████████████████▌                                                       | 7647/16384 [00:00<00:00, 26650.20it/s][2025-09-13 06:42:44] INFO:     127.0.0.1:33830 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28049.34it/s]
[2025-09-13 06:42:45] INFO:     127.0.0.1:33820 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:42:45] The server is fired up and ready to roll!
[2025-09-13 06:42:54 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:42:55] INFO:     127.0.0.1:46132 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:42:56] INFO:     127.0.0.1:46138 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:42:56 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 06:42:57] INFO:     127.0.0.1:46140 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:42:57] INFO:     127.0.0.1:46148 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:42:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:42:57] INFO:     127.0.0.1:46154 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:42:57] INFO:     127.0.0.1:46158 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:42:57] INFO:     127.0.0.1:46172 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:42:57] INFO:     127.0.0.1:46182 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:42:57] INFO:     127.0.0.1:46198 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:42:57] INFO:     127.0.0.1:46214 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:42:57 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 06:42:58 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:42:58 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:42:58 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:42:58 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:42:58 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:42:58 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:42:58 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:42:58 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:42:58 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 06:42:59 TP0] Decode batch. #running-req: 8, #token: 14458, token usage: 0.02, accept len: 2.58, cuda graph: True, gen throughput (token/s): 35.02, #queue-req: 0, 
[2025-09-13 06:43:00 TP0] Decode batch. #running-req: 8, #token: 15377, token usage: 0.02, accept len: 2.87, cuda graph: True, gen throughput (token/s): 797.15, #queue-req: 0, 
[2025-09-13 06:43:01 TP0] Decode batch. #running-req: 8, #token: 16362, token usage: 0.03, accept len: 3.08, cuda graph: True, gen throughput (token/s): 848.60, #queue-req: 0, 
[2025-09-13 06:43:02 TP0] Decode batch. #running-req: 8, #token: 17329, token usage: 0.03, accept len: 3.02, cuda graph: True, gen throughput (token/s): 833.77, #queue-req: 0, 
 75%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 6/8 [00:06<00:01,  1.84it/s][2025-09-13 06:43:03 TP0] Decode batch. #running-req: 2, #token: 1459, token usage: 0.00, accept len: 3.04, cuda graph: True, gen throughput (token/s): 517.72, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.23it/s]
[2025-09-13 06:43:04] INFO:     127.0.0.1:40530 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.49      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4068      
Request throughput (req/s):              1.23      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         631.32    
Total token throughput (tok/s):          631.32    
Concurrency:                             7.11      
Accept length:                           2.93      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5766.51   
Median E2E Latency (ms):                 5736.61   
---------------Time to First Token----------------
Mean TTFT (ms):                          606.59    
Median TTFT (ms):                        716.87    
P99 TTFT (ms):                           717.35    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.10     
Median ITL (ms):                         7.27      
P95 ITL (ms):                            27.47     
P99 ITL (ms):                            29.29     
Max ITL (ms):                            725.51    
==================================================
[2025-09-13 06:43:04] INFO:     127.0.0.1:40542 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:43:04] INFO:     127.0.0.1:40554 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:43:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 06:43:05] INFO:     127.0.0.1:40560 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:43:05] INFO:     127.0.0.1:40576 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:43:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:43:05] INFO:     127.0.0.1:40588 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:43:05] INFO:     127.0.0.1:40594 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:43:05] INFO:     127.0.0.1:40610 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:43:05] INFO:     127.0.0.1:40616 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:43:05] INFO:     127.0.0.1:40620 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:43:05] INFO:     127.0.0.1:40630 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:43:05 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 06:43:05 TP0] Decode batch. #running-req: 8, #token: 14136, token usage: 0.02, accept len: 2.61, cuda graph: True, gen throughput (token/s): 139.11, #queue-req: 0, 
[2025-09-13 06:43:07 TP0] Decode batch. #running-req: 8, #token: 15028, token usage: 0.02, accept len: 2.79, cuda graph: True, gen throughput (token/s): 792.10, #queue-req: 0, 
[2025-09-13 06:43:08 TP0] Decode batch. #running-req: 8, #token: 16008, token usage: 0.03, accept len: 3.06, cuda graph: True, gen throughput (token/s): 838.09, #queue-req: 0, 
[2025-09-13 06:43:09 TP0] Decode batch. #running-req: 8, #token: 17001, token usage: 0.03, accept len: 3.10, cuda graph: True, gen throughput (token/s): 848.83, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:08,  4.59s/it][2025-09-13 06:43:09] INFO:     127.0.0.1:53358 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:43:10 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:05<00:29,  2.13s/it][2025-09-13 06:43:10] INFO:     127.0.0.1:53374 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:43:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:16,  1.28s/it][2025-09-13 06:43:10] INFO:     127.0.0.1:53388 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:43:10 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.10it/s][2025-09-13 06:43:11] INFO:     127.0.0.1:53392 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:43:11 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:43:11 TP0] Decode batch. #running-req: 8, #token: 10767, token usage: 0.02, accept len: 2.98, cuda graph: True, gen throughput (token/s): 530.94, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:07,  1.43it/s][2025-09-13 06:43:11] INFO:     127.0.0.1:53406 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:43:11 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:06<00:05,  1.70it/s][2025-09-13 06:43:11] INFO:     127.0.0.1:53408 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:43:11] INFO:     127.0.0.1:53410 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:43:11 TP0] Prefill batch. #new-seq: 2, #new-token: 2369, #cached-token: 1751, token usage: 0.01, #running-req: 6, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:03,  2.24it/s][2025-09-13 06:43:12] INFO:     127.0.0.1:53426 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:43:12 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:43:12 TP0] Decode batch. #running-req: 8, #token: 14288, token usage: 0.02, accept len: 2.81, cuda graph: True, gen throughput (token/s): 526.52, #queue-req: 0, 
[2025-09-13 06:43:14 TP0] Decode batch. #running-req: 8, #token: 15181, token usage: 0.02, accept len: 2.79, cuda graph: True, gen throughput (token/s): 782.86, #queue-req: 0, 
[2025-09-13 06:43:15 TP0] Decode batch. #running-req: 8, #token: 16233, token usage: 0.03, accept len: 3.29, cuda graph: True, gen throughput (token/s): 920.04, #queue-req: 0, 
 75%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                | 12/16 [00:10<00:02,  1.57it/s][2025-09-13 06:43:16 TP0] Decode batch. #running-req: 4, #token: 9435, token usage: 0.02, accept len: 3.27, cuda graph: True, gen throughput (token/s): 809.23, #queue-req: 0, 
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 14/16 [00:11<00:01,  1.87it/s][2025-09-13 06:43:17 TP0] Decode batch. #running-req: 2, #token: 4234, token usage: 0.01, accept len: 2.80, cuda graph: True, gen throughput (token/s): 464.82, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.34it/s]
[2025-09-13 06:43:17] INFO:     127.0.0.1:53428 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.94     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8121      
Request throughput (req/s):              1.34      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         686.12    
Total token throughput (tok/s):          686.12    
Concurrency:                             7.42      
Accept length:                           2.96      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5535.70   
Median E2E Latency (ms):                 5539.49   
---------------Time to First Token----------------
Mean TTFT (ms):                          218.05    
Median TTFT (ms):                        232.50    
P99 TTFT (ms):                           273.76    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.41     
Median ITL (ms):                         7.26      
P95 ITL (ms):                            28.37     
P99 ITL (ms):                            53.63     
Max ITL (ms):                            263.11    
==================================================
[2025-09-13 06:43:17] INFO:     127.0.0.1:53430 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=3: batch_size=8, steps=3, topk=3, num_draft_tokens=4, speed=103.45 token/s, step_time=28.63 ms
Start i=4: batch_size=8, steps=3, topk=3, num_draft_tokens=6
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 3 --speculative-eagle-topk 3 --speculative-num-draft-tokens 6 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:43:28.139000 147451 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:43:28.139000 147451 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 06:43:28] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=637804341, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=3, speculative_eagle_topk=3, speculative_num_draft_tokens=6, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:43:28] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:43:37.375000 147693 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:43:37.375000 147693 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:43:37.505000 147691 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:43:37.505000 147691 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:43:37.549000 147689 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:43:37.549000 147689 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 06:43:37.667000 147686 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:43:37.667000 147686 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:43:37.703000 147692 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:43:37.703000 147692 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:43:37.754000 147688 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:43:37.754000 147688 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:43:37.774000 147687 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:43:37.774000 147687 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:43:37.847000 147690 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:43:37.847000 147690 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:43:37.848000 147694 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:43:37.848000 147694 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:43:38 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 06:43:38 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:43:38 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:43:40 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:43:42 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 06:43:44 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 06:43:44 TP0] Detected fp8 checkpoint.
[2025-09-13 06:43:44 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 22/1024 [00:00<00:05, 175.45it/s]
Loading safetensors checkpoint shards:   4% Completed | 40/1024 [00:00<00:13, 71.88it/s]
Loading safetensors checkpoint shards:   5% Completed | 51/1024 [00:00<00:13, 70.09it/s]
Loading safetensors checkpoint shards:   6% Completed | 60/1024 [00:00<00:14, 68.05it/s]
Loading safetensors checkpoint shards:   7% Completed | 68/1024 [00:01<00:17, 53.84it/s]
Loading safetensors checkpoint shards:   7% Completed | 75/1024 [00:01<00:18, 51.49it/s]
Loading safetensors checkpoint shards:   8% Completed | 81/1024 [00:01<00:17, 52.63it/s]
Loading safetensors checkpoint shards:   8% Completed | 87/1024 [00:01<00:20, 46.67it/s]
Loading safetensors checkpoint shards:   9% Completed | 92/1024 [00:01<00:23, 39.06it/s]
Loading safetensors checkpoint shards:   9% Completed | 97/1024 [00:01<00:23, 38.83it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:02<00:38, 23.84it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:02<00:34, 26.91it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:31, 28.98it/s]
Loading safetensors checkpoint shards:  11% Completed | 116/1024 [00:02<00:27, 32.71it/s]
Loading safetensors checkpoint shards:  12% Completed | 121/1024 [00:02<00:25, 35.93it/s]
Loading safetensors checkpoint shards:  12% Completed | 127/1024 [00:02<00:22, 39.70it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:02<00:22, 40.02it/s]
Loading safetensors checkpoint shards:  13% Completed | 138/1024 [00:03<00:19, 44.41it/s]
Loading safetensors checkpoint shards:  14% Completed | 143/1024 [00:03<00:19, 44.41it/s]
Loading safetensors checkpoint shards:  14% Completed | 148/1024 [00:03<00:20, 43.09it/s]
Loading safetensors checkpoint shards:  15% Completed | 154/1024 [00:03<00:18, 47.35it/s]
Loading safetensors checkpoint shards:  16% Completed | 159/1024 [00:03<00:18, 46.48it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:03<00:18, 45.82it/s]
Loading safetensors checkpoint shards:  17% Completed | 169/1024 [00:03<00:18, 46.28it/s]
Loading safetensors checkpoint shards:  17% Completed | 174/1024 [00:03<00:18, 46.46it/s]
Loading safetensors checkpoint shards:  17% Completed | 179/1024 [00:03<00:19, 44.30it/s]
Loading safetensors checkpoint shards:  18% Completed | 185/1024 [00:04<00:18, 46.06it/s]
Loading safetensors checkpoint shards:  19% Completed | 190/1024 [00:04<00:18, 45.42it/s]
Loading safetensors checkpoint shards:  19% Completed | 196/1024 [00:04<00:17, 46.83it/s]
Loading safetensors checkpoint shards:  20% Completed | 201/1024 [00:04<00:17, 46.29it/s]
Loading safetensors checkpoint shards:  20% Completed | 206/1024 [00:04<00:17, 45.61it/s]
Loading safetensors checkpoint shards:  21% Completed | 211/1024 [00:04<00:18, 45.08it/s]
Loading safetensors checkpoint shards:  21% Completed | 217/1024 [00:04<00:17, 46.58it/s]
Loading safetensors checkpoint shards:  22% Completed | 222/1024 [00:04<00:17, 44.76it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:04<00:17, 45.14it/s]
Loading safetensors checkpoint shards:  23% Completed | 232/1024 [00:05<00:17, 45.01it/s]
Loading safetensors checkpoint shards:  23% Completed | 237/1024 [00:05<00:17, 46.03it/s]
Loading safetensors checkpoint shards:  24% Completed | 242/1024 [00:05<00:17, 44.78it/s]
Loading safetensors checkpoint shards:  24% Completed | 247/1024 [00:05<00:17, 44.58it/s]
Loading safetensors checkpoint shards:  25% Completed | 253/1024 [00:05<00:16, 46.98it/s]
Loading safetensors checkpoint shards:  25% Completed | 258/1024 [00:05<00:16, 45.83it/s]
Loading safetensors checkpoint shards:  26% Completed | 263/1024 [00:05<00:16, 46.96it/s]
Loading safetensors checkpoint shards:  26% Completed | 268/1024 [00:05<00:16, 46.33it/s]
Loading safetensors checkpoint shards:  27% Completed | 274/1024 [00:05<00:15, 47.63it/s]
Loading safetensors checkpoint shards:  27% Completed | 279/1024 [00:06<00:16, 45.63it/s]
Loading safetensors checkpoint shards:  28% Completed | 284/1024 [00:06<00:15, 46.58it/s]
Loading safetensors checkpoint shards:  28% Completed | 289/1024 [00:06<00:16, 45.37it/s]
Loading safetensors checkpoint shards:  29% Completed | 294/1024 [00:06<00:15, 46.08it/s]
Loading safetensors checkpoint shards:  29% Completed | 299/1024 [00:06<00:30, 23.39it/s]
Loading safetensors checkpoint shards:  30% Completed | 304/1024 [00:07<00:26, 27.57it/s]
Loading safetensors checkpoint shards:  30% Completed | 308/1024 [00:07<00:24, 29.69it/s]
Loading safetensors checkpoint shards:  31% Completed | 313/1024 [00:07<00:21, 33.02it/s]
Loading safetensors checkpoint shards:  31% Completed | 319/1024 [00:07<00:18, 37.88it/s]
Loading safetensors checkpoint shards:  32% Completed | 324/1024 [00:07<00:18, 38.60it/s]
Loading safetensors checkpoint shards:  32% Completed | 329/1024 [00:07<00:16, 41.35it/s]
Loading safetensors checkpoint shards:  33% Completed | 334/1024 [00:07<00:16, 41.69it/s]
Loading safetensors checkpoint shards:  33% Completed | 339/1024 [00:07<00:15, 43.82it/s]
Loading safetensors checkpoint shards:  34% Completed | 344/1024 [00:07<00:15, 42.57it/s]
Loading safetensors checkpoint shards:  34% Completed | 349/1024 [00:08<00:15, 42.87it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:08<00:15, 41.99it/s]
Loading safetensors checkpoint shards:  35% Completed | 359/1024 [00:08<00:15, 42.75it/s]
Loading safetensors checkpoint shards:  36% Completed | 364/1024 [00:08<00:15, 42.90it/s]
Loading safetensors checkpoint shards:  36% Completed | 369/1024 [00:08<00:15, 41.59it/s]
Loading safetensors checkpoint shards:  37% Completed | 374/1024 [00:08<00:15, 42.97it/s]
Loading safetensors checkpoint shards:  37% Completed | 379/1024 [00:08<00:15, 41.56it/s]
Loading safetensors checkpoint shards:  38% Completed | 384/1024 [00:08<00:14, 42.91it/s]
Loading safetensors checkpoint shards:  38% Completed | 389/1024 [00:08<00:15, 41.26it/s]
Loading safetensors checkpoint shards:  38% Completed | 394/1024 [00:09<00:14, 42.25it/s]
Loading safetensors checkpoint shards:  39% Completed | 399/1024 [00:09<00:15, 41.63it/s]
Loading safetensors checkpoint shards:  39% Completed | 404/1024 [00:09<00:14, 43.72it/s]
Loading safetensors checkpoint shards:  40% Completed | 409/1024 [00:09<00:14, 43.09it/s]
Loading safetensors checkpoint shards:  40% Completed | 414/1024 [00:09<00:14, 43.42it/s]
Loading safetensors checkpoint shards:  41% Completed | 419/1024 [00:09<00:13, 43.72it/s]
Loading safetensors checkpoint shards:  41% Completed | 424/1024 [00:09<00:13, 43.09it/s]
Loading safetensors checkpoint shards:  42% Completed | 429/1024 [00:09<00:13, 44.89it/s]
Loading safetensors checkpoint shards:  42% Completed | 434/1024 [00:10<00:13, 43.00it/s]
Loading safetensors checkpoint shards:  43% Completed | 439/1024 [00:10<00:13, 44.65it/s]
Loading safetensors checkpoint shards:  43% Completed | 444/1024 [00:10<00:13, 43.77it/s]
Loading safetensors checkpoint shards:  44% Completed | 449/1024 [00:10<00:13, 44.18it/s]
Loading safetensors checkpoint shards:  44% Completed | 454/1024 [00:10<00:13, 43.42it/s]
Loading safetensors checkpoint shards:  45% Completed | 459/1024 [00:10<00:12, 44.28it/s]
Loading safetensors checkpoint shards:  45% Completed | 464/1024 [00:10<00:13, 42.53it/s]
Loading safetensors checkpoint shards:  46% Completed | 469/1024 [00:10<00:13, 42.20it/s]
Loading safetensors checkpoint shards:  46% Completed | 475/1024 [00:10<00:11, 46.40it/s]
Loading safetensors checkpoint shards:  47% Completed | 480/1024 [00:11<00:11, 45.49it/s]
Loading safetensors checkpoint shards:  47% Completed | 485/1024 [00:11<00:11, 46.37it/s]
Loading safetensors checkpoint shards:  48% Completed | 490/1024 [00:11<00:12, 43.65it/s]
Loading safetensors checkpoint shards:  48% Completed | 495/1024 [00:11<00:11, 45.29it/s]
Loading safetensors checkpoint shards:  49% Completed | 500/1024 [00:11<00:11, 44.42it/s]
Loading safetensors checkpoint shards:  49% Completed | 505/1024 [00:11<00:11, 44.56it/s]
Loading safetensors checkpoint shards:  50% Completed | 510/1024 [00:11<00:11, 44.01it/s]
Loading safetensors checkpoint shards:  50% Completed | 516/1024 [00:11<00:11, 45.37it/s]
Loading safetensors checkpoint shards:  51% Completed | 521/1024 [00:11<00:11, 43.29it/s]
Loading safetensors checkpoint shards:  51% Completed | 526/1024 [00:12<00:11, 44.74it/s]
Loading safetensors checkpoint shards:  52% Completed | 531/1024 [00:12<00:11, 44.45it/s]
Loading safetensors checkpoint shards:  52% Completed | 536/1024 [00:12<00:11, 42.58it/s]
Loading safetensors checkpoint shards:  53% Completed | 542/1024 [00:12<00:21, 22.12it/s]
Loading safetensors checkpoint shards:  53% Completed | 546/1024 [00:12<00:19, 24.72it/s]
Loading safetensors checkpoint shards:  54% Completed | 552/1024 [00:13<00:15, 29.74it/s]
Loading safetensors checkpoint shards:  54% Completed | 557/1024 [00:13<00:14, 32.69it/s]
Loading safetensors checkpoint shards:  55% Completed | 562/1024 [00:13<00:12, 35.58it/s]
Loading safetensors checkpoint shards:  55% Completed | 567/1024 [00:13<00:12, 37.08it/s]
Loading safetensors checkpoint shards:  56% Completed | 572/1024 [00:13<00:11, 39.28it/s]
Loading safetensors checkpoint shards:  56% Completed | 577/1024 [00:13<00:11, 38.42it/s]
Loading safetensors checkpoint shards:  57% Completed | 583/1024 [00:13<00:10, 42.03it/s]
Loading safetensors checkpoint shards:  57% Completed | 588/1024 [00:13<00:10, 41.00it/s]
Loading safetensors checkpoint shards:  58% Completed | 593/1024 [00:14<00:10, 41.42it/s]
Loading safetensors checkpoint shards:  58% Completed | 598/1024 [00:14<00:10, 40.09it/s]
Loading safetensors checkpoint shards:  59% Completed | 603/1024 [00:14<00:10, 39.74it/s]
Loading safetensors checkpoint shards:  59% Completed | 608/1024 [00:14<00:10, 40.01it/s]
Loading safetensors checkpoint shards:  60% Completed | 613/1024 [00:14<00:10, 39.22it/s]
Loading safetensors checkpoint shards:  60% Completed | 618/1024 [00:14<00:10, 40.24it/s]
Loading safetensors checkpoint shards:  61% Completed | 623/1024 [00:14<00:10, 39.61it/s]
Loading safetensors checkpoint shards:  61% Completed | 627/1024 [00:14<00:10, 38.78it/s]
Loading safetensors checkpoint shards:  62% Completed | 631/1024 [00:15<00:10, 37.67it/s]
Loading safetensors checkpoint shards:  62% Completed | 635/1024 [00:15<00:10, 36.93it/s]
Loading safetensors checkpoint shards:  62% Completed | 639/1024 [00:15<00:10, 37.19it/s]
Loading safetensors checkpoint shards:  63% Completed | 643/1024 [00:15<00:10, 37.77it/s]
Loading safetensors checkpoint shards:  63% Completed | 647/1024 [00:15<00:10, 36.62it/s]
Loading safetensors checkpoint shards:  64% Completed | 651/1024 [00:15<00:10, 37.18it/s]
Loading safetensors checkpoint shards:  64% Completed | 655/1024 [00:15<00:09, 37.51it/s]
Loading safetensors checkpoint shards:  64% Completed | 659/1024 [00:15<00:09, 36.56it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:15<00:10, 35.78it/s]
Loading safetensors checkpoint shards:  65% Completed | 667/1024 [00:16<00:09, 36.13it/s]
Loading safetensors checkpoint shards:  66% Completed | 671/1024 [00:16<00:09, 36.70it/s]
Loading safetensors checkpoint shards:  66% Completed | 675/1024 [00:16<00:09, 36.69it/s]
Loading safetensors checkpoint shards:  66% Completed | 679/1024 [00:16<00:09, 34.99it/s]
Loading safetensors checkpoint shards:  67% Completed | 683/1024 [00:16<00:09, 35.31it/s]
Loading safetensors checkpoint shards:  67% Completed | 687/1024 [00:16<00:09, 35.52it/s]
Loading safetensors checkpoint shards:  67% Completed | 691/1024 [00:16<00:09, 36.28it/s]
Loading safetensors checkpoint shards:  68% Completed | 696/1024 [00:16<00:08, 38.01it/s]
Loading safetensors checkpoint shards:  68% Completed | 700/1024 [00:16<00:08, 38.03it/s]
Loading safetensors checkpoint shards:  69% Completed | 704/1024 [00:17<00:08, 36.10it/s]
Loading safetensors checkpoint shards:  69% Completed | 708/1024 [00:17<00:08, 36.65it/s]
Loading safetensors checkpoint shards:  70% Completed | 712/1024 [00:17<00:08, 36.93it/s]
Loading safetensors checkpoint shards:  70% Completed | 717/1024 [00:17<00:08, 37.38it/s]
Loading safetensors checkpoint shards:  70% Completed | 721/1024 [00:17<00:08, 36.83it/s]
Loading safetensors checkpoint shards:  71% Completed | 725/1024 [00:17<00:08, 36.19it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:17<00:08, 36.42it/s]
Loading safetensors checkpoint shards:  72% Completed | 733/1024 [00:17<00:08, 35.61it/s]
Loading safetensors checkpoint shards:  72% Completed | 737/1024 [00:17<00:07, 35.96it/s]
Loading safetensors checkpoint shards:  72% Completed | 741/1024 [00:18<00:07, 36.05it/s]
Loading safetensors checkpoint shards:  73% Completed | 745/1024 [00:18<00:07, 36.16it/s]
Loading safetensors checkpoint shards:  73% Completed | 749/1024 [00:18<00:07, 35.35it/s]
Loading safetensors checkpoint shards:  74% Completed | 753/1024 [00:18<00:07, 35.57it/s]
Loading safetensors checkpoint shards:  74% Completed | 757/1024 [00:18<00:07, 36.11it/s]
Loading safetensors checkpoint shards:  74% Completed | 761/1024 [00:18<00:07, 36.89it/s]
Loading safetensors checkpoint shards:  75% Completed | 765/1024 [00:18<00:06, 37.61it/s]
Loading safetensors checkpoint shards:  75% Completed | 769/1024 [00:18<00:06, 37.83it/s]
Loading safetensors checkpoint shards:  75% Completed | 773/1024 [00:18<00:06, 36.53it/s]
Loading safetensors checkpoint shards:  76% Completed | 777/1024 [00:19<00:06, 37.42it/s]
Loading safetensors checkpoint shards:  76% Completed | 781/1024 [00:19<00:06, 38.05it/s]
Loading safetensors checkpoint shards:  77% Completed | 785/1024 [00:19<00:06, 38.37it/s]
Loading safetensors checkpoint shards:  77% Completed | 789/1024 [00:19<00:06, 36.80it/s]
Loading safetensors checkpoint shards:  77% Completed | 793/1024 [00:19<00:06, 37.44it/s]
Loading safetensors checkpoint shards:  78% Completed | 797/1024 [00:19<00:05, 38.04it/s]
Loading safetensors checkpoint shards:  78% Completed | 801/1024 [00:19<00:05, 37.94it/s]
Loading safetensors checkpoint shards:  79% Completed | 806/1024 [00:19<00:05, 38.61it/s]
Loading safetensors checkpoint shards:  79% Completed | 810/1024 [00:19<00:05, 38.23it/s]
Loading safetensors checkpoint shards:  79% Completed | 814/1024 [00:19<00:05, 38.71it/s]
Loading safetensors checkpoint shards:  80% Completed | 818/1024 [00:20<00:05, 38.30it/s]
Loading safetensors checkpoint shards:  80% Completed | 822/1024 [00:20<00:05, 38.27it/s]
Loading safetensors checkpoint shards:  81% Completed | 827/1024 [00:20<00:05, 39.22it/s]
Loading safetensors checkpoint shards:  81% Completed | 832/1024 [00:20<00:04, 40.18it/s]
Loading safetensors checkpoint shards:  82% Completed | 837/1024 [00:20<00:04, 41.36it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:21<00:09, 19.13it/s]
Loading safetensors checkpoint shards:  83% Completed | 846/1024 [00:21<00:08, 22.13it/s]
Loading safetensors checkpoint shards:  83% Completed | 851/1024 [00:21<00:06, 26.41it/s]
Loading safetensors checkpoint shards:  84% Completed | 856/1024 [00:21<00:05, 30.01it/s]
Loading safetensors checkpoint shards:  84% Completed | 860/1024 [00:21<00:05, 32.08it/s]
Loading safetensors checkpoint shards:  84% Completed | 865/1024 [00:21<00:04, 34.88it/s]
Loading safetensors checkpoint shards:  85% Completed | 870/1024 [00:21<00:04, 37.22it/s]
Loading safetensors checkpoint shards:  85% Completed | 875/1024 [00:21<00:03, 38.44it/s]
Loading safetensors checkpoint shards:  86% Completed | 880/1024 [00:22<00:03, 40.01it/s]
Loading safetensors checkpoint shards:  86% Completed | 885/1024 [00:22<00:03, 41.00it/s]
Loading safetensors checkpoint shards:  87% Completed | 890/1024 [00:22<00:03, 40.66it/s]
Loading safetensors checkpoint shards:  87% Completed | 895/1024 [00:22<00:03, 40.84it/s]
Loading safetensors checkpoint shards:  88% Completed | 900/1024 [00:22<00:03, 41.16it/s]
Loading safetensors checkpoint shards:  88% Completed | 905/1024 [00:22<00:02, 41.47it/s]
Loading safetensors checkpoint shards:  89% Completed | 910/1024 [00:22<00:02, 41.64it/s]
Loading safetensors checkpoint shards:  89% Completed | 915/1024 [00:22<00:02, 42.92it/s]
Loading safetensors checkpoint shards:  90% Completed | 920/1024 [00:22<00:02, 40.64it/s]
Loading safetensors checkpoint shards:  90% Completed | 925/1024 [00:23<00:02, 38.84it/s]
Loading safetensors checkpoint shards:  91% Completed | 929/1024 [00:23<00:02, 38.38it/s]
Loading safetensors checkpoint shards:  91% Completed | 933/1024 [00:23<00:02, 36.90it/s]
Loading safetensors checkpoint shards:  92% Completed | 937/1024 [00:23<00:02, 36.94it/s]
Loading safetensors checkpoint shards:  92% Completed | 941/1024 [00:23<00:02, 36.75it/s]
Loading safetensors checkpoint shards:  92% Completed | 945/1024 [00:23<00:02, 36.25it/s]
Loading safetensors checkpoint shards:  93% Completed | 949/1024 [00:23<00:02, 36.40it/s]
Loading safetensors checkpoint shards:  93% Completed | 953/1024 [00:23<00:01, 36.62it/s]
Loading safetensors checkpoint shards:  93% Completed | 957/1024 [00:23<00:01, 36.64it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:24<00:01, 35.52it/s]
Loading safetensors checkpoint shards:  94% Completed | 965/1024 [00:24<00:01, 36.18it/s]
Loading safetensors checkpoint shards:  95% Completed | 969/1024 [00:24<00:01, 36.67it/s]
Loading safetensors checkpoint shards:  95% Completed | 973/1024 [00:24<00:01, 36.09it/s]
Loading safetensors checkpoint shards:  95% Completed | 977/1024 [00:24<00:01, 36.53it/s]
Loading safetensors checkpoint shards:  96% Completed | 981/1024 [00:24<00:01, 36.52it/s]
Loading safetensors checkpoint shards:  98% Completed | 1000/1024 [00:24<00:00, 79.16it/s]
Loading safetensors checkpoint shards:  99% Completed | 1009/1024 [00:24<00:00, 75.78it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:24<00:00, 40.98it/s]

[2025-09-13 06:44:10 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 06:44:13 TP7] KV Cache is allocated. #tokens: 620177, KV size: 40.59 GB
[2025-09-13 06:44:13 TP6] KV Cache is allocated. #tokens: 620177, KV size: 40.59 GB
[2025-09-13 06:44:13 TP5] KV Cache is allocated. #tokens: 620177, KV size: 40.59 GB
[2025-09-13 06:44:13 TP4] KV Cache is allocated. #tokens: 620177, KV size: 40.59 GB
[2025-09-13 06:44:13 TP3] KV Cache is allocated. #tokens: 620177, KV size: 40.59 GB
[2025-09-13 06:44:13 TP1] KV Cache is allocated. #tokens: 620177, KV size: 40.59 GB
[2025-09-13 06:44:13 TP0] KV Cache is allocated. #tokens: 620177, KV size: 40.59 GB
[2025-09-13 06:44:13 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 06:44:13 TP2] KV Cache is allocated. #tokens: 620177, KV size: 40.59 GB
[2025-09-13 06:44:13 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 06:44:14 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.52 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 06:44:15 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:44:15 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 06:44:15 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:44:15 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:44:15 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:44:15 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:44:15 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:44:15 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:44:15 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26328.33it/s]
[2025-09-13 06:44:15 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:44:15 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27435.50it/s]
[2025-09-13 06:44:16 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:44:16 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28976.44it/s]
[2025-09-13 06:44:17 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:44:17 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28141.83it/s]
[2025-09-13 06:44:17 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:44:17 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28850.65it/s]
[2025-09-13 06:44:18 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.23 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.14it/s]
[2025-09-13 06:44:21 TP3] Registering 984 cuda graph addresses
[2025-09-13 06:44:21 TP0] Registering 984 cuda graph addresses
[2025-09-13 06:44:21 TP7] Registering 984 cuda graph addresses
[2025-09-13 06:44:21 TP2] Registering 984 cuda graph addresses
[2025-09-13 06:44:21 TP6] Registering 984 cuda graph addresses
[2025-09-13 06:44:21 TP5] Registering 984 cuda graph addresses
[2025-09-13 06:44:21 TP4] Registering 984 cuda graph addresses
[2025-09-13 06:44:21 TP1] Registering 984 cuda graph addresses
[2025-09-13 06:44:21 TP0] Capture cuda graph end. Time elapsed: 7.78 s. mem usage=0.35 GB. avail mem=17.21 GB.
[2025-09-13 06:44:21 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 06:44:21 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:44:21 TP0] Init torch distributed begin.
[2025-09-13 06:44:21 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 06:44:21 TP0] Load weight begin. avail mem=17.21 GB
[2025-09-13 06:44:21 TP0] Detected fp8 checkpoint.
[2025-09-13 06:44:21 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 175.59it/s]
Loading safetensors checkpoint shards:   4% Completed | 44/1024 [00:00<00:04, 223.51it/s]
Loading safetensors checkpoint shards:  10% Completed | 105/1024 [00:00<00:02, 396.70it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:00<00:01, 481.18it/s]
Loading safetensors checkpoint shards:  22% Completed | 229/1024 [00:00<00:01, 528.54it/s]
Loading safetensors checkpoint shards:  28% Completed | 291/1024 [00:00<00:01, 557.03it/s]
Loading safetensors checkpoint shards:  34% Completed | 353/1024 [00:00<00:01, 575.18it/s]
Loading safetensors checkpoint shards:  41% Completed | 416/1024 [00:00<00:01, 590.29it/s]
Loading safetensors checkpoint shards:  47% Completed | 478/1024 [00:00<00:00, 597.63it/s]
Loading safetensors checkpoint shards:  53% Completed | 540/1024 [00:01<00:00, 602.48it/s]
Loading safetensors checkpoint shards:  59% Completed | 602/1024 [00:01<00:00, 605.55it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:01<00:00, 599.73it/s]
Loading safetensors checkpoint shards:  71% Completed | 723/1024 [00:01<00:00, 593.58it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:01<00:00, 586.43it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:01<00:00, 583.96it/s]
Loading safetensors checkpoint shards:  88% Completed | 901/1024 [00:01<00:00, 579.72it/s]
Loading safetensors checkpoint shards:  94% Completed | 959/1024 [00:01<00:00, 578.91it/s]
Loading safetensors checkpoint shards:  99% Completed | 1017/1024 [00:01<00:00, 391.17it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 509.87it/s]

[2025-09-13 06:44:24 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.22 GB, mem usage=1.99 GB.
[2025-09-13 06:44:24 TP7] KV Cache is allocated. #tokens: 620177, KV size: 0.67 GB
[2025-09-13 06:44:24 TP6] KV Cache is allocated. #tokens: 620177, KV size: 0.67 GB
[2025-09-13 06:44:24 TP3] KV Cache is allocated. #tokens: 620177, KV size: 0.67 GB
[2025-09-13 06:44:24 TP4] KV Cache is allocated. #tokens: 620177, KV size: 0.67 GB
[2025-09-13 06:44:24 TP2] KV Cache is allocated. #tokens: 620177, KV size: 0.67 GB
[2025-09-13 06:44:24 TP5] KV Cache is allocated. #tokens: 620177, KV size: 0.67 GB
[2025-09-13 06:44:24 TP0] KV Cache is allocated. #tokens: 620177, KV size: 0.67 GB
[2025-09-13 06:44:24 TP0] Memory pool end. avail mem=14.55 GB
[2025-09-13 06:44:24 TP1] KV Cache is allocated. #tokens: 620177, KV size: 0.67 GB
[2025-09-13 06:44:24 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:44:24 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:44:24 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:44:24 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.99 GB
[2025-09-13 06:44:24 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:44:24 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.18 GB
[2025-09-13 06:44:24 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:44:24 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
Capturing batches (bs=1 avail_mem=14.68 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:03<00:00,  3.91it/s][2025-09-13 06:44:30 TP2] Registering 48 cuda graph addresses
[2025-09-13 06:44:30 TP3] Registering 48 cuda graph addresses
[2025-09-13 06:44:30 TP7] Registering 48 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.68 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.48it/s]
[2025-09-13 06:44:30 TP0] Registering 48 cuda graph addresses
[2025-09-13 06:44:30 TP5] Registering 48 cuda graph addresses
[2025-09-13 06:44:30 TP6] Registering 48 cuda graph addresses
[2025-09-13 06:44:30 TP1] Registering 48 cuda graph addresses
[2025-09-13 06:44:30 TP4] Registering 48 cuda graph addresses
[2025-09-13 06:44:30 TP4] Capture draft cuda graph end. Time elapsed: 6.12 s. mem usage=0.31 GB. avail mem=14.63 GB.
[2025-09-13 06:44:30 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.63 GB
[2025-09-13 06:44:30 TP7] Capture draft cuda graph end. Time elapsed: 6.11 s. mem usage=0.31 GB. avail mem=14.87 GB.
[2025-09-13 06:44:30 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 06:44:30 TP5] Capture draft cuda graph end. Time elapsed: 6.11 s. mem usage=0.31 GB. avail mem=14.63 GB.
[2025-09-13 06:44:30 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.63 GB
[2025-09-13 06:44:30 TP3] Capture draft cuda graph end. Time elapsed: 6.12 s. mem usage=0.31 GB. avail mem=14.63 GB.
[2025-09-13 06:44:30 TP1] Capture draft cuda graph end. Time elapsed: 6.12 s. mem usage=0.31 GB. avail mem=14.63 GB.
[2025-09-13 06:44:30 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.63 GB
[2025-09-13 06:44:30 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.63 GB
[2025-09-13 06:44:30 TP2] Capture draft cuda graph end. Time elapsed: 6.12 s. mem usage=0.31 GB. avail mem=14.63 GB.
[2025-09-13 06:44:30 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.63 GB
[2025-09-13 06:44:30 TP6] Capture draft cuda graph end. Time elapsed: 6.12 s. mem usage=0.31 GB. avail mem=14.63 GB.
[2025-09-13 06:44:30 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.63 GB
[2025-09-13 06:44:30 TP0] Capture draft cuda graph end. Time elapsed: 6.12 s. mem usage=0.31 GB. avail mem=14.67 GB.
[2025-09-13 06:44:30 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.67 GB
Capturing batches (bs=1 avail_mem=14.48 GB):  12%|██████████▊                                                                           | 1/8 [00:00<00:01,  6.23it/s][2025-09-13 06:44:31 TP2] Registering 24 cuda graph addresses
[2025-09-13 06:44:31 TP1] Registering 24 cuda graph addresses
[2025-09-13 06:44:31 TP6] Registering 24 cuda graph addresses
[2025-09-13 06:44:31 TP3] Registering 24 cuda graph addresses
[2025-09-13 06:44:31 TP5] Registering 24 cuda graph addresses
[2025-09-13 06:44:31 TP7] Registering 24 cuda graph addresses
[2025-09-13 06:44:31 TP4] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.48 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 27.16it/s]
[2025-09-13 06:44:31 TP0] Registering 24 cuda graph addresses
[2025-09-13 06:44:31 TP7] Capture draft extend cuda graph end. Time elapsed: 1.10 s. mem usage=0.19 GB. avail mem=14.68 GB.
[2025-09-13 06:44:31 TP5] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.44 GB.
[2025-09-13 06:44:31 TP6] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.44 GB.
[2025-09-13 06:44:31 TP3] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.44 GB.
[2025-09-13 06:44:31 TP4] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.44 GB.
[2025-09-13 06:44:31 TP0] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.48 GB.
[2025-09-13 06:44:31 TP2] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.44 GB.
[2025-09-13 06:44:31 TP0] max_total_num_tokens=620177, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.48 GB
[2025-09-13 06:44:31 TP1] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.44 GB.
[2025-09-13 06:44:32] INFO:     Started server process [147451]
[2025-09-13 06:44:32] INFO:     Waiting for application startup.
[2025-09-13 06:44:32] INFO:     Application startup complete.
[2025-09-13 06:44:32] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 06:44:32] INFO:     127.0.0.1:59452 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 06:44:33] INFO:     127.0.0.1:59454 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 06:44:33 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:44:33 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:44:33 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27958.44it/s]
[2025-09-13 06:44:34] INFO:     127.0.0.1:59456 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:34] The server is fired up and ready to roll!
[2025-09-13 06:44:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:44:43] INFO:     127.0.0.1:53024 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:44:43] INFO:     127.0.0.1:53040 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:43 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 06:44:45] INFO:     127.0.0.1:53050 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:45] INFO:     127.0.0.1:53064 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:44:45] INFO:     127.0.0.1:53068 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:45] INFO:     127.0.0.1:53074 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:45] INFO:     127.0.0.1:53080 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:45] INFO:     127.0.0.1:53086 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:45] INFO:     127.0.0.1:53088 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:45] INFO:     127.0.0.1:53098 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:45 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 06:44:45 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:44:45 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:44:45 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:44:45 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:44:45 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:44:45 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:44:45 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:44:45 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:44:45 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 06:44:46 TP0] Decode batch. #running-req: 8, #token: 14530, token usage: 0.02, accept len: 2.89, cuda graph: True, gen throughput (token/s): 42.67, #queue-req: 0, 
[2025-09-13 06:44:48 TP0] Decode batch. #running-req: 8, #token: 15543, token usage: 0.03, accept len: 3.17, cuda graph: True, gen throughput (token/s): 854.86, #queue-req: 0, 
[2025-09-13 06:44:49 TP0] Decode batch. #running-req: 8, #token: 16585, token usage: 0.03, accept len: 3.26, cuda graph: True, gen throughput (token/s): 853.27, #queue-req: 0, 
[2025-09-13 06:44:50 TP0] Decode batch. #running-req: 8, #token: 17011, token usage: 0.03, accept len: 3.24, cuda graph: True, gen throughput (token/s): 842.48, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.31it/s]
[2025-09-13 06:44:51] INFO:     127.0.0.1:59014 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.11      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4083      
Request throughput (req/s):              1.31      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         669.96    
Total token throughput (tok/s):          669.96    
Concurrency:                             7.33      
Accept length:                           3.16      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5602.91   
Median E2E Latency (ms):                 5574.95   
---------------Time to First Token----------------
Mean TTFT (ms):                          612.22    
Median TTFT (ms):                        722.60    
P99 TTFT (ms):                           723.08    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.77      
Median ITL (ms):                         7.67      
P95 ITL (ms):                            15.56     
P99 ITL (ms):                            31.18     
Max ITL (ms):                            728.22    
==================================================
[2025-09-13 06:44:51] INFO:     127.0.0.1:59018 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:44:51] INFO:     127.0.0.1:59020 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:44:51 TP0] Decode batch. #running-req: 1, #token: 4671, token usage: 0.01, accept len: 3.40, cuda graph: True, gen throughput (token/s): 346.62, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 06:44:52] INFO:     127.0.0.1:59034 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:52] INFO:     127.0.0.1:59036 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:44:52] INFO:     127.0.0.1:59042 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:52] INFO:     127.0.0.1:59058 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:52] INFO:     127.0.0.1:59074 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:52] INFO:     127.0.0.1:59076 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:52] INFO:     127.0.0.1:59084 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:52] INFO:     127.0.0.1:59092 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:52 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 06:44:53 TP0] Decode batch. #running-req: 8, #token: 14673, token usage: 0.02, accept len: 2.96, cuda graph: True, gen throughput (token/s): 335.53, #queue-req: 0, 
[2025-09-13 06:44:55 TP0] Decode batch. #running-req: 8, #token: 15699, token usage: 0.03, accept len: 3.21, cuda graph: True, gen throughput (token/s): 858.86, #queue-req: 0, 
[2025-09-13 06:44:56 TP0] Decode batch. #running-req: 8, #token: 16751, token usage: 0.03, accept len: 3.29, cuda graph: True, gen throughput (token/s): 861.73, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:09,  4.61s/it][2025-09-13 06:44:57] INFO:     127.0.0.1:59098 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:57 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:44:57 TP0] Decode batch. #running-req: 8, #token: 17974, token usage: 0.03, accept len: 3.25, cuda graph: True, gen throughput (token/s): 709.69, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:05<00:30,  2.21s/it][2025-09-13 06:44:57] INFO:     127.0.0.1:59104 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:16,  1.29s/it][2025-09-13 06:44:58] INFO:     127.0.0.1:35422 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:58 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:44:58] INFO:     127.0.0.1:35424 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:58 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:06,  1.63it/s][2025-09-13 06:44:58] INFO:     127.0.0.1:35440 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:58 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.85it/s][2025-09-13 06:44:58] INFO:     127.0.0.1:35456 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:58] INFO:     127.0.0.1:35468 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:58 TP0] Prefill batch. #new-seq: 2, #new-token: 2369, #cached-token: 1751, token usage: 0.01, #running-req: 6, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:03,  2.10it/s][2025-09-13 06:44:59] INFO:     127.0.0.1:35480 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:44:59 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:44:59 TP0] Decode batch. #running-req: 8, #token: 14227, token usage: 0.02, accept len: 3.13, cuda graph: True, gen throughput (token/s): 465.40, #queue-req: 0, 
[2025-09-13 06:45:01 TP0] Decode batch. #running-req: 8, #token: 15201, token usage: 0.02, accept len: 3.04, cuda graph: True, gen throughput (token/s): 796.20, #queue-req: 0, 
[2025-09-13 06:45:02 TP0] Decode batch. #running-req: 8, #token: 16220, token usage: 0.03, accept len: 3.18, cuda graph: True, gen throughput (token/s): 841.99, #queue-req: 0, 
 56%|█████████████████████████████████████████████████████████████████████████▏                                                        | 9/16 [00:10<00:09,  1.31s/it][2025-09-13 06:45:03 TP0] Decode batch. #running-req: 7, #token: 12993, token usage: 0.02, accept len: 3.43, cuda graph: True, gen throughput (token/s): 883.42, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.40it/s]
[2025-09-13 06:45:04] INFO:     127.0.0.1:35496 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.47     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8082      
Request throughput (req/s):              1.39      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         714.14    
Total token throughput (tok/s):          714.14    
Concurrency:                             7.70      
Accept length:                           3.19      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5522.71   
Median E2E Latency (ms):                 5547.27   
---------------Time to First Token----------------
Mean TTFT (ms):                          247.02    
Median TTFT (ms):                        293.85    
P99 TTFT (ms):                           330.16    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.32     
Median ITL (ms):                         7.64      
P95 ITL (ms):                            28.62     
P99 ITL (ms):                            54.10     
Max ITL (ms):                            263.83    
==================================================
[2025-09-13 06:45:04] INFO:     127.0.0.1:35500 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=4: batch_size=8, steps=3, topk=3, num_draft_tokens=6, speed=105.33 token/s, step_time=30.26 ms
Start i=5: batch_size=8, steps=3, topk=3, num_draft_tokens=8
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 3 --speculative-eagle-topk 3 --speculative-num-draft-tokens 8 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:45:14.988000 153047 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:45:14.988000 153047 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 06:45:15] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=1010796172, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=3, speculative_eagle_topk=3, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:45:15] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:45:23.979000 153261 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:45:23.979000 153261 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 06:45:24.372000 153258 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:45:24.372000 153258 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:45:24.602000 153263 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:45:24.602000 153263 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:45:24.611000 153257 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:45:24.611000 153257 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:45:24.623000 153259 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:45:24.623000 153259 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:45:24.636000 153256 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:45:24.636000 153256 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:45:24.681000 153262 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:45:24.681000 153262 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:45:24.682000 153260 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:45:24.682000 153260 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:45:24.684000 153255 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:45:24.684000 153255 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:45:25 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 06:45:25 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:45:25 TP0] Init torch distributed begin.
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:45:27 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:45:29 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 06:45:31 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 06:45:31 TP0] Detected fp8 checkpoint.
[2025-09-13 06:45:31 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:04, 216.00it/s]
Loading safetensors checkpoint shards:   5% Completed | 48/1024 [00:00<00:12, 79.12it/s]
Loading safetensors checkpoint shards:   6% Completed | 60/1024 [00:00<00:17, 56.13it/s]
Loading safetensors checkpoint shards:   7% Completed | 69/1024 [00:01<00:20, 46.15it/s]
Loading safetensors checkpoint shards:   7% Completed | 76/1024 [00:01<00:21, 43.13it/s]
Loading safetensors checkpoint shards:   8% Completed | 82/1024 [00:01<00:21, 43.43it/s]
Loading safetensors checkpoint shards:   8% Completed | 87/1024 [00:01<00:21, 44.03it/s]
Loading safetensors checkpoint shards:   9% Completed | 92/1024 [00:01<00:22, 40.78it/s]
Loading safetensors checkpoint shards:   9% Completed | 97/1024 [00:01<00:23, 39.45it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:02<00:22, 40.82it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:02<00:41, 22.27it/s]
Loading safetensors checkpoint shards:  11% Completed | 112/1024 [00:02<00:35, 25.89it/s]
Loading safetensors checkpoint shards:  12% Completed | 118/1024 [00:02<00:28, 31.31it/s]
Loading safetensors checkpoint shards:  12% Completed | 124/1024 [00:02<00:24, 36.25it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:03<00:21, 41.70it/s]
Loading safetensors checkpoint shards:  14% Completed | 139/1024 [00:03<00:18, 47.61it/s]
Loading safetensors checkpoint shards:  14% Completed | 146/1024 [00:03<00:16, 52.54it/s]
Loading safetensors checkpoint shards:  15% Completed | 153/1024 [00:03<00:15, 55.94it/s]
Loading safetensors checkpoint shards:  16% Completed | 161/1024 [00:03<00:14, 60.61it/s]
Loading safetensors checkpoint shards:  16% Completed | 168/1024 [00:03<00:13, 61.98it/s]
Loading safetensors checkpoint shards:  17% Completed | 175/1024 [00:03<00:13, 63.47it/s]
Loading safetensors checkpoint shards:  18% Completed | 182/1024 [00:03<00:13, 61.61it/s]
Loading safetensors checkpoint shards:  18% Completed | 189/1024 [00:03<00:13, 61.36it/s]
Loading safetensors checkpoint shards:  19% Completed | 196/1024 [00:04<00:13, 61.49it/s]
Loading safetensors checkpoint shards:  20% Completed | 203/1024 [00:04<00:14, 55.32it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:04<00:14, 54.93it/s]
Loading safetensors checkpoint shards:  21% Completed | 216/1024 [00:04<00:14, 57.26it/s]
Loading safetensors checkpoint shards:  22% Completed | 222/1024 [00:04<00:14, 56.73it/s]
Loading safetensors checkpoint shards:  22% Completed | 228/1024 [00:04<00:14, 55.80it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:04<00:14, 56.40it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:05<00:29, 26.28it/s]
Loading safetensors checkpoint shards:  24% Completed | 247/1024 [00:05<00:23, 32.76it/s]
Loading safetensors checkpoint shards:  25% Completed | 255/1024 [00:05<00:18, 40.66it/s]
Loading safetensors checkpoint shards:  26% Completed | 262/1024 [00:05<00:16, 45.43it/s]
Loading safetensors checkpoint shards:  26% Completed | 269/1024 [00:05<00:15, 49.19it/s]
Loading safetensors checkpoint shards:  27% Completed | 275/1024 [00:05<00:14, 50.86it/s]
Loading safetensors checkpoint shards:  28% Completed | 283/1024 [00:05<00:13, 55.37it/s]
Loading safetensors checkpoint shards:  28% Completed | 290/1024 [00:06<00:14, 51.88it/s]
Loading safetensors checkpoint shards:  29% Completed | 296/1024 [00:06<00:14, 49.71it/s]
Loading safetensors checkpoint shards:  29% Completed | 302/1024 [00:06<00:14, 48.67it/s]
Loading safetensors checkpoint shards:  30% Completed | 308/1024 [00:06<00:14, 50.55it/s]
Loading safetensors checkpoint shards:  31% Completed | 314/1024 [00:06<00:13, 51.00it/s]
Loading safetensors checkpoint shards:  31% Completed | 320/1024 [00:06<00:13, 53.26it/s]
Loading safetensors checkpoint shards:  32% Completed | 326/1024 [00:06<00:12, 53.85it/s]
Loading safetensors checkpoint shards:  32% Completed | 332/1024 [00:06<00:13, 51.37it/s]
Loading safetensors checkpoint shards:  33% Completed | 339/1024 [00:07<00:12, 54.15it/s]
Loading safetensors checkpoint shards:  34% Completed | 345/1024 [00:07<00:13, 50.44it/s]
Loading safetensors checkpoint shards:  34% Completed | 351/1024 [00:07<00:13, 48.67it/s]
Loading safetensors checkpoint shards:  35% Completed | 356/1024 [00:07<00:14, 47.36it/s]
Loading safetensors checkpoint shards:  35% Completed | 362/1024 [00:07<00:13, 48.39it/s]
Loading safetensors checkpoint shards:  36% Completed | 367/1024 [00:07<00:13, 48.45it/s]
Loading safetensors checkpoint shards:  36% Completed | 373/1024 [00:07<00:12, 51.22it/s]
Loading safetensors checkpoint shards:  37% Completed | 379/1024 [00:07<00:12, 49.66it/s]
Loading safetensors checkpoint shards:  38% Completed | 386/1024 [00:07<00:11, 54.43it/s]
Loading safetensors checkpoint shards:  38% Completed | 392/1024 [00:08<00:11, 53.02it/s]
Loading safetensors checkpoint shards:  39% Completed | 398/1024 [00:08<00:11, 53.42it/s]
Loading safetensors checkpoint shards:  39% Completed | 404/1024 [00:08<00:28, 22.11it/s]
Loading safetensors checkpoint shards:  40% Completed | 411/1024 [00:08<00:21, 28.47it/s]
Loading safetensors checkpoint shards:  41% Completed | 417/1024 [00:09<00:18, 33.29it/s]
Loading safetensors checkpoint shards:  41% Completed | 424/1024 [00:09<00:15, 39.14it/s]
Loading safetensors checkpoint shards:  42% Completed | 432/1024 [00:09<00:12, 47.03it/s]
Loading safetensors checkpoint shards:  43% Completed | 439/1024 [00:09<00:11, 51.64it/s]
Loading safetensors checkpoint shards:  44% Completed | 446/1024 [00:09<00:10, 55.23it/s]
Loading safetensors checkpoint shards:  44% Completed | 453/1024 [00:09<00:09, 58.31it/s]
Loading safetensors checkpoint shards:  45% Completed | 462/1024 [00:09<00:08, 64.52it/s]
Loading safetensors checkpoint shards:  46% Completed | 469/1024 [00:09<00:08, 62.86it/s]
Loading safetensors checkpoint shards:  46% Completed | 476/1024 [00:09<00:08, 63.96it/s]
Loading safetensors checkpoint shards:  47% Completed | 484/1024 [00:10<00:08, 66.78it/s]
Loading safetensors checkpoint shards:  48% Completed | 491/1024 [00:10<00:08, 63.30it/s]
Loading safetensors checkpoint shards:  49% Completed | 499/1024 [00:10<00:07, 65.86it/s]
Loading safetensors checkpoint shards:  49% Completed | 506/1024 [00:10<00:07, 65.79it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:10<00:08, 63.40it/s]
Loading safetensors checkpoint shards:  51% Completed | 520/1024 [00:10<00:07, 63.44it/s]
Loading safetensors checkpoint shards:  51% Completed | 527/1024 [00:10<00:07, 63.94it/s]
Loading safetensors checkpoint shards:  52% Completed | 534/1024 [00:10<00:08, 56.65it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:10<00:08, 57.80it/s]
Loading safetensors checkpoint shards:  54% Completed | 549/1024 [00:11<00:07, 62.39it/s]
Loading safetensors checkpoint shards:  54% Completed | 556/1024 [00:11<00:07, 59.91it/s]
Loading safetensors checkpoint shards:  55% Completed | 563/1024 [00:11<00:07, 61.25it/s]
Loading safetensors checkpoint shards:  56% Completed | 572/1024 [00:11<00:06, 68.12it/s]
Loading safetensors checkpoint shards:  57% Completed | 579/1024 [00:11<00:06, 63.78it/s]
Loading safetensors checkpoint shards:  57% Completed | 586/1024 [00:11<00:06, 64.55it/s]
Loading safetensors checkpoint shards:  58% Completed | 593/1024 [00:11<00:06, 62.56it/s]
Loading safetensors checkpoint shards:  59% Completed | 600/1024 [00:11<00:06, 60.99it/s]
Loading safetensors checkpoint shards:  59% Completed | 607/1024 [00:12<00:18, 23.15it/s]
Loading safetensors checkpoint shards:  60% Completed | 612/1024 [00:12<00:15, 26.28it/s]
Loading safetensors checkpoint shards:  60% Completed | 617/1024 [00:12<00:13, 29.74it/s]
Loading safetensors checkpoint shards:  61% Completed | 623/1024 [00:12<00:11, 34.84it/s]
Loading safetensors checkpoint shards:  62% Completed | 630/1024 [00:13<00:09, 40.35it/s]
Loading safetensors checkpoint shards:  62% Completed | 636/1024 [00:13<00:08, 43.87it/s]
Loading safetensors checkpoint shards:  63% Completed | 642/1024 [00:13<00:08, 43.35it/s]
Loading safetensors checkpoint shards:  63% Completed | 648/1024 [00:13<00:09, 39.13it/s]
Loading safetensors checkpoint shards:  64% Completed | 653/1024 [00:13<00:09, 41.08it/s]
Loading safetensors checkpoint shards:  64% Completed | 659/1024 [00:13<00:08, 40.93it/s]
Loading safetensors checkpoint shards:  65% Completed | 664/1024 [00:13<00:08, 40.37it/s]
Loading safetensors checkpoint shards:  65% Completed | 669/1024 [00:13<00:08, 41.87it/s]
Loading safetensors checkpoint shards:  66% Completed | 674/1024 [00:14<00:08, 43.39it/s]
Loading safetensors checkpoint shards:  66% Completed | 679/1024 [00:14<00:08, 38.59it/s]
Loading safetensors checkpoint shards:  67% Completed | 684/1024 [00:14<00:08, 40.26it/s]
Loading safetensors checkpoint shards:  67% Completed | 689/1024 [00:14<00:08, 41.21it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:14<00:07, 41.76it/s]
Loading safetensors checkpoint shards:  68% Completed | 699/1024 [00:14<00:08, 38.71it/s]
Loading safetensors checkpoint shards:  69% Completed | 703/1024 [00:14<00:08, 37.10it/s]
Loading safetensors checkpoint shards:  69% Completed | 707/1024 [00:15<00:08, 35.57it/s]
Loading safetensors checkpoint shards:  69% Completed | 711/1024 [00:15<00:09, 34.43it/s]
Loading safetensors checkpoint shards:  70% Completed | 715/1024 [00:15<00:09, 33.57it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:15<00:08, 35.11it/s]
Loading safetensors checkpoint shards:  71% Completed | 723/1024 [00:15<00:08, 33.62it/s]
Loading safetensors checkpoint shards:  71% Completed | 727/1024 [00:15<00:08, 34.43it/s]
Loading safetensors checkpoint shards:  71% Completed | 732/1024 [00:15<00:07, 36.59it/s]
Loading safetensors checkpoint shards:  72% Completed | 736/1024 [00:15<00:08, 35.63it/s]
Loading safetensors checkpoint shards:  72% Completed | 740/1024 [00:15<00:07, 36.07it/s]
Loading safetensors checkpoint shards:  73% Completed | 745/1024 [00:16<00:07, 38.48it/s]
Loading safetensors checkpoint shards:  73% Completed | 749/1024 [00:16<00:07, 36.95it/s]
Loading safetensors checkpoint shards:  74% Completed | 753/1024 [00:16<00:07, 37.00it/s]
Loading safetensors checkpoint shards:  74% Completed | 759/1024 [00:16<00:06, 40.82it/s]
Loading safetensors checkpoint shards:  75% Completed | 764/1024 [00:16<00:06, 38.77it/s]
Loading safetensors checkpoint shards:  75% Completed | 768/1024 [00:16<00:07, 35.12it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:16<00:07, 34.25it/s]
Loading safetensors checkpoint shards:  76% Completed | 777/1024 [00:16<00:06, 36.90it/s]
Loading safetensors checkpoint shards:  76% Completed | 781/1024 [00:17<00:06, 36.65it/s]
Loading safetensors checkpoint shards:  77% Completed | 785/1024 [00:17<00:07, 33.91it/s]
Loading safetensors checkpoint shards:  77% Completed | 789/1024 [00:17<00:06, 33.97it/s]
Loading safetensors checkpoint shards:  77% Completed | 793/1024 [00:17<00:07, 32.04it/s]
Loading safetensors checkpoint shards:  78% Completed | 797/1024 [00:17<00:06, 33.31it/s]
Loading safetensors checkpoint shards:  78% Completed | 801/1024 [00:17<00:06, 33.37it/s]
Loading safetensors checkpoint shards:  79% Completed | 805/1024 [00:17<00:06, 33.63it/s]
Loading safetensors checkpoint shards:  79% Completed | 809/1024 [00:17<00:06, 34.46it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:18<00:06, 34.98it/s]
Loading safetensors checkpoint shards:  80% Completed | 817/1024 [00:18<00:06, 31.66it/s]
Loading safetensors checkpoint shards:  80% Completed | 821/1024 [00:18<00:06, 31.36it/s]
Loading safetensors checkpoint shards:  81% Completed | 825/1024 [00:19<00:15, 12.90it/s]
Loading safetensors checkpoint shards:  81% Completed | 829/1024 [00:19<00:12, 16.18it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:19<00:09, 19.23it/s]
Loading safetensors checkpoint shards:  82% Completed | 837/1024 [00:19<00:08, 22.61it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:19<00:06, 26.91it/s]
Loading safetensors checkpoint shards:  83% Completed | 846/1024 [00:19<00:06, 27.13it/s]
Loading safetensors checkpoint shards:  83% Completed | 850/1024 [00:19<00:06, 28.59it/s]
Loading safetensors checkpoint shards:  83% Completed | 854/1024 [00:19<00:05, 30.58it/s]
Loading safetensors checkpoint shards:  84% Completed | 858/1024 [00:19<00:05, 31.28it/s]
Loading safetensors checkpoint shards:  84% Completed | 862/1024 [00:20<00:05, 31.47it/s]
Loading safetensors checkpoint shards:  85% Completed | 866/1024 [00:20<00:05, 30.07it/s]
Loading safetensors checkpoint shards:  85% Completed | 870/1024 [00:20<00:05, 28.05it/s]
Loading safetensors checkpoint shards:  85% Completed | 874/1024 [00:20<00:05, 28.32it/s]
Loading safetensors checkpoint shards:  86% Completed | 877/1024 [00:20<00:05, 27.82it/s]
Loading safetensors checkpoint shards:  86% Completed | 880/1024 [00:20<00:05, 26.54it/s]
Loading safetensors checkpoint shards:  86% Completed | 883/1024 [00:20<00:05, 24.65it/s]
Loading safetensors checkpoint shards:  87% Completed | 886/1024 [00:21<00:05, 24.52it/s]
Loading safetensors checkpoint shards:  87% Completed | 889/1024 [00:21<00:05, 24.58it/s]
Loading safetensors checkpoint shards:  87% Completed | 892/1024 [00:21<00:05, 24.17it/s]
Loading safetensors checkpoint shards:  88% Completed | 896/1024 [00:21<00:04, 27.24it/s]
Loading safetensors checkpoint shards:  88% Completed | 901/1024 [00:21<00:03, 31.75it/s]
Loading safetensors checkpoint shards:  88% Completed | 906/1024 [00:21<00:03, 35.27it/s]
Loading safetensors checkpoint shards:  89% Completed | 910/1024 [00:21<00:03, 35.01it/s]
Loading safetensors checkpoint shards:  89% Completed | 915/1024 [00:21<00:03, 36.23it/s]
Loading safetensors checkpoint shards:  90% Completed | 919/1024 [00:21<00:02, 37.11it/s]
Loading safetensors checkpoint shards:  90% Completed | 923/1024 [00:22<00:02, 36.27it/s]
Loading safetensors checkpoint shards:  91% Completed | 927/1024 [00:22<00:02, 37.17it/s]
Loading safetensors checkpoint shards:  91% Completed | 932/1024 [00:22<00:02, 39.59it/s]
Loading safetensors checkpoint shards:  92% Completed | 937/1024 [00:22<00:02, 41.63it/s]
Loading safetensors checkpoint shards:  92% Completed | 943/1024 [00:22<00:01, 46.55it/s]
Loading safetensors checkpoint shards:  93% Completed | 950/1024 [00:22<00:01, 51.26it/s]
Loading safetensors checkpoint shards:  93% Completed | 956/1024 [00:22<00:01, 53.63it/s]
Loading safetensors checkpoint shards:  94% Completed | 962/1024 [00:22<00:01, 51.33it/s]
Loading safetensors checkpoint shards:  95% Completed | 968/1024 [00:22<00:01, 51.78it/s]
Loading safetensors checkpoint shards:  95% Completed | 974/1024 [00:23<00:00, 51.51it/s]
Loading safetensors checkpoint shards:  96% Completed | 980/1024 [00:23<00:00, 49.39it/s]
Loading safetensors checkpoint shards:  97% Completed | 989/1024 [00:23<00:00, 59.02it/s]
Loading safetensors checkpoint shards:  98% Completed | 1001/1024 [00:23<00:00, 75.30it/s]
Loading safetensors checkpoint shards:  99% Completed | 1013/1024 [00:23<00:00, 87.10it/s]
Loading safetensors checkpoint shards: 100% Completed | 1022/1024 [00:23<00:00, 87.14it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:23<00:00, 43.27it/s]

[2025-09-13 06:46:00 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 06:46:00 TP0] KV Cache is allocated. #tokens: 620193, KV size: 40.59 GB
[2025-09-13 06:46:00 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 06:46:00 TP5] KV Cache is allocated. #tokens: 620193, KV size: 40.59 GB
[2025-09-13 06:46:00 TP4] KV Cache is allocated. #tokens: 620193, KV size: 40.59 GB
[2025-09-13 06:46:00 TP3] KV Cache is allocated. #tokens: 620193, KV size: 40.59 GB
[2025-09-13 06:46:00 TP6] KV Cache is allocated. #tokens: 620193, KV size: 40.59 GB
[2025-09-13 06:46:00 TP2] KV Cache is allocated. #tokens: 620193, KV size: 40.59 GB
[2025-09-13 06:46:00 TP1] KV Cache is allocated. #tokens: 620193, KV size: 40.59 GB
[2025-09-13 06:46:00 TP7] KV Cache is allocated. #tokens: 620193, KV size: 40.59 GB
[2025-09-13 06:46:00 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 06:46:00 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.51 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 06:46:01 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:46:01 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance

Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                                             Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 06:46:01 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:46:02 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:46:02 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:46:02 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:46:02 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:46:02 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:46:02 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25641.06it/s]
[2025-09-13 06:46:02 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:46:02 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26711.28it/s]
[2025-09-13 06:46:03 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:46:03 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27796.21it/s]
[2025-09-13 06:46:03 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:46:03 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26907.22it/s]
[2025-09-13 06:46:04 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:46:04 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28050.19it/s]
[2025-09-13 06:46:05 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.20 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.79it/s][2025-09-13 06:46:08 TP4] Registering 984 cuda graph addresses
[2025-09-13 06:46:08 TP5] Registering 984 cuda graph addresses
[2025-09-13 06:46:08 TP2] Registering 984 cuda graph addresses
[2025-09-13 06:46:08 TP6] Registering 984 cuda graph addresses
[2025-09-13 06:46:08 TP3] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.20 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.14it/s]
[2025-09-13 06:46:08 TP7] Registering 984 cuda graph addresses
[2025-09-13 06:46:08 TP1] Registering 984 cuda graph addresses
[2025-09-13 06:46:08 TP0] Registering 984 cuda graph addresses
[2025-09-13 06:46:08 TP0] Capture cuda graph end. Time elapsed: 7.83 s. mem usage=0.39 GB. avail mem=17.17 GB.
[2025-09-13 06:46:08 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 06:46:08 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:46:08 TP0] Init torch distributed begin.
[2025-09-13 06:46:08 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 06:46:08 TP0] Load weight begin. avail mem=17.17 GB
[2025-09-13 06:46:08 TP0] Detected fp8 checkpoint.
[2025-09-13 06:46:08 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 177.59it/s]
Loading safetensors checkpoint shards:   4% Completed | 42/1024 [00:00<00:04, 212.79it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:00<00:02, 388.39it/s]
Loading safetensors checkpoint shards:  16% Completed | 165/1024 [00:00<00:01, 482.79it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:00<00:01, 531.58it/s]
Loading safetensors checkpoint shards:  28% Completed | 289/1024 [00:00<00:01, 561.11it/s]
Loading safetensors checkpoint shards:  34% Completed | 351/1024 [00:00<00:01, 578.59it/s]
Loading safetensors checkpoint shards:  40% Completed | 413/1024 [00:00<00:01, 588.73it/s]
Loading safetensors checkpoint shards:  46% Completed | 475/1024 [00:00<00:00, 596.80it/s]
Loading safetensors checkpoint shards:  52% Completed | 537/1024 [00:01<00:00, 603.16it/s]
Loading safetensors checkpoint shards:  58% Completed | 599/1024 [00:01<00:00, 608.22it/s]
Loading safetensors checkpoint shards:  64% Completed | 660/1024 [00:01<00:00, 603.17it/s]
Loading safetensors checkpoint shards:  70% Completed | 721/1024 [00:01<00:00, 594.60it/s]
Loading safetensors checkpoint shards:  76% Completed | 781/1024 [00:01<00:00, 587.25it/s]
Loading safetensors checkpoint shards:  82% Completed | 840/1024 [00:01<00:00, 586.66it/s]
Loading safetensors checkpoint shards:  88% Completed | 899/1024 [00:01<00:00, 572.76it/s]
Loading safetensors checkpoint shards:  93% Completed | 957/1024 [00:01<00:00, 569.18it/s]
Loading safetensors checkpoint shards:  99% Completed | 1014/1024 [00:01<00:00, 406.44it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 509.18it/s]

[2025-09-13 06:46:10 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.18 GB, mem usage=1.99 GB.
[2025-09-13 06:46:10 TP5] KV Cache is allocated. #tokens: 620193, KV size: 0.67 GB
[2025-09-13 06:46:10 TP6] KV Cache is allocated. #tokens: 620193, KV size: 0.67 GB
[2025-09-13 06:46:10 TP0] KV Cache is allocated. #tokens: 620193, KV size: 0.67 GB
[2025-09-13 06:46:10 TP0] Memory pool end. avail mem=14.52 GB
[2025-09-13 06:46:10 TP4] KV Cache is allocated. #tokens: 620193, KV size: 0.67 GB
[2025-09-13 06:46:10 TP3] KV Cache is allocated. #tokens: 620193, KV size: 0.67 GB
[2025-09-13 06:46:10 TP7] KV Cache is allocated. #tokens: 620193, KV size: 0.67 GB
[2025-09-13 06:46:10 TP1] KV Cache is allocated. #tokens: 620193, KV size: 0.67 GB
[2025-09-13 06:46:10 TP2] KV Cache is allocated. #tokens: 620193, KV size: 0.67 GB
[2025-09-13 06:46:11 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 06:46:11 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 06:46:11 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 06:46:11 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.95 GB
[2025-09-13 06:46:11 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 06:46:11 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 06:46:11 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.14 GB
[2025-09-13 06:46:11 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
Capturing batches (bs=1 avail_mem=14.64 GB):  62%|█████████████████████████████████████████████████████▊                                | 5/8 [00:03<00:01,  2.41it/s][2025-09-13 06:46:17 TP4] Registering 48 cuda graph addresses
[2025-09-13 06:46:17 TP3] Registering 48 cuda graph addresses
[2025-09-13 06:46:17 TP2] Registering 48 cuda graph addresses
[2025-09-13 06:46:17 TP6] Registering 48 cuda graph addresses
[2025-09-13 06:46:17 TP5] Registering 48 cuda graph addresses
[2025-09-13 06:46:17 TP1] Registering 48 cuda graph addresses
[2025-09-13 06:46:17 TP7] Registering 48 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.64 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.50it/s]
[2025-09-13 06:46:17 TP0] Registering 48 cuda graph addresses
[2025-09-13 06:46:17 TP2] Capture draft cuda graph end. Time elapsed: 6.18 s. mem usage=0.31 GB. avail mem=14.60 GB.
[2025-09-13 06:46:17 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.60 GB
[2025-09-13 06:46:17 TP5] Capture draft cuda graph end. Time elapsed: 6.18 s. mem usage=0.31 GB. avail mem=14.60 GB.
[2025-09-13 06:46:17 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.60 GB
[2025-09-13 06:46:17 TP3] Capture draft cuda graph end. Time elapsed: 6.18 s. mem usage=0.31 GB. avail mem=14.60 GB.
[2025-09-13 06:46:17 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.60 GB
[2025-09-13 06:46:17 TP6] Capture draft cuda graph end. Time elapsed: 6.18 s. mem usage=0.31 GB. avail mem=14.60 GB.
[2025-09-13 06:46:17 TP1] Capture draft cuda graph end. Time elapsed: 6.18 s. mem usage=0.31 GB. avail mem=14.60 GB.
[2025-09-13 06:46:17 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.60 GB
[2025-09-13 06:46:17 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.60 GB
[2025-09-13 06:46:17 TP4] Capture draft cuda graph end. Time elapsed: 6.18 s. mem usage=0.31 GB. avail mem=14.60 GB.
[2025-09-13 06:46:17 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.60 GB
[2025-09-13 06:46:17 TP7] Capture draft cuda graph end. Time elapsed: 6.18 s. mem usage=0.31 GB. avail mem=14.83 GB.
[2025-09-13 06:46:17 TP0] Capture draft cuda graph end. Time elapsed: 6.18 s. mem usage=0.31 GB. avail mem=14.64 GB.
[2025-09-13 06:46:17 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.83 GB
[2025-09-13 06:46:17 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.64 GB
Capturing batches (bs=1 avail_mem=14.45 GB):  62%|█████████████████████████████████████████████████████▊                                | 5/8 [00:00<00:00, 49.37it/s][2025-09-13 06:46:18 TP4] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.45 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 49.35it/s]
[2025-09-13 06:46:18 TP7] Registering 24 cuda graph addresses
[2025-09-13 06:46:18 TP6] Registering 24 cuda graph addresses
[2025-09-13 06:46:18 TP3] Registering 24 cuda graph addresses
[2025-09-13 06:46:18 TP1] Registering 24 cuda graph addresses
[2025-09-13 06:46:18 TP5] Registering 24 cuda graph addresses
[2025-09-13 06:46:18 TP2] Registering 24 cuda graph addresses
[2025-09-13 06:46:18 TP0] Registering 24 cuda graph addresses
[2025-09-13 06:46:18 TP4] Capture draft extend cuda graph end. Time elapsed: 1.21 s. mem usage=0.19 GB. avail mem=14.41 GB.
[2025-09-13 06:46:18 TP7] Capture draft extend cuda graph end. Time elapsed: 1.21 s. mem usage=0.19 GB. avail mem=14.64 GB.
[2025-09-13 06:46:18 TP3] Capture draft extend cuda graph end. Time elapsed: 1.22 s. mem usage=0.19 GB. avail mem=14.41 GB.
[2025-09-13 06:46:18 TP0] Capture draft extend cuda graph end. Time elapsed: 1.21 s. mem usage=0.19 GB. avail mem=14.45 GB.
[2025-09-13 06:46:18 TP6] Capture draft extend cuda graph end. Time elapsed: 1.21 s. mem usage=0.19 GB. avail mem=14.41 GB.
[2025-09-13 06:46:18 TP0] max_total_num_tokens=620193, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.45 GB
[2025-09-13 06:46:18 TP2] Capture draft extend cuda graph end. Time elapsed: 1.22 s. mem usage=0.19 GB. avail mem=14.41 GB.
[2025-09-13 06:46:18 TP5] Capture draft extend cuda graph end. Time elapsed: 1.22 s. mem usage=0.19 GB. avail mem=14.41 GB.
[2025-09-13 06:46:18 TP1] Capture draft extend cuda graph end. Time elapsed: 1.22 s. mem usage=0.19 GB. avail mem=14.41 GB.
[2025-09-13 06:46:19] INFO:     Started server process [153047]
[2025-09-13 06:46:19] INFO:     Waiting for application startup.
[2025-09-13 06:46:19] INFO:     Application startup complete.
[2025-09-13 06:46:19] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 06:46:19] INFO:     127.0.0.1:46602 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 06:46:20] INFO:     127.0.0.1:46616 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 06:46:20 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:46:20 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:46:20 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 29023.26it/s]
[2025-09-13 06:46:21] INFO:     127.0.0.1:46630 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:21] The server is fired up and ready to roll!
[2025-09-13 06:46:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:46:30] INFO:     127.0.0.1:46016 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:46:30] INFO:     127.0.0.1:46020 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:30 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 06:46:32] INFO:     127.0.0.1:46030 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:32] INFO:     127.0.0.1:46036 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:46:32] INFO:     127.0.0.1:46044 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:32] INFO:     127.0.0.1:46058 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:32] INFO:     127.0.0.1:46066 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:32] INFO:     127.0.0.1:46070 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:32] INFO:     127.0.0.1:46082 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:32] INFO:     127.0.0.1:46094 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:32 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 06:46:32 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:46:32 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:46:32 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:46:32 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:46:32 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:46:32 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:46:32 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:46:32 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:46:32 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 06:46:33 TP0] Decode batch. #running-req: 8, #token: 14586, token usage: 0.02, accept len: 3.05, cuda graph: True, gen throughput (token/s): 46.10, #queue-req: 0, 
[2025-09-13 06:46:35 TP0] Decode batch. #running-req: 8, #token: 15667, token usage: 0.03, accept len: 3.38, cuda graph: True, gen throughput (token/s): 850.54, #queue-req: 0, 
[2025-09-13 06:46:36 TP0] Decode batch. #running-req: 8, #token: 16747, token usage: 0.03, accept len: 3.38, cuda graph: True, gen throughput (token/s): 844.32, #queue-req: 0, 
 12%|████████████████▍                                                                                                                  | 1/8 [00:05<00:37,  5.31s/it][2025-09-13 06:46:37 TP0] Decode batch. #running-req: 6, #token: 9450, token usage: 0.02, accept len: 3.37, cuda graph: True, gen throughput (token/s): 824.01, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.26it/s]
[2025-09-13 06:46:38] INFO:     127.0.0.1:58218 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.36      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4083      
Request throughput (req/s):              1.26      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         643.59    
Total token throughput (tok/s):          643.59    
Concurrency:                             7.20      
Accept length:                           3.31      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5728.23   
Median E2E Latency (ms):                 5624.11   
---------------Time to First Token----------------
Mean TTFT (ms):                          631.43    
Median TTFT (ms):                        747.12    
P99 TTFT (ms):                           747.60    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.97      
Median ITL (ms):                         7.99      
P95 ITL (ms):                            16.00     
P99 ITL (ms):                            34.62     
Max ITL (ms):                            372.75    
==================================================
[2025-09-13 06:46:38] INFO:     127.0.0.1:58220 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:46:38] INFO:     127.0.0.1:58224 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:46:38 TP0] Decode batch. #running-req: 1, #token: 4691, token usage: 0.01, accept len: 3.00, cuda graph: True, gen throughput (token/s): 197.07, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 06:46:39] INFO:     127.0.0.1:58234 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:39] INFO:     127.0.0.1:58246 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:46:39] INFO:     127.0.0.1:58260 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:39] INFO:     127.0.0.1:58274 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:39] INFO:     127.0.0.1:58284 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:39] INFO:     127.0.0.1:58290 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:39] INFO:     127.0.0.1:58292 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:39] INFO:     127.0.0.1:58298 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:40 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 06:46:41 TP0] Decode batch. #running-req: 8, #token: 14925, token usage: 0.02, accept len: 3.24, cuda graph: True, gen throughput (token/s): 406.01, #queue-req: 0, 
[2025-09-13 06:46:42 TP0] Decode batch. #running-req: 8, #token: 16002, token usage: 0.03, accept len: 3.37, cuda graph: True, gen throughput (token/s): 844.35, #queue-req: 0, 
[2025-09-13 06:46:43 TP0] Decode batch. #running-req: 8, #token: 17095, token usage: 0.03, accept len: 3.42, cuda graph: True, gen throughput (token/s): 857.73, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:10,  4.73s/it][2025-09-13 06:46:44] INFO:     127.0.0.1:58302 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:44 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:05<00:30,  2.15s/it][2025-09-13 06:46:44] INFO:     127.0.0.1:58318 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:16,  1.27s/it][2025-09-13 06:46:45] INFO:     127.0.0.1:58330 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:45 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:46:45] INFO:     127.0.0.1:58342 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:45 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:07,  1.54it/s][2025-09-13 06:46:45] INFO:     127.0.0.1:58344 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:45 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:46:45] INFO:     127.0.0.1:58348 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:45 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:46:46 TP0] Decode batch. #running-req: 8, #token: 12536, token usage: 0.02, accept len: 3.34, cuda graph: True, gen throughput (token/s): 482.30, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:05,  1.80it/s][2025-09-13 06:46:46] INFO:     127.0.0.1:58352 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:46] INFO:     127.0.0.1:58366 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:46:46 TP0] Prefill batch. #new-seq: 2, #new-token: 6010, #cached-token: 1737, token usage: 0.01, #running-req: 6, #queue-req: 0, 
[2025-09-13 06:46:47 TP0] Decode batch. #running-req: 8, #token: 14575, token usage: 0.02, accept len: 3.04, cuda graph: True, gen throughput (token/s): 620.10, #queue-req: 0, 
[2025-09-13 06:46:48 TP0] Decode batch. #running-req: 8, #token: 15599, token usage: 0.03, accept len: 3.20, cuda graph: True, gen throughput (token/s): 808.53, #queue-req: 0, 
[2025-09-13 06:46:50 TP0] Decode batch. #running-req: 8, #token: 16646, token usage: 0.03, accept len: 3.27, cuda graph: True, gen throughput (token/s): 819.30, #queue-req: 0, 
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 14/16 [00:11<00:00,  2.39it/s][2025-09-13 06:46:51 TP0] Decode batch. #running-req: 2, #token: 7841, token usage: 0.01, accept len: 3.37, cuda graph: True, gen throughput (token/s): 695.55, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.36it/s]
[2025-09-13 06:46:51] INFO:     127.0.0.1:36580 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.76     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8081      
Request throughput (req/s):              1.36      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         696.67    
Total token throughput (tok/s):          696.67    
Concurrency:                             7.69      
Accept length:                           3.28      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5650.41   
Median E2E Latency (ms):                 5624.30   
---------------Time to First Token----------------
Mean TTFT (ms):                          259.92    
Median TTFT (ms):                        288.83    
P99 TTFT (ms):                           340.21    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.55     
Median ITL (ms):                         7.98      
P95 ITL (ms):                            16.29     
P99 ITL (ms):                            52.90     
Max ITL (ms):                            339.25    
==================================================
[2025-09-13 06:46:51] INFO:     127.0.0.1:36584 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=5: batch_size=8, steps=3, topk=3, num_draft_tokens=8, speed=103.10 token/s, step_time=31.84 ms
Start i=6: batch_size=8, steps=3, topk=4, num_draft_tokens=4
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 3 --speculative-eagle-topk 4 --speculative-num-draft-tokens 4 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:47:02.358000 158707 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:47:02.358000 158707 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 06:47:02] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=59048293, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=3, speculative_eagle_topk=4, speculative_num_draft_tokens=4, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:47:03] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:47:11.828000 158916 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:47:11.828000 158916 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:47:11.950000 158919 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:47:11.950000 158919 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:47:11.973000 158923 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:47:11.973000 158923 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:47:12.033000 158922 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:47:12.033000 158922 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:47:12.068000 158918 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:47:12.068000 158918 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:47:12.122000 158920 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:47:12.122000 158920 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:47:12.194000 158915 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:47:12.194000 158915 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:47:12.194000 158917 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:47:12.194000 158917 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:47:12.247000 158921 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:47:12.247000 158921 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:47:12 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 06:47:12 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:47:12 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:47:14 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:47:17 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 06:47:18 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 06:47:18 TP0] Detected fp8 checkpoint.
[2025-09-13 06:47:19 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 24/1024 [00:00<00:04, 227.03it/s]
Loading safetensors checkpoint shards:   5% Completed | 47/1024 [00:00<00:07, 137.63it/s]
Loading safetensors checkpoint shards:   6% Completed | 63/1024 [00:00<00:08, 109.00it/s]
Loading safetensors checkpoint shards:   7% Completed | 76/1024 [00:00<00:11, 83.96it/s]
Loading safetensors checkpoint shards:   8% Completed | 86/1024 [00:00<00:13, 69.02it/s]
Loading safetensors checkpoint shards:   9% Completed | 94/1024 [00:01<00:16, 57.35it/s]
Loading safetensors checkpoint shards:  10% Completed | 101/1024 [00:01<00:28, 32.48it/s]
Loading safetensors checkpoint shards:  10% Completed | 106/1024 [00:01<00:27, 33.53it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:26, 34.53it/s]
Loading safetensors checkpoint shards:  11% Completed | 117/1024 [00:02<00:23, 38.02it/s]
Loading safetensors checkpoint shards:  12% Completed | 122/1024 [00:02<00:22, 40.26it/s]
Loading safetensors checkpoint shards:  12% Completed | 127/1024 [00:02<00:21, 41.39it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:02<00:21, 41.53it/s]
Loading safetensors checkpoint shards:  14% Completed | 139/1024 [00:02<00:19, 45.81it/s]
Loading safetensors checkpoint shards:  14% Completed | 144/1024 [00:02<00:19, 45.37it/s]
Loading safetensors checkpoint shards:  15% Completed | 149/1024 [00:02<00:19, 44.80it/s]
Loading safetensors checkpoint shards:  15% Completed | 154/1024 [00:02<00:19, 44.65it/s]
Loading safetensors checkpoint shards:  16% Completed | 159/1024 [00:03<00:18, 45.83it/s]
Loading safetensors checkpoint shards:  16% Completed | 165/1024 [00:03<00:17, 48.36it/s]
Loading safetensors checkpoint shards:  17% Completed | 170/1024 [00:03<00:18, 46.81it/s]
Loading safetensors checkpoint shards:  17% Completed | 176/1024 [00:03<00:17, 48.73it/s]
Loading safetensors checkpoint shards:  18% Completed | 183/1024 [00:03<00:15, 53.17it/s]
Loading safetensors checkpoint shards:  18% Completed | 189/1024 [00:03<00:16, 49.13it/s]
Loading safetensors checkpoint shards:  19% Completed | 196/1024 [00:03<00:16, 51.42it/s]
Loading safetensors checkpoint shards:  20% Completed | 202/1024 [00:03<00:16, 49.72it/s]
Loading safetensors checkpoint shards:  20% Completed | 208/1024 [00:04<00:17, 46.02it/s]
Loading safetensors checkpoint shards:  21% Completed | 213/1024 [00:04<00:18, 44.45it/s]
Loading safetensors checkpoint shards:  21% Completed | 218/1024 [00:04<00:18, 44.19it/s]
Loading safetensors checkpoint shards:  22% Completed | 223/1024 [00:04<00:19, 40.90it/s]
Loading safetensors checkpoint shards:  22% Completed | 228/1024 [00:04<00:19, 40.07it/s]
Loading safetensors checkpoint shards:  23% Completed | 233/1024 [00:04<00:22, 35.79it/s]
Loading safetensors checkpoint shards:  23% Completed | 237/1024 [00:05<00:41, 18.87it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:05<00:38, 20.35it/s]
Loading safetensors checkpoint shards:  24% Completed | 244/1024 [00:05<00:33, 23.40it/s]
Loading safetensors checkpoint shards:  24% Completed | 249/1024 [00:05<00:27, 28.23it/s]
Loading safetensors checkpoint shards:  25% Completed | 253/1024 [00:05<00:25, 30.22it/s]
Loading safetensors checkpoint shards:  25% Completed | 258/1024 [00:05<00:22, 34.25it/s]
Loading safetensors checkpoint shards:  26% Completed | 263/1024 [00:05<00:20, 37.23it/s]
Loading safetensors checkpoint shards:  26% Completed | 268/1024 [00:06<00:19, 38.00it/s]
Loading safetensors checkpoint shards:  27% Completed | 273/1024 [00:06<00:18, 39.69it/s]
Loading safetensors checkpoint shards:  27% Completed | 278/1024 [00:06<00:19, 38.39it/s]
Loading safetensors checkpoint shards:  28% Completed | 282/1024 [00:06<00:19, 38.18it/s]
Loading safetensors checkpoint shards:  28% Completed | 286/1024 [00:06<00:21, 33.76it/s]
Loading safetensors checkpoint shards:  28% Completed | 290/1024 [00:06<00:24, 30.54it/s]
Loading safetensors checkpoint shards:  29% Completed | 294/1024 [00:06<00:23, 31.09it/s]
Loading safetensors checkpoint shards:  29% Completed | 298/1024 [00:06<00:23, 31.35it/s]
Loading safetensors checkpoint shards:  29% Completed | 302/1024 [00:07<00:24, 29.09it/s]
Loading safetensors checkpoint shards:  30% Completed | 307/1024 [00:07<00:21, 32.84it/s]
Loading safetensors checkpoint shards:  30% Completed | 311/1024 [00:07<00:20, 34.09it/s]
Loading safetensors checkpoint shards:  31% Completed | 316/1024 [00:07<00:18, 37.36it/s]
Loading safetensors checkpoint shards:  31% Completed | 320/1024 [00:07<00:18, 37.87it/s]
Loading safetensors checkpoint shards:  32% Completed | 324/1024 [00:07<00:18, 37.50it/s]
Loading safetensors checkpoint shards:  32% Completed | 329/1024 [00:07<00:17, 39.22it/s]
Loading safetensors checkpoint shards:  33% Completed | 333/1024 [00:07<00:17, 39.01it/s]
Loading safetensors checkpoint shards:  33% Completed | 338/1024 [00:07<00:17, 40.15it/s]
Loading safetensors checkpoint shards:  33% Completed | 343/1024 [00:08<00:17, 38.75it/s]
Loading safetensors checkpoint shards:  34% Completed | 347/1024 [00:08<00:18, 37.16it/s]
Loading safetensors checkpoint shards:  34% Completed | 352/1024 [00:08<00:17, 38.27it/s]
Loading safetensors checkpoint shards:  35% Completed | 356/1024 [00:08<00:17, 37.44it/s]
Loading safetensors checkpoint shards:  35% Completed | 361/1024 [00:08<00:16, 39.39it/s]
Loading safetensors checkpoint shards:  36% Completed | 365/1024 [00:08<00:17, 38.08it/s]
Loading safetensors checkpoint shards:  36% Completed | 369/1024 [00:08<00:17, 37.30it/s]
Loading safetensors checkpoint shards:  37% Completed | 374/1024 [00:08<00:16, 38.45it/s]
Loading safetensors checkpoint shards:  37% Completed | 378/1024 [00:09<00:17, 37.53it/s]
Loading safetensors checkpoint shards:  37% Completed | 383/1024 [00:09<00:16, 38.88it/s]
Loading safetensors checkpoint shards:  38% Completed | 387/1024 [00:09<00:16, 38.18it/s]
Loading safetensors checkpoint shards:  38% Completed | 391/1024 [00:09<00:16, 37.71it/s]
Loading safetensors checkpoint shards:  39% Completed | 396/1024 [00:09<00:16, 38.37it/s]
Loading safetensors checkpoint shards:  39% Completed | 400/1024 [00:09<00:16, 37.77it/s]
Loading safetensors checkpoint shards:  40% Completed | 405/1024 [00:09<00:15, 39.18it/s]
Loading safetensors checkpoint shards:  40% Completed | 409/1024 [00:09<00:16, 38.24it/s]
Loading safetensors checkpoint shards:  40% Completed | 413/1024 [00:09<00:16, 37.85it/s]
Loading safetensors checkpoint shards:  41% Completed | 418/1024 [00:10<00:15, 38.94it/s]
Loading safetensors checkpoint shards:  41% Completed | 422/1024 [00:10<00:15, 38.42it/s]
Loading safetensors checkpoint shards:  42% Completed | 427/1024 [00:10<00:14, 40.22it/s]
Loading safetensors checkpoint shards:  42% Completed | 432/1024 [00:10<00:15, 38.56it/s]
Loading safetensors checkpoint shards:  43% Completed | 436/1024 [00:10<00:15, 38.48it/s]
Loading safetensors checkpoint shards:  43% Completed | 441/1024 [00:10<00:14, 39.80it/s]
Loading safetensors checkpoint shards:  43% Completed | 445/1024 [00:11<00:31, 18.51it/s]
Loading safetensors checkpoint shards:  44% Completed | 450/1024 [00:11<00:25, 22.85it/s]
Loading safetensors checkpoint shards:  44% Completed | 455/1024 [00:11<00:21, 26.59it/s]
Loading safetensors checkpoint shards:  45% Completed | 459/1024 [00:11<00:19, 28.61it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:11<00:18, 29.61it/s]
Loading safetensors checkpoint shards:  46% Completed | 467/1024 [00:11<00:17, 31.43it/s]
Loading safetensors checkpoint shards:  46% Completed | 473/1024 [00:11<00:15, 36.22it/s]
Loading safetensors checkpoint shards:  47% Completed | 477/1024 [00:11<00:14, 36.54it/s]
Loading safetensors checkpoint shards:  47% Completed | 481/1024 [00:12<00:14, 36.65it/s]
Loading safetensors checkpoint shards:  47% Completed | 486/1024 [00:12<00:13, 39.62it/s]
Loading safetensors checkpoint shards:  48% Completed | 491/1024 [00:12<00:14, 37.70it/s]
Loading safetensors checkpoint shards:  48% Completed | 496/1024 [00:12<00:13, 39.57it/s]
Loading safetensors checkpoint shards:  49% Completed | 501/1024 [00:12<00:13, 39.24it/s]
Loading safetensors checkpoint shards:  49% Completed | 506/1024 [00:12<00:12, 40.36it/s]
Loading safetensors checkpoint shards:  50% Completed | 511/1024 [00:12<00:12, 40.79it/s]
Loading safetensors checkpoint shards:  50% Completed | 517/1024 [00:12<00:11, 43.38it/s]
Loading safetensors checkpoint shards:  51% Completed | 522/1024 [00:13<00:11, 41.88it/s]
Loading safetensors checkpoint shards:  51% Completed | 527/1024 [00:13<00:11, 43.97it/s]
Loading safetensors checkpoint shards:  52% Completed | 532/1024 [00:13<00:11, 44.13it/s]
Loading safetensors checkpoint shards:  52% Completed | 537/1024 [00:13<00:10, 44.79it/s]
Loading safetensors checkpoint shards:  53% Completed | 542/1024 [00:13<00:10, 44.87it/s]
Loading safetensors checkpoint shards:  53% Completed | 547/1024 [00:13<00:10, 45.19it/s]
Loading safetensors checkpoint shards:  54% Completed | 553/1024 [00:13<00:09, 47.13it/s]
Loading safetensors checkpoint shards:  54% Completed | 558/1024 [00:13<00:10, 44.82it/s]
Loading safetensors checkpoint shards:  55% Completed | 563/1024 [00:13<00:09, 46.19it/s]
Loading safetensors checkpoint shards:  55% Completed | 568/1024 [00:14<00:10, 45.15it/s]
Loading safetensors checkpoint shards:  56% Completed | 573/1024 [00:14<00:09, 46.26it/s]
Loading safetensors checkpoint shards:  56% Completed | 578/1024 [00:14<00:10, 43.93it/s]
Loading safetensors checkpoint shards:  57% Completed | 584/1024 [00:14<00:09, 47.03it/s]
Loading safetensors checkpoint shards:  58% Completed | 589/1024 [00:14<00:09, 45.59it/s]
Loading safetensors checkpoint shards:  58% Completed | 594/1024 [00:14<00:09, 45.75it/s]
Loading safetensors checkpoint shards:  58% Completed | 599/1024 [00:14<00:09, 44.32it/s]
Loading safetensors checkpoint shards:  59% Completed | 605/1024 [00:14<00:09, 45.99it/s]
Loading safetensors checkpoint shards:  60% Completed | 610/1024 [00:15<00:09, 44.23it/s]
Loading safetensors checkpoint shards:  60% Completed | 616/1024 [00:15<00:08, 45.67it/s]
Loading safetensors checkpoint shards:  61% Completed | 621/1024 [00:15<00:08, 45.32it/s]
Loading safetensors checkpoint shards:  61% Completed | 626/1024 [00:15<00:08, 44.78it/s]
Loading safetensors checkpoint shards:  62% Completed | 631/1024 [00:15<00:09, 42.70it/s]
Loading safetensors checkpoint shards:  62% Completed | 636/1024 [00:15<00:09, 42.13it/s]
Loading safetensors checkpoint shards:  63% Completed | 641/1024 [00:15<00:09, 41.52it/s]
Loading safetensors checkpoint shards:  63% Completed | 646/1024 [00:15<00:09, 40.52it/s]
Loading safetensors checkpoint shards:  64% Completed | 651/1024 [00:15<00:09, 40.33it/s]
Loading safetensors checkpoint shards:  64% Completed | 656/1024 [00:16<00:09, 40.27it/s]
Loading safetensors checkpoint shards:  65% Completed | 661/1024 [00:16<00:09, 38.97it/s]
Loading safetensors checkpoint shards:  65% Completed | 666/1024 [00:16<00:09, 39.57it/s]
Loading safetensors checkpoint shards:  66% Completed | 671/1024 [00:16<00:08, 40.09it/s]
Loading safetensors checkpoint shards:  66% Completed | 676/1024 [00:16<00:08, 39.86it/s]
Loading safetensors checkpoint shards:  67% Completed | 681/1024 [00:16<00:08, 40.84it/s]
Loading safetensors checkpoint shards:  67% Completed | 686/1024 [00:16<00:08, 41.68it/s]
Loading safetensors checkpoint shards:  67% Completed | 691/1024 [00:16<00:07, 42.39it/s]
Loading safetensors checkpoint shards:  68% Completed | 697/1024 [00:17<00:07, 44.64it/s]
Loading safetensors checkpoint shards:  69% Completed | 702/1024 [00:17<00:07, 43.07it/s]
Loading safetensors checkpoint shards:  69% Completed | 707/1024 [00:17<00:07, 43.47it/s]
Loading safetensors checkpoint shards:  70% Completed | 712/1024 [00:17<00:07, 43.76it/s]
Loading safetensors checkpoint shards:  70% Completed | 717/1024 [00:17<00:07, 42.56it/s]
Loading safetensors checkpoint shards:  71% Completed | 722/1024 [00:17<00:07, 42.73it/s]
Loading safetensors checkpoint shards:  71% Completed | 727/1024 [00:18<00:15, 19.70it/s]
Loading safetensors checkpoint shards:  71% Completed | 732/1024 [00:18<00:12, 23.28it/s]
Loading safetensors checkpoint shards:  72% Completed | 737/1024 [00:18<00:10, 26.89it/s]
Loading safetensors checkpoint shards:  72% Completed | 742/1024 [00:18<00:09, 30.25it/s]
Loading safetensors checkpoint shards:  73% Completed | 747/1024 [00:18<00:08, 32.86it/s]
Loading safetensors checkpoint shards:  73% Completed | 752/1024 [00:18<00:07, 35.66it/s]
Loading safetensors checkpoint shards:  74% Completed | 757/1024 [00:18<00:07, 37.60it/s]
Loading safetensors checkpoint shards:  74% Completed | 762/1024 [00:19<00:06, 38.89it/s]
Loading safetensors checkpoint shards:  75% Completed | 767/1024 [00:19<00:06, 39.34it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:19<00:06, 38.72it/s]
Loading safetensors checkpoint shards:  76% Completed | 777/1024 [00:19<00:06, 39.42it/s]
Loading safetensors checkpoint shards:  76% Completed | 782/1024 [00:19<00:06, 39.75it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:19<00:06, 38.58it/s]
Loading safetensors checkpoint shards:  77% Completed | 791/1024 [00:19<00:05, 38.88it/s]
Loading safetensors checkpoint shards:  78% Completed | 795/1024 [00:19<00:06, 38.09it/s]
Loading safetensors checkpoint shards:  78% Completed | 799/1024 [00:20<00:05, 38.58it/s]
Loading safetensors checkpoint shards:  79% Completed | 804/1024 [00:20<00:05, 39.83it/s]
Loading safetensors checkpoint shards:  79% Completed | 808/1024 [00:20<00:05, 39.79it/s]
Loading safetensors checkpoint shards:  79% Completed | 812/1024 [00:20<00:05, 39.47it/s]
Loading safetensors checkpoint shards:  80% Completed | 816/1024 [00:20<00:05, 38.90it/s]
Loading safetensors checkpoint shards:  80% Completed | 820/1024 [00:20<00:05, 38.26it/s]
Loading safetensors checkpoint shards:  80% Completed | 824/1024 [00:20<00:05, 38.53it/s]
Loading safetensors checkpoint shards:  81% Completed | 829/1024 [00:20<00:04, 39.64it/s]
Loading safetensors checkpoint shards:  81% Completed | 834/1024 [00:20<00:04, 40.51it/s]
Loading safetensors checkpoint shards:  82% Completed | 839/1024 [00:21<00:04, 39.92it/s]
Loading safetensors checkpoint shards:  82% Completed | 843/1024 [00:21<00:04, 38.41it/s]
Loading safetensors checkpoint shards:  83% Completed | 847/1024 [00:21<00:04, 38.39it/s]
Loading safetensors checkpoint shards:  83% Completed | 851/1024 [00:21<00:04, 38.39it/s]
Loading safetensors checkpoint shards:  83% Completed | 855/1024 [00:21<00:04, 38.22it/s]
Loading safetensors checkpoint shards:  84% Completed | 859/1024 [00:21<00:04, 37.14it/s]
Loading safetensors checkpoint shards:  84% Completed | 863/1024 [00:21<00:04, 36.68it/s]
Loading safetensors checkpoint shards:  85% Completed | 867/1024 [00:21<00:04, 37.25it/s]
Loading safetensors checkpoint shards:  85% Completed | 872/1024 [00:21<00:03, 38.17it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:22<00:03, 37.36it/s]
Loading safetensors checkpoint shards:  86% Completed | 880/1024 [00:22<00:03, 37.38it/s]
Loading safetensors checkpoint shards:  86% Completed | 884/1024 [00:22<00:03, 37.20it/s]
Loading safetensors checkpoint shards:  87% Completed | 888/1024 [00:22<00:03, 37.33it/s]
Loading safetensors checkpoint shards:  87% Completed | 892/1024 [00:22<00:03, 36.28it/s]
Loading safetensors checkpoint shards:  88% Completed | 896/1024 [00:22<00:03, 36.51it/s]
Loading safetensors checkpoint shards:  88% Completed | 900/1024 [00:22<00:03, 37.07it/s]
Loading safetensors checkpoint shards:  88% Completed | 904/1024 [00:22<00:03, 37.11it/s]
Loading safetensors checkpoint shards:  89% Completed | 908/1024 [00:22<00:03, 37.06it/s]
Loading safetensors checkpoint shards:  89% Completed | 912/1024 [00:23<00:03, 37.19it/s]
Loading safetensors checkpoint shards:  90% Completed | 917/1024 [00:23<00:02, 38.58it/s]
Loading safetensors checkpoint shards:  90% Completed | 921/1024 [00:23<00:02, 38.73it/s]
Loading safetensors checkpoint shards:  90% Completed | 925/1024 [00:23<00:02, 37.46it/s]
Loading safetensors checkpoint shards:  91% Completed | 929/1024 [00:23<00:02, 36.65it/s]
Loading safetensors checkpoint shards:  91% Completed | 933/1024 [00:23<00:02, 35.80it/s]
Loading safetensors checkpoint shards:  92% Completed | 937/1024 [00:23<00:02, 36.56it/s]
Loading safetensors checkpoint shards:  92% Completed | 941/1024 [00:23<00:02, 36.96it/s]
Loading safetensors checkpoint shards:  92% Completed | 945/1024 [00:23<00:02, 35.23it/s]
Loading safetensors checkpoint shards:  93% Completed | 949/1024 [00:24<00:02, 35.07it/s]
Loading safetensors checkpoint shards:  93% Completed | 953/1024 [00:24<00:02, 35.13it/s]
Loading safetensors checkpoint shards:  93% Completed | 957/1024 [00:24<00:01, 35.39it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:24<00:01, 34.34it/s]
Loading safetensors checkpoint shards:  94% Completed | 966/1024 [00:24<00:01, 35.56it/s]
Loading safetensors checkpoint shards:  95% Completed | 970/1024 [00:24<00:01, 34.49it/s]
Loading safetensors checkpoint shards:  95% Completed | 974/1024 [00:24<00:01, 34.87it/s]
Loading safetensors checkpoint shards:  96% Completed | 978/1024 [00:24<00:01, 35.31it/s]
Loading safetensors checkpoint shards:  96% Completed | 986/1024 [00:24<00:00, 45.97it/s]
Loading safetensors checkpoint shards:  98% Completed | 1003/1024 [00:25<00:00, 74.83it/s]
Loading safetensors checkpoint shards:  99% Completed | 1011/1024 [00:25<00:00, 75.98it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 90.82it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 40.49it/s]

[2025-09-13 06:47:45 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 06:47:46 TP6] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 06:47:46 TP7] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 06:47:46 TP0] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 06:47:46 TP2] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 06:47:46 TP5] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 06:47:46 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 06:47:46 TP4] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 06:47:46 TP3] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 06:47:46 TP1] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 06:47:47 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 06:47:47 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.53 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 06:47:48 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:47:48 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 06:47:48 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:47:48 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:47:48 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:47:48 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:47:48 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:47:48 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:47:48 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25374.30it/s]
[2025-09-13 06:47:49 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:47:49 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26191.81it/s]
[2025-09-13 06:47:49 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:47:49 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27749.15it/s]
[2025-09-13 06:47:50 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:47:50 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26569.13it/s]
[2025-09-13 06:47:51 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:47:51 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27919.49it/s]
[2025-09-13 06:47:51 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.22 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.12it/s]
[2025-09-13 06:47:55 TP2] Registering 984 cuda graph addresses
[2025-09-13 06:47:55 TP3] Registering 984 cuda graph addresses
[2025-09-13 06:47:55 TP4] Registering 984 cuda graph addresses
[2025-09-13 06:47:55 TP5] Registering 984 cuda graph addresses
[2025-09-13 06:47:55 TP1] Registering 984 cuda graph addresses
[2025-09-13 06:47:55 TP7] Registering 984 cuda graph addresses
[2025-09-13 06:47:55 TP0] Registering 984 cuda graph addresses
[2025-09-13 06:47:55 TP6] Registering 984 cuda graph addresses
[2025-09-13 06:47:55 TP0] Capture cuda graph end. Time elapsed: 8.02 s. mem usage=0.36 GB. avail mem=17.20 GB.
[2025-09-13 06:47:55 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 06:47:55 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:47:55 TP0] Init torch distributed begin.
[2025-09-13 06:47:55 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 06:47:55 TP0] Load weight begin. avail mem=17.20 GB
[2025-09-13 06:47:55 TP0] Detected fp8 checkpoint.
[2025-09-13 06:47:55 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 19/1024 [00:00<00:05, 185.24it/s]
Loading safetensors checkpoint shards:   5% Completed | 52/1024 [00:00<00:03, 266.64it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:00<00:02, 411.82it/s]
Loading safetensors checkpoint shards:  17% Completed | 173/1024 [00:00<00:01, 491.58it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:00<00:01, 531.47it/s]
Loading safetensors checkpoint shards:  29% Completed | 296/1024 [00:00<00:01, 561.15it/s]
Loading safetensors checkpoint shards:  35% Completed | 357/1024 [00:00<00:01, 574.87it/s]
Loading safetensors checkpoint shards:  41% Completed | 419/1024 [00:00<00:01, 588.59it/s]
Loading safetensors checkpoint shards:  47% Completed | 480/1024 [00:00<00:00, 594.40it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:01<00:00, 597.51it/s]
Loading safetensors checkpoint shards:  59% Completed | 602/1024 [00:01<00:00, 600.95it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:01<00:00, 592.53it/s]
Loading safetensors checkpoint shards:  71% Completed | 723/1024 [00:01<00:00, 581.19it/s]
Loading safetensors checkpoint shards:  76% Completed | 782/1024 [00:01<00:00, 568.37it/s]
Loading safetensors checkpoint shards:  82% Completed | 839/1024 [00:01<00:00, 563.46it/s]
Loading safetensors checkpoint shards:  88% Completed | 896/1024 [00:01<00:00, 557.23it/s]
Loading safetensors checkpoint shards:  93% Completed | 953/1024 [00:01<00:00, 558.11it/s]
Loading safetensors checkpoint shards:  99% Completed | 1009/1024 [00:01<00:00, 410.71it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 506.74it/s]

[2025-09-13 06:47:57 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.21 GB, mem usage=1.99 GB.
[2025-09-13 06:47:57 TP7] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 06:47:57 TP1] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 06:47:57 TP3] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 06:47:57 TP4] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 06:47:57 TP0] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 06:47:57 TP5] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 06:47:57 TP6] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 06:47:57 TP2] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 06:47:57 TP0] Memory pool end. avail mem=14.54 GB
[2025-09-13 06:47:58 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:47:58 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:47:58 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.17 GB
[2025-09-13 06:47:58 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:47:58 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:47:58 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 06:47:58 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:47:58 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
Capturing batches (bs=1 avail_mem=14.61 GB):  62%|█████████████████████████████████████████████████████▊                                | 5/8 [00:03<00:01,  2.42it/s][2025-09-13 06:48:04 TP3] Registering 48 cuda graph addresses
[2025-09-13 06:48:04 TP5] Registering 48 cuda graph addresses
[2025-09-13 06:48:04 TP2] Registering 48 cuda graph addresses
[2025-09-13 06:48:04 TP4] Registering 48 cuda graph addresses
[2025-09-13 06:48:04 TP7] Registering 48 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.61 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.50it/s]
[2025-09-13 06:48:04 TP0] Registering 48 cuda graph addresses
[2025-09-13 06:48:04 TP1] Registering 48 cuda graph addresses
[2025-09-13 06:48:04 TP6] Registering 48 cuda graph addresses
[2025-09-13 06:48:04 TP3] Capture draft cuda graph end. Time elapsed: 6.20 s. mem usage=0.37 GB. avail mem=14.57 GB.
[2025-09-13 06:48:04 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.57 GB
[2025-09-13 06:48:04 TP5] Capture draft cuda graph end. Time elapsed: 6.20 s. mem usage=0.37 GB. avail mem=14.57 GB.
[2025-09-13 06:48:04 TP0] Capture draft cuda graph end. Time elapsed: 6.20 s. mem usage=0.37 GB. avail mem=14.61 GB.
[2025-09-13 06:48:04 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.57 GB
[2025-09-13 06:48:04 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.61 GB
[2025-09-13 06:48:04 TP1] Capture draft cuda graph end. Time elapsed: 6.20 s. mem usage=0.37 GB. avail mem=14.57 GB.
[2025-09-13 06:48:04 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.57 GB
[2025-09-13 06:48:04 TP4] Capture draft cuda graph end. Time elapsed: 6.20 s. mem usage=0.37 GB. avail mem=14.57 GB.
[2025-09-13 06:48:04 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.57 GB
[2025-09-13 06:48:04 TP7] Capture draft cuda graph end. Time elapsed: 6.20 s. mem usage=0.37 GB. avail mem=14.80 GB.
[2025-09-13 06:48:04 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.80 GB
[2025-09-13 06:48:04 TP2] Capture draft cuda graph end. Time elapsed: 6.20 s. mem usage=0.37 GB. avail mem=14.57 GB.
[2025-09-13 06:48:04 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.57 GB
[2025-09-13 06:48:04 TP6] Capture draft cuda graph end. Time elapsed: 6.20 s. mem usage=0.37 GB. avail mem=14.57 GB.
[2025-09-13 06:48:04 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.57 GB
Capturing batches (bs=1 avail_mem=14.42 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 45.79it/s][2025-09-13 06:48:05 TP4] Registering 24 cuda graph addresses

[2025-09-13 06:48:05 TP6] Registering 24 cuda graph addresses
[2025-09-13 06:48:05 TP7] Registering 24 cuda graph addresses
[2025-09-13 06:48:05 TP3] Registering 24 cuda graph addresses
[2025-09-13 06:48:05 TP2] Registering 24 cuda graph addresses
[2025-09-13 06:48:05 TP0] Registering 24 cuda graph addresses
[2025-09-13 06:48:05 TP5] Registering 24 cuda graph addresses
[2025-09-13 06:48:05 TP1] Registering 24 cuda graph addresses
[2025-09-13 06:48:05 TP7] Capture draft extend cuda graph end. Time elapsed: 0.95 s. mem usage=0.19 GB. avail mem=14.61 GB.
[2025-09-13 06:48:05 TP2] Capture draft extend cuda graph end. Time elapsed: 0.95 s. mem usage=0.19 GB. avail mem=14.38 GB.
[2025-09-13 06:48:05 TP0] Capture draft extend cuda graph end. Time elapsed: 0.96 s. mem usage=0.19 GB. avail mem=14.42 GB.
[2025-09-13 06:48:05 TP0] max_total_num_tokens=620185, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.42 GB
[2025-09-13 06:48:05 TP6] Capture draft extend cuda graph end. Time elapsed: 0.96 s. mem usage=0.19 GB. avail mem=14.38 GB.
[2025-09-13 06:48:05 TP1] Capture draft extend cuda graph end. Time elapsed: 0.96 s. mem usage=0.19 GB. avail mem=14.38 GB.
[2025-09-13 06:48:05 TP3] Capture draft extend cuda graph end. Time elapsed: 0.96 s. mem usage=0.19 GB. avail mem=14.38 GB.
[2025-09-13 06:48:05 TP4] Capture draft extend cuda graph end. Time elapsed: 0.96 s. mem usage=0.19 GB. avail mem=14.38 GB.
[2025-09-13 06:48:05 TP5] Capture draft extend cuda graph end. Time elapsed: 0.96 s. mem usage=0.19 GB. avail mem=14.38 GB.
[2025-09-13 06:48:05] INFO:     Started server process [158707]
[2025-09-13 06:48:05] INFO:     Waiting for application startup.
[2025-09-13 06:48:05] INFO:     Application startup complete.
[2025-09-13 06:48:05] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 06:48:06] INFO:     127.0.0.1:59252 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 06:48:06 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:48:06 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:48:06 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup:   0%|                                                                                                                      | 0/16384 [00:00<?, ?it/s][2025-09-13 06:48:06] INFO:     127.0.0.1:59280 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28803.40it/s]
[2025-09-13 06:48:07] INFO:     127.0.0.1:59264 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:07] The server is fired up and ready to roll!
[2025-09-13 06:48:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:48:17] INFO:     127.0.0.1:58116 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:48:18] INFO:     127.0.0.1:33042 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:18 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 06:48:19] INFO:     127.0.0.1:33044 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:19] INFO:     127.0.0.1:33046 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:19 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:48:19] INFO:     127.0.0.1:33058 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:19] INFO:     127.0.0.1:33066 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:19] INFO:     127.0.0.1:33072 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:19] INFO:     127.0.0.1:33086 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:19] INFO:     127.0.0.1:33088 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:19] INFO:     127.0.0.1:33098 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:19 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 06:48:20 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:48:20 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:48:20 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:48:20 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:48:20 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:48:20 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:48:20 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:48:20 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:48:20 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 06:48:21 TP0] Decode batch. #running-req: 8, #token: 14470, token usage: 0.02, accept len: 2.63, cuda graph: True, gen throughput (token/s): 36.73, #queue-req: 0, 
[2025-09-13 06:48:22 TP0] Decode batch. #running-req: 8, #token: 15399, token usage: 0.02, accept len: 2.90, cuda graph: True, gen throughput (token/s): 805.58, #queue-req: 0, 
[2025-09-13 06:48:23 TP0] Decode batch. #running-req: 8, #token: 16345, token usage: 0.03, accept len: 2.96, cuda graph: True, gen throughput (token/s): 807.45, #queue-req: 0, 
[2025-09-13 06:48:24 TP0] Decode batch. #running-req: 8, #token: 17312, token usage: 0.03, accept len: 3.02, cuda graph: True, gen throughput (token/s): 829.85, #queue-req: 0, 
 62%|█████████████████████████████████████████████████████████████████████████████████▉                                                 | 5/8 [00:05<00:02,  1.41it/s][2025-09-13 06:48:25 TP0] Decode batch. #running-req: 3, #token: 6489, token usage: 0.01, accept len: 3.17, cuda graph: True, gen throughput (token/s): 575.87, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.22it/s]
[2025-09-13 06:48:26] INFO:     127.0.0.1:33102 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.56      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4068      
Request throughput (req/s):              1.22      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         623.94    
Total token throughput (tok/s):          623.94    
Concurrency:                             7.10      
Accept length:                           2.94      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5823.45   
Median E2E Latency (ms):                 5742.75   
---------------Time to First Token----------------
Mean TTFT (ms):                          608.96    
Median TTFT (ms):                        720.88    
P99 TTFT (ms):                           721.56    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.20     
Median ITL (ms):                         7.33      
P95 ITL (ms):                            28.11     
P99 ITL (ms):                            32.46     
Max ITL (ms):                            725.44    
==================================================
[2025-09-13 06:48:26] INFO:     127.0.0.1:33114 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:48:26] INFO:     127.0.0.1:33116 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 06:48:27] INFO:     127.0.0.1:33122 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:27] INFO:     127.0.0.1:33136 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:48:27] INFO:     127.0.0.1:33150 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:27] INFO:     127.0.0.1:33162 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:27] INFO:     127.0.0.1:33164 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:27] INFO:     127.0.0.1:33180 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:27] INFO:     127.0.0.1:33192 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:27] INFO:     127.0.0.1:33200 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:27 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 06:48:28 TP0] Decode batch. #running-req: 8, #token: 14179, token usage: 0.02, accept len: 2.49, cuda graph: True, gen throughput (token/s): 139.64, #queue-req: 0, 
[2025-09-13 06:48:29 TP0] Decode batch. #running-req: 8, #token: 15097, token usage: 0.02, accept len: 2.87, cuda graph: True, gen throughput (token/s): 800.02, #queue-req: 0, 
[2025-09-13 06:48:30 TP0] Decode batch. #running-req: 8, #token: 16031, token usage: 0.03, accept len: 2.92, cuda graph: True, gen throughput (token/s): 806.25, #queue-req: 0, 
[2025-09-13 06:48:31 TP0] Decode batch. #running-req: 8, #token: 17021, token usage: 0.03, accept len: 3.09, cuda graph: True, gen throughput (token/s): 854.83, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:09,  4.65s/it][2025-09-13 06:48:32] INFO:     127.0.0.1:36146 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:32 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:05<00:30,  2.15s/it][2025-09-13 06:48:32] INFO:     127.0.0.1:36162 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:16,  1.28s/it][2025-09-13 06:48:32] INFO:     127.0.0.1:36172 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:32 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.10it/s][2025-09-13 06:48:33] INFO:     127.0.0.1:36180 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:33 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:48:33 TP0] Decode batch. #running-req: 8, #token: 9795, token usage: 0.02, accept len: 3.04, cuda graph: True, gen throughput (token/s): 536.10, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:07,  1.49it/s][2025-09-13 06:48:33] INFO:     127.0.0.1:36194 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:33 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:06<00:06,  1.59it/s][2025-09-13 06:48:33] INFO:     127.0.0.1:36196 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:33 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:48:33] INFO:     127.0.0.1:36208 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:03,  2.39it/s][2025-09-13 06:48:34] INFO:     127.0.0.1:36224 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:48:34 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:48:35 TP0] Decode batch. #running-req: 8, #token: 14334, token usage: 0.02, accept len: 2.83, cuda graph: True, gen throughput (token/s): 495.94, #queue-req: 0, 
[2025-09-13 06:48:36 TP0] Decode batch. #running-req: 8, #token: 15268, token usage: 0.02, accept len: 2.92, cuda graph: True, gen throughput (token/s): 805.44, #queue-req: 0, 
[2025-09-13 06:48:37 TP0] Decode batch. #running-req: 8, #token: 16259, token usage: 0.03, accept len: 3.10, cuda graph: True, gen throughput (token/s): 848.24, #queue-req: 0, 
 62%|████████████████████████████████████████████████████████████████████████████████▋                                                | 10/16 [00:10<00:06,  1.02s/it][2025-09-13 06:48:38 TP0] Decode batch. #running-req: 6, #token: 11402, token usage: 0.02, accept len: 3.12, cuda graph: True, gen throughput (token/s): 805.38, #queue-req: 0, 
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 13/16 [00:11<00:01,  1.84it/s][2025-09-13 06:48:39 TP0] Decode batch. #running-req: 1, #token: 3230, token usage: 0.01, accept len: 2.91, cuda graph: True, gen throughput (token/s): 454.80, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:12<00:00,  1.33it/s]
[2025-09-13 06:48:39] INFO:     127.0.0.1:37670 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  12.02     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8093      
Request throughput (req/s):              1.33      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         681.50    
Total token throughput (tok/s):          681.50    
Concurrency:                             7.59      
Accept length:                           2.95      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5701.09   
Median E2E Latency (ms):                 5594.88   
---------------Time to First Token----------------
Mean TTFT (ms):                          233.04    
Median TTFT (ms):                        275.58    
P99 TTFT (ms):                           290.59    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.70     
Median ITL (ms):                         7.29      
P95 ITL (ms):                            28.85     
P99 ITL (ms):                            52.26     
Max ITL (ms):                            264.36    
==================================================
[2025-09-13 06:48:39] INFO:     127.0.0.1:37678 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=6: batch_size=8, steps=3, topk=4, num_draft_tokens=4, speed=101.85 token/s, step_time=28.95 ms
Start i=7: batch_size=8, steps=3, topk=4, num_draft_tokens=6
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 3 --speculative-eagle-topk 4 --speculative-num-draft-tokens 6 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:48:50.237000 164333 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:48:50.237000 164333 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 06:48:50] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=961635860, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=3, speculative_eagle_topk=4, speculative_num_draft_tokens=6, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:48:51] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:48:59.277000 164594 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:48:59.277000 164594 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:48:59.397000 164591 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:48:59.397000 164591 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:48:59.457000 164596 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:48:59.457000 164596 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:48:59.677000 164592 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:48:59.677000 164592 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:48:59.680000 164588 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:48:59.680000 164588 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:48:59.744000 164590 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:48:59.744000 164590 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:48:59.764000 164589 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:48:59.764000 164589 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:48:59.802000 164593 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:48:59.802000 164593 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:48:59.826000 164595 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:48:59.826000 164595 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:49:00 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 06:49:00 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:49:00 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:49:02 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:49:04 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 06:49:06 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 06:49:06 TP0] Detected fp8 checkpoint.
[2025-09-13 06:49:06 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 27/1024 [00:00<00:03, 256.42it/s]
Loading safetensors checkpoint shards:   5% Completed | 53/1024 [00:00<00:13, 71.54it/s]
Loading safetensors checkpoint shards:   7% Completed | 67/1024 [00:00<00:14, 64.94it/s]
Loading safetensors checkpoint shards:   8% Completed | 77/1024 [00:01<00:15, 61.22it/s]
Loading safetensors checkpoint shards:   8% Completed | 85/1024 [00:01<00:15, 61.83it/s]
Loading safetensors checkpoint shards:   9% Completed | 93/1024 [00:01<00:17, 53.60it/s]
Loading safetensors checkpoint shards:  10% Completed | 100/1024 [00:02<00:30, 30.07it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:02<00:26, 34.41it/s]
Loading safetensors checkpoint shards:  11% Completed | 113/1024 [00:02<00:27, 33.58it/s]
Loading safetensors checkpoint shards:  12% Completed | 118/1024 [00:02<00:25, 35.15it/s]
Loading safetensors checkpoint shards:  12% Completed | 123/1024 [00:02<00:25, 34.93it/s]
Loading safetensors checkpoint shards:  12% Completed | 128/1024 [00:02<00:25, 35.29it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:02<00:24, 35.98it/s]
Loading safetensors checkpoint shards:  13% Completed | 138/1024 [00:02<00:21, 41.16it/s]
Loading safetensors checkpoint shards:  14% Completed | 143/1024 [00:03<00:21, 41.58it/s]
Loading safetensors checkpoint shards:  14% Completed | 148/1024 [00:03<00:21, 40.64it/s]
Loading safetensors checkpoint shards:  15% Completed | 154/1024 [00:03<00:19, 44.53it/s]
Loading safetensors checkpoint shards:  16% Completed | 159/1024 [00:03<00:20, 42.60it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:03<00:19, 43.62it/s]
Loading safetensors checkpoint shards:  17% Completed | 169/1024 [00:03<00:19, 43.47it/s]
Loading safetensors checkpoint shards:  17% Completed | 174/1024 [00:03<00:19, 44.39it/s]
Loading safetensors checkpoint shards:  17% Completed | 179/1024 [00:03<00:20, 40.26it/s]
Loading safetensors checkpoint shards:  18% Completed | 184/1024 [00:04<00:20, 41.00it/s]
Loading safetensors checkpoint shards:  18% Completed | 189/1024 [00:04<00:21, 38.70it/s]
Loading safetensors checkpoint shards:  19% Completed | 194/1024 [00:04<00:21, 37.93it/s]
Loading safetensors checkpoint shards:  19% Completed | 198/1024 [00:04<00:21, 38.20it/s]
Loading safetensors checkpoint shards:  20% Completed | 203/1024 [00:04<00:21, 38.81it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:04<00:19, 42.15it/s]
Loading safetensors checkpoint shards:  21% Completed | 214/1024 [00:04<00:19, 42.55it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:04<00:18, 43.45it/s]
Loading safetensors checkpoint shards:  22% Completed | 224/1024 [00:05<00:18, 43.40it/s]
Loading safetensors checkpoint shards:  22% Completed | 229/1024 [00:05<00:18, 43.88it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:05<00:18, 43.28it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:05<00:17, 45.20it/s]
Loading safetensors checkpoint shards:  24% Completed | 245/1024 [00:05<00:17, 44.28it/s]
Loading safetensors checkpoint shards:  25% Completed | 251/1024 [00:05<00:16, 46.15it/s]
Loading safetensors checkpoint shards:  25% Completed | 256/1024 [00:05<00:17, 44.67it/s]
Loading safetensors checkpoint shards:  25% Completed | 261/1024 [00:05<00:16, 45.94it/s]
Loading safetensors checkpoint shards:  26% Completed | 266/1024 [00:05<00:16, 45.52it/s]
Loading safetensors checkpoint shards:  26% Completed | 271/1024 [00:06<00:16, 46.37it/s]
Loading safetensors checkpoint shards:  27% Completed | 276/1024 [00:06<00:17, 43.29it/s]
Loading safetensors checkpoint shards:  27% Completed | 281/1024 [00:06<00:17, 42.75it/s]
Loading safetensors checkpoint shards:  28% Completed | 286/1024 [00:06<00:16, 44.21it/s]
Loading safetensors checkpoint shards:  28% Completed | 291/1024 [00:06<00:34, 21.03it/s]
Loading safetensors checkpoint shards:  29% Completed | 296/1024 [00:07<00:28, 25.16it/s]
Loading safetensors checkpoint shards:  29% Completed | 300/1024 [00:07<00:26, 27.64it/s]
Loading safetensors checkpoint shards:  30% Completed | 305/1024 [00:07<00:22, 31.50it/s]
Loading safetensors checkpoint shards:  30% Completed | 310/1024 [00:07<00:22, 32.40it/s]
Loading safetensors checkpoint shards:  31% Completed | 314/1024 [00:07<00:21, 33.22it/s]
Loading safetensors checkpoint shards:  31% Completed | 319/1024 [00:07<00:19, 35.79it/s]
Loading safetensors checkpoint shards:  32% Completed | 323/1024 [00:07<00:19, 35.79it/s]
Loading safetensors checkpoint shards:  32% Completed | 328/1024 [00:07<00:18, 37.91it/s]
Loading safetensors checkpoint shards:  32% Completed | 332/1024 [00:07<00:18, 38.18it/s]
Loading safetensors checkpoint shards:  33% Completed | 336/1024 [00:08<00:17, 38.48it/s]
Loading safetensors checkpoint shards:  33% Completed | 341/1024 [00:08<00:16, 40.87it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:08<00:16, 42.23it/s]
Loading safetensors checkpoint shards:  34% Completed | 351/1024 [00:08<00:16, 42.00it/s]
Loading safetensors checkpoint shards:  35% Completed | 356/1024 [00:08<00:16, 40.30it/s]
Loading safetensors checkpoint shards:  35% Completed | 361/1024 [00:08<00:16, 41.36it/s]
Loading safetensors checkpoint shards:  36% Completed | 366/1024 [00:08<00:16, 39.31it/s]
Loading safetensors checkpoint shards:  36% Completed | 370/1024 [00:08<00:16, 38.60it/s]
Loading safetensors checkpoint shards:  37% Completed | 375/1024 [00:08<00:16, 39.76it/s]
Loading safetensors checkpoint shards:  37% Completed | 379/1024 [00:09<00:16, 38.59it/s]
Loading safetensors checkpoint shards:  38% Completed | 384/1024 [00:09<00:15, 41.47it/s]
Loading safetensors checkpoint shards:  38% Completed | 389/1024 [00:09<00:16, 39.13it/s]
Loading safetensors checkpoint shards:  38% Completed | 393/1024 [00:09<00:16, 38.95it/s]
Loading safetensors checkpoint shards:  39% Completed | 397/1024 [00:09<00:16, 38.25it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:09<00:16, 37.92it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:09<00:15, 39.40it/s]
Loading safetensors checkpoint shards:  40% Completed | 410/1024 [00:09<00:15, 38.94it/s]
Loading safetensors checkpoint shards:  40% Completed | 414/1024 [00:10<00:15, 38.82it/s]
Loading safetensors checkpoint shards:  41% Completed | 418/1024 [00:10<00:15, 38.88it/s]
Loading safetensors checkpoint shards:  41% Completed | 422/1024 [00:10<00:15, 38.14it/s]
Loading safetensors checkpoint shards:  42% Completed | 427/1024 [00:10<00:14, 39.84it/s]
Loading safetensors checkpoint shards:  42% Completed | 431/1024 [00:10<00:15, 39.25it/s]
Loading safetensors checkpoint shards:  42% Completed | 435/1024 [00:10<00:15, 37.99it/s]
Loading safetensors checkpoint shards:  43% Completed | 440/1024 [00:10<00:14, 39.82it/s]
Loading safetensors checkpoint shards:  43% Completed | 444/1024 [00:10<00:14, 38.92it/s]
Loading safetensors checkpoint shards:  44% Completed | 448/1024 [00:10<00:14, 38.96it/s]
Loading safetensors checkpoint shards:  44% Completed | 452/1024 [00:10<00:14, 38.43it/s]
Loading safetensors checkpoint shards:  45% Completed | 456/1024 [00:11<00:14, 38.41it/s]
Loading safetensors checkpoint shards:  45% Completed | 461/1024 [00:11<00:13, 40.89it/s]
Loading safetensors checkpoint shards:  46% Completed | 466/1024 [00:11<00:14, 39.61it/s]
Loading safetensors checkpoint shards:  46% Completed | 473/1024 [00:11<00:11, 47.82it/s]
Loading safetensors checkpoint shards:  47% Completed | 478/1024 [00:11<00:11, 47.88it/s]
Loading safetensors checkpoint shards:  47% Completed | 485/1024 [00:11<00:10, 52.45it/s]
Loading safetensors checkpoint shards:  48% Completed | 491/1024 [00:11<00:09, 53.48it/s]
Loading safetensors checkpoint shards:  49% Completed | 498/1024 [00:11<00:09, 57.82it/s]
Loading safetensors checkpoint shards:  49% Completed | 505/1024 [00:11<00:08, 59.30it/s]
Loading safetensors checkpoint shards:  50% Completed | 512/1024 [00:12<00:08, 61.01it/s]
Loading safetensors checkpoint shards:  51% Completed | 519/1024 [00:12<00:22, 22.57it/s]
Loading safetensors checkpoint shards:  51% Completed | 524/1024 [00:12<00:19, 25.29it/s]
Loading safetensors checkpoint shards:  52% Completed | 531/1024 [00:13<00:15, 31.37it/s]
Loading safetensors checkpoint shards:  53% Completed | 539/1024 [00:13<00:12, 39.01it/s]
Loading safetensors checkpoint shards:  53% Completed | 547/1024 [00:13<00:10, 46.78it/s]
Loading safetensors checkpoint shards:  54% Completed | 555/1024 [00:13<00:08, 53.56it/s]
Loading safetensors checkpoint shards:  55% Completed | 562/1024 [00:13<00:08, 57.21it/s]
Loading safetensors checkpoint shards:  56% Completed | 572/1024 [00:13<00:06, 66.11it/s]
Loading safetensors checkpoint shards:  57% Completed | 580/1024 [00:13<00:06, 64.97it/s]
Loading safetensors checkpoint shards:  58% Completed | 589/1024 [00:13<00:06, 70.58it/s]
Loading safetensors checkpoint shards:  58% Completed | 597/1024 [00:13<00:06, 68.01it/s]
Loading safetensors checkpoint shards:  59% Completed | 605/1024 [00:14<00:05, 70.08it/s]
Loading safetensors checkpoint shards:  60% Completed | 613/1024 [00:14<00:06, 64.22it/s]
Loading safetensors checkpoint shards:  61% Completed | 621/1024 [00:14<00:06, 66.41it/s]
Loading safetensors checkpoint shards:  61% Completed | 628/1024 [00:14<00:06, 63.60it/s]
Loading safetensors checkpoint shards:  62% Completed | 635/1024 [00:14<00:07, 54.10it/s]
Loading safetensors checkpoint shards:  63% Completed | 642/1024 [00:14<00:06, 57.48it/s]
Loading safetensors checkpoint shards:  63% Completed | 649/1024 [00:14<00:07, 48.58it/s]
Loading safetensors checkpoint shards:  64% Completed | 655/1024 [00:15<00:08, 45.55it/s]
Loading safetensors checkpoint shards:  64% Completed | 660/1024 [00:15<00:08, 44.94it/s]
Loading safetensors checkpoint shards:  65% Completed | 665/1024 [00:15<00:08, 43.03it/s]
Loading safetensors checkpoint shards:  65% Completed | 670/1024 [00:15<00:08, 43.74it/s]
Loading safetensors checkpoint shards:  66% Completed | 676/1024 [00:15<00:07, 46.86it/s]
Loading safetensors checkpoint shards:  67% Completed | 681/1024 [00:15<00:07, 45.21it/s]
Loading safetensors checkpoint shards:  67% Completed | 686/1024 [00:15<00:07, 42.53it/s]
Loading safetensors checkpoint shards:  67% Completed | 691/1024 [00:15<00:07, 43.82it/s]
Loading safetensors checkpoint shards:  68% Completed | 697/1024 [00:15<00:07, 46.39it/s]
Loading safetensors checkpoint shards:  69% Completed | 702/1024 [00:16<00:07, 41.23it/s]
Loading safetensors checkpoint shards:  69% Completed | 707/1024 [00:16<00:08, 38.43it/s]
Loading safetensors checkpoint shards:  69% Completed | 711/1024 [00:16<00:08, 38.05it/s]
Loading safetensors checkpoint shards:  70% Completed | 715/1024 [00:16<00:17, 17.42it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:17<00:15, 19.99it/s]
Loading safetensors checkpoint shards:  71% Completed | 723/1024 [00:17<00:13, 22.59it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:17<00:10, 28.28it/s]
Loading safetensors checkpoint shards:  72% Completed | 733/1024 [00:17<00:09, 29.44it/s]
Loading safetensors checkpoint shards:  72% Completed | 738/1024 [00:17<00:08, 33.08it/s]
Loading safetensors checkpoint shards:  73% Completed | 744/1024 [00:17<00:07, 37.98it/s]
Loading safetensors checkpoint shards:  73% Completed | 751/1024 [00:17<00:06, 44.19it/s]
Loading safetensors checkpoint shards:  74% Completed | 758/1024 [00:17<00:05, 49.92it/s]
Loading safetensors checkpoint shards:  75% Completed | 764/1024 [00:18<00:05, 48.92it/s]
Loading safetensors checkpoint shards:  75% Completed | 770/1024 [00:18<00:05, 48.49it/s]
Loading safetensors checkpoint shards:  76% Completed | 776/1024 [00:18<00:05, 45.96it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:18<00:04, 50.64it/s]
Loading safetensors checkpoint shards:  77% Completed | 789/1024 [00:18<00:04, 49.94it/s]
Loading safetensors checkpoint shards:  78% Completed | 795/1024 [00:18<00:04, 48.93it/s]
Loading safetensors checkpoint shards:  78% Completed | 801/1024 [00:18<00:04, 50.48it/s]
Loading safetensors checkpoint shards:  79% Completed | 807/1024 [00:18<00:04, 52.39it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:19<00:03, 52.97it/s]
Loading safetensors checkpoint shards:  80% Completed | 819/1024 [00:19<00:04, 50.20it/s]
Loading safetensors checkpoint shards:  81% Completed | 826/1024 [00:19<00:03, 53.73it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:19<00:03, 56.81it/s]
Loading safetensors checkpoint shards:  82% Completed | 841/1024 [00:19<00:03, 60.72it/s]
Loading safetensors checkpoint shards:  83% Completed | 848/1024 [00:19<00:02, 59.10it/s]
Loading safetensors checkpoint shards:  83% Completed | 854/1024 [00:19<00:02, 58.28it/s]
Loading safetensors checkpoint shards:  84% Completed | 860/1024 [00:19<00:02, 57.83it/s]
Loading safetensors checkpoint shards:  85% Completed | 866/1024 [00:19<00:02, 56.60it/s]
Loading safetensors checkpoint shards:  85% Completed | 872/1024 [00:20<00:02, 53.92it/s]
Loading safetensors checkpoint shards:  86% Completed | 878/1024 [00:20<00:02, 53.83it/s]
Loading safetensors checkpoint shards:  86% Completed | 884/1024 [00:20<00:02, 51.83it/s]
Loading safetensors checkpoint shards:  87% Completed | 890/1024 [00:20<00:02, 48.67it/s]
Loading safetensors checkpoint shards:  88% Completed | 896/1024 [00:20<00:02, 50.90it/s]
Loading safetensors checkpoint shards:  88% Completed | 902/1024 [00:20<00:02, 53.17it/s]
Loading safetensors checkpoint shards:  89% Completed | 910/1024 [00:20<00:01, 59.94it/s]
Loading safetensors checkpoint shards:  90% Completed | 917/1024 [00:20<00:01, 62.48it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:20<00:01, 64.52it/s]
Loading safetensors checkpoint shards:  91% Completed | 931/1024 [00:21<00:01, 57.48it/s]
Loading safetensors checkpoint shards:  92% Completed | 937/1024 [00:21<00:01, 52.24it/s]
Loading safetensors checkpoint shards:  92% Completed | 943/1024 [00:22<00:04, 18.72it/s]
Loading safetensors checkpoint shards:  93% Completed | 949/1024 [00:22<00:03, 22.97it/s]
Loading safetensors checkpoint shards:  93% Completed | 956/1024 [00:22<00:02, 29.19it/s]
Loading safetensors checkpoint shards:  94% Completed | 962/1024 [00:22<00:01, 33.53it/s]
Loading safetensors checkpoint shards:  95% Completed | 968/1024 [00:22<00:01, 38.21it/s]
Loading safetensors checkpoint shards:  95% Completed | 975/1024 [00:22<00:01, 44.53it/s]
Loading safetensors checkpoint shards:  96% Completed | 981/1024 [00:22<00:00, 47.37it/s]
Loading safetensors checkpoint shards:  97% Completed | 993/1024 [00:22<00:00, 64.90it/s]
Loading safetensors checkpoint shards:  99% Completed | 1012/1024 [00:22<00:00, 96.64it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:23<00:00, 44.50it/s]

[2025-09-13 06:49:34 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 06:49:35 TP3] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 06:49:35 TP4] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 06:49:35 TP0] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 06:49:35 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 06:49:35 TP6] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 06:49:35 TP5] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 06:49:35 TP2] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 06:49:35 TP1] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 06:49:35 TP7] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 06:49:35 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 06:49:35 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.52 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s][2025-09-13 06:49:36 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:49:36 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 06:49:36 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:49:36 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:49:36 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:49:36 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:49:37 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:49:37 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:49:37 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25949.71it/s]
[2025-09-13 06:49:37 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:49:37 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26845.86it/s]
[2025-09-13 06:49:37 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:49:37 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28124.52it/s]
[2025-09-13 06:49:38 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:49:38 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27183.87it/s]
[2025-09-13 06:49:39 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:49:39 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27833.99it/s]
[2025-09-13 06:49:39 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.23 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.16it/s]
[2025-09-13 06:49:42 TP0] Registering 984 cuda graph addresses
[2025-09-13 06:49:42 TP5] Registering 984 cuda graph addresses
[2025-09-13 06:49:42 TP1] Registering 984 cuda graph addresses
[2025-09-13 06:49:42 TP3] Registering 984 cuda graph addresses
[2025-09-13 06:49:42 TP7] Registering 984 cuda graph addresses
[2025-09-13 06:49:42 TP6] Registering 984 cuda graph addresses
[2025-09-13 06:49:42 TP4] Registering 984 cuda graph addresses
[2025-09-13 06:49:42 TP2] Registering 984 cuda graph addresses
[2025-09-13 06:49:43 TP0] Capture cuda graph end. Time elapsed: 7.59 s. mem usage=0.35 GB. avail mem=17.21 GB.
[2025-09-13 06:49:43 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 06:49:43 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:49:43 TP0] Init torch distributed begin.
[2025-09-13 06:49:43 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 06:49:43 TP0] Load weight begin. avail mem=17.21 GB
[2025-09-13 06:49:43 TP0] Detected fp8 checkpoint.
[2025-09-13 06:49:43 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 19/1024 [00:00<00:05, 184.07it/s]
Loading safetensors checkpoint shards:   5% Completed | 52/1024 [00:00<00:03, 266.56it/s]
Loading safetensors checkpoint shards:  11% Completed | 110/1024 [00:00<00:02, 407.67it/s]
Loading safetensors checkpoint shards:  17% Completed | 170/1024 [00:00<00:01, 480.51it/s]
Loading safetensors checkpoint shards:  23% Completed | 231/1024 [00:00<00:01, 525.96it/s]
Loading safetensors checkpoint shards:  29% Completed | 292/1024 [00:00<00:01, 551.39it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:00<00:01, 570.44it/s]
Loading safetensors checkpoint shards:  40% Completed | 413/1024 [00:00<00:01, 574.82it/s]
Loading safetensors checkpoint shards:  46% Completed | 475/1024 [00:00<00:00, 588.01it/s]
Loading safetensors checkpoint shards:  52% Completed | 535/1024 [00:01<00:00, 591.54it/s]
Loading safetensors checkpoint shards:  58% Completed | 598/1024 [00:01<00:00, 600.54it/s]
Loading safetensors checkpoint shards:  64% Completed | 659/1024 [00:01<00:00, 596.73it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:01<00:00, 586.81it/s]
Loading safetensors checkpoint shards:  76% Completed | 778/1024 [00:01<00:00, 583.15it/s]
Loading safetensors checkpoint shards:  82% Completed | 837/1024 [00:01<00:00, 581.55it/s]
Loading safetensors checkpoint shards:  88% Completed | 896/1024 [00:01<00:00, 577.05it/s]
Loading safetensors checkpoint shards:  93% Completed | 954/1024 [00:01<00:00, 572.81it/s]
Loading safetensors checkpoint shards:  99% Completed | 1012/1024 [00:01<00:00, 408.47it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 506.83it/s]

[2025-09-13 06:49:45 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.22 GB, mem usage=1.99 GB.
[2025-09-13 06:49:45 TP7] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 06:49:45 TP6] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 06:49:45 TP4] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 06:49:45 TP5] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 06:49:45 TP2] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 06:49:45 TP1] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 06:49:45 TP3] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 06:49:45 TP0] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 06:49:45 TP0] Memory pool end. avail mem=14.55 GB
[2025-09-13 06:49:46 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:49:46 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:49:46 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:49:46 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:49:46 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.99 GB
[2025-09-13 06:49:46 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:49:46 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.18 GB
[2025-09-13 06:49:46 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
Capturing batches (bs=1 avail_mem=14.62 GB):  62%|█████████████████████████████████████████████████████▊                                | 5/8 [00:03<00:01,  2.30it/s][2025-09-13 06:49:52 TP2] Registering 48 cuda graph addresses
[2025-09-13 06:49:52 TP4] Registering 48 cuda graph addresses
[2025-09-13 06:49:52 TP1] Registering 48 cuda graph addresses
[2025-09-13 06:49:52 TP7] Registering 48 cuda graph addresses
[2025-09-13 06:49:52 TP6] Registering 48 cuda graph addresses
[2025-09-13 06:49:52 TP3] Registering 48 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.62 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.46it/s]
[2025-09-13 06:49:52 TP5] Registering 48 cuda graph addresses
[2025-09-13 06:49:52 TP0] Registering 48 cuda graph addresses
[2025-09-13 06:49:52 TP6] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.37 GB. avail mem=14.58 GB.
[2025-09-13 06:49:52 TP5] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.37 GB. avail mem=14.58 GB.
[2025-09-13 06:49:52 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 06:49:52 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 06:49:52 TP2] Capture draft cuda graph end. Time elapsed: 6.34 s. mem usage=0.37 GB. avail mem=14.58 GB.
[2025-09-13 06:49:52 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 06:49:52 TP3] Capture draft cuda graph end. Time elapsed: 6.34 s. mem usage=0.37 GB. avail mem=14.58 GB.
[2025-09-13 06:49:52 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 06:49:52 TP7] Capture draft cuda graph end. Time elapsed: 6.34 s. mem usage=0.37 GB. avail mem=14.81 GB.
[2025-09-13 06:49:52 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.81 GB
[2025-09-13 06:49:52 TP0] Capture draft cuda graph end. Time elapsed: 6.34 s. mem usage=0.37 GB. avail mem=14.62 GB.
[2025-09-13 06:49:52 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.62 GB
[2025-09-13 06:49:52 TP1] Capture draft cuda graph end. Time elapsed: 6.34 s. mem usage=0.37 GB. avail mem=14.58 GB.
[2025-09-13 06:49:52 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 06:49:52 TP4] Capture draft cuda graph end. Time elapsed: 6.34 s. mem usage=0.37 GB. avail mem=14.58 GB.
[2025-09-13 06:49:52 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
Capturing batches (bs=1 avail_mem=14.43 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:00<00:00, 55.21it/s][2025-09-13 06:49:53 TP6] Registering 24 cuda graph addresses
[2025-09-13 06:49:53 TP4] Registering 24 cuda graph addresses
[2025-09-13 06:49:53 TP2] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.43 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 51.97it/s]
[2025-09-13 06:49:53 TP7] Registering 24 cuda graph addresses
[2025-09-13 06:49:53 TP5] Registering 24 cuda graph addresses
[2025-09-13 06:49:53 TP1] Registering 24 cuda graph addresses
[2025-09-13 06:49:53 TP3] Registering 24 cuda graph addresses
[2025-09-13 06:49:53 TP0] Registering 24 cuda graph addresses
[2025-09-13 06:49:53 TP2] Capture draft extend cuda graph end. Time elapsed: 1.07 s. mem usage=0.19 GB. avail mem=14.39 GB.
[2025-09-13 06:49:53 TP1] Capture draft extend cuda graph end. Time elapsed: 1.07 s. mem usage=0.19 GB. avail mem=14.39 GB.
[2025-09-13 06:49:53 TP7] Capture draft extend cuda graph end. Time elapsed: 1.07 s. mem usage=0.19 GB. avail mem=14.62 GB.
[2025-09-13 06:49:53 TP0] Capture draft extend cuda graph end. Time elapsed: 1.07 s. mem usage=0.19 GB. avail mem=14.43 GB.
[2025-09-13 06:49:53 TP5] Capture draft extend cuda graph end. Time elapsed: 1.08 s. mem usage=0.19 GB. avail mem=14.39 GB.
[2025-09-13 06:49:53 TP3] Capture draft extend cuda graph end. Time elapsed: 1.07 s. mem usage=0.19 GB. avail mem=14.39 GB.
[2025-09-13 06:49:53 TP4] Capture draft extend cuda graph end. Time elapsed: 1.07 s. mem usage=0.19 GB. avail mem=14.39 GB.
[2025-09-13 06:49:53 TP6] Capture draft extend cuda graph end. Time elapsed: 1.08 s. mem usage=0.19 GB. avail mem=14.39 GB.
[2025-09-13 06:49:53 TP0] max_total_num_tokens=620201, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.43 GB
[2025-09-13 06:49:54] INFO:     Started server process [164333]
[2025-09-13 06:49:54] INFO:     Waiting for application startup.
[2025-09-13 06:49:54] INFO:     Application startup complete.
[2025-09-13 06:49:54] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 06:49:54] INFO:     127.0.0.1:33304 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 06:49:55] INFO:     127.0.0.1:33308 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 06:49:55 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:49:55 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:49:55 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27630.04it/s]
[2025-09-13 06:49:56] INFO:     127.0.0.1:33312 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:49:56] The server is fired up and ready to roll!
[2025-09-13 06:50:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:50:05] INFO:     127.0.0.1:46188 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:50:06] INFO:     127.0.0.1:46202 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:06 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 06:50:07] INFO:     127.0.0.1:46208 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:07] INFO:     127.0.0.1:46214 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:50:07] INFO:     127.0.0.1:46226 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:07] INFO:     127.0.0.1:46234 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:07] INFO:     127.0.0.1:46238 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:07] INFO:     127.0.0.1:46244 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:07] INFO:     127.0.0.1:46250 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:07] INFO:     127.0.0.1:46266 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:07 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 06:50:08 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:50:08 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:50:08 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:50:08 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:50:08 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:50:08 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:50:08 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:50:08 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:50:08 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 06:50:09 TP0] Decode batch. #running-req: 8, #token: 14525, token usage: 0.02, accept len: 2.87, cuda graph: True, gen throughput (token/s): 41.24, #queue-req: 0, 
[2025-09-13 06:50:10 TP0] Decode batch. #running-req: 8, #token: 15548, token usage: 0.03, accept len: 3.20, cuda graph: True, gen throughput (token/s): 865.72, #queue-req: 0, 
[2025-09-13 06:50:11 TP0] Decode batch. #running-req: 8, #token: 16570, token usage: 0.03, accept len: 3.19, cuda graph: True, gen throughput (token/s): 840.06, #queue-req: 0, 
[2025-09-13 06:50:12 TP0] Decode batch. #running-req: 8, #token: 16974, token usage: 0.03, accept len: 3.17, cuda graph: True, gen throughput (token/s): 834.14, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.28it/s]
[2025-09-13 06:50:13] INFO:     127.0.0.1:43852 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.23      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4015      
Request throughput (req/s):              1.28      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         657.26    
Total token throughput (tok/s):          657.26    
Concurrency:                             7.21      
Accept length:                           3.13      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5620.26   
Median E2E Latency (ms):                 5535.61   
---------------Time to First Token----------------
Mean TTFT (ms):                          608.25    
Median TTFT (ms):                        717.49    
P99 TTFT (ms):                           717.95    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.81      
Median ITL (ms):                         7.64      
P95 ITL (ms):                            16.37     
P99 ITL (ms):                            31.05     
Max ITL (ms):                            720.40    
==================================================
[2025-09-13 06:50:13] INFO:     127.0.0.1:43864 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:50:13] INFO:     127.0.0.1:43868 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:50:13 TP0] Decode batch. #running-req: 1, #token: 4671, token usage: 0.01, accept len: 3.39, cuda graph: True, gen throughput (token/s): 336.20, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 06:50:15] INFO:     127.0.0.1:43874 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:15] INFO:     127.0.0.1:43886 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:50:15] INFO:     127.0.0.1:43892 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:15] INFO:     127.0.0.1:43906 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:15] INFO:     127.0.0.1:43914 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:15] INFO:     127.0.0.1:43926 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:15] INFO:     127.0.0.1:43930 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:15] INFO:     127.0.0.1:43934 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:15 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 06:50:16 TP0] Decode batch. #running-req: 8, #token: 14674, token usage: 0.02, accept len: 2.96, cuda graph: True, gen throughput (token/s): 336.98, #queue-req: 0, 
[2025-09-13 06:50:17 TP0] Decode batch. #running-req: 8, #token: 15701, token usage: 0.03, accept len: 3.21, cuda graph: True, gen throughput (token/s): 860.84, #queue-req: 0, 
[2025-09-13 06:50:18 TP0] Decode batch. #running-req: 8, #token: 16719, token usage: 0.03, accept len: 3.18, cuda graph: True, gen throughput (token/s): 835.92, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:08,  4.59s/it][2025-09-13 06:50:19] INFO:     127.0.0.1:52638 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:19 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:29,  2.09s/it][2025-09-13 06:50:20] INFO:     127.0.0.1:52652 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:50:20 TP0] Decode batch. #running-req: 8, #token: 11951, token usage: 0.02, accept len: 3.20, cuda graph: True, gen throughput (token/s): 642.19, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:16,  1.24s/it][2025-09-13 06:50:20] INFO:     127.0.0.1:52668 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:20 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.20it/s][2025-09-13 06:50:20] INFO:     127.0.0.1:52670 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:20 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:06,  1.58it/s][2025-09-13 06:50:20] INFO:     127.0.0.1:52678 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:20 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.93it/s][2025-09-13 06:50:21] INFO:     127.0.0.1:52680 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:21 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:05,  1.79it/s][2025-09-13 06:50:21] INFO:     127.0.0.1:52686 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:03,  2.26it/s][2025-09-13 06:50:21] INFO:     127.0.0.1:52690 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:50:21 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:50:22 TP0] Decode batch. #running-req: 8, #token: 14222, token usage: 0.02, accept len: 3.26, cuda graph: True, gen throughput (token/s): 488.59, #queue-req: 0, 
[2025-09-13 06:50:23 TP0] Decode batch. #running-req: 8, #token: 15208, token usage: 0.02, accept len: 3.08, cuda graph: True, gen throughput (token/s): 815.77, #queue-req: 0, 
[2025-09-13 06:50:24 TP0] Decode batch. #running-req: 8, #token: 16297, token usage: 0.03, accept len: 3.40, cuda graph: True, gen throughput (token/s): 891.79, #queue-req: 0, 
 69%|████████████████████████████████████████████████████████████████████████████████████████▋                                        | 11/16 [00:10<00:04,  1.21it/s][2025-09-13 06:50:25 TP0] Decode batch. #running-req: 4, #token: 11247, token usage: 0.02, accept len: 3.51, cuda graph: True, gen throughput (token/s): 853.58, #queue-req: 0, 
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 15/16 [00:11<00:00,  2.46it/s][2025-09-13 06:50:26 TP0] Decode batch. #running-req: 1, #token: 3222, token usage: 0.01, accept len: 3.22, cuda graph: True, gen throughput (token/s): 283.74, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.36it/s]
[2025-09-13 06:50:26] INFO:     127.0.0.1:52696 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.73     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8027      
Request throughput (req/s):              1.36      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         698.39    
Total token throughput (tok/s):          698.39    
Concurrency:                             7.49      
Accept length:                           3.20      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5487.65   
Median E2E Latency (ms):                 5297.37   
---------------Time to First Token----------------
Mean TTFT (ms):                          224.15    
Median TTFT (ms):                        232.32    
P99 TTFT (ms):                           289.77    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.30     
Median ITL (ms):                         7.65      
P95 ITL (ms):                            28.29     
P99 ITL (ms):                            52.01     
Max ITL (ms):                            207.29    
==================================================
[2025-09-13 06:50:26] INFO:     127.0.0.1:52702 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=7: batch_size=8, steps=3, topk=4, num_draft_tokens=6, speed=105.98 token/s, step_time=30.22 ms
Start i=8: batch_size=8, steps=3, topk=4, num_draft_tokens=8
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 3 --speculative-eagle-topk 4 --speculative-num-draft-tokens 8 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:50:37.633000 170014 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:50:37.633000 170014 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 06:50:37] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=229905501, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=3, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:50:38] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:50:46.815000 170226 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:50:46.815000 170226 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:50:46.844000 170224 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:50:46.844000 170224 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:50:46.933000 170222 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:50:46.933000 170222 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:50:47.028000 170227 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:50:47.028000 170227 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:50:47.113000 170223 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:50:47.113000 170223 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:50:47.160000 170219 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:50:47.160000 170219 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:50:47.271000 170220 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:50:47.271000 170220 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:50:47.285000 170225 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:50:47.285000 170225 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:50:47.316000 170221 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:50:47.316000 170221 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:50:47 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 06:50:47 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:50:47 TP0] Init torch distributed begin.
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:50:49 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:50:52 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 06:50:53 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 06:50:53 TP0] Detected fp8 checkpoint.
[2025-09-13 06:50:54 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:04, 235.63it/s]
Loading safetensors checkpoint shards:   5% Completed | 50/1024 [00:00<00:14, 65.46it/s]
Loading safetensors checkpoint shards:   6% Completed | 63/1024 [00:00<00:17, 55.77it/s]
Loading safetensors checkpoint shards:   7% Completed | 72/1024 [00:01<00:18, 52.84it/s]
Loading safetensors checkpoint shards:   8% Completed | 79/1024 [00:01<00:19, 49.29it/s]
Loading safetensors checkpoint shards:   8% Completed | 85/1024 [00:01<00:19, 49.00it/s]
Loading safetensors checkpoint shards:   9% Completed | 91/1024 [00:01<00:19, 48.31it/s]
Loading safetensors checkpoint shards:   9% Completed | 97/1024 [00:01<00:20, 45.21it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:01<00:20, 45.03it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:01<00:20, 45.80it/s]
Loading safetensors checkpoint shards:  11% Completed | 112/1024 [00:02<00:20, 44.31it/s]
Loading safetensors checkpoint shards:  12% Completed | 118/1024 [00:02<00:19, 46.43it/s]
Loading safetensors checkpoint shards:  12% Completed | 123/1024 [00:02<00:34, 25.88it/s]
Loading safetensors checkpoint shards:  13% Completed | 129/1024 [00:02<00:29, 30.50it/s]
Loading safetensors checkpoint shards:  13% Completed | 134/1024 [00:02<00:27, 32.40it/s]
Loading safetensors checkpoint shards:  14% Completed | 140/1024 [00:03<00:23, 37.44it/s]
Loading safetensors checkpoint shards:  14% Completed | 145/1024 [00:03<00:22, 38.56it/s]
Loading safetensors checkpoint shards:  15% Completed | 150/1024 [00:03<00:21, 40.14it/s]
Loading safetensors checkpoint shards:  15% Completed | 155/1024 [00:03<00:21, 40.68it/s]
Loading safetensors checkpoint shards:  16% Completed | 161/1024 [00:03<00:19, 43.55it/s]
Loading safetensors checkpoint shards:  16% Completed | 166/1024 [00:03<00:20, 41.98it/s]
Loading safetensors checkpoint shards:  17% Completed | 172/1024 [00:03<00:19, 43.99it/s]
Loading safetensors checkpoint shards:  17% Completed | 177/1024 [00:03<00:19, 44.46it/s]
Loading safetensors checkpoint shards:  18% Completed | 182/1024 [00:03<00:18, 45.31it/s]
Loading safetensors checkpoint shards:  18% Completed | 187/1024 [00:04<00:18, 44.81it/s]
Loading safetensors checkpoint shards:  19% Completed | 192/1024 [00:04<00:18, 44.38it/s]
Loading safetensors checkpoint shards:  19% Completed | 198/1024 [00:04<00:18, 45.77it/s]
Loading safetensors checkpoint shards:  20% Completed | 203/1024 [00:04<00:18, 43.93it/s]
Loading safetensors checkpoint shards:  20% Completed | 208/1024 [00:04<00:17, 45.49it/s]
Loading safetensors checkpoint shards:  21% Completed | 213/1024 [00:04<00:18, 44.61it/s]
Loading safetensors checkpoint shards:  21% Completed | 218/1024 [00:04<00:17, 45.95it/s]
Loading safetensors checkpoint shards:  22% Completed | 223/1024 [00:04<00:18, 44.36it/s]
Loading safetensors checkpoint shards:  22% Completed | 228/1024 [00:04<00:17, 44.70it/s]
Loading safetensors checkpoint shards:  23% Completed | 233/1024 [00:05<00:17, 44.39it/s]
Loading safetensors checkpoint shards:  23% Completed | 238/1024 [00:05<00:17, 45.51it/s]
Loading safetensors checkpoint shards:  24% Completed | 243/1024 [00:05<00:17, 45.10it/s]
Loading safetensors checkpoint shards:  24% Completed | 248/1024 [00:05<00:16, 46.38it/s]
Loading safetensors checkpoint shards:  25% Completed | 253/1024 [00:05<00:16, 46.10it/s]
Loading safetensors checkpoint shards:  25% Completed | 258/1024 [00:05<00:17, 44.45it/s]
Loading safetensors checkpoint shards:  26% Completed | 263/1024 [00:05<00:16, 45.17it/s]
Loading safetensors checkpoint shards:  26% Completed | 268/1024 [00:05<00:16, 44.57it/s]
Loading safetensors checkpoint shards:  27% Completed | 273/1024 [00:05<00:16, 45.71it/s]
Loading safetensors checkpoint shards:  27% Completed | 278/1024 [00:06<00:17, 43.22it/s]
Loading safetensors checkpoint shards:  28% Completed | 283/1024 [00:06<00:16, 44.17it/s]
Loading safetensors checkpoint shards:  28% Completed | 288/1024 [00:06<00:17, 42.04it/s]
Loading safetensors checkpoint shards:  29% Completed | 293/1024 [00:06<00:17, 42.49it/s]
Loading safetensors checkpoint shards:  29% Completed | 298/1024 [00:06<00:17, 42.53it/s]
Loading safetensors checkpoint shards:  30% Completed | 303/1024 [00:06<00:16, 43.61it/s]
Loading safetensors checkpoint shards:  30% Completed | 308/1024 [00:06<00:16, 44.43it/s]
Loading safetensors checkpoint shards:  31% Completed | 313/1024 [00:06<00:15, 44.77it/s]
Loading safetensors checkpoint shards:  31% Completed | 319/1024 [00:07<00:15, 46.46it/s]
Loading safetensors checkpoint shards:  32% Completed | 324/1024 [00:07<00:29, 24.04it/s]
Loading safetensors checkpoint shards:  32% Completed | 330/1024 [00:07<00:23, 29.21it/s]
Loading safetensors checkpoint shards:  33% Completed | 335/1024 [00:07<00:21, 32.42it/s]
Loading safetensors checkpoint shards:  33% Completed | 341/1024 [00:07<00:18, 36.50it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:07<00:17, 37.67it/s]
Loading safetensors checkpoint shards:  34% Completed | 351/1024 [00:08<00:16, 40.43it/s]
Loading safetensors checkpoint shards:  35% Completed | 356/1024 [00:08<00:15, 41.82it/s]
Loading safetensors checkpoint shards:  35% Completed | 361/1024 [00:08<00:15, 43.80it/s]
Loading safetensors checkpoint shards:  36% Completed | 366/1024 [00:08<00:15, 42.94it/s]
Loading safetensors checkpoint shards:  36% Completed | 371/1024 [00:08<00:14, 44.51it/s]
Loading safetensors checkpoint shards:  37% Completed | 376/1024 [00:08<00:14, 43.52it/s]
Loading safetensors checkpoint shards:  37% Completed | 381/1024 [00:08<00:15, 41.83it/s]
Loading safetensors checkpoint shards:  38% Completed | 386/1024 [00:08<00:14, 43.67it/s]
Loading safetensors checkpoint shards:  38% Completed | 391/1024 [00:08<00:14, 42.68it/s]
Loading safetensors checkpoint shards:  39% Completed | 396/1024 [00:09<00:14, 42.24it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:09<00:15, 40.59it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:09<00:15, 41.17it/s]
Loading safetensors checkpoint shards:  40% Completed | 411/1024 [00:09<00:15, 39.42it/s]
Loading safetensors checkpoint shards:  41% Completed | 416/1024 [00:09<00:14, 40.92it/s]
Loading safetensors checkpoint shards:  41% Completed | 421/1024 [00:09<00:15, 39.38it/s]
Loading safetensors checkpoint shards:  42% Completed | 426/1024 [00:09<00:14, 41.34it/s]
Loading safetensors checkpoint shards:  42% Completed | 431/1024 [00:09<00:14, 41.61it/s]
Loading safetensors checkpoint shards:  43% Completed | 436/1024 [00:10<00:15, 38.90it/s]
Loading safetensors checkpoint shards:  43% Completed | 441/1024 [00:10<00:14, 40.48it/s]
Loading safetensors checkpoint shards:  44% Completed | 446/1024 [00:10<00:14, 39.55it/s]
Loading safetensors checkpoint shards:  44% Completed | 451/1024 [00:10<00:14, 40.47it/s]
Loading safetensors checkpoint shards:  45% Completed | 456/1024 [00:10<00:14, 40.08it/s]
Loading safetensors checkpoint shards:  45% Completed | 461/1024 [00:10<00:13, 42.00it/s]
Loading safetensors checkpoint shards:  46% Completed | 466/1024 [00:10<00:13, 41.37it/s]
Loading safetensors checkpoint shards:  46% Completed | 473/1024 [00:10<00:11, 46.36it/s]
Loading safetensors checkpoint shards:  47% Completed | 478/1024 [00:11<00:11, 46.06it/s]
Loading safetensors checkpoint shards:  47% Completed | 484/1024 [00:11<00:11, 47.45it/s]
Loading safetensors checkpoint shards:  48% Completed | 489/1024 [00:11<00:11, 45.51it/s]
Loading safetensors checkpoint shards:  48% Completed | 495/1024 [00:11<00:11, 46.98it/s]
Loading safetensors checkpoint shards:  49% Completed | 500/1024 [00:11<00:11, 46.51it/s]
Loading safetensors checkpoint shards:  49% Completed | 505/1024 [00:11<00:10, 47.25it/s]
Loading safetensors checkpoint shards:  50% Completed | 510/1024 [00:11<00:11, 46.27it/s]
Loading safetensors checkpoint shards:  50% Completed | 516/1024 [00:11<00:10, 46.92it/s]
Loading safetensors checkpoint shards:  51% Completed | 521/1024 [00:11<00:11, 44.17it/s]
Loading safetensors checkpoint shards:  51% Completed | 526/1024 [00:12<00:10, 45.60it/s]
Loading safetensors checkpoint shards:  52% Completed | 531/1024 [00:12<00:11, 44.75it/s]
Loading safetensors checkpoint shards:  52% Completed | 536/1024 [00:12<00:11, 43.03it/s]
Loading safetensors checkpoint shards:  53% Completed | 542/1024 [00:12<00:10, 45.00it/s]
Loading safetensors checkpoint shards:  53% Completed | 547/1024 [00:12<00:10, 44.70it/s]
Loading safetensors checkpoint shards:  54% Completed | 553/1024 [00:12<00:10, 46.66it/s]
Loading safetensors checkpoint shards:  54% Completed | 558/1024 [00:12<00:10, 43.68it/s]
Loading safetensors checkpoint shards:  55% Completed | 563/1024 [00:12<00:10, 44.82it/s]
Loading safetensors checkpoint shards:  55% Completed | 568/1024 [00:13<00:10, 43.95it/s]
Loading safetensors checkpoint shards:  56% Completed | 573/1024 [00:13<00:09, 45.53it/s]
Loading safetensors checkpoint shards:  56% Completed | 578/1024 [00:13<00:20, 21.46it/s]
Loading safetensors checkpoint shards:  57% Completed | 584/1024 [00:13<00:16, 27.17it/s]
Loading safetensors checkpoint shards:  58% Completed | 589/1024 [00:13<00:14, 30.98it/s]
Loading safetensors checkpoint shards:  58% Completed | 594/1024 [00:13<00:12, 34.23it/s]
Loading safetensors checkpoint shards:  58% Completed | 599/1024 [00:14<00:11, 37.01it/s]
Loading safetensors checkpoint shards:  59% Completed | 605/1024 [00:14<00:10, 40.22it/s]
Loading safetensors checkpoint shards:  60% Completed | 610/1024 [00:14<00:10, 40.51it/s]
Loading safetensors checkpoint shards:  60% Completed | 615/1024 [00:14<00:09, 42.50it/s]
Loading safetensors checkpoint shards:  61% Completed | 620/1024 [00:14<00:09, 41.73it/s]
Loading safetensors checkpoint shards:  61% Completed | 625/1024 [00:14<00:09, 41.14it/s]
Loading safetensors checkpoint shards:  62% Completed | 630/1024 [00:14<00:09, 39.87it/s]
Loading safetensors checkpoint shards:  62% Completed | 635/1024 [00:14<00:10, 38.76it/s]
Loading safetensors checkpoint shards:  62% Completed | 639/1024 [00:15<00:09, 38.61it/s]
Loading safetensors checkpoint shards:  63% Completed | 643/1024 [00:15<00:09, 38.20it/s]
Loading safetensors checkpoint shards:  63% Completed | 647/1024 [00:15<00:10, 37.04it/s]
Loading safetensors checkpoint shards:  64% Completed | 651/1024 [00:15<00:10, 36.79it/s]
Loading safetensors checkpoint shards:  64% Completed | 655/1024 [00:15<00:09, 36.99it/s]
Loading safetensors checkpoint shards:  64% Completed | 659/1024 [00:15<00:10, 35.96it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:15<00:10, 35.68it/s]
Loading safetensors checkpoint shards:  65% Completed | 667/1024 [00:15<00:09, 35.99it/s]
Loading safetensors checkpoint shards:  66% Completed | 671/1024 [00:15<00:09, 36.64it/s]
Loading safetensors checkpoint shards:  66% Completed | 675/1024 [00:16<00:09, 36.91it/s]
Loading safetensors checkpoint shards:  66% Completed | 679/1024 [00:16<00:09, 35.56it/s]
Loading safetensors checkpoint shards:  67% Completed | 683/1024 [00:16<00:09, 35.91it/s]
Loading safetensors checkpoint shards:  67% Completed | 687/1024 [00:16<00:09, 35.56it/s]
Loading safetensors checkpoint shards:  67% Completed | 691/1024 [00:16<00:09, 35.79it/s]
Loading safetensors checkpoint shards:  68% Completed | 696/1024 [00:16<00:08, 38.15it/s]
Loading safetensors checkpoint shards:  68% Completed | 700/1024 [00:16<00:08, 37.78it/s]
Loading safetensors checkpoint shards:  69% Completed | 704/1024 [00:16<00:08, 36.18it/s]
Loading safetensors checkpoint shards:  69% Completed | 708/1024 [00:16<00:08, 36.65it/s]
Loading safetensors checkpoint shards:  70% Completed | 713/1024 [00:17<00:08, 37.70it/s]
Loading safetensors checkpoint shards:  70% Completed | 717/1024 [00:17<00:08, 36.79it/s]
Loading safetensors checkpoint shards:  70% Completed | 721/1024 [00:17<00:08, 35.95it/s]
Loading safetensors checkpoint shards:  71% Completed | 725/1024 [00:17<00:08, 35.95it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:17<00:08, 36.08it/s]
Loading safetensors checkpoint shards:  72% Completed | 733/1024 [00:17<00:08, 35.64it/s]
Loading safetensors checkpoint shards:  72% Completed | 737/1024 [00:17<00:08, 35.75it/s]
Loading safetensors checkpoint shards:  72% Completed | 741/1024 [00:17<00:07, 36.04it/s]
Loading safetensors checkpoint shards:  73% Completed | 745/1024 [00:17<00:07, 36.60it/s]
Loading safetensors checkpoint shards:  73% Completed | 749/1024 [00:18<00:07, 35.76it/s]
Loading safetensors checkpoint shards:  74% Completed | 753/1024 [00:18<00:07, 36.13it/s]
Loading safetensors checkpoint shards:  74% Completed | 757/1024 [00:18<00:07, 36.60it/s]
Loading safetensors checkpoint shards:  74% Completed | 761/1024 [00:18<00:07, 36.58it/s]
Loading safetensors checkpoint shards:  75% Completed | 765/1024 [00:18<00:06, 37.43it/s]
Loading safetensors checkpoint shards:  75% Completed | 769/1024 [00:18<00:06, 37.91it/s]
Loading safetensors checkpoint shards:  75% Completed | 773/1024 [00:18<00:06, 36.58it/s]
Loading safetensors checkpoint shards:  76% Completed | 777/1024 [00:18<00:06, 36.62it/s]
Loading safetensors checkpoint shards:  76% Completed | 781/1024 [00:18<00:06, 36.42it/s]
Loading safetensors checkpoint shards:  77% Completed | 785/1024 [00:19<00:06, 36.60it/s]
Loading safetensors checkpoint shards:  77% Completed | 789/1024 [00:19<00:06, 34.90it/s]
Loading safetensors checkpoint shards:  77% Completed | 793/1024 [00:19<00:06, 34.55it/s]
Loading safetensors checkpoint shards:  78% Completed | 797/1024 [00:19<00:06, 35.35it/s]
Loading safetensors checkpoint shards:  78% Completed | 801/1024 [00:19<00:06, 35.95it/s]
Loading safetensors checkpoint shards:  79% Completed | 806/1024 [00:19<00:05, 37.48it/s]
Loading safetensors checkpoint shards:  79% Completed | 810/1024 [00:19<00:05, 37.43it/s]
Loading safetensors checkpoint shards:  79% Completed | 814/1024 [00:19<00:05, 37.61it/s]
Loading safetensors checkpoint shards:  80% Completed | 818/1024 [00:19<00:05, 36.39it/s]
Loading safetensors checkpoint shards:  80% Completed | 822/1024 [00:20<00:05, 35.58it/s]
Loading safetensors checkpoint shards:  81% Completed | 826/1024 [00:20<00:05, 35.68it/s]
Loading safetensors checkpoint shards:  81% Completed | 830/1024 [00:20<00:05, 35.68it/s]
Loading safetensors checkpoint shards:  81% Completed | 834/1024 [00:20<00:05, 36.46it/s]
Loading safetensors checkpoint shards:  82% Completed | 838/1024 [00:20<00:05, 36.73it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:20<00:04, 36.72it/s]
Loading safetensors checkpoint shards:  83% Completed | 846/1024 [00:20<00:04, 35.92it/s]
Loading safetensors checkpoint shards:  83% Completed | 850/1024 [00:20<00:04, 35.87it/s]
Loading safetensors checkpoint shards:  83% Completed | 854/1024 [00:20<00:04, 36.07it/s]
Loading safetensors checkpoint shards:  84% Completed | 858/1024 [00:21<00:04, 35.30it/s]
Loading safetensors checkpoint shards:  84% Completed | 862/1024 [00:21<00:04, 35.79it/s]
Loading safetensors checkpoint shards:  85% Completed | 866/1024 [00:21<00:04, 33.86it/s]
Loading safetensors checkpoint shards:  85% Completed | 870/1024 [00:21<00:04, 32.93it/s]
Loading safetensors checkpoint shards:  85% Completed | 874/1024 [00:22<00:10, 14.09it/s]
Loading safetensors checkpoint shards:  86% Completed | 878/1024 [00:22<00:08, 17.46it/s]
Loading safetensors checkpoint shards:  86% Completed | 882/1024 [00:22<00:06, 20.99it/s]
Loading safetensors checkpoint shards:  87% Completed | 886/1024 [00:22<00:05, 24.47it/s]
Loading safetensors checkpoint shards:  87% Completed | 890/1024 [00:22<00:04, 26.98it/s]
Loading safetensors checkpoint shards:  87% Completed | 894/1024 [00:22<00:04, 29.79it/s]
Loading safetensors checkpoint shards:  88% Completed | 899/1024 [00:22<00:03, 32.74it/s]
Loading safetensors checkpoint shards:  88% Completed | 903/1024 [00:22<00:03, 34.32it/s]
Loading safetensors checkpoint shards:  89% Completed | 907/1024 [00:22<00:03, 35.78it/s]
Loading safetensors checkpoint shards:  89% Completed | 911/1024 [00:23<00:03, 36.70it/s]
Loading safetensors checkpoint shards:  89% Completed | 916/1024 [00:23<00:02, 38.89it/s]
Loading safetensors checkpoint shards:  90% Completed | 921/1024 [00:23<00:02, 38.97it/s]
Loading safetensors checkpoint shards:  90% Completed | 925/1024 [00:23<00:02, 38.60it/s]
Loading safetensors checkpoint shards:  91% Completed | 929/1024 [00:23<00:02, 38.08it/s]
Loading safetensors checkpoint shards:  91% Completed | 933/1024 [00:23<00:02, 37.00it/s]
Loading safetensors checkpoint shards:  92% Completed | 937/1024 [00:23<00:02, 37.23it/s]
Loading safetensors checkpoint shards:  92% Completed | 941/1024 [00:23<00:02, 37.43it/s]
Loading safetensors checkpoint shards:  92% Completed | 945/1024 [00:23<00:02, 37.08it/s]
Loading safetensors checkpoint shards:  93% Completed | 949/1024 [00:24<00:02, 36.73it/s]
Loading safetensors checkpoint shards:  93% Completed | 953/1024 [00:24<00:01, 36.73it/s]
Loading safetensors checkpoint shards:  93% Completed | 957/1024 [00:24<00:01, 36.43it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:24<00:01, 35.84it/s]
Loading safetensors checkpoint shards:  94% Completed | 965/1024 [00:24<00:01, 36.20it/s]
Loading safetensors checkpoint shards:  95% Completed | 969/1024 [00:24<00:01, 36.78it/s]
Loading safetensors checkpoint shards:  95% Completed | 973/1024 [00:24<00:01, 35.91it/s]
Loading safetensors checkpoint shards:  96% Completed | 978/1024 [00:24<00:01, 37.33it/s]
Loading safetensors checkpoint shards:  96% Completed | 986/1024 [00:24<00:00, 47.87it/s]
Loading safetensors checkpoint shards:  99% Completed | 1011/1024 [00:25<00:00, 101.54it/s]
Loading safetensors checkpoint shards: 100% Completed | 1022/1024 [00:25<00:00, 101.41it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 40.58it/s]
 
[2025-09-13 06:51:20 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 06:51:20 TP5] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 06:51:20 TP7] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 06:51:21 TP0] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 06:51:21 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 06:51:21 TP1] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 06:51:21 TP6] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 06:51:21 TP4] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 06:51:21 TP3] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 06:51:21 TP2] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 06:51:21 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 06:51:21 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.51 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s][2025-09-13 06:51:22 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:51:22 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 06:51:22 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:51:22 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:51:22 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:51:22 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:51:22 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:51:22 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:51:22 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26594.26it/s]
[2025-09-13 06:51:23 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:51:23 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27431.60it/s]
[2025-09-13 06:51:23 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:51:23 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28731.70it/s]
[2025-09-13 06:51:24 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:51:24 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28144.66it/s]
[2025-09-13 06:51:24 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:51:24 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 29390.51it/s]
[2025-09-13 06:51:25 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.20 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.16it/s]
[2025-09-13 06:51:28 TP5] Registering 984 cuda graph addresses
[2025-09-13 06:51:28 TP1] Registering 984 cuda graph addresses
[2025-09-13 06:51:28 TP3] Registering 984 cuda graph addresses
[2025-09-13 06:51:28 TP4] Registering 984 cuda graph addresses
[2025-09-13 06:51:28 TP0] Registering 984 cuda graph addresses
[2025-09-13 06:51:28 TP7] Registering 984 cuda graph addresses
[2025-09-13 06:51:28 TP6] Registering 984 cuda graph addresses
[2025-09-13 06:51:28 TP2] Registering 984 cuda graph addresses
[2025-09-13 06:51:28 TP0] Capture cuda graph end. Time elapsed: 7.65 s. mem usage=0.39 GB. avail mem=17.17 GB.
[2025-09-13 06:51:29 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 06:51:29 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:51:29 TP0] Init torch distributed begin.
[2025-09-13 06:51:29 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 06:51:29 TP0] Load weight begin. avail mem=17.17 GB
[2025-09-13 06:51:29 TP0] Detected fp8 checkpoint.
[2025-09-13 06:51:29 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 19/1024 [00:00<00:05, 183.29it/s]
Loading safetensors checkpoint shards:   5% Completed | 50/1024 [00:00<00:03, 255.34it/s]
Loading safetensors checkpoint shards:  11% Completed | 109/1024 [00:00<00:02, 406.10it/s]
Loading safetensors checkpoint shards:  17% Completed | 169/1024 [00:00<00:01, 480.10it/s]
Loading safetensors checkpoint shards:  22% Completed | 229/1024 [00:00<00:01, 520.96it/s]
Loading safetensors checkpoint shards:  28% Completed | 289/1024 [00:00<00:01, 544.99it/s]
Loading safetensors checkpoint shards:  34% Completed | 349/1024 [00:00<00:01, 560.26it/s]
Loading safetensors checkpoint shards:  40% Completed | 409/1024 [00:00<00:01, 570.50it/s]
Loading safetensors checkpoint shards:  46% Completed | 468/1024 [00:00<00:00, 575.07it/s]
Loading safetensors checkpoint shards:  52% Completed | 529/1024 [00:01<00:00, 583.01it/s]
Loading safetensors checkpoint shards:  58% Completed | 589/1024 [00:01<00:00, 585.77it/s]
Loading safetensors checkpoint shards:  63% Completed | 648/1024 [00:01<00:00, 580.40it/s]
Loading safetensors checkpoint shards:  69% Completed | 707/1024 [00:01<00:00, 573.14it/s]
Loading safetensors checkpoint shards:  75% Completed | 765/1024 [00:01<00:00, 566.84it/s]
Loading safetensors checkpoint shards:  80% Completed | 822/1024 [00:01<00:00, 564.05it/s]
Loading safetensors checkpoint shards:  86% Completed | 879/1024 [00:01<00:00, 560.86it/s]
Loading safetensors checkpoint shards:  91% Completed | 936/1024 [00:01<00:00, 561.54it/s]
Loading safetensors checkpoint shards:  97% Completed | 993/1024 [00:01<00:00, 490.94it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 499.90it/s]

[2025-09-13 06:51:31 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.18 GB, mem usage=1.99 GB.
[2025-09-13 06:51:31 TP5] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 06:51:31 TP6] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 06:51:31 TP2] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 06:51:31 TP3] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 06:51:31 TP7] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 06:51:31 TP0] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 06:51:31 TP1] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 06:51:31 TP0] Memory pool end. avail mem=14.52 GB
[2025-09-13 06:51:31 TP4] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 06:51:31 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 06:51:31 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 06:51:31 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 06:51:31 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 06:51:31 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.14 GB
[2025-09-13 06:51:31 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.95 GB
[2025-09-13 06:51:31 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 06:51:31 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
Capturing batches (bs=1 avail_mem=14.58 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.48it/s]
[2025-09-13 06:51:37 TP7] Registering 48 cuda graph addresses
[2025-09-13 06:51:37 TP5] Registering 48 cuda graph addresses
[2025-09-13 06:51:37 TP0] Registering 48 cuda graph addresses
[2025-09-13 06:51:37 TP2] Registering 48 cuda graph addresses
[2025-09-13 06:51:37 TP3] Registering 48 cuda graph addresses
[2025-09-13 06:51:37 TP4] Registering 48 cuda graph addresses
[2025-09-13 06:51:37 TP1] Registering 48 cuda graph addresses
[2025-09-13 06:51:37 TP6] Registering 48 cuda graph addresses
[2025-09-13 06:51:37 TP2] Capture draft cuda graph end. Time elapsed: 6.18 s. mem usage=0.37 GB. avail mem=14.54 GB.
[2025-09-13 06:51:37 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 06:51:37 TP3] Capture draft cuda graph end. Time elapsed: 6.18 s. mem usage=0.37 GB. avail mem=14.54 GB.
[2025-09-13 06:51:37 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 06:51:37 TP1] Capture draft cuda graph end. Time elapsed: 6.18 s. mem usage=0.37 GB. avail mem=14.54 GB.
[2025-09-13 06:51:37 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 06:51:37 TP5] Capture draft cuda graph end. Time elapsed: 6.18 s. mem usage=0.37 GB. avail mem=14.54 GB.
[2025-09-13 06:51:37 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 06:51:37 TP7] Capture draft cuda graph end. Time elapsed: 6.18 s. mem usage=0.37 GB. avail mem=14.77 GB.
[2025-09-13 06:51:37 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.77 GB
[2025-09-13 06:51:37 TP6] Capture draft cuda graph end. Time elapsed: 6.18 s. mem usage=0.37 GB. avail mem=14.54 GB.
[2025-09-13 06:51:37 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 06:51:37 TP0] Capture draft cuda graph end. Time elapsed: 6.18 s. mem usage=0.37 GB. avail mem=14.58 GB.
[2025-09-13 06:51:37 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 06:51:37 TP4] Capture draft cuda graph end. Time elapsed: 6.19 s. mem usage=0.37 GB. avail mem=14.54 GB.
[2025-09-13 06:51:37 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
Capturing batches (bs=1 avail_mem=14.39 GB):  12%|██████████▊                                                                           | 1/8 [00:00<00:01,  4.83it/s][2025-09-13 06:51:39 TP2] Registering 24 cuda graph addresses
[2025-09-13 06:51:39 TP1] Registering 24 cuda graph addresses
[2025-09-13 06:51:39 TP6] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.39 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 28.90it/s][2025-09-13 06:51:39 TP5] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.39 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 24.34it/s]
[2025-09-13 06:51:39 TP3] Registering 24 cuda graph addresses
[2025-09-13 06:51:39 TP0] Registering 24 cuda graph addresses
[2025-09-13 06:51:39 TP4] Registering 24 cuda graph addresses
[2025-09-13 06:51:39 TP7] Registering 24 cuda graph addresses
[2025-09-13 06:51:39 TP1] Capture draft extend cuda graph end. Time elapsed: 1.06 s. mem usage=0.19 GB. avail mem=14.35 GB.
[2025-09-13 06:51:39 TP6] Capture draft extend cuda graph end. Time elapsed: 1.06 s. mem usage=0.19 GB. avail mem=14.35 GB.
[2025-09-13 06:51:39 TP2] Capture draft extend cuda graph end. Time elapsed: 1.06 s. mem usage=0.19 GB. avail mem=14.35 GB.
[2025-09-13 06:51:39 TP0] Capture draft extend cuda graph end. Time elapsed: 1.06 s. mem usage=0.19 GB. avail mem=14.39 GB.
[2025-09-13 06:51:39 TP0] max_total_num_tokens=620217, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.39 GB
[2025-09-13 06:51:39 TP3] Capture draft extend cuda graph end. Time elapsed: 1.07 s. mem usage=0.19 GB. avail mem=14.35 GB.
[2025-09-13 06:51:39 TP4] Capture draft extend cuda graph end. Time elapsed: 1.06 s. mem usage=0.19 GB. avail mem=14.35 GB.
[2025-09-13 06:51:39 TP5] Capture draft extend cuda graph end. Time elapsed: 1.07 s. mem usage=0.19 GB. avail mem=14.35 GB.
[2025-09-13 06:51:39 TP7] Capture draft extend cuda graph end. Time elapsed: 1.07 s. mem usage=0.19 GB. avail mem=14.58 GB.
[2025-09-13 06:51:39] INFO:     Started server process [170014]
[2025-09-13 06:51:39] INFO:     Waiting for application startup.
[2025-09-13 06:51:39] INFO:     Application startup complete.
[2025-09-13 06:51:39] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 06:51:40] INFO:     127.0.0.1:40084 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 06:51:40 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:51:40 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:51:40 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 29144.43it/s]
[2025-09-13 06:51:41] INFO:     127.0.0.1:40090 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:41] The server is fired up and ready to roll!
[2025-09-13 06:51:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:51:42] INFO:     127.0.0.1:40092 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:51:43] INFO:     127.0.0.1:40100 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:43 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 06:51:44] INFO:     127.0.0.1:40106 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:44] INFO:     127.0.0.1:40114 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:44 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:51:44] INFO:     127.0.0.1:40124 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:44] INFO:     127.0.0.1:40126 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:44] INFO:     127.0.0.1:40130 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:44] INFO:     127.0.0.1:40140 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:44] INFO:     127.0.0.1:40154 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:44] INFO:     127.0.0.1:40160 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:44 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 06:51:45 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:51:45 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:51:45 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:51:45 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:51:45 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:51:45 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:51:45 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:51:45 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:51:45 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 06:51:46 TP0] Decode batch. #running-req: 8, #token: 14573, token usage: 0.02, accept len: 2.99, cuda graph: True, gen throughput (token/s): 92.52, #queue-req: 0, 
[2025-09-13 06:51:47 TP0] Decode batch. #running-req: 8, #token: 15669, token usage: 0.03, accept len: 3.42, cuda graph: True, gen throughput (token/s): 854.63, #queue-req: 0, 
[2025-09-13 06:51:49 TP0] Decode batch. #running-req: 8, #token: 16805, token usage: 0.03, accept len: 3.55, cuda graph: True, gen throughput (token/s): 878.44, #queue-req: 0, 
 38%|█████████████████████████████████████████████████▏                                                                                 | 3/8 [00:05<00:07,  1.44s/it][2025-09-13 06:51:50 TP0] Decode batch. #running-req: 5, #token: 5193, token usage: 0.01, accept len: 3.52, cuda graph: True, gen throughput (token/s): 818.70, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.28it/s]
[2025-09-13 06:51:51] INFO:     127.0.0.1:39134 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.27      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4077      
Request throughput (req/s):              1.28      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         653.52    
Total token throughput (tok/s):          653.52    
Concurrency:                             7.24      
Accept length:                           3.40      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5676.01   
Median E2E Latency (ms):                 5638.81   
---------------Time to First Token----------------
Mean TTFT (ms):                          638.50    
Median TTFT (ms):                        753.39    
P99 TTFT (ms):                           753.96    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.86      
Median ITL (ms):                         8.06      
P95 ITL (ms):                            16.16     
P99 ITL (ms):                            32.80     
Max ITL (ms):                            379.77    
==================================================
[2025-09-13 06:51:51] INFO:     127.0.0.1:39142 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:51:51] INFO:     127.0.0.1:39144 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 06:51:52] INFO:     127.0.0.1:39150 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:52] INFO:     127.0.0.1:39154 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:51:52] INFO:     127.0.0.1:39156 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:52] INFO:     127.0.0.1:39162 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:52] INFO:     127.0.0.1:39170 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:52] INFO:     127.0.0.1:39186 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:52] INFO:     127.0.0.1:39200 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:52] INFO:     127.0.0.1:39202 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:52 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 06:51:52 TP0] Decode batch. #running-req: 8, #token: 14020, token usage: 0.02, accept len: 2.89, cuda graph: True, gen throughput (token/s): 106.86, #queue-req: 0, 
[2025-09-13 06:51:54 TP0] Decode batch. #running-req: 8, #token: 15052, token usage: 0.02, accept len: 3.23, cuda graph: True, gen throughput (token/s): 833.11, #queue-req: 0, 
[2025-09-13 06:51:55 TP0] Decode batch. #running-req: 8, #token: 16177, token usage: 0.03, accept len: 3.52, cuda graph: True, gen throughput (token/s): 879.52, #queue-req: 0, 
[2025-09-13 06:51:56 TP0] Decode batch. #running-req: 8, #token: 17320, token usage: 0.03, accept len: 3.57, cuda graph: True, gen throughput (token/s): 891.15, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:09,  4.65s/it][2025-09-13 06:51:57] INFO:     127.0.0.1:39206 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:57 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:29,  2.10s/it][2025-09-13 06:51:57] INFO:     127.0.0.1:39220 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:16,  1.26s/it][2025-09-13 06:51:57] INFO:     127.0.0.1:39236 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:57 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.17it/s][2025-09-13 06:51:57] INFO:     127.0.0.1:35398 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:57 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:51:57] INFO:     127.0.0.1:35400 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:58 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.90it/s][2025-09-13 06:51:58] INFO:     127.0.0.1:35414 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:58 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:51:58] INFO:     127.0.0.1:35416 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:51:59 TP0] Decode batch. #running-req: 8, #token: 10305, token usage: 0.02, accept len: 3.33, cuda graph: True, gen throughput (token/s): 446.11, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:03,  2.01it/s][2025-09-13 06:51:59] INFO:     127.0.0.1:35420 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:51:59 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:52:00 TP0] Decode batch. #running-req: 8, #token: 14845, token usage: 0.02, accept len: 3.19, cuda graph: True, gen throughput (token/s): 684.97, #queue-req: 0, 
[2025-09-13 06:52:01 TP0] Decode batch. #running-req: 8, #token: 15927, token usage: 0.03, accept len: 3.38, cuda graph: True, gen throughput (token/s): 857.82, #queue-req: 0, 
[2025-09-13 06:52:03 TP0] Decode batch. #running-req: 8, #token: 17078, token usage: 0.03, accept len: 3.60, cuda graph: True, gen throughput (token/s): 906.87, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.40it/s]
[2025-09-13 06:52:03] INFO:     127.0.0.1:35432 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.44     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8094      
Request throughput (req/s):              1.40      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         716.02    
Total token throughput (tok/s):          716.02    
Concurrency:                             7.74      
Accept length:                           3.39      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5534.26   
Median E2E Latency (ms):                 5481.76   
---------------Time to First Token----------------
Mean TTFT (ms):                          241.33    
Median TTFT (ms):                        283.19    
P99 TTFT (ms):                           336.81    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.36     
Median ITL (ms):                         7.97      
P95 ITL (ms):                            16.09     
P99 ITL (ms):                            51.92     
Max ITL (ms):                            265.61    
==================================================
[2025-09-13 06:52:03] INFO:     127.0.0.1:35444 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=8: batch_size=8, steps=3, topk=4, num_draft_tokens=8, speed=106.76 token/s, step_time=31.73 ms
Start i=9: batch_size=8, steps=3, topk=4, num_draft_tokens=12
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 3 --speculative-eagle-topk 4 --speculative-num-draft-tokens 12 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:52:14.674000 175654 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:52:14.674000 175654 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 06:52:15] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=195973618, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=3, speculative_eagle_topk=4, speculative_num_draft_tokens=12, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:52:15] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:52:23.707000 175873 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:52:23.707000 175873 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:52:23.825000 175875 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:52:23.825000 175875 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:52:23.994000 175870 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:52:23.994000 175870 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:52:24.164000 175874 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:52:24.164000 175874 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:52:24.171000 175871 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:52:24.171000 175871 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:52:24.240000 175878 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:52:24.240000 175878 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:52:24.370000 175872 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:52:24.370000 175872 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:52:24.371000 175876 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:52:24.371000 175876 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:52:24.381000 175877 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:52:24.381000 175877 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[2025-09-13 06:52:24 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 06:52:24 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:52:24 TP0] Init torch distributed begin.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:52:26 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:52:29 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 06:52:30 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 06:52:30 TP0] Detected fp8 checkpoint.
[2025-09-13 06:52:31 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 28/1024 [00:00<00:04, 222.36it/s]
Loading safetensors checkpoint shards:   5% Completed | 51/1024 [00:00<00:16, 59.59it/s]
Loading safetensors checkpoint shards:   6% Completed | 63/1024 [00:01<00:19, 48.98it/s]
Loading safetensors checkpoint shards:   7% Completed | 71/1024 [00:01<00:20, 46.48it/s]
Loading safetensors checkpoint shards:   8% Completed | 78/1024 [00:01<00:22, 42.67it/s]
Loading safetensors checkpoint shards:   8% Completed | 84/1024 [00:01<00:20, 44.91it/s]
Loading safetensors checkpoint shards:   9% Completed | 90/1024 [00:01<00:19, 46.80it/s]
Loading safetensors checkpoint shards:   9% Completed | 96/1024 [00:01<00:20, 44.48it/s]
Loading safetensors checkpoint shards:  10% Completed | 101/1024 [00:02<00:21, 43.76it/s]
Loading safetensors checkpoint shards:  10% Completed | 106/1024 [00:02<00:20, 44.63it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:36, 24.82it/s]
Loading safetensors checkpoint shards:  11% Completed | 116/1024 [00:02<00:33, 27.50it/s]
Loading safetensors checkpoint shards:  12% Completed | 120/1024 [00:02<00:31, 28.48it/s]
Loading safetensors checkpoint shards:  12% Completed | 127/1024 [00:02<00:25, 35.35it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:03<00:24, 37.15it/s]
Loading safetensors checkpoint shards:  14% Completed | 139/1024 [00:03<00:20, 42.68it/s]
Loading safetensors checkpoint shards:  14% Completed | 145/1024 [00:03<00:19, 46.01it/s]
Loading safetensors checkpoint shards:  15% Completed | 151/1024 [00:03<00:18, 48.10it/s]
Loading safetensors checkpoint shards:  15% Completed | 157/1024 [00:03<00:18, 47.89it/s]
Loading safetensors checkpoint shards:  16% Completed | 163/1024 [00:03<00:17, 49.34it/s]
Loading safetensors checkpoint shards:  17% Completed | 169/1024 [00:03<00:17, 49.79it/s]
Loading safetensors checkpoint shards:  17% Completed | 175/1024 [00:03<00:17, 49.06it/s]
Loading safetensors checkpoint shards:  18% Completed | 180/1024 [00:04<00:18, 46.41it/s]
Loading safetensors checkpoint shards:  18% Completed | 187/1024 [00:04<00:16, 49.66it/s]
Loading safetensors checkpoint shards:  19% Completed | 193/1024 [00:04<00:16, 50.51it/s]
Loading safetensors checkpoint shards:  19% Completed | 199/1024 [00:04<00:16, 49.68it/s]
Loading safetensors checkpoint shards:  20% Completed | 204/1024 [00:04<00:16, 49.25it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:04<00:16, 48.60it/s]
Loading safetensors checkpoint shards:  21% Completed | 216/1024 [00:04<00:15, 52.27it/s]
Loading safetensors checkpoint shards:  22% Completed | 222/1024 [00:04<00:17, 46.34it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:04<00:17, 46.00it/s]
Loading safetensors checkpoint shards:  23% Completed | 232/1024 [00:05<00:16, 46.77it/s]
Loading safetensors checkpoint shards:  23% Completed | 238/1024 [00:05<00:16, 49.04it/s]
Loading safetensors checkpoint shards:  24% Completed | 244/1024 [00:05<00:16, 48.62it/s]
Loading safetensors checkpoint shards:  24% Completed | 250/1024 [00:05<00:15, 49.54it/s]
Loading safetensors checkpoint shards:  25% Completed | 255/1024 [00:05<00:32, 23.41it/s]
Loading safetensors checkpoint shards:  25% Completed | 261/1024 [00:06<00:26, 28.59it/s]
Loading safetensors checkpoint shards:  26% Completed | 266/1024 [00:06<00:23, 31.72it/s]
Loading safetensors checkpoint shards:  27% Completed | 273/1024 [00:06<00:19, 38.16it/s]
Loading safetensors checkpoint shards:  27% Completed | 278/1024 [00:06<00:19, 39.12it/s]
Loading safetensors checkpoint shards:  28% Completed | 283/1024 [00:06<00:18, 40.17it/s]
Loading safetensors checkpoint shards:  28% Completed | 288/1024 [00:06<00:20, 36.08it/s]
Loading safetensors checkpoint shards:  29% Completed | 293/1024 [00:06<00:21, 34.51it/s]
Loading safetensors checkpoint shards:  29% Completed | 297/1024 [00:06<00:22, 32.91it/s]
Loading safetensors checkpoint shards:  29% Completed | 301/1024 [00:07<00:22, 32.42it/s]
Loading safetensors checkpoint shards:  30% Completed | 305/1024 [00:07<00:22, 31.47it/s]
Loading safetensors checkpoint shards:  30% Completed | 309/1024 [00:07<00:23, 29.85it/s]
Loading safetensors checkpoint shards:  31% Completed | 313/1024 [00:07<00:22, 31.82it/s]
Loading safetensors checkpoint shards:  31% Completed | 319/1024 [00:07<00:19, 36.79it/s]
Loading safetensors checkpoint shards:  32% Completed | 324/1024 [00:07<00:18, 37.24it/s]
Loading safetensors checkpoint shards:  32% Completed | 329/1024 [00:07<00:17, 39.22it/s]
Loading safetensors checkpoint shards:  33% Completed | 333/1024 [00:07<00:17, 38.55it/s]
Loading safetensors checkpoint shards:  33% Completed | 338/1024 [00:08<00:17, 39.88it/s]
Loading safetensors checkpoint shards:  33% Completed | 343/1024 [00:08<00:16, 41.59it/s]
Loading safetensors checkpoint shards:  34% Completed | 349/1024 [00:08<00:15, 44.23it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:08<00:15, 44.13it/s]
Loading safetensors checkpoint shards:  35% Completed | 359/1024 [00:08<00:14, 44.60it/s]
Loading safetensors checkpoint shards:  36% Completed | 364/1024 [00:08<00:14, 44.40it/s]
Loading safetensors checkpoint shards:  36% Completed | 370/1024 [00:08<00:14, 45.63it/s]
Loading safetensors checkpoint shards:  37% Completed | 376/1024 [00:08<00:13, 46.84it/s]
Loading safetensors checkpoint shards:  37% Completed | 381/1024 [00:09<00:14, 43.66it/s]
Loading safetensors checkpoint shards:  38% Completed | 386/1024 [00:09<00:14, 44.19it/s]
Loading safetensors checkpoint shards:  38% Completed | 391/1024 [00:09<00:13, 45.25it/s]
Loading safetensors checkpoint shards:  39% Completed | 396/1024 [00:09<00:13, 45.68it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:09<00:14, 44.20it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:09<00:13, 44.59it/s]
Loading safetensors checkpoint shards:  40% Completed | 411/1024 [00:09<00:14, 42.36it/s]
Loading safetensors checkpoint shards:  41% Completed | 416/1024 [00:09<00:14, 41.69it/s]
Loading safetensors checkpoint shards:  41% Completed | 421/1024 [00:10<00:16, 36.40it/s]
Loading safetensors checkpoint shards:  42% Completed | 425/1024 [00:10<00:33, 17.84it/s]
Loading safetensors checkpoint shards:  42% Completed | 429/1024 [00:10<00:28, 20.66it/s]
Loading safetensors checkpoint shards:  42% Completed | 433/1024 [00:10<00:25, 22.92it/s]
Loading safetensors checkpoint shards:  43% Completed | 437/1024 [00:10<00:22, 25.74it/s]
Loading safetensors checkpoint shards:  43% Completed | 441/1024 [00:11<00:20, 28.04it/s]
Loading safetensors checkpoint shards:  43% Completed | 445/1024 [00:11<00:19, 29.76it/s]
Loading safetensors checkpoint shards:  44% Completed | 449/1024 [00:11<00:17, 32.06it/s]
Loading safetensors checkpoint shards:  44% Completed | 453/1024 [00:11<00:17, 33.05it/s]
Loading safetensors checkpoint shards:  45% Completed | 457/1024 [00:11<00:16, 33.49it/s]
Loading safetensors checkpoint shards:  45% Completed | 462/1024 [00:11<00:14, 37.66it/s]
Loading safetensors checkpoint shards:  46% Completed | 466/1024 [00:11<00:14, 37.94it/s]
Loading safetensors checkpoint shards:  46% Completed | 470/1024 [00:11<00:14, 38.08it/s]
Loading safetensors checkpoint shards:  46% Completed | 475/1024 [00:11<00:14, 38.51it/s]
Loading safetensors checkpoint shards:  47% Completed | 481/1024 [00:12<00:13, 40.32it/s]
Loading safetensors checkpoint shards:  47% Completed | 486/1024 [00:12<00:13, 40.15it/s]
Loading safetensors checkpoint shards:  48% Completed | 491/1024 [00:12<00:14, 36.19it/s]
Loading safetensors checkpoint shards:  48% Completed | 495/1024 [00:12<00:14, 36.79it/s]
Loading safetensors checkpoint shards:  49% Completed | 499/1024 [00:12<00:14, 36.51it/s]
Loading safetensors checkpoint shards:  49% Completed | 503/1024 [00:12<00:15, 34.35it/s]
Loading safetensors checkpoint shards:  50% Completed | 508/1024 [00:12<00:13, 37.05it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:12<00:13, 38.93it/s]
Loading safetensors checkpoint shards:  51% Completed | 519/1024 [00:13<00:12, 41.57it/s]
Loading safetensors checkpoint shards:  51% Completed | 524/1024 [00:13<00:11, 42.61it/s]
Loading safetensors checkpoint shards:  52% Completed | 530/1024 [00:13<00:10, 45.08it/s]
Loading safetensors checkpoint shards:  52% Completed | 535/1024 [00:13<00:11, 43.84it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:13<00:10, 45.54it/s]
Loading safetensors checkpoint shards:  53% Completed | 546/1024 [00:13<00:10, 44.21it/s]
Loading safetensors checkpoint shards:  54% Completed | 552/1024 [00:13<00:10, 46.00it/s]
Loading safetensors checkpoint shards:  54% Completed | 557/1024 [00:13<00:10, 44.29it/s]
Loading safetensors checkpoint shards:  55% Completed | 562/1024 [00:14<00:10, 44.22it/s]
Loading safetensors checkpoint shards:  55% Completed | 567/1024 [00:14<00:10, 44.10it/s]
Loading safetensors checkpoint shards:  56% Completed | 573/1024 [00:14<00:09, 46.04it/s]
Loading safetensors checkpoint shards:  56% Completed | 578/1024 [00:14<00:10, 43.78it/s]
Loading safetensors checkpoint shards:  57% Completed | 584/1024 [00:14<00:09, 46.77it/s]
Loading safetensors checkpoint shards:  58% Completed | 589/1024 [00:14<00:09, 46.08it/s]
Loading safetensors checkpoint shards:  58% Completed | 594/1024 [00:14<00:09, 46.33it/s]
Loading safetensors checkpoint shards:  58% Completed | 599/1024 [00:14<00:09, 45.68it/s]
Loading safetensors checkpoint shards:  59% Completed | 605/1024 [00:14<00:08, 47.51it/s]
Loading safetensors checkpoint shards:  60% Completed | 610/1024 [00:15<00:09, 45.78it/s]
Loading safetensors checkpoint shards:  60% Completed | 615/1024 [00:15<00:08, 46.75it/s]
Loading safetensors checkpoint shards:  61% Completed | 620/1024 [00:15<00:08, 46.41it/s]
Loading safetensors checkpoint shards:  61% Completed | 625/1024 [00:15<00:08, 45.84it/s]
Loading safetensors checkpoint shards:  62% Completed | 630/1024 [00:15<00:08, 43.81it/s]
Loading safetensors checkpoint shards:  62% Completed | 635/1024 [00:15<00:08, 43.38it/s]
Loading safetensors checkpoint shards:  62% Completed | 640/1024 [00:15<00:08, 43.37it/s]
Loading safetensors checkpoint shards:  63% Completed | 645/1024 [00:15<00:08, 42.27it/s]
Loading safetensors checkpoint shards:  63% Completed | 650/1024 [00:15<00:08, 42.04it/s]
Loading safetensors checkpoint shards:  64% Completed | 655/1024 [00:16<00:08, 42.45it/s]
Loading safetensors checkpoint shards:  64% Completed | 660/1024 [00:16<00:08, 41.85it/s]
Loading safetensors checkpoint shards:  65% Completed | 665/1024 [00:16<00:08, 40.34it/s]
Loading safetensors checkpoint shards:  65% Completed | 670/1024 [00:16<00:08, 40.32it/s]
Loading safetensors checkpoint shards:  66% Completed | 675/1024 [00:16<00:08, 40.16it/s]
Loading safetensors checkpoint shards:  66% Completed | 680/1024 [00:17<00:18, 19.07it/s]
Loading safetensors checkpoint shards:  67% Completed | 684/1024 [00:17<00:15, 21.77it/s]
Loading safetensors checkpoint shards:  67% Completed | 688/1024 [00:17<00:13, 24.78it/s]
Loading safetensors checkpoint shards:  68% Completed | 693/1024 [00:17<00:11, 29.12it/s]
Loading safetensors checkpoint shards:  68% Completed | 697/1024 [00:17<00:10, 30.99it/s]
Loading safetensors checkpoint shards:  68% Completed | 701/1024 [00:17<00:10, 31.82it/s]
Loading safetensors checkpoint shards:  69% Completed | 705/1024 [00:17<00:09, 33.36it/s]
Loading safetensors checkpoint shards:  69% Completed | 709/1024 [00:17<00:09, 34.64it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:18<00:08, 36.59it/s]
Loading safetensors checkpoint shards:  70% Completed | 718/1024 [00:18<00:08, 37.16it/s]
Loading safetensors checkpoint shards:  71% Completed | 723/1024 [00:18<00:07, 38.77it/s]
Loading safetensors checkpoint shards:  71% Completed | 728/1024 [00:18<00:07, 39.79it/s]
Loading safetensors checkpoint shards:  72% Completed | 733/1024 [00:18<00:07, 39.99it/s]
Loading safetensors checkpoint shards:  72% Completed | 738/1024 [00:18<00:07, 40.61it/s]
Loading safetensors checkpoint shards:  73% Completed | 743/1024 [00:18<00:06, 41.65it/s]
Loading safetensors checkpoint shards:  73% Completed | 748/1024 [00:18<00:06, 41.33it/s]
Loading safetensors checkpoint shards:  74% Completed | 753/1024 [00:18<00:06, 42.10it/s]
Loading safetensors checkpoint shards:  74% Completed | 758/1024 [00:19<00:06, 42.50it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:19<00:06, 42.79it/s]
Loading safetensors checkpoint shards:  75% Completed | 768/1024 [00:19<00:06, 42.66it/s]
Loading safetensors checkpoint shards:  75% Completed | 773/1024 [00:19<00:06, 41.51it/s]
Loading safetensors checkpoint shards:  76% Completed | 778/1024 [00:19<00:05, 41.32it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:19<00:05, 40.67it/s]
Loading safetensors checkpoint shards:  77% Completed | 788/1024 [00:19<00:05, 39.43it/s]
Loading safetensors checkpoint shards:  77% Completed | 792/1024 [00:19<00:05, 39.37it/s]
Loading safetensors checkpoint shards:  78% Completed | 796/1024 [00:20<00:05, 39.12it/s]
Loading safetensors checkpoint shards:  78% Completed | 801/1024 [00:20<00:05, 39.62it/s]
Loading safetensors checkpoint shards:  79% Completed | 806/1024 [00:20<00:05, 41.11it/s]
Loading safetensors checkpoint shards:  79% Completed | 811/1024 [00:20<00:05, 41.96it/s]
Loading safetensors checkpoint shards:  80% Completed | 816/1024 [00:20<00:05, 41.41it/s]
Loading safetensors checkpoint shards:  80% Completed | 821/1024 [00:20<00:04, 41.59it/s]
Loading safetensors checkpoint shards:  81% Completed | 826/1024 [00:20<00:04, 42.29it/s]
Loading safetensors checkpoint shards:  81% Completed | 831/1024 [00:20<00:04, 42.60it/s]
Loading safetensors checkpoint shards:  82% Completed | 836/1024 [00:20<00:04, 43.17it/s]
Loading safetensors checkpoint shards:  82% Completed | 841/1024 [00:21<00:04, 42.77it/s]
Loading safetensors checkpoint shards:  83% Completed | 846/1024 [00:21<00:04, 41.16it/s]
Loading safetensors checkpoint shards:  83% Completed | 851/1024 [00:21<00:04, 40.88it/s]
Loading safetensors checkpoint shards:  84% Completed | 856/1024 [00:21<00:04, 41.35it/s]
Loading safetensors checkpoint shards:  84% Completed | 861/1024 [00:21<00:04, 39.95it/s]
Loading safetensors checkpoint shards:  85% Completed | 866/1024 [00:21<00:03, 39.77it/s]
Loading safetensors checkpoint shards:  85% Completed | 870/1024 [00:21<00:03, 39.52it/s]
Loading safetensors checkpoint shards:  85% Completed | 874/1024 [00:21<00:03, 38.10it/s]
Loading safetensors checkpoint shards:  86% Completed | 878/1024 [00:22<00:03, 38.00it/s]
Loading safetensors checkpoint shards:  86% Completed | 882/1024 [00:22<00:03, 37.70it/s]
Loading safetensors checkpoint shards:  87% Completed | 886/1024 [00:22<00:03, 37.66it/s]
Loading safetensors checkpoint shards:  87% Completed | 890/1024 [00:22<00:03, 36.94it/s]
Loading safetensors checkpoint shards:  87% Completed | 894/1024 [00:22<00:03, 37.18it/s]
Loading safetensors checkpoint shards:  88% Completed | 898/1024 [00:22<00:03, 36.89it/s]
Loading safetensors checkpoint shards:  88% Completed | 902/1024 [00:22<00:03, 36.67it/s]
Loading safetensors checkpoint shards:  88% Completed | 906/1024 [00:22<00:03, 37.05it/s]
Loading safetensors checkpoint shards:  89% Completed | 910/1024 [00:22<00:03, 37.45it/s]
Loading safetensors checkpoint shards:  89% Completed | 915/1024 [00:23<00:02, 38.37it/s]
Loading safetensors checkpoint shards:  90% Completed | 919/1024 [00:23<00:02, 37.95it/s]
Loading safetensors checkpoint shards:  90% Completed | 923/1024 [00:23<00:02, 37.32it/s]
Loading safetensors checkpoint shards:  91% Completed | 927/1024 [00:23<00:02, 37.31it/s]
Loading safetensors checkpoint shards:  91% Completed | 931/1024 [00:23<00:02, 36.31it/s]
Loading safetensors checkpoint shards:  91% Completed | 935/1024 [00:23<00:02, 35.80it/s]
Loading safetensors checkpoint shards:  92% Completed | 939/1024 [00:23<00:02, 35.73it/s]
Loading safetensors checkpoint shards:  92% Completed | 943/1024 [00:23<00:02, 35.85it/s]
Loading safetensors checkpoint shards:  92% Completed | 947/1024 [00:23<00:02, 35.07it/s]
Loading safetensors checkpoint shards:  93% Completed | 951/1024 [00:24<00:02, 35.74it/s]
Loading safetensors checkpoint shards:  93% Completed | 955/1024 [00:24<00:01, 35.97it/s]
Loading safetensors checkpoint shards:  94% Completed | 959/1024 [00:24<00:01, 36.16it/s]
Loading safetensors checkpoint shards:  94% Completed | 963/1024 [00:24<00:01, 35.77it/s]
Loading safetensors checkpoint shards:  94% Completed | 967/1024 [00:24<00:01, 36.20it/s]
Loading safetensors checkpoint shards:  95% Completed | 971/1024 [00:24<00:01, 35.30it/s]
Loading safetensors checkpoint shards:  95% Completed | 975/1024 [00:24<00:01, 35.80it/s]
Loading safetensors checkpoint shards:  96% Completed | 979/1024 [00:24<00:01, 36.40it/s]
Loading safetensors checkpoint shards:  97% Completed | 992/1024 [00:24<00:00, 62.01it/s]
Loading safetensors checkpoint shards:  98% Completed | 1001/1024 [00:25<00:00, 65.50it/s]
Loading safetensors checkpoint shards:  99% Completed | 1011/1024 [00:25<00:00, 74.06it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 40.53it/s]

[2025-09-13 06:52:56 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 06:52:58 TP0] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 06:52:58 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 06:52:58 TP2] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 06:52:58 TP5] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 06:52:58 TP7] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 06:52:58 TP6] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 06:52:58 TP3] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 06:52:58 TP4] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 06:52:58 TP1] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 06:52:58 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 06:52:59 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.50 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 06:53:00 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:53:00 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 06:53:00 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:53:00 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:53:00 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:53:00 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:53:00 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:53:00 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:53:00 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25440.60it/s]
[2025-09-13 06:53:00 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:53:00 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25695.10it/s]
[2025-09-13 06:53:01 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:53:01 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27037.76it/s]
[2025-09-13 06:53:02 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:53:02 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26630.81it/s]
[2025-09-13 06:53:02 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:53:02 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27722.40it/s]
[2025-09-13 06:53:03 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.16 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.01it/s]
[2025-09-13 06:53:07 TP3] Registering 984 cuda graph addresses
[2025-09-13 06:53:07 TP0] Registering 984 cuda graph addresses
[2025-09-13 06:53:07 TP1] Registering 984 cuda graph addresses
[2025-09-13 06:53:07 TP6] Registering 984 cuda graph addresses
[2025-09-13 06:53:07 TP7] Registering 984 cuda graph addresses
[2025-09-13 06:53:07 TP5] Registering 984 cuda graph addresses
[2025-09-13 06:53:07 TP4] Registering 984 cuda graph addresses
[2025-09-13 06:53:07 TP2] Registering 984 cuda graph addresses
[2025-09-13 06:53:07 TP0] Capture cuda graph end. Time elapsed: 8.70 s. mem usage=0.43 GB. avail mem=17.14 GB.
[2025-09-13 06:53:07 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 06:53:07 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:53:07 TP0] Init torch distributed begin.
[2025-09-13 06:53:07 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 06:53:07 TP0] Load weight begin. avail mem=17.14 GB
[2025-09-13 06:53:07 TP0] Detected fp8 checkpoint.
[2025-09-13 06:53:07 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 175.21it/s]
Loading safetensors checkpoint shards:   4% Completed | 43/1024 [00:00<00:04, 216.62it/s]
Loading safetensors checkpoint shards:  10% Completed | 106/1024 [00:00<00:02, 402.07it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:00<00:01, 481.21it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:00<00:01, 521.84it/s]
Loading safetensors checkpoint shards:  28% Completed | 287/1024 [00:00<00:01, 546.04it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:00<00:01, 558.00it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:00<00:01, 569.37it/s]
Loading safetensors checkpoint shards:  45% Completed | 465/1024 [00:00<00:00, 573.10it/s]
Loading safetensors checkpoint shards:  51% Completed | 525/1024 [00:01<00:00, 578.98it/s]
Loading safetensors checkpoint shards:  57% Completed | 586/1024 [00:01<00:00, 585.34it/s]
Loading safetensors checkpoint shards:  63% Completed | 645/1024 [00:01<00:00, 581.66it/s]
Loading safetensors checkpoint shards:  69% Completed | 704/1024 [00:01<00:00, 574.27it/s]
Loading safetensors checkpoint shards:  74% Completed | 762/1024 [00:01<00:00, 566.82it/s]
Loading safetensors checkpoint shards:  80% Completed | 819/1024 [00:01<00:00, 564.24it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:01<00:00, 561.61it/s]
Loading safetensors checkpoint shards:  91% Completed | 934/1024 [00:01<00:00, 564.54it/s]
Loading safetensors checkpoint shards:  97% Completed | 991/1024 [00:01<00:00, 499.83it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 500.81it/s]

[2025-09-13 06:53:10 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.15 GB, mem usage=1.99 GB.
[2025-09-13 06:53:10 TP4] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 06:53:10 TP7] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 06:53:10 TP0] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 06:53:10 TP1] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 06:53:10 TP3] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 06:53:10 TP0] Memory pool end. avail mem=14.48 GB
[2025-09-13 06:53:10 TP6] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 06:53:10 TP5] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 06:53:10 TP2] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 06:53:10 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 06:53:10 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 06:53:10 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 06:53:10 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 06:53:10 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 06:53:10 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 06:53:10 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 06:53:10 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.11 GB
Capturing batches (bs=1 avail_mem=14.55 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.43it/s]
[2025-09-13 06:53:16 TP0] Registering 48 cuda graph addresses
[2025-09-13 06:53:16 TP1] Registering 48 cuda graph addresses
[2025-09-13 06:53:16 TP3] Registering 48 cuda graph addresses
[2025-09-13 06:53:16 TP2] Registering 48 cuda graph addresses
[2025-09-13 06:53:16 TP4] Registering 48 cuda graph addresses
[2025-09-13 06:53:16 TP5] Registering 48 cuda graph addresses
[2025-09-13 06:53:16 TP6] Registering 48 cuda graph addresses
[2025-09-13 06:53:16 TP7] Registering 48 cuda graph addresses
[2025-09-13 06:53:16 TP7] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.37 GB. avail mem=14.74 GB.
[2025-09-13 06:53:16 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.74 GB
[2025-09-13 06:53:16 TP2] Capture draft cuda graph end. Time elapsed: 6.28 s. mem usage=0.37 GB. avail mem=14.50 GB.
[2025-09-13 06:53:16 TP5] Capture draft cuda graph end. Time elapsed: 6.28 s. mem usage=0.37 GB. avail mem=14.50 GB.
[2025-09-13 06:53:16 TP0] Capture draft cuda graph end. Time elapsed: 6.28 s. mem usage=0.37 GB. avail mem=14.55 GB.
[2025-09-13 06:53:16 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.55 GB
[2025-09-13 06:53:16 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 06:53:16 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 06:53:16 TP4] Capture draft cuda graph end. Time elapsed: 6.28 s. mem usage=0.37 GB. avail mem=14.50 GB.
[2025-09-13 06:53:16 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 06:53:16 TP1] Capture draft cuda graph end. Time elapsed: 6.23 s. mem usage=0.37 GB. avail mem=14.50 GB.
[2025-09-13 06:53:16 TP3] Capture draft cuda graph end. Time elapsed: 6.23 s. mem usage=0.37 GB. avail mem=14.50 GB.
[2025-09-13 06:53:16 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 06:53:16 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 06:53:16 TP6] Capture draft cuda graph end. Time elapsed: 6.28 s. mem usage=0.37 GB. avail mem=14.50 GB.
[2025-09-13 06:53:16 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
Capturing batches (bs=1 avail_mem=14.36 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 37.13it/s]
[2025-09-13 06:53:17 TP6] Registering 24 cuda graph addresses
[2025-09-13 06:53:17 TP3] Registering 24 cuda graph addresses
[2025-09-13 06:53:17 TP2] Registering 24 cuda graph addresses
[2025-09-13 06:53:17 TP7] Registering 24 cuda graph addresses
[2025-09-13 06:53:17 TP4] Registering 24 cuda graph addresses
[2025-09-13 06:53:17 TP1] Registering 24 cuda graph addresses
[2025-09-13 06:53:17 TP0] Registering 24 cuda graph addresses
[2025-09-13 06:53:17 TP5] Registering 24 cuda graph addresses
[2025-09-13 06:53:17 TP5] Capture draft extend cuda graph end. Time elapsed: 0.96 s. mem usage=0.19 GB. avail mem=14.31 GB.
[2025-09-13 06:53:17 TP7] Capture draft extend cuda graph end. Time elapsed: 0.96 s. mem usage=0.19 GB. avail mem=14.55 GB.
[2025-09-13 06:53:17 TP4] Capture draft extend cuda graph end. Time elapsed: 0.96 s. mem usage=0.19 GB. avail mem=14.31 GB.
[2025-09-13 06:53:17 TP0] Capture draft extend cuda graph end. Time elapsed: 0.96 s. mem usage=0.19 GB. avail mem=14.36 GB.
[2025-09-13 06:53:17 TP0] max_total_num_tokens=620249, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.36 GB
[2025-09-13 06:53:17 TP2] Capture draft extend cuda graph end. Time elapsed: 0.96 s. mem usage=0.19 GB. avail mem=14.31 GB.
[2025-09-13 06:53:17 TP6] Capture draft extend cuda graph end. Time elapsed: 0.96 s. mem usage=0.19 GB. avail mem=14.31 GB.
[2025-09-13 06:53:17 TP1] Capture draft extend cuda graph end. Time elapsed: 0.96 s. mem usage=0.19 GB. avail mem=14.31 GB.
[2025-09-13 06:53:17 TP3] Capture draft extend cuda graph end. Time elapsed: 0.96 s. mem usage=0.19 GB. avail mem=14.31 GB.
[2025-09-13 06:53:18] INFO:     Started server process [175654]
[2025-09-13 06:53:18] INFO:     Waiting for application startup.
[2025-09-13 06:53:18] INFO:     Application startup complete.
[2025-09-13 06:53:18] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 06:53:19] INFO:     127.0.0.1:58796 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 06:53:19] INFO:     127.0.0.1:58800 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 06:53:19 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:53:19 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:53:19 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27471.88it/s]
[2025-09-13 06:53:21] INFO:     127.0.0.1:58814 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:21] The server is fired up and ready to roll!
[2025-09-13 06:53:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:53:30] INFO:     127.0.0.1:57960 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:53:30] INFO:     127.0.0.1:57974 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:30 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 06:53:31] INFO:     127.0.0.1:57990 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:31] INFO:     127.0.0.1:58002 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:31 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:53:31] INFO:     127.0.0.1:58008 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:31] INFO:     127.0.0.1:58020 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:31] INFO:     127.0.0.1:58026 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:31] INFO:     127.0.0.1:58040 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:31] INFO:     127.0.0.1:58048 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:31] INFO:     127.0.0.1:58054 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:32 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 06:53:32 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:53:32 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:53:32 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:53:32 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:53:32 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:53:32 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:53:32 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:53:32 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:53:32 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 06:53:33 TP0] Decode batch. #running-req: 8, #token: 14628, token usage: 0.02, accept len: 3.23, cuda graph: True, gen throughput (token/s): 46.53, #queue-req: 0, 
[2025-09-13 06:53:35 TP0] Decode batch. #running-req: 8, #token: 15761, token usage: 0.03, accept len: 3.54, cuda graph: True, gen throughput (token/s): 834.26, #queue-req: 0, 
[2025-09-13 06:53:36 TP0] Decode batch. #running-req: 8, #token: 16901, token usage: 0.03, accept len: 3.56, cuda graph: True, gen throughput (token/s): 831.67, #queue-req: 0, 
 62%|█████████████████████████████████████████████████████████████████████████████████▉                                                 | 5/8 [00:06<00:02,  1.31it/s][2025-09-13 06:53:37 TP0] Decode batch. #running-req: 3, #token: 10586, token usage: 0.02, accept len: 3.59, cuda graph: True, gen throughput (token/s): 643.03, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.19it/s]
[2025-09-13 06:53:38] INFO:     127.0.0.1:39612 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.74      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4061      
Request throughput (req/s):              1.19      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         608.11    
Total token throughput (tok/s):          608.11    
Concurrency:                             7.08      
Accept length:                           3.50      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5964.94   
Median E2E Latency (ms):                 5897.58   
---------------Time to First Token----------------
Mean TTFT (ms):                          607.08    
Median TTFT (ms):                        716.91    
P99 TTFT (ms):                           717.35    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.49     
Median ITL (ms):                         8.55      
P95 ITL (ms):                            17.08     
P99 ITL (ms):                            58.43     
Max ITL (ms):                            208.34    
==================================================
[2025-09-13 06:53:38] INFO:     127.0.0.1:39618 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:53:38] INFO:     127.0.0.1:39620 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 06:53:39] INFO:     127.0.0.1:39634 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:39] INFO:     127.0.0.1:39650 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:53:39] INFO:     127.0.0.1:39666 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:39] INFO:     127.0.0.1:39668 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:39] INFO:     127.0.0.1:39682 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:39] INFO:     127.0.0.1:39684 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:39] INFO:     127.0.0.1:39690 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:39] INFO:     127.0.0.1:39702 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:40 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 06:53:40 TP0] Decode batch. #running-req: 8, #token: 14142, token usage: 0.02, accept len: 3.19, cuda graph: True, gen throughput (token/s): 133.68, #queue-req: 0, 
[2025-09-13 06:53:41 TP0] Decode batch. #running-req: 8, #token: 15248, token usage: 0.02, accept len: 3.46, cuda graph: True, gen throughput (token/s): 818.21, #queue-req: 0, 
[2025-09-13 06:53:43 TP0] Decode batch. #running-req: 8, #token: 16383, token usage: 0.03, accept len: 3.55, cuda graph: True, gen throughput (token/s): 824.06, #queue-req: 0, 
[2025-09-13 06:53:44 TP0] Decode batch. #running-req: 8, #token: 17528, token usage: 0.03, accept len: 3.58, cuda graph: True, gen throughput (token/s): 830.02, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:13,  4.93s/it][2025-09-13 06:53:44] INFO:     127.0.0.1:39704 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:44 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:53:44] INFO:     127.0.0.1:39714 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:19,  1.51s/it][2025-09-13 06:53:45] INFO:     127.0.0.1:39718 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:45 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:12,  1.08s/it][2025-09-13 06:53:45] INFO:     127.0.0.1:39732 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:45 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:06<00:08,  1.28it/s][2025-09-13 06:53:45] INFO:     127.0.0.1:39746 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:45 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:06<00:06,  1.55it/s][2025-09-13 06:53:46] INFO:     127.0.0.1:39750 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:46 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:04,  1.98it/s][2025-09-13 06:53:46] INFO:     127.0.0.1:39752 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:53:47 TP0] Decode batch. #running-req: 8, #token: 10545, token usage: 0.02, accept len: 3.43, cuda graph: True, gen throughput (token/s): 434.80, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:07<00:04,  1.70it/s][2025-09-13 06:53:47] INFO:     127.0.0.1:39754 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:53:47 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:53:48 TP0] Decode batch. #running-req: 8, #token: 15110, token usage: 0.02, accept len: 3.27, cuda graph: True, gen throughput (token/s): 653.40, #queue-req: 0, 
[2025-09-13 06:53:50 TP0] Decode batch. #running-req: 8, #token: 16289, token usage: 0.03, accept len: 3.68, cuda graph: True, gen throughput (token/s): 853.15, #queue-req: 0, 
 69%|████████████████████████████████████████████████████████████████████████████████████████▋                                        | 11/16 [00:11<00:04,  1.13it/s][2025-09-13 06:53:51 TP0] Decode batch. #running-req: 4, #token: 12052, token usage: 0.02, accept len: 3.72, cuda graph: True, gen throughput (token/s): 802.11, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:12<00:00,  1.31it/s]
[2025-09-13 06:53:52] INFO:     127.0.0.1:52596 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  12.20     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8100      
Request throughput (req/s):              1.31      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         671.73    
Total token throughput (tok/s):          671.73    
Concurrency:                             7.63      
Accept length:                           3.50      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5812.57   
Median E2E Latency (ms):                 5762.57   
---------------Time to First Token----------------
Mean TTFT (ms):                          287.09    
Median TTFT (ms):                        326.68    
P99 TTFT (ms):                           479.78    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.81     
Median ITL (ms):                         8.60      
P95 ITL (ms):                            17.31     
P99 ITL (ms):                            55.23     
Max ITL (ms):                            166.14    
==================================================
[2025-09-13 06:53:52] INFO:     127.0.0.1:52608 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=9: batch_size=8, steps=3, topk=4, num_draft_tokens=12, speed=102.44 token/s, step_time=34.21 ms
Start i=10: batch_size=8, steps=4, topk=1, num_draft_tokens=4
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 4 --speculative-eagle-topk 1 --speculative-num-draft-tokens 4 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:54:02.977000 182381 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:54:02.977000 182381 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
WARNING:sglang.srt.server_args:speculative_num_draft_tokens is adjusted to speculative_num_steps + 1 when speculative_eagle_topk == 1
[2025-09-13 06:54:03] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=645430470, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=4, speculative_eagle_topk=1, speculative_num_draft_tokens=5, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:54:03] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:54:12.035000 182603 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:54:12.035000 182603 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:54:12.214000 182599 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:54:12.214000 182599 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:54:12.316000 182601 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:54:12.316000 182601 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:54:12.467000 182604 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:54:12.467000 182604 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:54:12.487000 182597 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:54:12.487000 182597 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:54:12.590000 182598 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:54:12.590000 182598 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:54:12.683000 182602 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:54:12.683000 182602 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:54:12.694000 182600 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:54:12.694000 182600 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:54:12.748000 182605 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:54:12.748000 182605 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:54:13 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 06:54:13 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:54:13 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:54:14 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:54:17 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 06:54:19 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 06:54:19 TP0] Detected fp8 checkpoint.
[2025-09-13 06:54:19 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 28/1024 [00:00<00:04, 243.30it/s]
Loading safetensors checkpoint shards:   5% Completed | 53/1024 [00:00<00:08, 113.33it/s]
Loading safetensors checkpoint shards:   7% Completed | 68/1024 [00:00<00:11, 81.29it/s]
Loading safetensors checkpoint shards:   8% Completed | 79/1024 [00:00<00:13, 69.33it/s]
Loading safetensors checkpoint shards:   9% Completed | 88/1024 [00:01<00:14, 65.93it/s]
Loading safetensors checkpoint shards:   9% Completed | 96/1024 [00:01<00:28, 32.82it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:01<00:27, 33.49it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:02<00:25, 35.80it/s]
Loading safetensors checkpoint shards:  11% Completed | 113/1024 [00:02<00:24, 37.85it/s]
Loading safetensors checkpoint shards:  12% Completed | 120/1024 [00:02<00:21, 42.22it/s]
Loading safetensors checkpoint shards:  12% Completed | 126/1024 [00:02<00:19, 45.11it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:02<00:20, 44.36it/s]
Loading safetensors checkpoint shards:  13% Completed | 137/1024 [00:02<00:19, 44.87it/s]
Loading safetensors checkpoint shards:  14% Completed | 143/1024 [00:02<00:18, 46.68it/s]
Loading safetensors checkpoint shards:  15% Completed | 150/1024 [00:02<00:17, 51.11it/s]
Loading safetensors checkpoint shards:  15% Completed | 156/1024 [00:02<00:16, 53.35it/s]
Loading safetensors checkpoint shards:  16% Completed | 162/1024 [00:03<00:15, 54.75it/s]
Loading safetensors checkpoint shards:  16% Completed | 168/1024 [00:03<00:16, 51.09it/s]
Loading safetensors checkpoint shards:  17% Completed | 175/1024 [00:03<00:15, 55.18it/s]
Loading safetensors checkpoint shards:  18% Completed | 181/1024 [00:03<00:15, 53.97it/s]
Loading safetensors checkpoint shards:  19% Completed | 190/1024 [00:03<00:13, 60.82it/s]
Loading safetensors checkpoint shards:  19% Completed | 198/1024 [00:03<00:13, 63.07it/s]
Loading safetensors checkpoint shards:  20% Completed | 206/1024 [00:03<00:12, 65.25it/s]
Loading safetensors checkpoint shards:  21% Completed | 213/1024 [00:03<00:13, 59.56it/s]
Loading safetensors checkpoint shards:  21% Completed | 220/1024 [00:04<00:13, 57.99it/s]
Loading safetensors checkpoint shards:  22% Completed | 226/1024 [00:04<00:14, 55.42it/s]
Loading safetensors checkpoint shards:  23% Completed | 232/1024 [00:04<00:31, 25.27it/s]
Loading safetensors checkpoint shards:  23% Completed | 237/1024 [00:04<00:27, 28.42it/s]
Loading safetensors checkpoint shards:  24% Completed | 242/1024 [00:04<00:24, 31.37it/s]
Loading safetensors checkpoint shards:  24% Completed | 247/1024 [00:05<00:22, 34.15it/s]
Loading safetensors checkpoint shards:  25% Completed | 253/1024 [00:05<00:20, 38.28it/s]
Loading safetensors checkpoint shards:  25% Completed | 258/1024 [00:05<00:18, 40.51it/s]
Loading safetensors checkpoint shards:  26% Completed | 266/1024 [00:05<00:15, 47.65it/s]
Loading safetensors checkpoint shards:  27% Completed | 272/1024 [00:05<00:15, 48.78it/s]
Loading safetensors checkpoint shards:  27% Completed | 278/1024 [00:05<00:14, 49.93it/s]
Loading safetensors checkpoint shards:  28% Completed | 286/1024 [00:05<00:13, 54.53it/s]
Loading safetensors checkpoint shards:  29% Completed | 292/1024 [00:05<00:13, 54.25it/s]
Loading safetensors checkpoint shards:  29% Completed | 299/1024 [00:06<00:12, 56.70it/s]
Loading safetensors checkpoint shards:  30% Completed | 305/1024 [00:06<00:13, 54.68it/s]
Loading safetensors checkpoint shards:  30% Completed | 311/1024 [00:06<00:12, 55.14it/s]
Loading safetensors checkpoint shards:  31% Completed | 318/1024 [00:06<00:12, 57.42it/s]
Loading safetensors checkpoint shards:  32% Completed | 324/1024 [00:06<00:12, 55.69it/s]
Loading safetensors checkpoint shards:  32% Completed | 331/1024 [00:06<00:12, 57.61it/s]
Loading safetensors checkpoint shards:  33% Completed | 337/1024 [00:06<00:12, 55.43it/s]
Loading safetensors checkpoint shards:  33% Completed | 343/1024 [00:06<00:14, 47.78it/s]
Loading safetensors checkpoint shards:  34% Completed | 348/1024 [00:07<00:15, 43.11it/s]
Loading safetensors checkpoint shards:  34% Completed | 353/1024 [00:07<00:16, 39.96it/s]
Loading safetensors checkpoint shards:  35% Completed | 358/1024 [00:07<00:17, 38.29it/s]
Loading safetensors checkpoint shards:  35% Completed | 363/1024 [00:07<00:16, 39.37it/s]
Loading safetensors checkpoint shards:  36% Completed | 368/1024 [00:07<00:17, 37.55it/s]
Loading safetensors checkpoint shards:  36% Completed | 373/1024 [00:07<00:16, 39.24it/s]
Loading safetensors checkpoint shards:  37% Completed | 378/1024 [00:07<00:15, 41.58it/s]
Loading safetensors checkpoint shards:  38% Completed | 384/1024 [00:07<00:14, 43.35it/s]
Loading safetensors checkpoint shards:  38% Completed | 389/1024 [00:08<00:14, 43.69it/s]
Loading safetensors checkpoint shards:  38% Completed | 394/1024 [00:08<00:30, 20.76it/s]
Loading safetensors checkpoint shards:  39% Completed | 399/1024 [00:08<00:25, 24.68it/s]
Loading safetensors checkpoint shards:  40% Completed | 405/1024 [00:08<00:20, 30.36it/s]
Loading safetensors checkpoint shards:  40% Completed | 410/1024 [00:08<00:19, 32.16it/s]
Loading safetensors checkpoint shards:  41% Completed | 415/1024 [00:09<00:17, 35.30it/s]
Loading safetensors checkpoint shards:  41% Completed | 420/1024 [00:09<00:16, 37.72it/s]
Loading safetensors checkpoint shards:  42% Completed | 425/1024 [00:09<00:14, 40.07it/s]
Loading safetensors checkpoint shards:  42% Completed | 431/1024 [00:09<00:14, 42.25it/s]
Loading safetensors checkpoint shards:  43% Completed | 436/1024 [00:09<00:13, 42.26it/s]
Loading safetensors checkpoint shards:  43% Completed | 442/1024 [00:09<00:13, 44.20it/s]
Loading safetensors checkpoint shards:  44% Completed | 447/1024 [00:09<00:13, 42.66it/s]
Loading safetensors checkpoint shards:  44% Completed | 452/1024 [00:09<00:13, 42.93it/s]
Loading safetensors checkpoint shards:  45% Completed | 458/1024 [00:09<00:12, 45.43it/s]
Loading safetensors checkpoint shards:  45% Completed | 465/1024 [00:10<00:11, 50.17it/s]
Loading safetensors checkpoint shards:  46% Completed | 472/1024 [00:10<00:10, 54.82it/s]
Loading safetensors checkpoint shards:  47% Completed | 478/1024 [00:10<00:10, 51.83it/s]
Loading safetensors checkpoint shards:  47% Completed | 484/1024 [00:10<00:10, 50.51it/s]
Loading safetensors checkpoint shards:  48% Completed | 490/1024 [00:10<00:10, 52.96it/s]
Loading safetensors checkpoint shards:  49% Completed | 497/1024 [00:10<00:09, 57.07it/s]
Loading safetensors checkpoint shards:  49% Completed | 503/1024 [00:10<00:09, 57.36it/s]
Loading safetensors checkpoint shards:  50% Completed | 509/1024 [00:10<00:09, 56.07it/s]
Loading safetensors checkpoint shards:  50% Completed | 515/1024 [00:10<00:09, 52.67it/s]
Loading safetensors checkpoint shards:  51% Completed | 521/1024 [00:11<00:10, 46.13it/s]
Loading safetensors checkpoint shards:  51% Completed | 526/1024 [00:11<00:10, 46.55it/s]
Loading safetensors checkpoint shards:  52% Completed | 531/1024 [00:11<00:10, 44.82it/s]
Loading safetensors checkpoint shards:  52% Completed | 536/1024 [00:11<00:11, 43.47it/s]
Loading safetensors checkpoint shards:  53% Completed | 542/1024 [00:11<00:10, 46.11it/s]
Loading safetensors checkpoint shards:  53% Completed | 547/1024 [00:11<00:10, 46.87it/s]
Loading safetensors checkpoint shards:  54% Completed | 552/1024 [00:11<00:10, 46.29it/s]
Loading safetensors checkpoint shards:  54% Completed | 557/1024 [00:11<00:10, 46.07it/s]
Loading safetensors checkpoint shards:  55% Completed | 564/1024 [00:12<00:09, 50.70it/s]
Loading safetensors checkpoint shards:  56% Completed | 570/1024 [00:12<00:08, 51.87it/s]
Loading safetensors checkpoint shards:  56% Completed | 576/1024 [00:12<00:09, 45.73it/s]
Loading safetensors checkpoint shards:  57% Completed | 581/1024 [00:12<00:09, 46.72it/s]
Loading safetensors checkpoint shards:  57% Completed | 586/1024 [00:13<00:21, 20.01it/s]
Loading safetensors checkpoint shards:  58% Completed | 590/1024 [00:13<00:20, 21.70it/s]
Loading safetensors checkpoint shards:  58% Completed | 595/1024 [00:13<00:17, 25.23it/s]
Loading safetensors checkpoint shards:  59% Completed | 601/1024 [00:13<00:13, 30.42it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:13<00:12, 32.84it/s]
Loading safetensors checkpoint shards:  60% Completed | 611/1024 [00:13<00:12, 33.97it/s]
Loading safetensors checkpoint shards:  60% Completed | 617/1024 [00:13<00:10, 39.50it/s]
Loading safetensors checkpoint shards:  61% Completed | 622/1024 [00:13<00:10, 39.95it/s]
Loading safetensors checkpoint shards:  61% Completed | 627/1024 [00:14<00:10, 38.03it/s]
Loading safetensors checkpoint shards:  62% Completed | 632/1024 [00:14<00:09, 39.53it/s]
Loading safetensors checkpoint shards:  62% Completed | 637/1024 [00:14<00:10, 38.62it/s]
Loading safetensors checkpoint shards:  63% Completed | 642/1024 [00:14<00:10, 36.92it/s]
Loading safetensors checkpoint shards:  63% Completed | 646/1024 [00:14<00:10, 36.40it/s]
Loading safetensors checkpoint shards:  63% Completed | 650/1024 [00:14<00:11, 33.04it/s]
Loading safetensors checkpoint shards:  64% Completed | 654/1024 [00:14<00:11, 31.06it/s]
Loading safetensors checkpoint shards:  64% Completed | 659/1024 [00:15<00:11, 32.76it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:15<00:10, 34.15it/s]
Loading safetensors checkpoint shards:  65% Completed | 667/1024 [00:15<00:10, 33.88it/s]
Loading safetensors checkpoint shards:  66% Completed | 672/1024 [00:15<00:10, 35.10it/s]
Loading safetensors checkpoint shards:  66% Completed | 677/1024 [00:15<00:09, 37.95it/s]
Loading safetensors checkpoint shards:  67% Completed | 682/1024 [00:15<00:08, 39.51it/s]
Loading safetensors checkpoint shards:  67% Completed | 688/1024 [00:15<00:07, 43.65it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:15<00:07, 46.48it/s]
Loading safetensors checkpoint shards:  68% Completed | 699/1024 [00:15<00:06, 46.95it/s]
Loading safetensors checkpoint shards:  69% Completed | 704/1024 [00:16<00:07, 44.66it/s]
Loading safetensors checkpoint shards:  69% Completed | 709/1024 [00:16<00:07, 41.93it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:16<00:07, 39.52it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:16<00:07, 39.24it/s]
Loading safetensors checkpoint shards:  71% Completed | 724/1024 [00:16<00:07, 40.09it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:16<00:07, 39.52it/s]
Loading safetensors checkpoint shards:  72% Completed | 735/1024 [00:16<00:06, 42.45it/s]
Loading safetensors checkpoint shards:  72% Completed | 742/1024 [00:16<00:05, 47.74it/s]
Loading safetensors checkpoint shards:  73% Completed | 747/1024 [00:17<00:05, 46.34it/s]
Loading safetensors checkpoint shards:  73% Completed | 752/1024 [00:17<00:05, 46.18it/s]
Loading safetensors checkpoint shards:  74% Completed | 758/1024 [00:17<00:05, 47.85it/s]
Loading safetensors checkpoint shards:  75% Completed | 764/1024 [00:17<00:05, 50.79it/s]
Loading safetensors checkpoint shards:  75% Completed | 770/1024 [00:17<00:04, 52.68it/s]
Loading safetensors checkpoint shards:  76% Completed | 777/1024 [00:17<00:04, 55.81it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:17<00:04, 54.90it/s]
Loading safetensors checkpoint shards:  77% Completed | 789/1024 [00:17<00:04, 48.74it/s]
Loading safetensors checkpoint shards:  78% Completed | 795/1024 [00:18<00:12, 18.80it/s]
Loading safetensors checkpoint shards:  78% Completed | 799/1024 [00:18<00:10, 20.62it/s]
Loading safetensors checkpoint shards:  79% Completed | 804/1024 [00:18<00:09, 23.34it/s]
Loading safetensors checkpoint shards:  79% Completed | 808/1024 [00:19<00:08, 24.67it/s]
Loading safetensors checkpoint shards:  79% Completed | 812/1024 [00:19<00:08, 25.66it/s]
Loading safetensors checkpoint shards:  80% Completed | 816/1024 [00:19<00:07, 27.43it/s]
Loading safetensors checkpoint shards:  80% Completed | 820/1024 [00:19<00:07, 27.15it/s]
Loading safetensors checkpoint shards:  80% Completed | 824/1024 [00:19<00:06, 29.69it/s]
Loading safetensors checkpoint shards:  81% Completed | 828/1024 [00:19<00:06, 30.37it/s]
Loading safetensors checkpoint shards:  81% Completed | 832/1024 [00:19<00:06, 28.35it/s]
Loading safetensors checkpoint shards:  82% Completed | 836/1024 [00:20<00:06, 28.87it/s]
Loading safetensors checkpoint shards:  82% Completed | 840/1024 [00:20<00:06, 27.66it/s]
Loading safetensors checkpoint shards:  82% Completed | 843/1024 [00:20<00:06, 28.02it/s]
Loading safetensors checkpoint shards:  83% Completed | 846/1024 [00:20<00:06, 27.64it/s]
Loading safetensors checkpoint shards:  83% Completed | 849/1024 [00:20<00:06, 26.26it/s]
Loading safetensors checkpoint shards:  83% Completed | 852/1024 [00:20<00:06, 26.19it/s]
Loading safetensors checkpoint shards:  83% Completed | 855/1024 [00:20<00:06, 27.12it/s]
Loading safetensors checkpoint shards:  84% Completed | 859/1024 [00:20<00:05, 29.46it/s]
Loading safetensors checkpoint shards:  84% Completed | 862/1024 [00:20<00:05, 29.20it/s]
Loading safetensors checkpoint shards:  85% Completed | 866/1024 [00:21<00:05, 30.95it/s]
Loading safetensors checkpoint shards:  85% Completed | 870/1024 [00:21<00:05, 29.48it/s]
Loading safetensors checkpoint shards:  85% Completed | 873/1024 [00:21<00:05, 29.36it/s]
Loading safetensors checkpoint shards:  86% Completed | 877/1024 [00:21<00:04, 29.78it/s]
Loading safetensors checkpoint shards:  86% Completed | 881/1024 [00:21<00:04, 30.18it/s]
Loading safetensors checkpoint shards:  86% Completed | 885/1024 [00:21<00:04, 30.67it/s]
Loading safetensors checkpoint shards:  87% Completed | 889/1024 [00:21<00:04, 31.30it/s]
Loading safetensors checkpoint shards:  87% Completed | 893/1024 [00:21<00:04, 30.28it/s]
Loading safetensors checkpoint shards:  88% Completed | 897/1024 [00:22<00:04, 31.29it/s]
Loading safetensors checkpoint shards:  88% Completed | 901/1024 [00:22<00:03, 32.84it/s]
Loading safetensors checkpoint shards:  88% Completed | 905/1024 [00:22<00:03, 34.40it/s]
Loading safetensors checkpoint shards:  89% Completed | 910/1024 [00:22<00:03, 36.02it/s]
Loading safetensors checkpoint shards:  89% Completed | 915/1024 [00:22<00:02, 37.65it/s]
Loading safetensors checkpoint shards:  90% Completed | 919/1024 [00:22<00:02, 36.87it/s]
Loading safetensors checkpoint shards:  90% Completed | 923/1024 [00:22<00:02, 35.28it/s]
Loading safetensors checkpoint shards:  91% Completed | 927/1024 [00:22<00:02, 35.66it/s]
Loading safetensors checkpoint shards:  91% Completed | 931/1024 [00:23<00:02, 33.41it/s]
Loading safetensors checkpoint shards:  91% Completed | 935/1024 [00:23<00:02, 33.59it/s]
Loading safetensors checkpoint shards:  92% Completed | 939/1024 [00:23<00:02, 35.21it/s]
Loading safetensors checkpoint shards:  92% Completed | 943/1024 [00:23<00:02, 34.67it/s]
Loading safetensors checkpoint shards:  92% Completed | 947/1024 [00:23<00:02, 34.19it/s]
Loading safetensors checkpoint shards:  93% Completed | 951/1024 [00:23<00:02, 35.35it/s]
Loading safetensors checkpoint shards:  93% Completed | 955/1024 [00:23<00:01, 34.56it/s]
Loading safetensors checkpoint shards:  94% Completed | 959/1024 [00:23<00:01, 34.87it/s]
Loading safetensors checkpoint shards:  94% Completed | 963/1024 [00:23<00:01, 34.53it/s]
Loading safetensors checkpoint shards:  94% Completed | 967/1024 [00:24<00:01, 33.83it/s]
Loading safetensors checkpoint shards:  95% Completed | 971/1024 [00:24<00:01, 33.00it/s]
Loading safetensors checkpoint shards:  95% Completed | 975/1024 [00:24<00:01, 32.21it/s]
Loading safetensors checkpoint shards:  96% Completed | 979/1024 [00:24<00:01, 31.66it/s]
Loading safetensors checkpoint shards:  96% Completed | 985/1024 [00:24<00:01, 37.86it/s]
Loading safetensors checkpoint shards:  97% Completed | 992/1024 [00:24<00:00, 45.15it/s]
Loading safetensors checkpoint shards:  98% Completed | 1000/1024 [00:24<00:00, 54.15it/s]
Loading safetensors checkpoint shards:  99% Completed | 1015/1024 [00:24<00:00, 80.11it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:24<00:00, 41.14it/s]

[2025-09-13 06:54:45 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 06:54:47 TP2] KV Cache is allocated. #tokens: 620129, KV size: 40.58 GB
[2025-09-13 06:54:47 TP4] KV Cache is allocated. #tokens: 620129, KV size: 40.58 GB
[2025-09-13 06:54:47 TP3] KV Cache is allocated. #tokens: 620129, KV size: 40.58 GB
[2025-09-13 06:54:47 TP6] KV Cache is allocated. #tokens: 620129, KV size: 40.58 GB
[2025-09-13 06:54:47 TP5] KV Cache is allocated. #tokens: 620129, KV size: 40.58 GB
[2025-09-13 06:54:47 TP1] KV Cache is allocated. #tokens: 620129, KV size: 40.58 GB
[2025-09-13 06:54:47 TP7] KV Cache is allocated. #tokens: 620129, KV size: 40.58 GB
[2025-09-13 06:54:47 TP0] KV Cache is allocated. #tokens: 620129, KV size: 40.58 GB
[2025-09-13 06:54:47 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 06:54:47 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 06:54:47 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.53 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 06:54:48 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:54:48 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 06:54:48 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:54:48 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:54:48 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:54:48 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:54:48 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:54:48 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:54:49 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25929.22it/s]
[2025-09-13 06:54:49 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:54:49 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27260.77it/s]
[2025-09-13 06:54:49 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:54:49 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28568.11it/s]
[2025-09-13 06:54:50 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:54:50 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28173.53it/s]
[2025-09-13 06:54:51 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:54:51 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28886.64it/s]
[2025-09-13 06:54:51 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.28 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.18it/s]
[2025-09-13 06:54:54 TP0] Registering 984 cuda graph addresses
[2025-09-13 06:54:54 TP1] Registering 984 cuda graph addresses
[2025-09-13 06:54:54 TP4] Registering 984 cuda graph addresses
[2025-09-13 06:54:54 TP7] Registering 984 cuda graph addresses
[2025-09-13 06:54:54 TP5] Registering 984 cuda graph addresses
[2025-09-13 06:54:54 TP6] Registering 984 cuda graph addresses
[2025-09-13 06:54:54 TP2] Registering 984 cuda graph addresses
[2025-09-13 06:54:54 TP3] Registering 984 cuda graph addresses
[2025-09-13 06:54:54 TP0] Capture cuda graph end. Time elapsed: 7.47 s. mem usage=0.31 GB. avail mem=17.26 GB.
[2025-09-13 06:54:55 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 06:54:55 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:54:55 TP0] Init torch distributed begin.
[2025-09-13 06:54:55 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 06:54:55 TP0] Load weight begin. avail mem=17.26 GB
[2025-09-13 06:54:55 TP0] Detected fp8 checkpoint.
[2025-09-13 06:54:55 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 170.91it/s]
Loading safetensors checkpoint shards:   4% Completed | 45/1024 [00:00<00:04, 226.70it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:00<00:02, 402.57it/s]
Loading safetensors checkpoint shards:  17% Completed | 169/1024 [00:00<00:01, 485.71it/s]
Loading safetensors checkpoint shards:  23% Completed | 231/1024 [00:00<00:01, 532.18it/s]
Loading safetensors checkpoint shards:  29% Completed | 294/1024 [00:00<00:01, 563.00it/s]
Loading safetensors checkpoint shards:  35% Completed | 356/1024 [00:00<00:01, 578.33it/s]
Loading safetensors checkpoint shards:  41% Completed | 419/1024 [00:00<00:01, 592.48it/s]
Loading safetensors checkpoint shards:  47% Completed | 481/1024 [00:00<00:00, 598.49it/s]
Loading safetensors checkpoint shards:  53% Completed | 544/1024 [00:01<00:00, 605.07it/s]
Loading safetensors checkpoint shards:  59% Completed | 607/1024 [00:01<00:00, 612.21it/s]
Loading safetensors checkpoint shards:  65% Completed | 669/1024 [00:01<00:00, 604.22it/s]
Loading safetensors checkpoint shards:  71% Completed | 730/1024 [00:01<00:00, 598.54it/s]
Loading safetensors checkpoint shards:  77% Completed | 790/1024 [00:01<00:00, 592.51it/s]
Loading safetensors checkpoint shards:  83% Completed | 850/1024 [00:01<00:00, 589.41it/s]
Loading safetensors checkpoint shards:  89% Completed | 909/1024 [00:01<00:00, 584.86it/s]
Loading safetensors checkpoint shards:  95% Completed | 968/1024 [00:01<00:00, 584.77it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 507.73it/s]

[2025-09-13 06:54:57 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.28 GB, mem usage=1.98 GB.
[2025-09-13 06:54:57 TP0] KV Cache is allocated. #tokens: 620129, KV size: 0.67 GB
[2025-09-13 06:54:57 TP5] KV Cache is allocated. #tokens: 620129, KV size: 0.67 GB
[2025-09-13 06:54:57 TP6] KV Cache is allocated. #tokens: 620129, KV size: 0.67 GB
[2025-09-13 06:54:57 TP7] KV Cache is allocated. #tokens: 620129, KV size: 0.67 GB
[2025-09-13 06:54:57 TP0] Memory pool end. avail mem=14.61 GB
[2025-09-13 06:54:57 TP4] KV Cache is allocated. #tokens: 620129, KV size: 0.67 GB
[2025-09-13 06:54:57 TP1] KV Cache is allocated. #tokens: 620129, KV size: 0.67 GB
[2025-09-13 06:54:57 TP2] KV Cache is allocated. #tokens: 620129, KV size: 0.67 GB
[2025-09-13 06:54:57 TP3] KV Cache is allocated. #tokens: 620129, KV size: 0.67 GB
[2025-09-13 06:54:57 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.00 GB
[2025-09-13 06:54:57 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.04 GB
[2025-09-13 06:54:57 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.00 GB
[2025-09-13 06:54:57 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.00 GB
[2025-09-13 06:54:57 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.00 GB
[2025-09-13 06:54:57 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.00 GB
[2025-09-13 06:54:57 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.23 GB
[2025-09-13 06:54:57 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.00 GB
Capturing batches (bs=1 avail_mem=14.83 GB):  62%|█████████████████████████████████████████████████████▊                                | 5/8 [00:01<00:00,  4.20it/s][2025-09-13 06:55:01 TP3] Registering 72 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.83 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:02<00:00,  3.10it/s]
[2025-09-13 06:55:01 TP2] Registering 72 cuda graph addresses
[2025-09-13 06:55:01 TP4] Registering 72 cuda graph addresses
[2025-09-13 06:55:01 TP1] Registering 72 cuda graph addresses
[2025-09-13 06:55:01 TP5] Registering 72 cuda graph addresses
[2025-09-13 06:55:01 TP0] Registering 72 cuda graph addresses
[2025-09-13 06:55:01 TP7] Registering 72 cuda graph addresses
[2025-09-13 06:55:01 TP6] Registering 72 cuda graph addresses
[2025-09-13 06:55:01 TP1] Capture draft cuda graph end. Time elapsed: 3.24 s. mem usage=0.21 GB. avail mem=14.79 GB.
[2025-09-13 06:55:01 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 06:55:01 TP7] Capture draft cuda graph end. Time elapsed: 3.24 s. mem usage=0.21 GB. avail mem=15.02 GB.
[2025-09-13 06:55:01 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.02 GB
[2025-09-13 06:55:01 TP3] Capture draft cuda graph end. Time elapsed: 3.24 s. mem usage=0.21 GB. avail mem=14.79 GB.
[2025-09-13 06:55:01 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 06:55:01 TP6] Capture draft cuda graph end. Time elapsed: 3.24 s. mem usage=0.21 GB. avail mem=14.79 GB.
[2025-09-13 06:55:01 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 06:55:01 TP4] Capture draft cuda graph end. Time elapsed: 3.24 s. mem usage=0.21 GB. avail mem=14.79 GB.
[2025-09-13 06:55:01 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 06:55:01 TP5] Capture draft cuda graph end. Time elapsed: 3.24 s. mem usage=0.21 GB. avail mem=14.79 GB.
[2025-09-13 06:55:01 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 06:55:01 TP0] Capture draft cuda graph end. Time elapsed: 3.24 s. mem usage=0.21 GB. avail mem=14.83 GB.
[2025-09-13 06:55:01 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.83 GB
[2025-09-13 06:55:01 TP2] Capture draft cuda graph end. Time elapsed: 3.24 s. mem usage=0.21 GB. avail mem=14.79 GB.
[2025-09-13 06:55:01 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
Capturing batches (bs=1 avail_mem=14.68 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 40.58it/s][2025-09-13 06:55:01 TP2] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.68 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 37.49it/s]
[2025-09-13 06:55:01 TP5] Registering 24 cuda graph addresses
[2025-09-13 06:55:01 TP1] Registering 24 cuda graph addresses
[2025-09-13 06:55:01 TP3] Registering 24 cuda graph addresses
[2025-09-13 06:55:01 TP0] Registering 24 cuda graph addresses
[2025-09-13 06:55:01 TP6] Registering 24 cuda graph addresses
[2025-09-13 06:55:01 TP4] Registering 24 cuda graph addresses
[2025-09-13 06:55:01 TP7] Registering 24 cuda graph addresses
[2025-09-13 06:55:01 TP7] Capture draft extend cuda graph end. Time elapsed: 0.95 s. mem usage=0.15 GB. avail mem=14.87 GB.
[2025-09-13 06:55:01 TP2] Capture draft extend cuda graph end. Time elapsed: 0.95 s. mem usage=0.15 GB. avail mem=14.64 GB.
[2025-09-13 06:55:01 TP4] Capture draft extend cuda graph end. Time elapsed: 0.95 s. mem usage=0.15 GB. avail mem=14.64 GB.
[2025-09-13 06:55:01 TP6] Capture draft extend cuda graph end. Time elapsed: 0.95 s. mem usage=0.15 GB. avail mem=14.64 GB.
[2025-09-13 06:55:01 TP0] Capture draft extend cuda graph end. Time elapsed: 0.95 s. mem usage=0.15 GB. avail mem=14.68 GB.
[2025-09-13 06:55:01 TP1] Capture draft extend cuda graph end. Time elapsed: 0.96 s. mem usage=0.15 GB. avail mem=14.64 GB.
[2025-09-13 06:55:01 TP0] max_total_num_tokens=620129, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.68 GB
[2025-09-13 06:55:01 TP3] Capture draft extend cuda graph end. Time elapsed: 0.95 s. mem usage=0.15 GB. avail mem=14.64 GB.
[2025-09-13 06:55:01 TP5] Capture draft extend cuda graph end. Time elapsed: 0.95 s. mem usage=0.15 GB. avail mem=14.64 GB.
[2025-09-13 06:55:02] INFO:     Started server process [182381]
[2025-09-13 06:55:02] INFO:     Waiting for application startup.
[2025-09-13 06:55:02] INFO:     Application startup complete.
[2025-09-13 06:55:02] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 06:55:03] INFO:     127.0.0.1:39134 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 06:55:03 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:55:03 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:55:03 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27405.71it/s]
[2025-09-13 06:55:05] INFO:     127.0.0.1:39140 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:05] The server is fired up and ready to roll!
[2025-09-13 06:55:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:55:08] INFO:     127.0.0.1:39146 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:55:08] INFO:     127.0.0.1:39970 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:08 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 06:55:10] INFO:     127.0.0.1:39972 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:10] INFO:     127.0.0.1:39988 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:55:10] INFO:     127.0.0.1:39992 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:10] INFO:     127.0.0.1:39994 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:10] INFO:     127.0.0.1:40004 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:10] INFO:     127.0.0.1:40016 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:10] INFO:     127.0.0.1:40020 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:10] INFO:     127.0.0.1:40028 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:10 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 06:55:10 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:55:10 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:55:10 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:55:10 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:55:10 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:55:10 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:55:10 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:55:10 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:55:10 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 06:55:11 TP0] Decode batch. #running-req: 8, #token: 14510, token usage: 0.02, accept len: 2.81, cuda graph: True, gen throughput (token/s): 63.46, #queue-req: 0, 
[2025-09-13 06:55:12 TP0] Decode batch. #running-req: 8, #token: 15569, token usage: 0.03, accept len: 3.31, cuda graph: True, gen throughput (token/s): 920.14, #queue-req: 0, 
[2025-09-13 06:55:14 TP0] Decode batch. #running-req: 8, #token: 16738, token usage: 0.03, accept len: 3.65, cuda graph: True, gen throughput (token/s): 1017.26, #queue-req: 0, 
 38%|█████████████████████████████████████████████████▏                                                                                 | 3/8 [00:04<00:06,  1.28s/it][2025-09-13 06:55:15 TP0] Decode batch. #running-req: 5, #token: 4497, token usage: 0.01, accept len: 3.69, cuda graph: True, gen throughput (token/s): 934.86, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.32it/s]
[2025-09-13 06:55:16] INFO:     127.0.0.1:40040 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.08      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4077      
Request throughput (req/s):              1.32      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         673.99    
Total token throughput (tok/s):          673.99    
Concurrency:                             6.90      
Accept length:                           3.40      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5239.80   
Median E2E Latency (ms):                 5174.32   
---------------Time to First Token----------------
Mean TTFT (ms):                          603.31    
Median TTFT (ms):                        716.54    
P99 TTFT (ms):                           717.02    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.07      
Median ITL (ms):                         5.81      
P95 ITL (ms):                            17.94     
P99 ITL (ms):                            47.02     
Max ITL (ms):                            834.68    
==================================================
[2025-09-13 06:55:16] INFO:     127.0.0.1:40052 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:55:16] INFO:     127.0.0.1:40058 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:55:16 TP0] Decode batch. #running-req: 1, #token: 4681, token usage: 0.01, accept len: 3.36, cuda graph: True, gen throughput (token/s): 186.92, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 06:55:17] INFO:     127.0.0.1:40066 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:17] INFO:     127.0.0.1:40078 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:55:17] INFO:     127.0.0.1:40090 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:17] INFO:     127.0.0.1:40100 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:17] INFO:     127.0.0.1:40116 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:17] INFO:     127.0.0.1:40122 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:17] INFO:     127.0.0.1:40136 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:17] INFO:     127.0.0.1:40140 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:17 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 06:55:18 TP0] Decode batch. #running-req: 8, #token: 14710, token usage: 0.02, accept len: 2.91, cuda graph: True, gen throughput (token/s): 332.32, #queue-req: 0, 
[2025-09-13 06:55:20 TP0] Decode batch. #running-req: 8, #token: 15771, token usage: 0.03, accept len: 3.32, cuda graph: True, gen throughput (token/s): 916.96, #queue-req: 0, 
[2025-09-13 06:55:21 TP0] Decode batch. #running-req: 8, #token: 16971, token usage: 0.03, accept len: 3.75, cuda graph: True, gen throughput (token/s): 1041.67, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:01,  4.13s/it][2025-09-13 06:55:21] INFO:     127.0.0.1:55956 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:21 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:27,  1.93s/it][2025-09-13 06:55:22] INFO:     127.0.0.1:55962 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:04<00:15,  1.17s/it][2025-09-13 06:55:22] INFO:     127.0.0.1:55964 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:22 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.19it/s][2025-09-13 06:55:22] INFO:     127.0.0.1:55976 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:22 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:06,  1.66it/s][2025-09-13 06:55:22] INFO:     127.0.0.1:55982 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:22 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:55:23 TP0] Decode batch. #running-req: 8, #token: 8299, token usage: 0.01, accept len: 3.46, cuda graph: True, gen throughput (token/s): 541.84, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.94it/s][2025-09-13 06:55:23] INFO:     127.0.0.1:55994 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:23 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:04,  1.86it/s][2025-09-13 06:55:23] INFO:     127.0.0.1:56000 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:04,  1.94it/s][2025-09-13 06:55:24] INFO:     127.0.0.1:56006 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:55:24 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:55:24 TP0] Decode batch. #running-req: 8, #token: 14506, token usage: 0.02, accept len: 3.10, cuda graph: True, gen throughput (token/s): 608.49, #queue-req: 0, 
[2025-09-13 06:55:26 TP0] Decode batch. #running-req: 8, #token: 15521, token usage: 0.03, accept len: 3.17, cuda graph: True, gen throughput (token/s): 827.26, #queue-req: 0, 
[2025-09-13 06:55:27 TP0] Decode batch. #running-req: 8, #token: 16653, token usage: 0.03, accept len: 3.54, cuda graph: True, gen throughput (token/s): 979.09, #queue-req: 0, 
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 14/16 [00:10<00:00,  3.01it/s][2025-09-13 06:55:28 TP0] Decode batch. #running-req: 2, #token: 3120, token usage: 0.01, accept len: 3.38, cuda graph: True, gen throughput (token/s): 747.38, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.42it/s]
[2025-09-13 06:55:28] INFO:     127.0.0.1:59842 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.26     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8092      
Request throughput (req/s):              1.42      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         727.38    
Total token throughput (tok/s):          727.38    
Concurrency:                             7.46      
Accept length:                           3.35      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5250.91   
Median E2E Latency (ms):                 5210.57   
---------------Time to First Token----------------
Mean TTFT (ms):                          267.80    
Median TTFT (ms):                        232.27    
P99 TTFT (ms):                           393.03    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.75      
Median ITL (ms):                         5.93      
P95 ITL (ms):                            28.38     
P99 ITL (ms):                            53.22     
Max ITL (ms):                            297.00    
==================================================
[2025-09-13 06:55:28] INFO:     127.0.0.1:59848 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=10: batch_size=8, steps=4, topk=1, num_draft_tokens=4, speed=116.50 token/s, step_time=28.79 ms
Start i=11: batch_size=8, steps=4, topk=2, num_draft_tokens=4
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 4 --speculative-eagle-topk 2 --speculative-num-draft-tokens 4 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:55:39.823000 188665 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:55:39.823000 188665 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 06:55:40] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=538503781, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=4, speculative_eagle_topk=2, speculative_num_draft_tokens=4, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:55:40] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:55:48.993000 188876 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:55:48.993000 188876 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:55:49.336000 188880 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:55:49.336000 188880 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:55:49.344000 188878 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:55:49.344000 188878 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:55:49.347000 188874 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:55:49.347000 188874 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:55:49.396000 188877 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:55:49.396000 188877 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:55:49.397000 188879 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:55:49.397000 188879 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:55:49.404000 188875 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:55:49.404000 188875 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:55:49.430000 188881 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:55:49.430000 188881 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:55:49.467000 188873 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:55:49.467000 188873 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:55:50 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 06:55:50 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:55:50 TP0] Init torch distributed begin.
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:55:51 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:55:54 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 06:55:56 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 06:55:56 TP0] Detected fp8 checkpoint.
[2025-09-13 06:55:56 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:04, 223.19it/s]
Loading safetensors checkpoint shards:   5% Completed | 49/1024 [00:00<00:14, 65.03it/s]
Loading safetensors checkpoint shards:   6% Completed | 61/1024 [00:00<00:16, 57.17it/s]
Loading safetensors checkpoint shards:   7% Completed | 70/1024 [00:01<00:18, 51.50it/s]
Loading safetensors checkpoint shards:   8% Completed | 77/1024 [00:01<00:20, 46.48it/s]
Loading safetensors checkpoint shards:   8% Completed | 83/1024 [00:01<00:20, 46.16it/s]
Loading safetensors checkpoint shards:   9% Completed | 89/1024 [00:01<00:21, 43.94it/s]
Loading safetensors checkpoint shards:   9% Completed | 94/1024 [00:01<00:22, 41.51it/s]
Loading safetensors checkpoint shards:  10% Completed | 99/1024 [00:01<00:22, 41.01it/s]
Loading safetensors checkpoint shards:  10% Completed | 104/1024 [00:02<00:21, 42.43it/s]
Loading safetensors checkpoint shards:  11% Completed | 109/1024 [00:02<00:22, 41.39it/s]
Loading safetensors checkpoint shards:  11% Completed | 114/1024 [00:02<00:22, 40.93it/s]
Loading safetensors checkpoint shards:  12% Completed | 119/1024 [00:02<00:21, 42.69it/s]
Loading safetensors checkpoint shards:  12% Completed | 124/1024 [00:02<00:38, 23.42it/s]
Loading safetensors checkpoint shards:  13% Completed | 129/1024 [00:02<00:32, 27.66it/s]
Loading safetensors checkpoint shards:  13% Completed | 133/1024 [00:03<00:30, 29.50it/s]
Loading safetensors checkpoint shards:  14% Completed | 139/1024 [00:03<00:24, 35.71it/s]
Loading safetensors checkpoint shards:  14% Completed | 144/1024 [00:03<00:23, 37.84it/s]
Loading safetensors checkpoint shards:  15% Completed | 149/1024 [00:03<00:21, 40.30it/s]
Loading safetensors checkpoint shards:  15% Completed | 154/1024 [00:03<00:21, 41.11it/s]
Loading safetensors checkpoint shards:  16% Completed | 159/1024 [00:03<00:20, 42.08it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:03<00:20, 42.81it/s]
Loading safetensors checkpoint shards:  17% Completed | 169/1024 [00:03<00:20, 41.31it/s]
Loading safetensors checkpoint shards:  17% Completed | 174/1024 [00:03<00:19, 42.61it/s]
Loading safetensors checkpoint shards:  17% Completed | 179/1024 [00:04<00:20, 40.43it/s]
Loading safetensors checkpoint shards:  18% Completed | 184/1024 [00:04<00:20, 41.59it/s]
Loading safetensors checkpoint shards:  18% Completed | 189/1024 [00:04<00:21, 38.94it/s]
Loading safetensors checkpoint shards:  19% Completed | 194/1024 [00:04<00:20, 39.80it/s]
Loading safetensors checkpoint shards:  19% Completed | 199/1024 [00:04<00:21, 38.10it/s]
Loading safetensors checkpoint shards:  20% Completed | 203/1024 [00:04<00:22, 36.66it/s]
Loading safetensors checkpoint shards:  20% Completed | 208/1024 [00:04<00:21, 38.31it/s]
Loading safetensors checkpoint shards:  21% Completed | 212/1024 [00:04<00:21, 38.33it/s]
Loading safetensors checkpoint shards:  21% Completed | 217/1024 [00:05<00:20, 39.96it/s]
Loading safetensors checkpoint shards:  22% Completed | 222/1024 [00:05<00:21, 38.05it/s]
Loading safetensors checkpoint shards:  22% Completed | 226/1024 [00:05<00:20, 38.09it/s]
Loading safetensors checkpoint shards:  22% Completed | 230/1024 [00:05<00:20, 38.24it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:05<00:20, 38.11it/s]
Loading safetensors checkpoint shards:  23% Completed | 239/1024 [00:05<00:19, 39.37it/s]
Loading safetensors checkpoint shards:  24% Completed | 243/1024 [00:05<00:20, 38.66it/s]
Loading safetensors checkpoint shards:  24% Completed | 247/1024 [00:05<00:20, 38.07it/s]
Loading safetensors checkpoint shards:  25% Completed | 252/1024 [00:05<00:19, 40.14it/s]
Loading safetensors checkpoint shards:  25% Completed | 257/1024 [00:06<00:19, 39.88it/s]
Loading safetensors checkpoint shards:  26% Completed | 262/1024 [00:06<00:18, 41.68it/s]
Loading safetensors checkpoint shards:  26% Completed | 267/1024 [00:06<00:18, 41.62it/s]
Loading safetensors checkpoint shards:  27% Completed | 272/1024 [00:06<00:17, 43.42it/s]
Loading safetensors checkpoint shards:  27% Completed | 277/1024 [00:06<00:18, 40.98it/s]
Loading safetensors checkpoint shards:  28% Completed | 282/1024 [00:06<00:17, 41.51it/s]
Loading safetensors checkpoint shards:  28% Completed | 287/1024 [00:06<00:18, 40.01it/s]
Loading safetensors checkpoint shards:  29% Completed | 292/1024 [00:06<00:19, 37.04it/s]
Loading safetensors checkpoint shards:  29% Completed | 297/1024 [00:07<00:19, 37.98it/s]
Loading safetensors checkpoint shards:  29% Completed | 301/1024 [00:07<00:19, 37.21it/s]
Loading safetensors checkpoint shards:  30% Completed | 306/1024 [00:07<00:19, 37.58it/s]
Loading safetensors checkpoint shards:  30% Completed | 310/1024 [00:07<00:18, 37.67it/s]
Loading safetensors checkpoint shards:  31% Completed | 314/1024 [00:07<00:18, 37.84it/s]
Loading safetensors checkpoint shards:  31% Completed | 319/1024 [00:07<00:17, 40.23it/s]
Loading safetensors checkpoint shards:  32% Completed | 324/1024 [00:08<00:35, 19.75it/s]
Loading safetensors checkpoint shards:  32% Completed | 329/1024 [00:08<00:29, 23.77it/s]
Loading safetensors checkpoint shards:  33% Completed | 333/1024 [00:08<00:26, 26.29it/s]
Loading safetensors checkpoint shards:  33% Completed | 338/1024 [00:08<00:22, 30.23it/s]
Loading safetensors checkpoint shards:  33% Completed | 342/1024 [00:08<00:21, 32.08it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:08<00:21, 32.11it/s]
Loading safetensors checkpoint shards:  34% Completed | 351/1024 [00:08<00:19, 35.15it/s]
Loading safetensors checkpoint shards:  35% Completed | 355/1024 [00:08<00:18, 35.72it/s]
Loading safetensors checkpoint shards:  35% Completed | 359/1024 [00:09<00:18, 36.65it/s]
Loading safetensors checkpoint shards:  36% Completed | 364/1024 [00:09<00:17, 37.79it/s]
Loading safetensors checkpoint shards:  36% Completed | 368/1024 [00:09<00:17, 37.66it/s]
Loading safetensors checkpoint shards:  36% Completed | 373/1024 [00:09<00:16, 40.11it/s]
Loading safetensors checkpoint shards:  37% Completed | 378/1024 [00:09<00:16, 39.33it/s]
Loading safetensors checkpoint shards:  37% Completed | 383/1024 [00:09<00:15, 40.25it/s]
Loading safetensors checkpoint shards:  38% Completed | 388/1024 [00:09<00:16, 39.28it/s]
Loading safetensors checkpoint shards:  38% Completed | 392/1024 [00:09<00:16, 38.19it/s]
Loading safetensors checkpoint shards:  39% Completed | 397/1024 [00:10<00:15, 40.98it/s]
Loading safetensors checkpoint shards:  39% Completed | 402/1024 [00:10<00:14, 41.81it/s]
Loading safetensors checkpoint shards:  40% Completed | 408/1024 [00:10<00:13, 44.46it/s]
Loading safetensors checkpoint shards:  40% Completed | 413/1024 [00:10<00:13, 44.77it/s]
Loading safetensors checkpoint shards:  41% Completed | 419/1024 [00:10<00:12, 47.41it/s]
Loading safetensors checkpoint shards:  41% Completed | 424/1024 [00:10<00:14, 42.77it/s]
Loading safetensors checkpoint shards:  42% Completed | 429/1024 [00:10<00:13, 43.12it/s]
Loading safetensors checkpoint shards:  42% Completed | 434/1024 [00:10<00:14, 40.83it/s]
Loading safetensors checkpoint shards:  43% Completed | 439/1024 [00:11<00:13, 42.34it/s]
Loading safetensors checkpoint shards:  43% Completed | 444/1024 [00:11<00:14, 40.91it/s]
Loading safetensors checkpoint shards:  44% Completed | 449/1024 [00:11<00:13, 42.51it/s]
Loading safetensors checkpoint shards:  44% Completed | 454/1024 [00:11<00:14, 39.73it/s]
Loading safetensors checkpoint shards:  45% Completed | 459/1024 [00:11<00:13, 40.45it/s]
Loading safetensors checkpoint shards:  45% Completed | 464/1024 [00:11<00:14, 38.91it/s]
Loading safetensors checkpoint shards:  46% Completed | 468/1024 [00:11<00:14, 38.08it/s]
Loading safetensors checkpoint shards:  46% Completed | 474/1024 [00:11<00:13, 42.09it/s]
Loading safetensors checkpoint shards:  47% Completed | 479/1024 [00:11<00:12, 42.09it/s]
Loading safetensors checkpoint shards:  47% Completed | 485/1024 [00:12<00:11, 45.92it/s]
Loading safetensors checkpoint shards:  48% Completed | 491/1024 [00:12<00:10, 48.57it/s]
Loading safetensors checkpoint shards:  49% Completed | 499/1024 [00:12<00:09, 55.56it/s]
Loading safetensors checkpoint shards:  50% Completed | 507/1024 [00:12<00:08, 57.99it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:12<00:09, 55.77it/s]
Loading safetensors checkpoint shards:  51% Completed | 519/1024 [00:12<00:09, 53.06it/s]
Loading safetensors checkpoint shards:  51% Completed | 525/1024 [00:12<00:10, 48.60it/s]
Loading safetensors checkpoint shards:  52% Completed | 531/1024 [00:12<00:10, 49.23it/s]
Loading safetensors checkpoint shards:  52% Completed | 536/1024 [00:13<00:09, 48.96it/s]
Loading safetensors checkpoint shards:  53% Completed | 542/1024 [00:13<00:09, 50.21it/s]
Loading safetensors checkpoint shards:  54% Completed | 548/1024 [00:13<00:20, 23.61it/s]
Loading safetensors checkpoint shards:  54% Completed | 552/1024 [00:13<00:18, 25.41it/s]
Loading safetensors checkpoint shards:  54% Completed | 557/1024 [00:13<00:16, 28.81it/s]
Loading safetensors checkpoint shards:  55% Completed | 562/1024 [00:14<00:14, 32.37it/s]
Loading safetensors checkpoint shards:  55% Completed | 567/1024 [00:14<00:12, 35.40it/s]
Loading safetensors checkpoint shards:  56% Completed | 574/1024 [00:14<00:11, 40.71it/s]
Loading safetensors checkpoint shards:  57% Completed | 579/1024 [00:14<00:11, 39.64it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:14<00:09, 44.34it/s]
Loading safetensors checkpoint shards:  58% Completed | 590/1024 [00:14<00:09, 45.31it/s]
Loading safetensors checkpoint shards:  58% Completed | 595/1024 [00:14<00:09, 46.50it/s]
Loading safetensors checkpoint shards:  59% Completed | 600/1024 [00:14<00:10, 42.14it/s]
Loading safetensors checkpoint shards:  59% Completed | 605/1024 [00:14<00:09, 43.99it/s]
Loading safetensors checkpoint shards:  60% Completed | 610/1024 [00:15<00:10, 39.06it/s]
Loading safetensors checkpoint shards:  60% Completed | 615/1024 [00:15<00:10, 38.43it/s]
Loading safetensors checkpoint shards:  61% Completed | 620/1024 [00:15<00:11, 35.34it/s]
Loading safetensors checkpoint shards:  61% Completed | 624/1024 [00:15<00:11, 33.73it/s]
Loading safetensors checkpoint shards:  61% Completed | 629/1024 [00:15<00:11, 35.26it/s]
Loading safetensors checkpoint shards:  62% Completed | 633/1024 [00:15<00:12, 31.48it/s]
Loading safetensors checkpoint shards:  62% Completed | 637/1024 [00:16<00:12, 29.85it/s]
Loading safetensors checkpoint shards:  63% Completed | 641/1024 [00:16<00:12, 30.65it/s]
Loading safetensors checkpoint shards:  63% Completed | 645/1024 [00:16<00:12, 30.05it/s]
Loading safetensors checkpoint shards:  63% Completed | 649/1024 [00:16<00:11, 31.77it/s]
Loading safetensors checkpoint shards:  64% Completed | 653/1024 [00:16<00:11, 32.47it/s]
Loading safetensors checkpoint shards:  64% Completed | 657/1024 [00:16<00:12, 28.36it/s]
Loading safetensors checkpoint shards:  64% Completed | 660/1024 [00:16<00:12, 28.68it/s]
Loading safetensors checkpoint shards:  65% Completed | 665/1024 [00:16<00:10, 33.28it/s]
Loading safetensors checkpoint shards:  66% Completed | 672/1024 [00:17<00:08, 41.46it/s]
Loading safetensors checkpoint shards:  66% Completed | 678/1024 [00:17<00:07, 45.55it/s]
Loading safetensors checkpoint shards:  67% Completed | 683/1024 [00:17<00:07, 46.67it/s]
Loading safetensors checkpoint shards:  67% Completed | 689/1024 [00:17<00:06, 48.29it/s]
Loading safetensors checkpoint shards:  68% Completed | 695/1024 [00:17<00:06, 50.78it/s]
Loading safetensors checkpoint shards:  68% Completed | 701/1024 [00:17<00:06, 51.28it/s]
Loading safetensors checkpoint shards:  69% Completed | 707/1024 [00:17<00:06, 48.81it/s]
Loading safetensors checkpoint shards:  70% Completed | 713/1024 [00:17<00:06, 51.20it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:17<00:06, 48.25it/s]
Loading safetensors checkpoint shards:  71% Completed | 725/1024 [00:18<00:05, 50.52it/s]
Loading safetensors checkpoint shards:  71% Completed | 732/1024 [00:18<00:05, 52.83it/s]
Loading safetensors checkpoint shards:  72% Completed | 738/1024 [00:18<00:05, 54.43it/s]
Loading safetensors checkpoint shards:  73% Completed | 744/1024 [00:18<00:05, 54.13it/s]
Loading safetensors checkpoint shards:  73% Completed | 750/1024 [00:18<00:05, 53.19it/s]
Loading safetensors checkpoint shards:  74% Completed | 758/1024 [00:18<00:04, 57.90it/s]
Loading safetensors checkpoint shards:  75% Completed | 764/1024 [00:19<00:12, 20.70it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:19<00:09, 27.41it/s]
Loading safetensors checkpoint shards:  76% Completed | 780/1024 [00:19<00:06, 34.86it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:19<00:05, 40.50it/s]
Loading safetensors checkpoint shards:  78% Completed | 795/1024 [00:19<00:04, 48.07it/s]
Loading safetensors checkpoint shards:  78% Completed | 802/1024 [00:19<00:04, 52.47it/s]
Loading safetensors checkpoint shards:  79% Completed | 810/1024 [00:20<00:03, 57.84it/s]
Loading safetensors checkpoint shards:  80% Completed | 817/1024 [00:20<00:03, 56.06it/s]
Loading safetensors checkpoint shards:  80% Completed | 824/1024 [00:20<00:03, 54.90it/s]
Loading safetensors checkpoint shards:  81% Completed | 832/1024 [00:20<00:03, 59.42it/s]
Loading safetensors checkpoint shards:  82% Completed | 840/1024 [00:20<00:02, 64.25it/s]
Loading safetensors checkpoint shards:  83% Completed | 847/1024 [00:20<00:02, 61.66it/s]
Loading safetensors checkpoint shards:  83% Completed | 854/1024 [00:20<00:02, 62.19it/s]
Loading safetensors checkpoint shards:  84% Completed | 861/1024 [00:20<00:02, 58.61it/s]
Loading safetensors checkpoint shards:  85% Completed | 868/1024 [00:21<00:02, 54.71it/s]
Loading safetensors checkpoint shards:  85% Completed | 874/1024 [00:21<00:03, 49.12it/s]
Loading safetensors checkpoint shards:  86% Completed | 880/1024 [00:21<00:02, 48.70it/s]
Loading safetensors checkpoint shards:  87% Completed | 887/1024 [00:21<00:02, 52.46it/s]
Loading safetensors checkpoint shards:  87% Completed | 893/1024 [00:21<00:02, 53.97it/s]
Loading safetensors checkpoint shards:  88% Completed | 900/1024 [00:21<00:02, 57.11it/s]
Loading safetensors checkpoint shards:  89% Completed | 908/1024 [00:21<00:01, 61.78it/s]
Loading safetensors checkpoint shards:  90% Completed | 917/1024 [00:21<00:01, 66.90it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:21<00:01, 65.80it/s]
Loading safetensors checkpoint shards:  91% Completed | 931/1024 [00:22<00:01, 63.74it/s]
Loading safetensors checkpoint shards:  92% Completed | 939/1024 [00:22<00:01, 67.07it/s]
Loading safetensors checkpoint shards:  92% Completed | 946/1024 [00:22<00:01, 61.80it/s]
Loading safetensors checkpoint shards:  93% Completed | 953/1024 [00:22<00:01, 63.37it/s]
Loading safetensors checkpoint shards:  94% Completed | 960/1024 [00:22<00:00, 65.05it/s]
Loading safetensors checkpoint shards:  94% Completed | 967/1024 [00:22<00:00, 62.10it/s]
Loading safetensors checkpoint shards:  95% Completed | 974/1024 [00:22<00:00, 60.71it/s]
Loading safetensors checkpoint shards:  96% Completed | 982/1024 [00:22<00:00, 65.21it/s]
Loading safetensors checkpoint shards:  97% Completed | 994/1024 [00:23<00:00, 78.62it/s]
Loading safetensors checkpoint shards:  99% Completed | 1009/1024 [00:23<00:00, 97.27it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:23<00:00, 44.15it/s]

[2025-09-13 06:56:24 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 06:56:24 TP3] KV Cache is allocated. #tokens: 620153, KV size: 40.59 GB
[2025-09-13 06:56:24 TP5] KV Cache is allocated. #tokens: 620153, KV size: 40.59 GB
[2025-09-13 06:56:24 TP4] KV Cache is allocated. #tokens: 620153, KV size: 40.59 GB
[2025-09-13 06:56:24 TP1] KV Cache is allocated. #tokens: 620153, KV size: 40.59 GB
[2025-09-13 06:56:24 TP2] KV Cache is allocated. #tokens: 620153, KV size: 40.59 GB
[2025-09-13 06:56:24 TP7] KV Cache is allocated. #tokens: 620153, KV size: 40.59 GB
[2025-09-13 06:56:24 TP0] KV Cache is allocated. #tokens: 620153, KV size: 40.59 GB
[2025-09-13 06:56:24 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 06:56:24 TP6] KV Cache is allocated. #tokens: 620153, KV size: 40.59 GB
[2025-09-13 06:56:24 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 06:56:25 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.53 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 06:56:25 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:56:25 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 06:56:26 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:56:26 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:56:26 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:56:26 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:56:26 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:56:26 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:56:26 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 24383.02it/s]
[2025-09-13 06:56:26 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:56:26 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 24879.76it/s]
[2025-09-13 06:56:27 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:56:27 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27810.81it/s]
[2025-09-13 06:56:28 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:56:28 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27370.32it/s]
[2025-09-13 06:56:28 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:56:28 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27899.95it/s]
[2025-09-13 06:56:29 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.22 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.14it/s]
[2025-09-13 06:56:32 TP1] Registering 984 cuda graph addresses
[2025-09-13 06:56:32 TP7] Registering 984 cuda graph addresses
[2025-09-13 06:56:32 TP2] Registering 984 cuda graph addresses
[2025-09-13 06:56:32 TP0] Registering 984 cuda graph addresses
[2025-09-13 06:56:32 TP5] Registering 984 cuda graph addresses
[2025-09-13 06:56:32 TP3] Registering 984 cuda graph addresses
[2025-09-13 06:56:32 TP4] Registering 984 cuda graph addresses
[2025-09-13 06:56:32 TP6] Registering 984 cuda graph addresses
[2025-09-13 06:56:32 TP0] Capture cuda graph end. Time elapsed: 7.76 s. mem usage=0.36 GB. avail mem=17.20 GB.
[2025-09-13 06:56:32 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 06:56:32 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:56:32 TP0] Init torch distributed begin.
[2025-09-13 06:56:32 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 06:56:32 TP0] Load weight begin. avail mem=17.20 GB
[2025-09-13 06:56:32 TP0] Detected fp8 checkpoint.
[2025-09-13 06:56:32 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 19/1024 [00:00<00:05, 182.28it/s]
Loading safetensors checkpoint shards:   4% Completed | 45/1024 [00:00<00:04, 226.43it/s]
Loading safetensors checkpoint shards:  10% Completed | 106/1024 [00:00<00:02, 398.52it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:00<00:01, 478.36it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:00<00:01, 521.80it/s]
Loading safetensors checkpoint shards:  28% Completed | 286/1024 [00:00<00:01, 543.62it/s]
Loading safetensors checkpoint shards:  34% Completed | 345/1024 [00:00<00:01, 555.84it/s]
Loading safetensors checkpoint shards:  40% Completed | 407/1024 [00:00<00:01, 575.11it/s]
Loading safetensors checkpoint shards:  46% Completed | 468/1024 [00:00<00:00, 585.69it/s]
Loading safetensors checkpoint shards:  52% Completed | 532/1024 [00:01<00:00, 600.01it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:01<00:00, 609.44it/s]
Loading safetensors checkpoint shards:  64% Completed | 657/1024 [00:01<00:00, 604.15it/s]
Loading safetensors checkpoint shards:  70% Completed | 718/1024 [00:01<00:00, 597.39it/s]
Loading safetensors checkpoint shards:  76% Completed | 778/1024 [00:01<00:00, 593.14it/s]
Loading safetensors checkpoint shards:  82% Completed | 838/1024 [00:01<00:00, 591.69it/s]
Loading safetensors checkpoint shards:  88% Completed | 898/1024 [00:01<00:00, 585.15it/s]
Loading safetensors checkpoint shards:  93% Completed | 957/1024 [00:01<00:00, 579.25it/s]
Loading safetensors checkpoint shards:  99% Completed | 1015/1024 [00:01<00:00, 401.30it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 510.36it/s]

[2025-09-13 06:56:35 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.21 GB, mem usage=1.99 GB.
[2025-09-13 06:56:35 TP0] KV Cache is allocated. #tokens: 620153, KV size: 0.67 GB
[2025-09-13 06:56:35 TP0] Memory pool end. avail mem=14.54 GB
[2025-09-13 06:56:35 TP3] KV Cache is allocated. #tokens: 620153, KV size: 0.67 GB
[2025-09-13 06:56:35 TP1] KV Cache is allocated. #tokens: 620153, KV size: 0.67 GB
[2025-09-13 06:56:35 TP6] KV Cache is allocated. #tokens: 620153, KV size: 0.67 GB
[2025-09-13 06:56:35 TP2] KV Cache is allocated. #tokens: 620153, KV size: 0.67 GB
[2025-09-13 06:56:35 TP5] KV Cache is allocated. #tokens: 620153, KV size: 0.67 GB
[2025-09-13 06:56:35 TP7] KV Cache is allocated. #tokens: 620153, KV size: 0.67 GB
[2025-09-13 06:56:35 TP4] KV Cache is allocated. #tokens: 620153, KV size: 0.67 GB
[2025-09-13 06:56:35 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:56:35 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:56:35 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:56:35 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.17 GB
[2025-09-13 06:56:35 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:56:35 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 06:56:35 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 06:56:35 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
Capturing batches (bs=1 avail_mem=14.67 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:03<00:00,  3.79it/s][2025-09-13 06:56:41 TP2] Registering 72 cuda graph addresses
[2025-09-13 06:56:41 TP3] Registering 72 cuda graph addresses
[2025-09-13 06:56:41 TP1] Registering 72 cuda graph addresses
[2025-09-13 06:56:41 TP5] Registering 72 cuda graph addresses
[2025-09-13 06:56:41 TP7] Registering 72 cuda graph addresses
[2025-09-13 06:56:41 TP4] Registering 72 cuda graph addresses
[2025-09-13 06:56:41 TP6] Registering 72 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.67 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.50it/s]
[2025-09-13 06:56:41 TP0] Registering 72 cuda graph addresses
[2025-09-13 06:56:41 TP3] Capture draft cuda graph end. Time elapsed: 6.27 s. mem usage=0.30 GB. avail mem=14.63 GB.
[2025-09-13 06:56:41 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.63 GB
[2025-09-13 06:56:41 TP2] Capture draft cuda graph end. Time elapsed: 6.28 s. mem usage=0.30 GB. avail mem=14.63 GB.
[2025-09-13 06:56:41 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.63 GB
[2025-09-13 06:56:41 TP5] Capture draft cuda graph end. Time elapsed: 6.28 s. mem usage=0.30 GB. avail mem=14.63 GB.
[2025-09-13 06:56:41 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.63 GB
[2025-09-13 06:56:41 TP6] Capture draft cuda graph end. Time elapsed: 6.28 s. mem usage=0.30 GB. avail mem=14.63 GB.
[2025-09-13 06:56:41 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.63 GB
[2025-09-13 06:56:41 TP1] Capture draft cuda graph end. Time elapsed: 6.28 s. mem usage=0.30 GB. avail mem=14.63 GB.
[2025-09-13 06:56:41 TP7] Capture draft cuda graph end. Time elapsed: 6.28 s. mem usage=0.30 GB. avail mem=14.86 GB.
[2025-09-13 06:56:41 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.63 GB
[2025-09-13 06:56:41 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.86 GB
[2025-09-13 06:56:41 TP4] Capture draft cuda graph end. Time elapsed: 6.28 s. mem usage=0.30 GB. avail mem=14.63 GB.
[2025-09-13 06:56:41 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.63 GB
[2025-09-13 06:56:41 TP0] Capture draft cuda graph end. Time elapsed: 6.28 s. mem usage=0.31 GB. avail mem=14.67 GB.
[2025-09-13 06:56:41 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.67 GB
Capturing batches (bs=1 avail_mem=14.50 GB):  38%|████████████████████████████████▎                                                     | 3/8 [00:00<00:00, 27.94it/s][2025-09-13 06:56:42 TP1] Registering 24 cuda graph addresses
[2025-09-13 06:56:42 TP3] Registering 24 cuda graph addresses
[2025-09-13 06:56:42 TP2] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.50 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 38.20it/s]
[2025-09-13 06:56:42 TP5] Registering 24 cuda graph addresses
[2025-09-13 06:56:42 TP6] Registering 24 cuda graph addresses
[2025-09-13 06:56:42 TP4] Registering 24 cuda graph addresses
[2025-09-13 06:56:42 TP7] Registering 24 cuda graph addresses
[2025-09-13 06:56:42 TP0] Registering 24 cuda graph addresses
[2025-09-13 06:56:42 TP1] Capture draft extend cuda graph end. Time elapsed: 1.01 s. mem usage=0.18 GB. avail mem=14.45 GB.
[2025-09-13 06:56:42 TP0] Capture draft extend cuda graph end. Time elapsed: 1.02 s. mem usage=0.18 GB. avail mem=14.49 GB.
[2025-09-13 06:56:42 TP0] max_total_num_tokens=620153, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.49 GB
[2025-09-13 06:56:42 TP2] Capture draft extend cuda graph end. Time elapsed: 1.02 s. mem usage=0.18 GB. avail mem=14.45 GB.
[2025-09-13 06:56:42 TP3] Capture draft extend cuda graph end. Time elapsed: 1.03 s. mem usage=0.18 GB. avail mem=14.45 GB.
[2025-09-13 06:56:42 TP7] Capture draft extend cuda graph end. Time elapsed: 1.03 s. mem usage=0.18 GB. avail mem=14.69 GB.
[2025-09-13 06:56:42 TP5] Capture draft extend cuda graph end. Time elapsed: 1.03 s. mem usage=0.18 GB. avail mem=14.45 GB.
[2025-09-13 06:56:42 TP4] Capture draft extend cuda graph end. Time elapsed: 1.03 s. mem usage=0.18 GB. avail mem=14.45 GB.
[2025-09-13 06:56:42 TP6] Capture draft extend cuda graph end. Time elapsed: 1.03 s. mem usage=0.18 GB. avail mem=14.45 GB.
[2025-09-13 06:56:43] INFO:     Started server process [188665]
[2025-09-13 06:56:43] INFO:     Waiting for application startup.
[2025-09-13 06:56:43] INFO:     Application startup complete.
[2025-09-13 06:56:43] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 06:56:44] INFO:     127.0.0.1:49568 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 06:56:44] INFO:     127.0.0.1:49574 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 06:56:44 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:56:44 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:56:44 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 23943.62it/s]
[2025-09-13 06:56:45] INFO:     127.0.0.1:49576 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:56:45] The server is fired up and ready to roll!
[2025-09-13 06:56:54 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:56:55] INFO:     127.0.0.1:40652 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:56:55] INFO:     127.0.0.1:40658 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:56:55 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 06:56:56] INFO:     127.0.0.1:40664 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:56:56] INFO:     127.0.0.1:40680 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:56:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:56:56] INFO:     127.0.0.1:40692 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:56:56] INFO:     127.0.0.1:40706 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:56:56] INFO:     127.0.0.1:40710 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:56:56] INFO:     127.0.0.1:40724 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:56:56] INFO:     127.0.0.1:40728 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:56:56] INFO:     127.0.0.1:40736 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:56:57 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 06:56:57 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:56:57 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:56:57 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:56:57 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:56:57 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:56:57 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:56:57 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:56:57 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:56:57 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 06:56:58 TP0] Decode batch. #running-req: 8, #token: 14459, token usage: 0.02, accept len: 2.58, cuda graph: True, gen throughput (token/s): 36.54, #queue-req: 0, 
[2025-09-13 06:56:59 TP0] Decode batch. #running-req: 8, #token: 15376, token usage: 0.02, accept len: 2.87, cuda graph: True, gen throughput (token/s): 780.84, #queue-req: 0, 
[2025-09-13 06:57:00 TP0] Decode batch. #running-req: 8, #token: 16349, token usage: 0.03, accept len: 3.04, cuda graph: True, gen throughput (token/s): 818.12, #queue-req: 0, 
[2025-09-13 06:57:02 TP0] Decode batch. #running-req: 8, #token: 17336, token usage: 0.03, accept len: 3.08, cuda graph: True, gen throughput (token/s): 829.78, #queue-req: 0, 
 62%|█████████████████████████████████████████████████████████████████████████████████▉                                                 | 5/8 [00:06<00:01,  1.64it/s][2025-09-13 06:57:03 TP0] Decode batch. #running-req: 2, #token: 8834, token usage: 0.01, accept len: 3.07, cuda graph: True, gen throughput (token/s): 523.37, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.23it/s]
[2025-09-13 06:57:03] INFO:     127.0.0.1:47716 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.50      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4074      
Request throughput (req/s):              1.23      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         629.69    
Total token throughput (tok/s):          629.69    
Concurrency:                             7.28      
Accept length:                           2.94      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5917.97   
Median E2E Latency (ms):                 5933.03   
---------------Time to First Token----------------
Mean TTFT (ms):                          619.73    
Median TTFT (ms):                        731.65    
P99 TTFT (ms):                           732.14    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.37     
Median ITL (ms):                         7.46      
P95 ITL (ms):                            28.17     
P99 ITL (ms):                            30.35     
Max ITL (ms):                            734.67    
==================================================
[2025-09-13 06:57:03] INFO:     127.0.0.1:47722 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:57:03] INFO:     127.0.0.1:47726 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:57:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 06:57:04] INFO:     127.0.0.1:47728 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:57:04] INFO:     127.0.0.1:47744 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:57:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:57:04] INFO:     127.0.0.1:47760 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:57:04] INFO:     127.0.0.1:47776 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:57:04] INFO:     127.0.0.1:47782 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:57:04] INFO:     127.0.0.1:47798 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:57:04] INFO:     127.0.0.1:47814 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:57:04] INFO:     127.0.0.1:47830 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:57:04 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 06:57:05 TP0] Decode batch. #running-req: 8, #token: 14316, token usage: 0.02, accept len: 2.50, cuda graph: True, gen throughput (token/s): 193.40, #queue-req: 0, 
[2025-09-13 06:57:06 TP0] Decode batch. #running-req: 8, #token: 15242, token usage: 0.02, accept len: 2.89, cuda graph: True, gen throughput (token/s): 793.74, #queue-req: 0, 
[2025-09-13 06:57:07 TP0] Decode batch. #running-req: 8, #token: 16198, token usage: 0.03, accept len: 2.99, cuda graph: True, gen throughput (token/s): 809.22, #queue-req: 0, 
[2025-09-13 06:57:09 TP0] Decode batch. #running-req: 8, #token: 17180, token usage: 0.03, accept len: 3.07, cuda graph: True, gen throughput (token/s): 834.10, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:08,  4.60s/it][2025-09-13 06:57:09] INFO:     127.0.0.1:52806 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:57:09 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:05<00:31,  2.28s/it][2025-09-13 06:57:10] INFO:     127.0.0.1:52822 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:57:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:17,  1.38s/it][2025-09-13 06:57:10] INFO:     127.0.0.1:52824 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:57:10 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:11,  1.07it/s][2025-09-13 06:57:10] INFO:     127.0.0.1:52828 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:57:10 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:06<00:07,  1.50it/s][2025-09-13 06:57:10] INFO:     127.0.0.1:52830 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:57:10 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:57:11 TP0] Decode batch. #running-req: 8, #token: 15695, token usage: 0.03, accept len: 2.98, cuda graph: True, gen throughput (token/s): 475.66, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:06<00:05,  1.79it/s][2025-09-13 06:57:11] INFO:     127.0.0.1:52834 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:57:11 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:04,  1.91it/s][2025-09-13 06:57:11] INFO:     127.0.0.1:52842 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:57:11 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:07<00:03,  2.30it/s][2025-09-13 06:57:11] INFO:     127.0.0.1:52850 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:57:11 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:57:12 TP0] Decode batch. #running-req: 8, #token: 14416, token usage: 0.02, accept len: 2.65, cuda graph: True, gen throughput (token/s): 510.84, #queue-req: 0, 
[2025-09-13 06:57:13 TP0] Decode batch. #running-req: 8, #token: 15342, token usage: 0.02, accept len: 2.89, cuda graph: True, gen throughput (token/s): 789.69, #queue-req: 0, 
[2025-09-13 06:57:15 TP0] Decode batch. #running-req: 8, #token: 16324, token usage: 0.03, accept len: 3.07, cuda graph: True, gen throughput (token/s): 833.08, #queue-req: 0, 
 56%|█████████████████████████████████████████████████████████████████████████▏                                                        | 9/16 [00:10<00:10,  1.46s/it][2025-09-13 06:57:16 TP0] Decode batch. #running-req: 7, #token: 14735, token usage: 0.02, accept len: 3.08, cuda graph: True, gen throughput (token/s): 807.29, #queue-req: 0, 
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 15/16 [00:12<00:00,  2.38it/s][2025-09-13 06:57:17 TP0] Decode batch. #running-req: 1, #token: 3215, token usage: 0.01, accept len: 2.92, cuda graph: True, gen throughput (token/s): 360.26, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:12<00:00,  1.29it/s]
[2025-09-13 06:57:17] INFO:     127.0.0.1:52854 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  12.38     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8113      
Request throughput (req/s):              1.29      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         661.73    
Total token throughput (tok/s):          661.73    
Concurrency:                             7.53      
Accept length:                           2.93      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5825.18   
Median E2E Latency (ms):                 5681.73   
---------------Time to First Token----------------
Mean TTFT (ms):                          220.53    
Median TTFT (ms):                        232.62    
P99 TTFT (ms):                           282.72    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.97     
Median ITL (ms):                         7.40      
P95 ITL (ms):                            29.17     
P99 ITL (ms):                            53.81     
Max ITL (ms):                            263.39    
==================================================
[2025-09-13 06:57:17] INFO:     127.0.0.1:52870 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=11: batch_size=8, steps=4, topk=2, num_draft_tokens=4, speed=99.66 token/s, step_time=29.37 ms
Start i=12: batch_size=8, steps=4, topk=2, num_draft_tokens=6
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 4 --speculative-eagle-topk 2 --speculative-num-draft-tokens 6 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:57:27.793000 194297 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:57:27.793000 194297 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 06:57:28] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=191281375, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=4, speculative_eagle_topk=2, speculative_num_draft_tokens=6, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:57:28] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:57:37.001000 194536 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:57:37.001000 194536 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:57:37.104000 194540 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:57:37.104000 194540 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:57:37.268000 194534 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:57:37.268000 194534 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:57:37.292000 194539 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:57:37.292000 194539 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:57:37.419000 194535 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:57:37.419000 194535 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:57:37.429000 194537 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:57:37.429000 194537 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:57:37.490000 194538 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:57:37.490000 194538 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:57:37.532000 194533 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:57:37.532000 194533 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:57:37.551000 194532 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:57:37.551000 194532 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:57:38 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 06:57:38 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:57:38 TP0] Init torch distributed begin.
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:57:39 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:57:42 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 06:57:44 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 06:57:44 TP0] Detected fp8 checkpoint.
[2025-09-13 06:57:44 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 25/1024 [00:00<00:04, 238.13it/s]
Loading safetensors checkpoint shards:   5% Completed | 49/1024 [00:00<00:15, 61.15it/s]
Loading safetensors checkpoint shards:   6% Completed | 62/1024 [00:01<00:18, 51.81it/s]
Loading safetensors checkpoint shards:   7% Completed | 71/1024 [00:01<00:19, 49.80it/s]
Loading safetensors checkpoint shards:   8% Completed | 78/1024 [00:01<00:20, 47.02it/s]
Loading safetensors checkpoint shards:   8% Completed | 84/1024 [00:01<00:19, 48.23it/s]
Loading safetensors checkpoint shards:   9% Completed | 90/1024 [00:01<00:19, 48.05it/s]
Loading safetensors checkpoint shards:   9% Completed | 96/1024 [00:01<00:21, 44.00it/s]
Loading safetensors checkpoint shards:  10% Completed | 101/1024 [00:01<00:21, 43.13it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:02<00:20, 44.71it/s]
Loading safetensors checkpoint shards:  11% Completed | 112/1024 [00:02<00:20, 43.60it/s]
Loading safetensors checkpoint shards:  11% Completed | 117/1024 [00:02<00:20, 44.24it/s]
Loading safetensors checkpoint shards:  12% Completed | 122/1024 [00:02<00:36, 24.68it/s]
Loading safetensors checkpoint shards:  12% Completed | 127/1024 [00:02<00:31, 28.10it/s]
Loading safetensors checkpoint shards:  13% Completed | 131/1024 [00:02<00:29, 30.01it/s]
Loading safetensors checkpoint shards:  13% Completed | 135/1024 [00:03<00:28, 30.93it/s]
Loading safetensors checkpoint shards:  14% Completed | 141/1024 [00:03<00:24, 36.14it/s]
Loading safetensors checkpoint shards:  14% Completed | 146/1024 [00:03<00:23, 38.01it/s]
Loading safetensors checkpoint shards:  15% Completed | 151/1024 [00:03<00:21, 39.76it/s]
Loading safetensors checkpoint shards:  15% Completed | 156/1024 [00:03<00:21, 40.49it/s]
Loading safetensors checkpoint shards:  16% Completed | 161/1024 [00:03<00:20, 42.54it/s]
Loading safetensors checkpoint shards:  16% Completed | 166/1024 [00:03<00:20, 41.63it/s]
Loading safetensors checkpoint shards:  17% Completed | 172/1024 [00:03<00:19, 43.83it/s]
Loading safetensors checkpoint shards:  17% Completed | 177/1024 [00:04<00:19, 43.64it/s]
Loading safetensors checkpoint shards:  18% Completed | 182/1024 [00:04<00:19, 43.85it/s]
Loading safetensors checkpoint shards:  18% Completed | 187/1024 [00:04<00:19, 42.87it/s]
Loading safetensors checkpoint shards:  19% Completed | 192/1024 [00:04<00:18, 43.81it/s]
Loading safetensors checkpoint shards:  19% Completed | 198/1024 [00:04<00:17, 46.13it/s]
Loading safetensors checkpoint shards:  20% Completed | 203/1024 [00:04<00:18, 44.22it/s]
Loading safetensors checkpoint shards:  20% Completed | 208/1024 [00:04<00:17, 45.74it/s]
Loading safetensors checkpoint shards:  21% Completed | 214/1024 [00:04<00:16, 49.21it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:04<00:16, 49.04it/s]
Loading safetensors checkpoint shards:  22% Completed | 224/1024 [00:05<00:16, 48.60it/s]
Loading safetensors checkpoint shards:  22% Completed | 229/1024 [00:05<00:17, 46.40it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:05<00:18, 41.63it/s]
Loading safetensors checkpoint shards:  23% Completed | 239/1024 [00:05<00:18, 42.82it/s]
Loading safetensors checkpoint shards:  24% Completed | 244/1024 [00:05<00:18, 42.84it/s]
Loading safetensors checkpoint shards:  24% Completed | 249/1024 [00:05<00:17, 44.03it/s]
Loading safetensors checkpoint shards:  25% Completed | 254/1024 [00:05<00:18, 42.47it/s]
Loading safetensors checkpoint shards:  25% Completed | 259/1024 [00:05<00:18, 41.52it/s]
Loading safetensors checkpoint shards:  26% Completed | 265/1024 [00:05<00:17, 44.03it/s]
Loading safetensors checkpoint shards:  26% Completed | 270/1024 [00:06<00:19, 38.42it/s]
Loading safetensors checkpoint shards:  27% Completed | 275/1024 [00:06<00:19, 38.18it/s]
Loading safetensors checkpoint shards:  27% Completed | 279/1024 [00:06<00:19, 37.84it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:06<00:17, 41.83it/s]
Loading safetensors checkpoint shards:  28% Completed | 290/1024 [00:06<00:18, 39.71it/s]
Loading safetensors checkpoint shards:  29% Completed | 295/1024 [00:06<00:18, 40.47it/s]
Loading safetensors checkpoint shards:  29% Completed | 300/1024 [00:06<00:18, 39.51it/s]
Loading safetensors checkpoint shards:  30% Completed | 305/1024 [00:07<00:17, 41.02it/s]
Loading safetensors checkpoint shards:  30% Completed | 310/1024 [00:07<00:18, 39.07it/s]
Loading safetensors checkpoint shards:  31% Completed | 314/1024 [00:07<00:34, 20.32it/s]
Loading safetensors checkpoint shards:  31% Completed | 319/1024 [00:07<00:28, 24.41it/s]
Loading safetensors checkpoint shards:  32% Completed | 323/1024 [00:07<00:26, 26.24it/s]
Loading safetensors checkpoint shards:  32% Completed | 328/1024 [00:07<00:23, 29.89it/s]
Loading safetensors checkpoint shards:  32% Completed | 332/1024 [00:08<00:21, 31.78it/s]
Loading safetensors checkpoint shards:  33% Completed | 336/1024 [00:08<00:20, 32.95it/s]
Loading safetensors checkpoint shards:  33% Completed | 341/1024 [00:08<00:19, 35.91it/s]
Loading safetensors checkpoint shards:  34% Completed | 345/1024 [00:08<00:19, 35.71it/s]
Loading safetensors checkpoint shards:  34% Completed | 350/1024 [00:08<00:17, 37.70it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:08<00:18, 37.18it/s]
Loading safetensors checkpoint shards:  35% Completed | 358/1024 [00:08<00:17, 37.27it/s]
Loading safetensors checkpoint shards:  35% Completed | 363/1024 [00:08<00:16, 39.09it/s]
Loading safetensors checkpoint shards:  36% Completed | 367/1024 [00:09<00:17, 38.28it/s]
Loading safetensors checkpoint shards:  36% Completed | 372/1024 [00:09<00:16, 39.40it/s]
Loading safetensors checkpoint shards:  37% Completed | 376/1024 [00:09<00:16, 38.90it/s]
Loading safetensors checkpoint shards:  37% Completed | 380/1024 [00:09<00:17, 36.82it/s]
Loading safetensors checkpoint shards:  38% Completed | 384/1024 [00:09<00:17, 37.50it/s]
Loading safetensors checkpoint shards:  38% Completed | 388/1024 [00:09<00:17, 35.74it/s]
Loading safetensors checkpoint shards:  38% Completed | 392/1024 [00:09<00:18, 34.87it/s]
Loading safetensors checkpoint shards:  39% Completed | 397/1024 [00:09<00:16, 38.06it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:09<00:16, 37.96it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:10<00:15, 40.16it/s]
Loading safetensors checkpoint shards:  40% Completed | 411/1024 [00:10<00:15, 39.60it/s]
Loading safetensors checkpoint shards:  41% Completed | 416/1024 [00:10<00:14, 40.79it/s]
Loading safetensors checkpoint shards:  41% Completed | 421/1024 [00:10<00:15, 38.50it/s]
Loading safetensors checkpoint shards:  42% Completed | 425/1024 [00:10<00:15, 37.49it/s]
Loading safetensors checkpoint shards:  42% Completed | 430/1024 [00:10<00:15, 39.08it/s]
Loading safetensors checkpoint shards:  42% Completed | 434/1024 [00:10<00:16, 36.57it/s]
Loading safetensors checkpoint shards:  43% Completed | 439/1024 [00:10<00:15, 37.94it/s]
Loading safetensors checkpoint shards:  43% Completed | 443/1024 [00:11<00:15, 37.55it/s]
Loading safetensors checkpoint shards:  44% Completed | 447/1024 [00:11<00:15, 37.26it/s]
Loading safetensors checkpoint shards:  44% Completed | 452/1024 [00:11<00:14, 39.49it/s]
Loading safetensors checkpoint shards:  45% Completed | 456/1024 [00:11<00:14, 38.85it/s]
Loading safetensors checkpoint shards:  45% Completed | 461/1024 [00:11<00:13, 41.11it/s]
Loading safetensors checkpoint shards:  46% Completed | 466/1024 [00:11<00:14, 39.06it/s]
Loading safetensors checkpoint shards:  46% Completed | 472/1024 [00:11<00:12, 42.84it/s]
Loading safetensors checkpoint shards:  47% Completed | 477/1024 [00:11<00:12, 42.47it/s]
Loading safetensors checkpoint shards:  47% Completed | 482/1024 [00:11<00:12, 43.46it/s]
Loading safetensors checkpoint shards:  48% Completed | 487/1024 [00:12<00:12, 42.41it/s]
Loading safetensors checkpoint shards:  48% Completed | 492/1024 [00:12<00:13, 40.73it/s]
Loading safetensors checkpoint shards:  49% Completed | 497/1024 [00:12<00:12, 42.08it/s]
Loading safetensors checkpoint shards:  49% Completed | 502/1024 [00:12<00:12, 41.14it/s]
Loading safetensors checkpoint shards:  50% Completed | 507/1024 [00:12<00:12, 40.47it/s]
Loading safetensors checkpoint shards:  50% Completed | 512/1024 [00:12<00:12, 39.57it/s]
Loading safetensors checkpoint shards:  50% Completed | 517/1024 [00:12<00:12, 41.06it/s]
Loading safetensors checkpoint shards:  51% Completed | 522/1024 [00:12<00:13, 38.34it/s]
Loading safetensors checkpoint shards:  51% Completed | 527/1024 [00:13<00:12, 39.90it/s]
Loading safetensors checkpoint shards:  52% Completed | 532/1024 [00:13<00:12, 39.00it/s]
Loading safetensors checkpoint shards:  52% Completed | 536/1024 [00:13<00:13, 37.49it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:13<00:12, 38.55it/s]
Loading safetensors checkpoint shards:  53% Completed | 545/1024 [00:13<00:12, 37.73it/s]
Loading safetensors checkpoint shards:  54% Completed | 550/1024 [00:13<00:11, 39.91it/s]
Loading safetensors checkpoint shards:  54% Completed | 555/1024 [00:13<00:11, 40.42it/s]
Loading safetensors checkpoint shards:  55% Completed | 560/1024 [00:13<00:11, 41.69it/s]
Loading safetensors checkpoint shards:  55% Completed | 565/1024 [00:14<00:11, 41.24it/s]
Loading safetensors checkpoint shards:  56% Completed | 570/1024 [00:14<00:22, 19.81it/s]
Loading safetensors checkpoint shards:  56% Completed | 574/1024 [00:14<00:20, 22.06it/s]
Loading safetensors checkpoint shards:  56% Completed | 578/1024 [00:14<00:17, 24.97it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:14<00:13, 32.64it/s]
Loading safetensors checkpoint shards:  58% Completed | 590/1024 [00:15<00:13, 32.18it/s]
Loading safetensors checkpoint shards:  58% Completed | 594/1024 [00:15<00:13, 32.93it/s]
Loading safetensors checkpoint shards:  58% Completed | 598/1024 [00:15<00:12, 33.55it/s]
Loading safetensors checkpoint shards:  59% Completed | 602/1024 [00:15<00:12, 34.23it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:15<00:11, 35.12it/s]
Loading safetensors checkpoint shards:  60% Completed | 610/1024 [00:15<00:11, 35.37it/s]
Loading safetensors checkpoint shards:  60% Completed | 614/1024 [00:15<00:11, 35.46it/s]
Loading safetensors checkpoint shards:  60% Completed | 619/1024 [00:15<00:10, 37.61it/s]
Loading safetensors checkpoint shards:  61% Completed | 623/1024 [00:15<00:10, 37.43it/s]
Loading safetensors checkpoint shards:  61% Completed | 627/1024 [00:16<00:10, 36.56it/s]
Loading safetensors checkpoint shards:  62% Completed | 631/1024 [00:16<00:10, 36.31it/s]
Loading safetensors checkpoint shards:  62% Completed | 635/1024 [00:16<00:10, 36.60it/s]
Loading safetensors checkpoint shards:  62% Completed | 639/1024 [00:16<00:10, 36.62it/s]
Loading safetensors checkpoint shards:  63% Completed | 643/1024 [00:16<00:10, 36.26it/s]
Loading safetensors checkpoint shards:  63% Completed | 647/1024 [00:16<00:10, 34.31it/s]
Loading safetensors checkpoint shards:  64% Completed | 651/1024 [00:16<00:10, 34.91it/s]
Loading safetensors checkpoint shards:  64% Completed | 655/1024 [00:16<00:10, 36.02it/s]
Loading safetensors checkpoint shards:  64% Completed | 659/1024 [00:16<00:10, 35.60it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:17<00:10, 35.64it/s]
Loading safetensors checkpoint shards:  65% Completed | 668/1024 [00:17<00:09, 37.45it/s]
Loading safetensors checkpoint shards:  66% Completed | 673/1024 [00:17<00:09, 38.78it/s]
Loading safetensors checkpoint shards:  66% Completed | 677/1024 [00:17<00:09, 37.53it/s]
Loading safetensors checkpoint shards:  67% Completed | 681/1024 [00:17<00:09, 37.76it/s]
Loading safetensors checkpoint shards:  67% Completed | 685/1024 [00:17<00:09, 37.64it/s]
Loading safetensors checkpoint shards:  67% Completed | 689/1024 [00:17<00:08, 37.63it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:17<00:08, 39.49it/s]
Loading safetensors checkpoint shards:  68% Completed | 698/1024 [00:17<00:08, 38.64it/s]
Loading safetensors checkpoint shards:  69% Completed | 702/1024 [00:18<00:08, 36.51it/s]
Loading safetensors checkpoint shards:  69% Completed | 706/1024 [00:18<00:08, 36.00it/s]
Loading safetensors checkpoint shards:  69% Completed | 710/1024 [00:18<00:08, 35.63it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:18<00:08, 35.70it/s]
Loading safetensors checkpoint shards:  70% Completed | 718/1024 [00:18<00:08, 34.15it/s]
Loading safetensors checkpoint shards:  71% Completed | 722/1024 [00:18<00:08, 34.63it/s]
Loading safetensors checkpoint shards:  71% Completed | 726/1024 [00:18<00:08, 35.77it/s]
Loading safetensors checkpoint shards:  71% Completed | 731/1024 [00:18<00:07, 37.11it/s]
Loading safetensors checkpoint shards:  72% Completed | 735/1024 [00:19<00:07, 36.19it/s]
Loading safetensors checkpoint shards:  72% Completed | 739/1024 [00:19<00:07, 36.34it/s]
Loading safetensors checkpoint shards:  73% Completed | 743/1024 [00:19<00:07, 36.73it/s]
Loading safetensors checkpoint shards:  73% Completed | 747/1024 [00:19<00:07, 36.33it/s]
Loading safetensors checkpoint shards:  73% Completed | 751/1024 [00:19<00:07, 36.81it/s]
Loading safetensors checkpoint shards:  74% Completed | 755/1024 [00:19<00:07, 37.39it/s]
Loading safetensors checkpoint shards:  74% Completed | 759/1024 [00:19<00:07, 37.36it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:19<00:07, 37.09it/s]
Loading safetensors checkpoint shards:  75% Completed | 767/1024 [00:19<00:07, 36.53it/s]
Loading safetensors checkpoint shards:  75% Completed | 771/1024 [00:20<00:06, 36.79it/s]
Loading safetensors checkpoint shards:  76% Completed | 775/1024 [00:20<00:06, 35.79it/s]
Loading safetensors checkpoint shards:  76% Completed | 779/1024 [00:20<00:06, 35.35it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:20<00:06, 34.92it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:20<00:07, 33.18it/s]
Loading safetensors checkpoint shards:  77% Completed | 791/1024 [00:20<00:06, 34.01it/s]
Loading safetensors checkpoint shards:  78% Completed | 795/1024 [00:20<00:06, 34.78it/s]
Loading safetensors checkpoint shards:  78% Completed | 799/1024 [00:20<00:06, 35.37it/s]
Loading safetensors checkpoint shards:  79% Completed | 804/1024 [00:20<00:06, 36.43it/s]
Loading safetensors checkpoint shards:  79% Completed | 808/1024 [00:21<00:05, 36.77it/s]
Loading safetensors checkpoint shards:  79% Completed | 812/1024 [00:21<00:05, 36.91it/s]
Loading safetensors checkpoint shards:  80% Completed | 816/1024 [00:21<00:05, 35.73it/s]
Loading safetensors checkpoint shards:  80% Completed | 820/1024 [00:21<00:05, 34.76it/s]
Loading safetensors checkpoint shards:  80% Completed | 824/1024 [00:21<00:05, 35.27it/s]
Loading safetensors checkpoint shards:  81% Completed | 828/1024 [00:21<00:05, 35.94it/s]
Loading safetensors checkpoint shards:  81% Completed | 832/1024 [00:21<00:05, 36.20it/s]
Loading safetensors checkpoint shards:  82% Completed | 836/1024 [00:21<00:05, 36.47it/s]
Loading safetensors checkpoint shards:  82% Completed | 840/1024 [00:21<00:05, 36.43it/s]
Loading safetensors checkpoint shards:  82% Completed | 844/1024 [00:22<00:05, 35.61it/s]
Loading safetensors checkpoint shards:  83% Completed | 848/1024 [00:22<00:04, 35.54it/s]
Loading safetensors checkpoint shards:  83% Completed | 852/1024 [00:22<00:04, 35.73it/s]
Loading safetensors checkpoint shards:  84% Completed | 856/1024 [00:22<00:04, 35.75it/s]
Loading safetensors checkpoint shards:  84% Completed | 860/1024 [00:22<00:04, 34.87it/s]
Loading safetensors checkpoint shards:  84% Completed | 864/1024 [00:23<00:09, 16.08it/s]
Loading safetensors checkpoint shards:  85% Completed | 868/1024 [00:23<00:08, 19.30it/s]
Loading safetensors checkpoint shards:  85% Completed | 872/1024 [00:23<00:06, 22.54it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:23<00:05, 24.94it/s]
Loading safetensors checkpoint shards:  86% Completed | 880/1024 [00:23<00:05, 27.25it/s]
Loading safetensors checkpoint shards:  86% Completed | 884/1024 [00:23<00:04, 29.35it/s]
Loading safetensors checkpoint shards:  87% Completed | 888/1024 [00:23<00:04, 31.31it/s]
Loading safetensors checkpoint shards:  87% Completed | 892/1024 [00:23<00:04, 32.21it/s]
Loading safetensors checkpoint shards:  88% Completed | 896/1024 [00:23<00:03, 34.14it/s]
Loading safetensors checkpoint shards:  88% Completed | 900/1024 [00:24<00:03, 35.62it/s]
Loading safetensors checkpoint shards:  88% Completed | 905/1024 [00:24<00:03, 37.34it/s]
Loading safetensors checkpoint shards:  89% Completed | 910/1024 [00:24<00:02, 38.19it/s]
Loading safetensors checkpoint shards:  89% Completed | 915/1024 [00:24<00:02, 39.98it/s]
Loading safetensors checkpoint shards:  90% Completed | 920/1024 [00:24<00:02, 37.66it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:24<00:02, 36.03it/s]
Loading safetensors checkpoint shards:  91% Completed | 928/1024 [00:24<00:02, 36.29it/s]
Loading safetensors checkpoint shards:  91% Completed | 932/1024 [00:24<00:02, 35.17it/s]
Loading safetensors checkpoint shards:  91% Completed | 936/1024 [00:25<00:02, 35.73it/s]
Loading safetensors checkpoint shards:  92% Completed | 940/1024 [00:25<00:02, 36.34it/s]
Loading safetensors checkpoint shards:  92% Completed | 945/1024 [00:25<00:02, 37.21it/s]
Loading safetensors checkpoint shards:  93% Completed | 949/1024 [00:25<00:01, 37.63it/s]
Loading safetensors checkpoint shards:  93% Completed | 954/1024 [00:25<00:01, 38.54it/s]
Loading safetensors checkpoint shards:  94% Completed | 959/1024 [00:25<00:01, 39.04it/s]
Loading safetensors checkpoint shards:  94% Completed | 963/1024 [00:25<00:01, 38.30it/s]
Loading safetensors checkpoint shards:  94% Completed | 967/1024 [00:25<00:01, 38.31it/s]
Loading safetensors checkpoint shards:  95% Completed | 971/1024 [00:25<00:01, 37.54it/s]
Loading safetensors checkpoint shards:  95% Completed | 975/1024 [00:26<00:01, 38.05it/s]
Loading safetensors checkpoint shards:  96% Completed | 980/1024 [00:26<00:01, 39.48it/s]
Loading safetensors checkpoint shards:  97% Completed | 992/1024 [00:26<00:00, 58.91it/s]
Loading safetensors checkpoint shards:  98% Completed | 1003/1024 [00:26<00:00, 72.29it/s]
Loading safetensors checkpoint shards:  99% Completed | 1015/1024 [00:26<00:00, 85.46it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:26<00:00, 38.59it/s]

[2025-09-13 06:58:11 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 06:58:11 TP2] KV Cache is allocated. #tokens: 620169, KV size: 40.59 GB
[2025-09-13 06:58:11 TP4] KV Cache is allocated. #tokens: 620169, KV size: 40.59 GB
[2025-09-13 06:58:11 TP0] KV Cache is allocated. #tokens: 620169, KV size: 40.59 GB
[2025-09-13 06:58:11 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 06:58:11 TP3] KV Cache is allocated. #tokens: 620169, KV size: 40.59 GB
[2025-09-13 06:58:11 TP5] KV Cache is allocated. #tokens: 620169, KV size: 40.59 GB
[2025-09-13 06:58:11 TP7] KV Cache is allocated. #tokens: 620169, KV size: 40.59 GB
[2025-09-13 06:58:11 TP6] KV Cache is allocated. #tokens: 620169, KV size: 40.59 GB
[2025-09-13 06:58:11 TP1] KV Cache is allocated. #tokens: 620169, KV size: 40.59 GB
[2025-09-13 06:58:11 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 06:58:12 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.52 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 06:58:13 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:58:13 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 06:58:13 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:58:13 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:58:13 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:58:13 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:58:13 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 06:58:13 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 06:58:13 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25019.85it/s]
[2025-09-13 06:58:13 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:58:13 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26391.54it/s]
[2025-09-13 06:58:14 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:58:14 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27778.13it/s]
[2025-09-13 06:58:15 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:58:15 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27098.11it/s]
[2025-09-13 06:58:15 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:58:15 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27978.16it/s]
[2025-09-13 06:58:16 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.23 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.79it/s][2025-09-13 06:58:19 TP4] Registering 984 cuda graph addresses
[2025-09-13 06:58:19 TP6] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.23 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.12it/s]
[2025-09-13 06:58:19 TP7] Registering 984 cuda graph addresses
[2025-09-13 06:58:19 TP2] Registering 984 cuda graph addresses
[2025-09-13 06:58:19 TP0] Registering 984 cuda graph addresses
[2025-09-13 06:58:19 TP5] Registering 984 cuda graph addresses
[2025-09-13 06:58:19 TP1] Registering 984 cuda graph addresses
[2025-09-13 06:58:19 TP3] Registering 984 cuda graph addresses
[2025-09-13 06:58:19 TP0] Capture cuda graph end. Time elapsed: 7.87 s. mem usage=0.35 GB. avail mem=17.21 GB.
[2025-09-13 06:58:20 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 06:58:20 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:58:20 TP0] Init torch distributed begin.
[2025-09-13 06:58:20 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 06:58:20 TP0] Load weight begin. avail mem=17.21 GB
[2025-09-13 06:58:20 TP0] Detected fp8 checkpoint.
[2025-09-13 06:58:20 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 17/1024 [00:00<00:05, 167.94it/s]
Loading safetensors checkpoint shards:   4% Completed | 37/1024 [00:00<00:05, 186.64it/s]
Loading safetensors checkpoint shards:   9% Completed | 97/1024 [00:00<00:02, 373.46it/s]
Loading safetensors checkpoint shards:  15% Completed | 157/1024 [00:00<00:01, 461.10it/s]
Loading safetensors checkpoint shards:  21% Completed | 217/1024 [00:00<00:01, 510.89it/s]
Loading safetensors checkpoint shards:  27% Completed | 278/1024 [00:00<00:01, 542.79it/s]
Loading safetensors checkpoint shards:  33% Completed | 340/1024 [00:00<00:01, 565.29it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:00<00:01, 578.97it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:00<00:00, 588.89it/s]
Loading safetensors checkpoint shards:  51% Completed | 524/1024 [00:01<00:00, 592.99it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:01<00:00, 596.61it/s]
Loading safetensors checkpoint shards:  63% Completed | 645/1024 [00:01<00:00, 588.49it/s]
Loading safetensors checkpoint shards:  69% Completed | 704/1024 [00:01<00:00, 577.92it/s]
Loading safetensors checkpoint shards:  74% Completed | 762/1024 [00:01<00:00, 566.89it/s]
Loading safetensors checkpoint shards:  80% Completed | 819/1024 [00:01<00:00, 562.46it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:01<00:00, 556.45it/s]
Loading safetensors checkpoint shards:  91% Completed | 932/1024 [00:01<00:00, 556.72it/s]
Loading safetensors checkpoint shards:  96% Completed | 988/1024 [00:01<00:00, 499.18it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 495.30it/s]

[2025-09-13 06:58:22 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.22 GB, mem usage=1.99 GB.
[2025-09-13 06:58:22 TP4] KV Cache is allocated. #tokens: 620169, KV size: 0.67 GB
[2025-09-13 06:58:22 TP0] KV Cache is allocated. #tokens: 620169, KV size: 0.67 GB
[2025-09-13 06:58:22 TP7] KV Cache is allocated. #tokens: 620169, KV size: 0.67 GB
[2025-09-13 06:58:22 TP0] Memory pool end. avail mem=14.55 GB
[2025-09-13 06:58:22 TP5] KV Cache is allocated. #tokens: 620169, KV size: 0.67 GB
[2025-09-13 06:58:22 TP6] KV Cache is allocated. #tokens: 620169, KV size: 0.67 GB
[2025-09-13 06:58:22 TP3] KV Cache is allocated. #tokens: 620169, KV size: 0.67 GB
[2025-09-13 06:58:22 TP1] KV Cache is allocated. #tokens: 620169, KV size: 0.67 GB
[2025-09-13 06:58:22 TP2] KV Cache is allocated. #tokens: 620169, KV size: 0.67 GB
[2025-09-13 06:58:22 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:58:22 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:58:22 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.18 GB
[2025-09-13 06:58:22 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.99 GB
[2025-09-13 06:58:22 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:58:22 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:58:22 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 06:58:22 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
Capturing batches (bs=1 avail_mem=14.68 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  3.15it/s][2025-09-13 06:58:28 TP4] Registering 72 cuda graph addresses
[2025-09-13 06:58:28 TP1] Registering 72 cuda graph addresses
[2025-09-13 06:58:28 TP5] Registering 72 cuda graph addresses
[2025-09-13 06:58:28 TP7] Registering 72 cuda graph addresses
[2025-09-13 06:58:28 TP3] Registering 72 cuda graph addresses
[2025-09-13 06:58:28 TP2] Registering 72 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.68 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.45it/s]
[2025-09-13 06:58:28 TP6] Registering 72 cuda graph addresses
[2025-09-13 06:58:28 TP0] Registering 72 cuda graph addresses
[2025-09-13 06:58:28 TP5] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.30 GB. avail mem=14.64 GB.
[2025-09-13 06:58:28 TP0] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.30 GB. avail mem=14.68 GB.
[2025-09-13 06:58:28 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.68 GB
[2025-09-13 06:58:28 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.64 GB
[2025-09-13 06:58:28 TP1] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.30 GB. avail mem=14.64 GB.
[2025-09-13 06:58:28 TP2] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.30 GB. avail mem=14.64 GB.
[2025-09-13 06:58:28 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.64 GB
[2025-09-13 06:58:28 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.64 GB
[2025-09-13 06:58:28 TP7] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.30 GB. avail mem=14.88 GB.
[2025-09-13 06:58:28 TP6] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.30 GB. avail mem=14.64 GB.
[2025-09-13 06:58:28 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.88 GB
[2025-09-13 06:58:28 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.64 GB
[2025-09-13 06:58:28 TP3] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.30 GB. avail mem=14.64 GB.
[2025-09-13 06:58:28 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.64 GB
[2025-09-13 06:58:28 TP4] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.30 GB. avail mem=14.64 GB.
[2025-09-13 06:58:28 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.64 GB
Capturing batches (bs=1 avail_mem=14.51 GB):  38%|████████████████████████████████▎                                                     | 3/8 [00:00<00:00, 26.96it/s][2025-09-13 06:58:30 TP4] Registering 24 cuda graph addresses
[2025-09-13 06:58:30 TP7] Registering 24 cuda graph addresses
[2025-09-13 06:58:30 TP2] Registering 24 cuda graph addresses
[2025-09-13 06:58:30 TP6] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.51 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 39.55it/s][2025-09-13 06:58:30 TP3] Registering 24 cuda graph addresses
[2025-09-13 06:58:30 TP1] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.51 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 37.55it/s]
[2025-09-13 06:58:30 TP5] Registering 24 cuda graph addresses
[2025-09-13 06:58:30 TP0] Registering 24 cuda graph addresses
[2025-09-13 06:58:30 TP1] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.18 GB. avail mem=14.46 GB.
[2025-09-13 06:58:30 TP7] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.18 GB. avail mem=14.70 GB.
[2025-09-13 06:58:30 TP3] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.18 GB. avail mem=14.46 GB.
[2025-09-13 06:58:30 TP2] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.18 GB. avail mem=14.46 GB.
[2025-09-13 06:58:30 TP5] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.18 GB. avail mem=14.46 GB.
[2025-09-13 06:58:30 TP6] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.18 GB. avail mem=14.46 GB.
[2025-09-13 06:58:30 TP0] Capture draft extend cuda graph end. Time elapsed: 1.16 s. mem usage=0.18 GB. avail mem=14.50 GB.
[2025-09-13 06:58:30 TP4] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.18 GB. avail mem=14.46 GB.
[2025-09-13 06:58:30 TP0] max_total_num_tokens=620169, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.50 GB
[2025-09-13 06:58:30] INFO:     Started server process [194297]
[2025-09-13 06:58:30] INFO:     Waiting for application startup.
[2025-09-13 06:58:30] INFO:     Application startup complete.
[2025-09-13 06:58:30] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 06:58:31] INFO:     127.0.0.1:51712 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 06:58:31 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:58:31 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 06:58:31 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup:  83%|█████████████████████████████████████████████████████████████████████████████████████▏                 | 13551/16384 [00:00<00:00, 28427.16it/s][2025-09-13 06:58:32] INFO:     127.0.0.1:51738 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27635.16it/s]
[2025-09-13 06:58:33] INFO:     127.0.0.1:51724 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:33] The server is fired up and ready to roll!
[2025-09-13 06:58:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:58:43] INFO:     127.0.0.1:60130 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:58:43] INFO:     127.0.0.1:60140 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:43 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 06:58:45] INFO:     127.0.0.1:60146 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:45] INFO:     127.0.0.1:60160 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:58:45] INFO:     127.0.0.1:60170 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:45] INFO:     127.0.0.1:60174 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:45] INFO:     127.0.0.1:60182 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:45] INFO:     127.0.0.1:60188 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:45] INFO:     127.0.0.1:60192 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:45] INFO:     127.0.0.1:60202 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:45 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 06:58:45 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:58:45 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:58:45 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:58:45 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:58:45 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:58:45 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:58:45 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:58:45 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 06:58:45 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 06:58:46 TP0] Decode batch. #running-req: 8, #token: 14585, token usage: 0.02, accept len: 3.04, cuda graph: True, gen throughput (token/s): 42.14, #queue-req: 0, 
[2025-09-13 06:58:47 TP0] Decode batch. #running-req: 8, #token: 15659, token usage: 0.03, accept len: 3.36, cuda graph: True, gen throughput (token/s): 877.41, #queue-req: 0, 
[2025-09-13 06:58:49 TP0] Decode batch. #running-req: 8, #token: 16824, token usage: 0.03, accept len: 3.64, cuda graph: True, gen throughput (token/s): 932.86, #queue-req: 0, 
 38%|█████████████████████████████████████████████████▏                                                                                 | 3/8 [00:04<00:05,  1.18s/it][2025-09-13 06:58:50 TP0] Decode batch. #running-req: 5, #token: 8826, token usage: 0.01, accept len: 3.61, cuda graph: True, gen throughput (token/s): 790.14, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.30it/s]
[2025-09-13 06:58:51] INFO:     127.0.0.1:51844 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.15      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4090      
Request throughput (req/s):              1.30      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         665.57    
Total token throughput (tok/s):          665.57    
Concurrency:                             6.99      
Accept length:                           3.43      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5377.99   
Median E2E Latency (ms):                 5390.06   
---------------Time to First Token----------------
Mean TTFT (ms):                          647.21    
Median TTFT (ms):                        756.92    
P99 TTFT (ms):                           757.38    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.26      
Median ITL (ms):                         6.32      
P95 ITL (ms):                            15.80     
P99 ITL (ms):                            31.29     
Max ITL (ms):                            721.14    
==================================================
[2025-09-13 06:58:51] INFO:     127.0.0.1:51850 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 06:58:51] INFO:     127.0.0.1:51858 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:58:51 TP0] Decode batch. #running-req: 1, #token: 4695, token usage: 0.01, accept len: 3.05, cuda graph: True, gen throughput (token/s): 214.65, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 06:58:52] INFO:     127.0.0.1:51860 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:52] INFO:     127.0.0.1:51876 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 06:58:52] INFO:     127.0.0.1:51884 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:52] INFO:     127.0.0.1:51886 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:52] INFO:     127.0.0.1:51894 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:52] INFO:     127.0.0.1:51898 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:52] INFO:     127.0.0.1:51914 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:52] INFO:     127.0.0.1:51924 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:52 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 06:58:54 TP0] Decode batch. #running-req: 8, #token: 14931, token usage: 0.02, accept len: 3.17, cuda graph: True, gen throughput (token/s): 413.86, #queue-req: 0, 
[2025-09-13 06:58:55 TP0] Decode batch. #running-req: 8, #token: 16034, token usage: 0.03, accept len: 3.45, cuda graph: True, gen throughput (token/s): 892.77, #queue-req: 0, 
[2025-09-13 06:58:56 TP0] Decode batch. #running-req: 8, #token: 17211, token usage: 0.03, accept len: 3.68, cuda graph: True, gen throughput (token/s): 932.45, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:00,  4.02s/it][2025-09-13 06:58:56] INFO:     127.0.0.1:51936 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:56 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:27,  1.93s/it][2025-09-13 06:58:57] INFO:     127.0.0.1:51938 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:04<00:15,  1.23s/it][2025-09-13 06:58:57] INFO:     127.0.0.1:51940 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:57 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:11,  1.06it/s][2025-09-13 06:58:58] INFO:     127.0.0.1:34360 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:58 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:07,  1.46it/s][2025-09-13 06:58:58] INFO:     127.0.0.1:34362 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:58 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.84it/s][2025-09-13 06:58:58] INFO:     127.0.0.1:34374 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:58 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:58:58 TP0] Decode batch. #running-req: 8, #token: 9063, token usage: 0.01, accept len: 3.42, cuda graph: True, gen throughput (token/s): 477.00, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:05,  1.70it/s][2025-09-13 06:58:59] INFO:     127.0.0.1:34376 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:58:59] INFO:     127.0.0.1:34384 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 06:58:59 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 06:59:00 TP0] Decode batch. #running-req: 8, #token: 14745, token usage: 0.02, accept len: 3.14, cuda graph: True, gen throughput (token/s): 634.94, #queue-req: 0, 
[2025-09-13 06:59:01 TP0] Decode batch. #running-req: 8, #token: 15867, token usage: 0.03, accept len: 3.51, cuda graph: True, gen throughput (token/s): 905.51, #queue-req: 0, 
 69%|████████████████████████████████████████████████████████████████████████████████████████▋                                        | 11/16 [00:10<00:03,  1.43it/s][2025-09-13 06:59:02 TP0] Decode batch. #running-req: 5, #token: 12878, token usage: 0.02, accept len: 3.59, cuda graph: True, gen throughput (token/s): 840.73, #queue-req: 0, 
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 14/16 [00:11<00:00,  2.07it/s][2025-09-13 06:59:03 TP0] Decode batch. #running-req: 2, #token: 7791, token usage: 0.01, accept len: 3.56, cuda graph: True, gen throughput (token/s): 518.60, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.36it/s]
[2025-09-13 06:59:04] INFO:     127.0.0.1:34400 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.81     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8150      
Request throughput (req/s):              1.36      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         693.86    
Total token throughput (tok/s):          693.86    
Concurrency:                             7.24      
Accept length:                           3.42      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5340.30   
Median E2E Latency (ms):                 5223.47   
---------------Time to First Token----------------
Mean TTFT (ms):                          237.73    
Median TTFT (ms):                        263.12    
P99 TTFT (ms):                           378.73    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.99      
Median ITL (ms):                         6.38      
P95 ITL (ms):                            30.10     
P99 ITL (ms):                            55.49     
Max ITL (ms):                            263.25    
==================================================
[2025-09-13 06:59:04] INFO:     127.0.0.1:34410 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=12: batch_size=8, steps=4, topk=2, num_draft_tokens=6, speed=110.51 token/s, step_time=30.94 ms
Start i=13: batch_size=8, steps=4, topk=2, num_draft_tokens=8
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 4 --speculative-eagle-topk 2 --speculative-num-draft-tokens 8 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 06:59:15.194000 199934 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:59:15.194000 199934 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 06:59:15] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=6286465, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=4, speculative_eagle_topk=2, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:59:15] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:59:24.415000 200145 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:59:24.415000 200145 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:59:24.432000 200150 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:59:24.432000 200150 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:59:24.597000 200148 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:59:24.597000 200148 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:59:24.616000 200147 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:59:24.616000 200147 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 06:59:24.724000 200146 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:59:24.724000 200146 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:59:24.732000 200144 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:59:24.732000 200144 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 06:59:24.760000 200142 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:59:24.760000 200142 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 06:59:24.780000 200143 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:59:24.780000 200143 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 06:59:24.835000 200149 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 06:59:24.835000 200149 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 06:59:25 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 06:59:25 TP0] Chunked prefix cache is turned on.
[2025-09-13 06:59:25 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:59:27 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 06:59:29 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 06:59:31 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 06:59:31 TP0] Detected fp8 checkpoint.
[2025-09-13 06:59:31 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 24/1024 [00:00<00:04, 234.32it/s]
Loading safetensors checkpoint shards:   5% Completed | 48/1024 [00:00<00:14, 68.39it/s]
Loading safetensors checkpoint shards:   6% Completed | 61/1024 [00:00<00:14, 65.13it/s]
Loading safetensors checkpoint shards:   7% Completed | 71/1024 [00:01<00:17, 54.02it/s]
Loading safetensors checkpoint shards:   8% Completed | 79/1024 [00:01<00:17, 53.84it/s]
Loading safetensors checkpoint shards:   8% Completed | 86/1024 [00:01<00:18, 50.00it/s]
Loading safetensors checkpoint shards:   9% Completed | 92/1024 [00:01<00:21, 44.20it/s]
Loading safetensors checkpoint shards:   9% Completed | 97/1024 [00:01<00:22, 41.40it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:02<00:35, 26.26it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:02<00:30, 29.59it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:30, 29.70it/s]
Loading safetensors checkpoint shards:  11% Completed | 116/1024 [00:02<00:28, 32.36it/s]
Loading safetensors checkpoint shards:  12% Completed | 121/1024 [00:02<00:25, 35.77it/s]
Loading safetensors checkpoint shards:  12% Completed | 126/1024 [00:02<00:23, 38.42it/s]
Loading safetensors checkpoint shards:  13% Completed | 131/1024 [00:02<00:23, 38.26it/s]
Loading safetensors checkpoint shards:  13% Completed | 136/1024 [00:03<00:24, 36.91it/s]
Loading safetensors checkpoint shards:  14% Completed | 141/1024 [00:03<00:22, 39.65it/s]
Loading safetensors checkpoint shards:  14% Completed | 146/1024 [00:03<00:22, 38.65it/s]
Loading safetensors checkpoint shards:  15% Completed | 151/1024 [00:03<00:22, 38.85it/s]
Loading safetensors checkpoint shards:  15% Completed | 155/1024 [00:03<00:22, 38.37it/s]
Loading safetensors checkpoint shards:  16% Completed | 159/1024 [00:03<00:22, 37.96it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:03<00:23, 37.15it/s]
Loading safetensors checkpoint shards:  16% Completed | 168/1024 [00:03<00:23, 36.88it/s]
Loading safetensors checkpoint shards:  17% Completed | 172/1024 [00:04<00:22, 37.41it/s]
Loading safetensors checkpoint shards:  17% Completed | 176/1024 [00:04<00:22, 37.50it/s]
Loading safetensors checkpoint shards:  18% Completed | 180/1024 [00:04<00:23, 36.04it/s]
Loading safetensors checkpoint shards:  18% Completed | 185/1024 [00:04<00:21, 38.19it/s]
Loading safetensors checkpoint shards:  18% Completed | 189/1024 [00:04<00:21, 38.66it/s]
Loading safetensors checkpoint shards:  19% Completed | 194/1024 [00:04<00:20, 41.04it/s]
Loading safetensors checkpoint shards:  19% Completed | 199/1024 [00:04<00:20, 40.70it/s]
Loading safetensors checkpoint shards:  20% Completed | 204/1024 [00:04<00:19, 41.37it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:04<00:20, 40.16it/s]
Loading safetensors checkpoint shards:  21% Completed | 214/1024 [00:05<00:20, 39.23it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:05<00:20, 39.18it/s]
Loading safetensors checkpoint shards:  22% Completed | 223/1024 [00:05<00:20, 38.76it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:05<00:20, 39.03it/s]
Loading safetensors checkpoint shards:  23% Completed | 231/1024 [00:05<00:20, 38.39it/s]
Loading safetensors checkpoint shards:  23% Completed | 235/1024 [00:05<00:20, 37.70it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:05<00:19, 39.61it/s]
Loading safetensors checkpoint shards:  24% Completed | 244/1024 [00:05<00:19, 39.23it/s]
Loading safetensors checkpoint shards:  24% Completed | 250/1024 [00:05<00:18, 42.87it/s]
Loading safetensors checkpoint shards:  25% Completed | 255/1024 [00:06<00:19, 40.03it/s]
Loading safetensors checkpoint shards:  25% Completed | 260/1024 [00:06<00:18, 41.51it/s]
Loading safetensors checkpoint shards:  26% Completed | 265/1024 [00:06<00:18, 40.58it/s]
Loading safetensors checkpoint shards:  26% Completed | 270/1024 [00:06<00:18, 39.98it/s]
Loading safetensors checkpoint shards:  27% Completed | 275/1024 [00:06<00:18, 40.43it/s]
Loading safetensors checkpoint shards:  27% Completed | 280/1024 [00:06<00:18, 39.69it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:06<00:17, 41.56it/s]
Loading safetensors checkpoint shards:  28% Completed | 290/1024 [00:06<00:18, 40.19it/s]
Loading safetensors checkpoint shards:  29% Completed | 295/1024 [00:07<00:17, 40.75it/s]
Loading safetensors checkpoint shards:  29% Completed | 300/1024 [00:07<00:32, 22.00it/s]
Loading safetensors checkpoint shards:  30% Completed | 305/1024 [00:07<00:27, 25.93it/s]
Loading safetensors checkpoint shards:  30% Completed | 309/1024 [00:07<00:26, 27.21it/s]
Loading safetensors checkpoint shards:  31% Completed | 313/1024 [00:07<00:24, 28.82it/s]
Loading safetensors checkpoint shards:  31% Completed | 318/1024 [00:08<00:22, 32.06it/s]
Loading safetensors checkpoint shards:  31% Completed | 322/1024 [00:08<00:21, 32.68it/s]
Loading safetensors checkpoint shards:  32% Completed | 327/1024 [00:08<00:19, 35.30it/s]
Loading safetensors checkpoint shards:  32% Completed | 331/1024 [00:08<00:19, 36.26it/s]
Loading safetensors checkpoint shards:  33% Completed | 335/1024 [00:08<00:18, 37.14it/s]
Loading safetensors checkpoint shards:  33% Completed | 340/1024 [00:08<00:17, 39.31it/s]
Loading safetensors checkpoint shards:  34% Completed | 345/1024 [00:08<00:18, 37.65it/s]
Loading safetensors checkpoint shards:  34% Completed | 350/1024 [00:08<00:17, 39.35it/s]
Loading safetensors checkpoint shards:  35% Completed | 355/1024 [00:08<00:17, 37.89it/s]
Loading safetensors checkpoint shards:  35% Completed | 359/1024 [00:09<00:17, 38.17it/s]
Loading safetensors checkpoint shards:  35% Completed | 363/1024 [00:09<00:17, 38.38it/s]
Loading safetensors checkpoint shards:  36% Completed | 367/1024 [00:09<00:17, 38.13it/s]
Loading safetensors checkpoint shards:  36% Completed | 372/1024 [00:09<00:16, 39.66it/s]
Loading safetensors checkpoint shards:  37% Completed | 376/1024 [00:09<00:16, 38.76it/s]
Loading safetensors checkpoint shards:  37% Completed | 380/1024 [00:09<00:17, 35.79it/s]
Loading safetensors checkpoint shards:  38% Completed | 385/1024 [00:09<00:17, 37.43it/s]
Loading safetensors checkpoint shards:  38% Completed | 389/1024 [00:09<00:17, 36.94it/s]
Loading safetensors checkpoint shards:  38% Completed | 393/1024 [00:09<00:16, 37.34it/s]
Loading safetensors checkpoint shards:  39% Completed | 397/1024 [00:10<00:16, 36.90it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:10<00:17, 36.50it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:10<00:16, 38.41it/s]
Loading safetensors checkpoint shards:  40% Completed | 410/1024 [00:10<00:16, 38.24it/s]
Loading safetensors checkpoint shards:  40% Completed | 414/1024 [00:10<00:15, 38.54it/s]
Loading safetensors checkpoint shards:  41% Completed | 418/1024 [00:10<00:15, 38.83it/s]
Loading safetensors checkpoint shards:  41% Completed | 422/1024 [00:10<00:15, 38.05it/s]
Loading safetensors checkpoint shards:  42% Completed | 427/1024 [00:10<00:15, 39.64it/s]
Loading safetensors checkpoint shards:  42% Completed | 431/1024 [00:10<00:15, 38.51it/s]
Loading safetensors checkpoint shards:  42% Completed | 435/1024 [00:11<00:15, 36.90it/s]
Loading safetensors checkpoint shards:  43% Completed | 440/1024 [00:11<00:15, 38.62it/s]
Loading safetensors checkpoint shards:  43% Completed | 444/1024 [00:11<00:15, 37.84it/s]
Loading safetensors checkpoint shards:  44% Completed | 448/1024 [00:11<00:15, 38.40it/s]
Loading safetensors checkpoint shards:  44% Completed | 452/1024 [00:11<00:15, 37.47it/s]
Loading safetensors checkpoint shards:  45% Completed | 456/1024 [00:11<00:15, 37.12it/s]
Loading safetensors checkpoint shards:  45% Completed | 461/1024 [00:11<00:14, 38.33it/s]
Loading safetensors checkpoint shards:  46% Completed | 466/1024 [00:11<00:13, 40.22it/s]
Loading safetensors checkpoint shards:  46% Completed | 474/1024 [00:11<00:11, 48.94it/s]
Loading safetensors checkpoint shards:  47% Completed | 479/1024 [00:12<00:11, 45.95it/s]
Loading safetensors checkpoint shards:  47% Completed | 485/1024 [00:12<00:11, 47.57it/s]
Loading safetensors checkpoint shards:  48% Completed | 490/1024 [00:12<00:11, 45.61it/s]
Loading safetensors checkpoint shards:  49% Completed | 498/1024 [00:12<00:09, 53.72it/s]
Loading safetensors checkpoint shards:  49% Completed | 505/1024 [00:12<00:09, 57.45it/s]
Loading safetensors checkpoint shards:  50% Completed | 511/1024 [00:12<00:10, 47.38it/s]
Loading safetensors checkpoint shards:  50% Completed | 517/1024 [00:12<00:11, 45.98it/s]
Loading safetensors checkpoint shards:  51% Completed | 522/1024 [00:13<00:12, 41.22it/s]
Loading safetensors checkpoint shards:  51% Completed | 527/1024 [00:13<00:22, 21.66it/s]
Loading safetensors checkpoint shards:  52% Completed | 531/1024 [00:13<00:20, 23.98it/s]
Loading safetensors checkpoint shards:  52% Completed | 535/1024 [00:13<00:19, 25.06it/s]
Loading safetensors checkpoint shards:  53% Completed | 540/1024 [00:13<00:16, 29.19it/s]
Loading safetensors checkpoint shards:  53% Completed | 544/1024 [00:14<00:15, 30.80it/s]
Loading safetensors checkpoint shards:  54% Completed | 550/1024 [00:14<00:13, 35.80it/s]
Loading safetensors checkpoint shards:  54% Completed | 555/1024 [00:14<00:12, 36.69it/s]
Loading safetensors checkpoint shards:  55% Completed | 560/1024 [00:14<00:12, 37.85it/s]
Loading safetensors checkpoint shards:  55% Completed | 565/1024 [00:14<00:12, 37.90it/s]
Loading safetensors checkpoint shards:  56% Completed | 570/1024 [00:14<00:11, 40.26it/s]
Loading safetensors checkpoint shards:  56% Completed | 575/1024 [00:14<00:11, 39.68it/s]
Loading safetensors checkpoint shards:  57% Completed | 580/1024 [00:14<00:11, 40.17it/s]
Loading safetensors checkpoint shards:  57% Completed | 586/1024 [00:15<00:09, 44.74it/s]
Loading safetensors checkpoint shards:  58% Completed | 591/1024 [00:15<00:09, 43.44it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:15<00:09, 45.02it/s]
Loading safetensors checkpoint shards:  59% Completed | 601/1024 [00:15<00:09, 44.56it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:15<00:09, 45.04it/s]
Loading safetensors checkpoint shards:  60% Completed | 611/1024 [00:15<00:09, 44.36it/s]
Loading safetensors checkpoint shards:  60% Completed | 617/1024 [00:15<00:08, 45.94it/s]
Loading safetensors checkpoint shards:  61% Completed | 622/1024 [00:15<00:08, 45.59it/s]
Loading safetensors checkpoint shards:  61% Completed | 627/1024 [00:15<00:08, 45.29it/s]
Loading safetensors checkpoint shards:  62% Completed | 632/1024 [00:16<00:09, 43.40it/s]
Loading safetensors checkpoint shards:  62% Completed | 637/1024 [00:16<00:08, 43.20it/s]
Loading safetensors checkpoint shards:  63% Completed | 642/1024 [00:16<00:08, 42.63it/s]
Loading safetensors checkpoint shards:  63% Completed | 647/1024 [00:16<00:09, 41.51it/s]
Loading safetensors checkpoint shards:  64% Completed | 652/1024 [00:16<00:08, 41.59it/s]
Loading safetensors checkpoint shards:  64% Completed | 657/1024 [00:16<00:08, 41.59it/s]
Loading safetensors checkpoint shards:  65% Completed | 662/1024 [00:16<00:09, 39.30it/s]
Loading safetensors checkpoint shards:  65% Completed | 667/1024 [00:16<00:08, 39.94it/s]
Loading safetensors checkpoint shards:  66% Completed | 672/1024 [00:17<00:08, 40.56it/s]
Loading safetensors checkpoint shards:  66% Completed | 677/1024 [00:17<00:08, 40.06it/s]
Loading safetensors checkpoint shards:  67% Completed | 682/1024 [00:17<00:08, 40.83it/s]
Loading safetensors checkpoint shards:  67% Completed | 687/1024 [00:17<00:08, 41.72it/s]
Loading safetensors checkpoint shards:  68% Completed | 693/1024 [00:17<00:07, 44.50it/s]
Loading safetensors checkpoint shards:  68% Completed | 698/1024 [00:17<00:07, 45.38it/s]
Loading safetensors checkpoint shards:  69% Completed | 703/1024 [00:17<00:07, 44.43it/s]
Loading safetensors checkpoint shards:  69% Completed | 708/1024 [00:17<00:07, 45.01it/s]
Loading safetensors checkpoint shards:  70% Completed | 713/1024 [00:17<00:06, 45.63it/s]
Loading safetensors checkpoint shards:  70% Completed | 718/1024 [00:18<00:06, 43.81it/s]
Loading safetensors checkpoint shards:  71% Completed | 723/1024 [00:18<00:06, 43.85it/s]
Loading safetensors checkpoint shards:  71% Completed | 728/1024 [00:18<00:06, 43.74it/s]
Loading safetensors checkpoint shards:  72% Completed | 733/1024 [00:18<00:06, 42.80it/s]
Loading safetensors checkpoint shards:  72% Completed | 738/1024 [00:18<00:06, 42.97it/s]
Loading safetensors checkpoint shards:  73% Completed | 743/1024 [00:18<00:06, 43.37it/s]
Loading safetensors checkpoint shards:  73% Completed | 748/1024 [00:18<00:06, 42.10it/s]
Loading safetensors checkpoint shards:  74% Completed | 753/1024 [00:18<00:06, 41.90it/s]
Loading safetensors checkpoint shards:  74% Completed | 758/1024 [00:19<00:06, 41.96it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:19<00:06, 42.95it/s]
Loading safetensors checkpoint shards:  75% Completed | 768/1024 [00:19<00:06, 42.56it/s]
Loading safetensors checkpoint shards:  75% Completed | 773/1024 [00:19<00:06, 41.37it/s]
Loading safetensors checkpoint shards:  76% Completed | 778/1024 [00:19<00:05, 41.86it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:19<00:05, 42.41it/s]
Loading safetensors checkpoint shards:  77% Completed | 788/1024 [00:19<00:05, 41.59it/s]
Loading safetensors checkpoint shards:  77% Completed | 793/1024 [00:19<00:05, 42.60it/s]
Loading safetensors checkpoint shards:  78% Completed | 798/1024 [00:19<00:05, 43.32it/s]
Loading safetensors checkpoint shards:  78% Completed | 803/1024 [00:20<00:04, 44.95it/s]
Loading safetensors checkpoint shards:  79% Completed | 808/1024 [00:20<00:04, 44.47it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:20<00:04, 43.41it/s]
Loading safetensors checkpoint shards:  80% Completed | 818/1024 [00:20<00:04, 42.42it/s]
Loading safetensors checkpoint shards:  80% Completed | 823/1024 [00:21<00:11, 17.96it/s]
Loading safetensors checkpoint shards:  81% Completed | 828/1024 [00:21<00:09, 21.77it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:21<00:07, 25.81it/s]
Loading safetensors checkpoint shards:  82% Completed | 838/1024 [00:21<00:06, 29.48it/s]
Loading safetensors checkpoint shards:  82% Completed | 843/1024 [00:21<00:05, 32.10it/s]
Loading safetensors checkpoint shards:  83% Completed | 848/1024 [00:21<00:05, 35.02it/s]
Loading safetensors checkpoint shards:  83% Completed | 853/1024 [00:21<00:04, 37.38it/s]
Loading safetensors checkpoint shards:  84% Completed | 858/1024 [00:21<00:04, 38.61it/s]
Loading safetensors checkpoint shards:  84% Completed | 863/1024 [00:22<00:04, 38.90it/s]
Loading safetensors checkpoint shards:  85% Completed | 868/1024 [00:22<00:03, 39.71it/s]
Loading safetensors checkpoint shards:  85% Completed | 873/1024 [00:22<00:03, 40.82it/s]
Loading safetensors checkpoint shards:  86% Completed | 878/1024 [00:22<00:03, 39.69it/s]
Loading safetensors checkpoint shards:  86% Completed | 883/1024 [00:22<00:03, 40.63it/s]
Loading safetensors checkpoint shards:  87% Completed | 888/1024 [00:22<00:03, 41.56it/s]
Loading safetensors checkpoint shards:  87% Completed | 893/1024 [00:22<00:03, 41.04it/s]
Loading safetensors checkpoint shards:  88% Completed | 898/1024 [00:22<00:03, 41.30it/s]
Loading safetensors checkpoint shards:  88% Completed | 903/1024 [00:22<00:02, 42.10it/s]
Loading safetensors checkpoint shards:  89% Completed | 908/1024 [00:23<00:02, 42.85it/s]
Loading safetensors checkpoint shards:  89% Completed | 913/1024 [00:23<00:02, 42.17it/s]
Loading safetensors checkpoint shards:  90% Completed | 919/1024 [00:23<00:02, 44.36it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:23<00:02, 43.89it/s]
Loading safetensors checkpoint shards:  91% Completed | 929/1024 [00:23<00:02, 43.43it/s]
Loading safetensors checkpoint shards:  91% Completed | 934/1024 [00:23<00:02, 41.96it/s]
Loading safetensors checkpoint shards:  92% Completed | 939/1024 [00:23<00:02, 42.40it/s]
Loading safetensors checkpoint shards:  92% Completed | 944/1024 [00:23<00:01, 43.26it/s]
Loading safetensors checkpoint shards:  93% Completed | 949/1024 [00:24<00:01, 42.02it/s]
Loading safetensors checkpoint shards:  93% Completed | 954/1024 [00:24<00:01, 42.07it/s]
Loading safetensors checkpoint shards:  94% Completed | 959/1024 [00:24<00:01, 41.97it/s]
Loading safetensors checkpoint shards:  94% Completed | 964/1024 [00:24<00:01, 41.14it/s]
Loading safetensors checkpoint shards:  95% Completed | 969/1024 [00:24<00:01, 42.12it/s]
Loading safetensors checkpoint shards:  95% Completed | 974/1024 [00:24<00:01, 41.94it/s]
Loading safetensors checkpoint shards:  96% Completed | 979/1024 [00:24<00:01, 43.00it/s]
Loading safetensors checkpoint shards:  98% Completed | 999/1024 [00:24<00:00, 84.58it/s]
Loading safetensors checkpoint shards:  98% Completed | 1008/1024 [00:24<00:00, 80.39it/s]
Loading safetensors checkpoint shards: 100% Completed | 1019/1024 [00:25<00:00, 88.21it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 40.83it/s]

[2025-09-13 06:59:57 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:00:00 TP0] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:00:00 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:00:00 TP3] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:00:00 TP6] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:00:00 TP7] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:00:00 TP5] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:00:00 TP4] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:00:00 TP2] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:00:00 TP1] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:00:00 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:00:01 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.51 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:00:01 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:00:01 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:00:02 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:00:02 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:00:02 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:00:02 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:00:02 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:00:02 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:00:02 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26312.43it/s]
[2025-09-13 07:00:02 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:00:02 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27374.19it/s]
[2025-09-13 07:00:03 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:00:03 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28785.90it/s]
[2025-09-13 07:00:03 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:00:03 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28262.05it/s]
[2025-09-13 07:00:04 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:00:04 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 29339.71it/s]
[2025-09-13 07:00:04 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.20 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.77it/s][2025-09-13 07:00:08 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:00:08 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:00:08 TP3] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.20 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  2.00it/s][2025-09-13 07:00:08 TP4] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.20 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.15it/s][2025-09-13 07:00:08 TP6] Registering 984 cuda graph addresses

[2025-09-13 07:00:08 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:00:08 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:00:08 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:00:08 TP0] Capture cuda graph end. Time elapsed: 7.65 s. mem usage=0.39 GB. avail mem=17.17 GB.
[2025-09-13 07:00:08 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:00:08 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:00:08 TP0] Init torch distributed begin.
[2025-09-13 07:00:08 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:00:08 TP0] Load weight begin. avail mem=17.17 GB
[2025-09-13 07:00:08 TP0] Detected fp8 checkpoint.
[2025-09-13 07:00:08 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 172.66it/s]
Loading safetensors checkpoint shards:   4% Completed | 36/1024 [00:00<00:05, 171.71it/s]
Loading safetensors checkpoint shards:   6% Completed | 66/1024 [00:00<00:04, 228.09it/s]
Loading safetensors checkpoint shards:  11% Completed | 114/1024 [00:00<00:02, 324.92it/s]
Loading safetensors checkpoint shards:  17% Completed | 178/1024 [00:00<00:01, 435.84it/s]
Loading safetensors checkpoint shards:  24% Completed | 242/1024 [00:00<00:01, 502.42it/s]
Loading safetensors checkpoint shards:  30% Completed | 306/1024 [00:00<00:01, 546.70it/s]
Loading safetensors checkpoint shards:  36% Completed | 370/1024 [00:00<00:01, 574.83it/s]
Loading safetensors checkpoint shards:  42% Completed | 434/1024 [00:00<00:00, 593.59it/s]
Loading safetensors checkpoint shards:  49% Completed | 499/1024 [00:01<00:00, 608.21it/s]
Loading safetensors checkpoint shards:  55% Completed | 563/1024 [00:01<00:00, 617.20it/s]
Loading safetensors checkpoint shards:  61% Completed | 627/1024 [00:01<00:00, 623.46it/s]
Loading safetensors checkpoint shards:  67% Completed | 690/1024 [00:01<00:00, 613.71it/s]
Loading safetensors checkpoint shards:  73% Completed | 752/1024 [00:01<00:00, 610.08it/s]
Loading safetensors checkpoint shards:  79% Completed | 814/1024 [00:01<00:00, 607.96it/s]
Loading safetensors checkpoint shards:  85% Completed | 875/1024 [00:01<00:00, 604.32it/s]
Loading safetensors checkpoint shards:  91% Completed | 936/1024 [00:01<00:00, 604.50it/s]
Loading safetensors checkpoint shards:  97% Completed | 997/1024 [00:01<00:00, 495.12it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 499.00it/s]

[2025-09-13 07:00:10 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.18 GB, mem usage=1.99 GB.
[2025-09-13 07:00:10 TP0] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:00:10 TP6] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:00:10 TP5] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:00:10 TP0] Memory pool end. avail mem=14.52 GB
[2025-09-13 07:00:10 TP3] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:00:10 TP2] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:00:10 TP4] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:00:10 TP7] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:00:10 TP1] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:00:11 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:00:11 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.95 GB
[2025-09-13 07:00:11 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:00:11 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.14 GB
[2025-09-13 07:00:11 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:00:11 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:00:11 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:00:11 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
Capturing batches (bs=1 avail_mem=14.65 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  3.12it/s][2025-09-13 07:00:17 TP3] Registering 72 cuda graph addresses
[2025-09-13 07:00:17 TP7] Registering 72 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.65 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.42it/s]
[2025-09-13 07:00:17 TP0] Registering 72 cuda graph addresses
[2025-09-13 07:00:17 TP6] Registering 72 cuda graph addresses
[2025-09-13 07:00:17 TP5] Registering 72 cuda graph addresses
[2025-09-13 07:00:17 TP4] Registering 72 cuda graph addresses
[2025-09-13 07:00:17 TP2] Registering 72 cuda graph addresses
[2025-09-13 07:00:17 TP1] Registering 72 cuda graph addresses
[2025-09-13 07:00:17 TP1] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.30 GB. avail mem=14.60 GB.
[2025-09-13 07:00:17 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.60 GB
[2025-09-13 07:00:17 TP0] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.31 GB. avail mem=14.64 GB.
[2025-09-13 07:00:17 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.64 GB
[2025-09-13 07:00:17 TP2] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.30 GB. avail mem=14.60 GB.
[2025-09-13 07:00:17 TP4] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.30 GB. avail mem=14.60 GB.
[2025-09-13 07:00:17 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.60 GB
[2025-09-13 07:00:17 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.60 GB
[2025-09-13 07:00:17 TP3] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.30 GB. avail mem=14.60 GB.
[2025-09-13 07:00:17 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.60 GB
[2025-09-13 07:00:17 TP7] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.30 GB. avail mem=14.84 GB.
[2025-09-13 07:00:17 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.84 GB
[2025-09-13 07:00:17 TP6] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.30 GB. avail mem=14.60 GB.
[2025-09-13 07:00:17 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.60 GB
[2025-09-13 07:00:17 TP5] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.30 GB. avail mem=14.60 GB.
[2025-09-13 07:00:17 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.60 GB
Capturing batches (bs=1 avail_mem=14.47 GB):  62%|█████████████████████████████████████████████████████▊                                | 5/8 [00:00<00:00, 16.89it/s][2025-09-13 07:00:18 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:00:18 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:00:18 TP2] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.47 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 19.44it/s]
[2025-09-13 07:00:18 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:00:18 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:00:18 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:00:18 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:00:18 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:00:18 TP7] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.18 GB. avail mem=14.66 GB.
[2025-09-13 07:00:18 TP1] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.18 GB. avail mem=14.43 GB.
[2025-09-13 07:00:18 TP4] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.18 GB. avail mem=14.43 GB.
[2025-09-13 07:00:18 TP3] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.18 GB. avail mem=14.43 GB.
[2025-09-13 07:00:18 TP5] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.18 GB. avail mem=14.43 GB.
[2025-09-13 07:00:18 TP2] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.18 GB. avail mem=14.43 GB.
[2025-09-13 07:00:18 TP0] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.18 GB. avail mem=14.47 GB.
[2025-09-13 07:00:18 TP6] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.18 GB. avail mem=14.43 GB.
[2025-09-13 07:00:18 TP0] max_total_num_tokens=620185, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.47 GB
[2025-09-13 07:00:19] INFO:     Started server process [199934]
[2025-09-13 07:00:19] INFO:     Waiting for application startup.
[2025-09-13 07:00:19] INFO:     Application startup complete.
[2025-09-13 07:00:19] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:00:19] INFO:     127.0.0.1:41422 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:00:20] INFO:     127.0.0.1:41424 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:00:20 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:00:20 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:00:20 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27153.41it/s]
[2025-09-13 07:00:21] INFO:     127.0.0.1:41430 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:21] The server is fired up and ready to roll!
[2025-09-13 07:00:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:00:30] INFO:     127.0.0.1:40862 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:00:30] INFO:     127.0.0.1:40870 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:30 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:00:32] INFO:     127.0.0.1:40882 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:32] INFO:     127.0.0.1:40884 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:00:32] INFO:     127.0.0.1:40892 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:32] INFO:     127.0.0.1:40902 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:32] INFO:     127.0.0.1:40914 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:32] INFO:     127.0.0.1:40930 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:32] INFO:     127.0.0.1:40936 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:32] INFO:     127.0.0.1:40952 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:32 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:00:33 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:00:33 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:00:33 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:00:33 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:00:33 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:00:33 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:00:33 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:00:33 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:00:33 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:00:34 TP0] Decode batch. #running-req: 8, #token: 14630, token usage: 0.02, accept len: 3.24, cuda graph: True, gen throughput (token/s): 49.11, #queue-req: 0, 
[2025-09-13 07:00:35 TP0] Decode batch. #running-req: 8, #token: 15724, token usage: 0.03, accept len: 3.42, cuda graph: True, gen throughput (token/s): 849.09, #queue-req: 0, 
[2025-09-13 07:00:36 TP0] Decode batch. #running-req: 8, #token: 16938, token usage: 0.03, accept len: 3.79, cuda graph: True, gen throughput (token/s): 930.82, #queue-req: 0, 
 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 7/8 [00:05<00:00,  2.64it/s][2025-09-13 07:00:38 TP0] Decode batch. #running-req: 1, #token: 1468, token usage: 0.00, accept len: 3.86, cuda graph: True, gen throughput (token/s): 702.80, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.35it/s]
[2025-09-13 07:00:38] INFO:     127.0.0.1:34776 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  5.93      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4092      
Request throughput (req/s):              1.35      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         690.49    
Total token throughput (tok/s):          690.49    
Concurrency:                             7.29      
Accept length:                           3.59      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5408.64   
Median E2E Latency (ms):                 5405.62   
---------------Time to First Token----------------
Mean TTFT (ms):                          617.71    
Median TTFT (ms):                        729.70    
P99 TTFT (ms):                           730.13    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.38      
Median ITL (ms):                         6.57      
P95 ITL (ms):                            16.33     
P99 ITL (ms):                            32.63     
Max ITL (ms):                            734.64    
==================================================
[2025-09-13 07:00:38] INFO:     127.0.0.1:34782 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:00:38] INFO:     127.0.0.1:34788 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:00:39] INFO:     127.0.0.1:34800 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:39] INFO:     127.0.0.1:34802 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:00:39] INFO:     127.0.0.1:34810 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:39] INFO:     127.0.0.1:34820 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:39] INFO:     127.0.0.1:34824 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:39] INFO:     127.0.0.1:34830 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:39] INFO:     127.0.0.1:34842 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:39] INFO:     127.0.0.1:34856 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:39 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:00:40 TP0] Decode batch. #running-req: 8, #token: 14343, token usage: 0.02, accept len: 3.16, cuda graph: True, gen throughput (token/s): 212.73, #queue-req: 0, 
[2025-09-13 07:00:41 TP0] Decode batch. #running-req: 8, #token: 15440, token usage: 0.02, accept len: 3.43, cuda graph: True, gen throughput (token/s): 854.77, #queue-req: 0, 
[2025-09-13 07:00:43 TP0] Decode batch. #running-req: 8, #token: 16636, token usage: 0.03, accept len: 3.74, cuda graph: True, gen throughput (token/s): 917.12, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:05,  4.37s/it][2025-09-13 07:00:44] INFO:     127.0.0.1:34858 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:44 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:00:44 TP0] Decode batch. #running-req: 8, #token: 8795, token usage: 0.01, accept len: 3.80, cuda graph: True, gen throughput (token/s): 782.19, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:29,  2.12s/it][2025-09-13 07:00:44] INFO:     127.0.0.1:34870 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:44] INFO:     127.0.0.1:34882 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:44 TP0] Prefill batch. #new-seq: 2, #new-token: 2409, #cached-token: 1752, token usage: 0.01, #running-req: 6, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.13it/s][2025-09-13 07:00:44] INFO:     127.0.0.1:34888 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:44 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:00:44] INFO:     127.0.0.1:34892 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:45 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.76it/s][2025-09-13 07:00:45] INFO:     127.0.0.1:34896 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:45 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:00:45] INFO:     127.0.0.1:34912 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:04,  1.97it/s][2025-09-13 07:00:46] INFO:     127.0.0.1:34914 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:00:46 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:00:46 TP0] Decode batch. #running-req: 8, #token: 14357, token usage: 0.02, accept len: 3.34, cuda graph: True, gen throughput (token/s): 463.45, #queue-req: 0, 
[2025-09-13 07:00:48 TP0] Decode batch. #running-req: 8, #token: 15524, token usage: 0.03, accept len: 3.65, cuda graph: True, gen throughput (token/s): 895.07, #queue-req: 0, 
[2025-09-13 07:00:49 TP0] Decode batch. #running-req: 8, #token: 16813, token usage: 0.03, accept len: 4.03, cuda graph: True, gen throughput (token/s): 981.14, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.47it/s]
[2025-09-13 07:00:50] INFO:     127.0.0.1:36316 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  10.92     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8087      
Request throughput (req/s):              1.47      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         750.16    
Total token throughput (tok/s):          750.16    
Concurrency:                             7.70      
Accept length:                           3.61      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5256.07   
Median E2E Latency (ms):                 5219.15   
---------------Time to First Token----------------
Mean TTFT (ms):                          245.61    
Median TTFT (ms):                        282.55    
P99 TTFT (ms):                           360.16    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.81      
Median ITL (ms):                         6.58      
P95 ITL (ms):                            17.01     
P99 ITL (ms):                            53.48     
Max ITL (ms):                            267.41    
==================================================
[2025-09-13 07:00:50] INFO:     127.0.0.1:36318 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=13: batch_size=8, steps=4, topk=2, num_draft_tokens=8, speed=111.09 token/s, step_time=32.52 ms
Start i=14: batch_size=8, steps=4, topk=3, num_draft_tokens=4
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 4 --speculative-eagle-topk 3 --speculative-num-draft-tokens 4 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:01:01.559000 205519 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:01:01.559000 205519 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:01:01] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=302495163, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=4, speculative_eagle_topk=3, speculative_num_draft_tokens=4, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:01:02] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:01:10.730000 205730 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:01:10.730000 205730 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:01:10.794000 205727 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:01:10.794000 205727 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:01:10.919000 205732 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:01:10.919000 205732 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:01:10.979000 205728 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:01:10.979000 205728 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:01:11.019000 205733 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:01:11.019000 205733 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:01:11.057000 205729 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:01:11.057000 205729 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:01:11.058000 205731 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:01:11.058000 205731 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:01:11.098000 205735 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:01:11.098000 205735 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:01:11.112000 205734 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:01:11.112000 205734 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:01:11 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:01:11 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:01:11 TP0] Init torch distributed begin.
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:01:12 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:01:16 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:01:17 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:01:17 TP0] Detected fp8 checkpoint.
[2025-09-13 07:01:18 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 25/1024 [00:00<00:04, 241.72it/s]
Loading safetensors checkpoint shards:   5% Completed | 50/1024 [00:00<00:07, 128.23it/s]
Loading safetensors checkpoint shards:   6% Completed | 66/1024 [00:00<00:09, 96.25it/s]
Loading safetensors checkpoint shards:   8% Completed | 78/1024 [00:00<00:11, 79.13it/s]
Loading safetensors checkpoint shards:   9% Completed | 88/1024 [00:01<00:13, 71.49it/s]
Loading safetensors checkpoint shards:   9% Completed | 96/1024 [00:01<00:24, 38.31it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:01<00:22, 40.62it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:01<00:23, 38.28it/s]
Loading safetensors checkpoint shards:  11% Completed | 113/1024 [00:01<00:23, 38.23it/s]
Loading safetensors checkpoint shards:  12% Completed | 118/1024 [00:02<00:23, 39.30it/s]
Loading safetensors checkpoint shards:  12% Completed | 123/1024 [00:02<00:23, 38.00it/s]
Loading safetensors checkpoint shards:  12% Completed | 128/1024 [00:02<00:23, 37.43it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:02<00:25, 35.11it/s]
Loading safetensors checkpoint shards:  13% Completed | 136/1024 [00:02<00:25, 34.53it/s]
Loading safetensors checkpoint shards:  14% Completed | 143/1024 [00:02<00:21, 40.57it/s]
Loading safetensors checkpoint shards:  14% Completed | 148/1024 [00:02<00:20, 42.30it/s]
Loading safetensors checkpoint shards:  15% Completed | 154/1024 [00:03<00:19, 44.80it/s]
Loading safetensors checkpoint shards:  16% Completed | 159/1024 [00:03<00:20, 42.77it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:03<00:20, 42.89it/s]
Loading safetensors checkpoint shards:  17% Completed | 169/1024 [00:03<00:20, 41.80it/s]
Loading safetensors checkpoint shards:  17% Completed | 176/1024 [00:03<00:17, 47.49it/s]
Loading safetensors checkpoint shards:  18% Completed | 181/1024 [00:03<00:18, 46.68it/s]
Loading safetensors checkpoint shards:  18% Completed | 187/1024 [00:03<00:17, 48.76it/s]
Loading safetensors checkpoint shards:  19% Completed | 192/1024 [00:03<00:17, 47.45it/s]
Loading safetensors checkpoint shards:  19% Completed | 197/1024 [00:03<00:18, 45.38it/s]
Loading safetensors checkpoint shards:  20% Completed | 202/1024 [00:04<00:20, 39.66it/s]
Loading safetensors checkpoint shards:  20% Completed | 207/1024 [00:04<00:20, 40.61it/s]
Loading safetensors checkpoint shards:  21% Completed | 212/1024 [00:04<00:20, 40.10it/s]
Loading safetensors checkpoint shards:  21% Completed | 217/1024 [00:04<00:18, 42.52it/s]
Loading safetensors checkpoint shards:  22% Completed | 222/1024 [00:04<00:19, 41.22it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:04<00:19, 40.28it/s]
Loading safetensors checkpoint shards:  23% Completed | 232/1024 [00:04<00:22, 35.46it/s]
Loading safetensors checkpoint shards:  23% Completed | 236/1024 [00:05<00:42, 18.33it/s]
Loading safetensors checkpoint shards:  24% Completed | 242/1024 [00:05<00:32, 23.75it/s]
Loading safetensors checkpoint shards:  24% Completed | 247/1024 [00:05<00:28, 27.23it/s]
Loading safetensors checkpoint shards:  25% Completed | 253/1024 [00:05<00:23, 32.36it/s]
Loading safetensors checkpoint shards:  25% Completed | 258/1024 [00:05<00:22, 34.23it/s]
Loading safetensors checkpoint shards:  26% Completed | 263/1024 [00:06<00:20, 37.61it/s]
Loading safetensors checkpoint shards:  26% Completed | 268/1024 [00:06<00:19, 38.25it/s]
Loading safetensors checkpoint shards:  27% Completed | 273/1024 [00:06<00:19, 39.02it/s]
Loading safetensors checkpoint shards:  27% Completed | 278/1024 [00:06<00:18, 39.89it/s]
Loading safetensors checkpoint shards:  28% Completed | 283/1024 [00:06<00:18, 40.35it/s]
Loading safetensors checkpoint shards:  28% Completed | 288/1024 [00:06<00:18, 38.83it/s]
Loading safetensors checkpoint shards:  29% Completed | 293/1024 [00:06<00:19, 37.71it/s]
Loading safetensors checkpoint shards:  29% Completed | 297/1024 [00:06<00:21, 33.80it/s]
Loading safetensors checkpoint shards:  29% Completed | 301/1024 [00:07<00:23, 30.83it/s]
Loading safetensors checkpoint shards:  30% Completed | 305/1024 [00:07<00:22, 31.74it/s]
Loading safetensors checkpoint shards:  30% Completed | 309/1024 [00:07<00:23, 30.03it/s]
Loading safetensors checkpoint shards:  31% Completed | 313/1024 [00:07<00:23, 30.14it/s]
Loading safetensors checkpoint shards:  31% Completed | 318/1024 [00:07<00:22, 31.57it/s]
Loading safetensors checkpoint shards:  31% Completed | 322/1024 [00:07<00:21, 32.36it/s]
Loading safetensors checkpoint shards:  32% Completed | 329/1024 [00:07<00:17, 40.43it/s]
Loading safetensors checkpoint shards:  33% Completed | 336/1024 [00:07<00:14, 47.31it/s]
Loading safetensors checkpoint shards:  33% Completed | 343/1024 [00:08<00:13, 51.99it/s]
Loading safetensors checkpoint shards:  34% Completed | 349/1024 [00:08<00:13, 48.93it/s]
Loading safetensors checkpoint shards:  35% Completed | 355/1024 [00:08<00:13, 49.14it/s]
Loading safetensors checkpoint shards:  35% Completed | 361/1024 [00:08<00:13, 49.51it/s]
Loading safetensors checkpoint shards:  36% Completed | 367/1024 [00:08<00:14, 45.65it/s]
Loading safetensors checkpoint shards:  36% Completed | 372/1024 [00:08<00:14, 45.07it/s]
Loading safetensors checkpoint shards:  37% Completed | 377/1024 [00:08<00:14, 45.07it/s]
Loading safetensors checkpoint shards:  38% Completed | 384/1024 [00:08<00:12, 49.99it/s]
Loading safetensors checkpoint shards:  38% Completed | 391/1024 [00:09<00:11, 54.37it/s]
Loading safetensors checkpoint shards:  39% Completed | 397/1024 [00:09<00:11, 55.71it/s]
Loading safetensors checkpoint shards:  39% Completed | 403/1024 [00:09<00:23, 26.17it/s]
Loading safetensors checkpoint shards:  40% Completed | 411/1024 [00:09<00:18, 33.92it/s]
Loading safetensors checkpoint shards:  41% Completed | 417/1024 [00:09<00:16, 37.35it/s]
Loading safetensors checkpoint shards:  41% Completed | 423/1024 [00:10<00:14, 41.47it/s]
Loading safetensors checkpoint shards:  42% Completed | 429/1024 [00:10<00:13, 45.26it/s]
Loading safetensors checkpoint shards:  42% Completed | 435/1024 [00:10<00:13, 43.20it/s]
Loading safetensors checkpoint shards:  43% Completed | 441/1024 [00:10<00:12, 46.29it/s]
Loading safetensors checkpoint shards:  44% Completed | 447/1024 [00:10<00:13, 42.27it/s]
Loading safetensors checkpoint shards:  44% Completed | 453/1024 [00:10<00:12, 44.25it/s]
Loading safetensors checkpoint shards:  45% Completed | 458/1024 [00:10<00:13, 43.00it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:10<00:13, 42.63it/s]
Loading safetensors checkpoint shards:  46% Completed | 468/1024 [00:11<00:13, 40.84it/s]
Loading safetensors checkpoint shards:  46% Completed | 476/1024 [00:11<00:11, 49.63it/s]
Loading safetensors checkpoint shards:  47% Completed | 483/1024 [00:11<00:10, 53.78it/s]
Loading safetensors checkpoint shards:  48% Completed | 489/1024 [00:11<00:10, 52.71it/s]
Loading safetensors checkpoint shards:  48% Completed | 495/1024 [00:11<00:09, 54.20it/s]
Loading safetensors checkpoint shards:  49% Completed | 501/1024 [00:11<00:09, 54.24it/s]
Loading safetensors checkpoint shards:  50% Completed | 507/1024 [00:11<00:10, 50.85it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:11<00:10, 47.48it/s]
Loading safetensors checkpoint shards:  51% Completed | 518/1024 [00:11<00:10, 48.01it/s]
Loading safetensors checkpoint shards:  51% Completed | 523/1024 [00:12<00:10, 46.47it/s]
Loading safetensors checkpoint shards:  52% Completed | 529/1024 [00:12<00:10, 48.37it/s]
Loading safetensors checkpoint shards:  52% Completed | 534/1024 [00:12<00:10, 44.90it/s]
Loading safetensors checkpoint shards:  53% Completed | 540/1024 [00:12<00:10, 46.78it/s]
Loading safetensors checkpoint shards:  53% Completed | 545/1024 [00:12<00:11, 41.57it/s]
Loading safetensors checkpoint shards:  54% Completed | 550/1024 [00:12<00:13, 35.22it/s]
Loading safetensors checkpoint shards:  54% Completed | 554/1024 [00:12<00:13, 34.72it/s]
Loading safetensors checkpoint shards:  55% Completed | 560/1024 [00:13<00:11, 39.12it/s]
Loading safetensors checkpoint shards:  55% Completed | 567/1024 [00:13<00:10, 45.53it/s]
Loading safetensors checkpoint shards:  56% Completed | 574/1024 [00:13<00:08, 50.38it/s]
Loading safetensors checkpoint shards:  57% Completed | 583/1024 [00:13<00:07, 60.51it/s]
Loading safetensors checkpoint shards:  58% Completed | 590/1024 [00:13<00:07, 56.64it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:14<00:20, 20.43it/s]
Loading safetensors checkpoint shards:  59% Completed | 604/1024 [00:14<00:15, 27.10it/s]
Loading safetensors checkpoint shards:  60% Completed | 611/1024 [00:14<00:12, 32.43it/s]
Loading safetensors checkpoint shards:  60% Completed | 619/1024 [00:14<00:10, 39.97it/s]
Loading safetensors checkpoint shards:  61% Completed | 627/1024 [00:14<00:08, 47.03it/s]
Loading safetensors checkpoint shards:  62% Completed | 634/1024 [00:14<00:07, 50.86it/s]
Loading safetensors checkpoint shards:  63% Completed | 642/1024 [00:14<00:06, 56.95it/s]
Loading safetensors checkpoint shards:  63% Completed | 649/1024 [00:15<00:06, 59.74it/s]
Loading safetensors checkpoint shards:  64% Completed | 657/1024 [00:15<00:05, 64.07it/s]
Loading safetensors checkpoint shards:  65% Completed | 665/1024 [00:15<00:05, 63.06it/s]
Loading safetensors checkpoint shards:  66% Completed | 672/1024 [00:15<00:05, 61.55it/s]
Loading safetensors checkpoint shards:  66% Completed | 679/1024 [00:15<00:05, 60.67it/s]
Loading safetensors checkpoint shards:  67% Completed | 687/1024 [00:15<00:05, 65.10it/s]
Loading safetensors checkpoint shards:  68% Completed | 696/1024 [00:15<00:04, 70.12it/s]
Loading safetensors checkpoint shards:  69% Completed | 704/1024 [00:15<00:04, 67.34it/s]
Loading safetensors checkpoint shards:  70% Completed | 712/1024 [00:15<00:04, 70.30it/s]
Loading safetensors checkpoint shards:  70% Completed | 720/1024 [00:16<00:04, 69.89it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:16<00:03, 73.84it/s]
Loading safetensors checkpoint shards:  72% Completed | 737/1024 [00:16<00:03, 71.97it/s]
Loading safetensors checkpoint shards:  73% Completed | 745/1024 [00:16<00:03, 70.67it/s]
Loading safetensors checkpoint shards:  74% Completed | 753/1024 [00:16<00:04, 66.50it/s]
Loading safetensors checkpoint shards:  74% Completed | 761/1024 [00:16<00:03, 69.19it/s]
Loading safetensors checkpoint shards:  75% Completed | 769/1024 [00:16<00:03, 66.38it/s]
Loading safetensors checkpoint shards:  76% Completed | 776/1024 [00:16<00:03, 62.87it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:17<00:03, 63.25it/s]
Loading safetensors checkpoint shards:  77% Completed | 790/1024 [00:17<00:03, 63.67it/s]
Loading safetensors checkpoint shards:  78% Completed | 798/1024 [00:17<00:03, 68.00it/s]
Loading safetensors checkpoint shards:  79% Completed | 805/1024 [00:17<00:03, 67.91it/s]
Loading safetensors checkpoint shards:  79% Completed | 812/1024 [00:18<00:10, 20.75it/s]
Loading safetensors checkpoint shards:  80% Completed | 818/1024 [00:18<00:08, 24.23it/s]
Loading safetensors checkpoint shards:  80% Completed | 824/1024 [00:18<00:06, 28.58it/s]
Loading safetensors checkpoint shards:  81% Completed | 831/1024 [00:18<00:05, 34.84it/s]
Loading safetensors checkpoint shards:  82% Completed | 838/1024 [00:18<00:04, 39.71it/s]
Loading safetensors checkpoint shards:  82% Completed | 844/1024 [00:18<00:04, 41.43it/s]
Loading safetensors checkpoint shards:  83% Completed | 851/1024 [00:18<00:03, 46.34it/s]
Loading safetensors checkpoint shards:  84% Completed | 858/1024 [00:19<00:03, 47.82it/s]
Loading safetensors checkpoint shards:  84% Completed | 864/1024 [00:19<00:03, 50.01it/s]
Loading safetensors checkpoint shards:  85% Completed | 871/1024 [00:19<00:02, 53.48it/s]
Loading safetensors checkpoint shards:  86% Completed | 877/1024 [00:19<00:02, 50.37it/s]
Loading safetensors checkpoint shards:  86% Completed | 883/1024 [00:19<00:02, 51.95it/s]
Loading safetensors checkpoint shards:  87% Completed | 889/1024 [00:19<00:02, 53.53it/s]
Loading safetensors checkpoint shards:  87% Completed | 895/1024 [00:19<00:02, 53.02it/s]
Loading safetensors checkpoint shards:  88% Completed | 901/1024 [00:19<00:02, 52.07it/s]
Loading safetensors checkpoint shards:  89% Completed | 907/1024 [00:20<00:02, 51.05it/s]
Loading safetensors checkpoint shards:  89% Completed | 913/1024 [00:20<00:02, 50.78it/s]
Loading safetensors checkpoint shards:  90% Completed | 919/1024 [00:20<00:02, 49.05it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:20<00:02, 48.73it/s]
Loading safetensors checkpoint shards:  91% Completed | 930/1024 [00:20<00:01, 49.10it/s]
Loading safetensors checkpoint shards:  91% Completed | 936/1024 [00:20<00:01, 51.11it/s]
Loading safetensors checkpoint shards:  92% Completed | 943/1024 [00:20<00:01, 55.07it/s]
Loading safetensors checkpoint shards:  93% Completed | 949/1024 [00:20<00:01, 54.39it/s]
Loading safetensors checkpoint shards:  93% Completed | 955/1024 [00:20<00:01, 54.81it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:21<00:01, 54.58it/s]
Loading safetensors checkpoint shards:  94% Completed | 967/1024 [00:21<00:01, 55.92it/s]
Loading safetensors checkpoint shards:  95% Completed | 974/1024 [00:21<00:00, 57.95it/s]
Loading safetensors checkpoint shards:  96% Completed | 983/1024 [00:21<00:00, 66.56it/s]
Loading safetensors checkpoint shards:  97% Completed | 996/1024 [00:21<00:00, 84.57it/s]
Loading safetensors checkpoint shards:  99% Completed | 1014/1024 [00:21<00:00, 109.51it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:21<00:00, 47.31it/s]
 
[2025-09-13 07:01:47 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:01:47 TP0] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:01:47 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:01:47 TP6] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:01:47 TP3] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:01:47 TP7] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:01:47 TP5] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:01:47 TP1] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:01:47 TP4] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:01:47 TP2] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:01:47 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:01:47 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.53 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s][2025-09-13 07:01:48 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:01:48 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:01:48 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:01:48 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:01:48 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:01:48 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:01:48 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:01:48 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:01:48 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26092.66it/s]
[2025-09-13 07:01:49 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:01:49 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27111.46it/s]
[2025-09-13 07:01:49 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:01:49 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28916.48it/s]
[2025-09-13 07:01:50 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:01:50 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28053.74it/s]
[2025-09-13 07:01:51 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:01:51 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28928.58it/s]
[2025-09-13 07:01:51 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.22 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.97it/s][2025-09-13 07:01:54 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:01:54 TP5] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.22 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.18it/s]
[2025-09-13 07:01:54 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:01:54 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:01:54 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:01:54 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:01:54 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:01:54 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:01:54 TP0] Capture cuda graph end. Time elapsed: 7.45 s. mem usage=0.36 GB. avail mem=17.20 GB.
[2025-09-13 07:01:55 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:01:55 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:01:55 TP0] Init torch distributed begin.
[2025-09-13 07:01:55 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:01:55 TP0] Load weight begin. avail mem=17.20 GB
[2025-09-13 07:01:55 TP0] Detected fp8 checkpoint.
[2025-09-13 07:01:55 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 174.65it/s]
Loading safetensors checkpoint shards:   4% Completed | 45/1024 [00:00<00:04, 228.16it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:00<00:02, 407.43it/s]
Loading safetensors checkpoint shards:  17% Completed | 170/1024 [00:00<00:01, 488.59it/s]
Loading safetensors checkpoint shards:  23% Completed | 232/1024 [00:00<00:01, 534.06it/s]
Loading safetensors checkpoint shards:  29% Completed | 296/1024 [00:00<00:01, 567.08it/s]
Loading safetensors checkpoint shards:  35% Completed | 358/1024 [00:00<00:01, 582.23it/s]
Loading safetensors checkpoint shards:  41% Completed | 421/1024 [00:00<00:01, 596.30it/s]
Loading safetensors checkpoint shards:  47% Completed | 484/1024 [00:00<00:00, 604.56it/s]
Loading safetensors checkpoint shards:  53% Completed | 546/1024 [00:01<00:00, 606.72it/s]
Loading safetensors checkpoint shards:  59% Completed | 608/1024 [00:01<00:00, 610.12it/s]
Loading safetensors checkpoint shards:  65% Completed | 670/1024 [00:01<00:00, 600.37it/s]
Loading safetensors checkpoint shards:  71% Completed | 731/1024 [00:01<00:00, 590.34it/s]
Loading safetensors checkpoint shards:  77% Completed | 791/1024 [00:01<00:00, 587.31it/s]
Loading safetensors checkpoint shards:  83% Completed | 850/1024 [00:01<00:00, 586.26it/s]
Loading safetensors checkpoint shards:  89% Completed | 909/1024 [00:01<00:00, 585.49it/s]
Loading safetensors checkpoint shards:  95% Completed | 968/1024 [00:01<00:00, 582.44it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 510.43it/s]

[2025-09-13 07:01:57 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.21 GB, mem usage=1.99 GB.
[2025-09-13 07:01:57 TP6] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:01:57 TP3] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:01:57 TP5] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:01:57 TP4] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:01:57 TP7] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:01:57 TP0] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:01:57 TP2] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:01:57 TP1] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:01:57 TP0] Memory pool end. avail mem=14.54 GB
[2025-09-13 07:01:57 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:01:57 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:01:57 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:01:57 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:01:57 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:01:57 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:01:57 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:01:57 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.17 GB
Capturing batches (bs=1 avail_mem=14.62 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  3.17it/s][2025-09-13 07:02:04 TP3] Registering 72 cuda graph addresses
[2025-09-13 07:02:04 TP1] Registering 72 cuda graph addresses
[2025-09-13 07:02:04 TP2] Registering 72 cuda graph addresses
[2025-09-13 07:02:04 TP4] Registering 72 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.62 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.47it/s]
[2025-09-13 07:02:04 TP6] Registering 72 cuda graph addresses
[2025-09-13 07:02:04 TP0] Registering 72 cuda graph addresses
[2025-09-13 07:02:04 TP7] Registering 72 cuda graph addresses
[2025-09-13 07:02:04 TP5] Registering 72 cuda graph addresses
[2025-09-13 07:02:04 TP4] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.35 GB. avail mem=14.58 GB.
[2025-09-13 07:02:04 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 07:02:04 TP3] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.35 GB. avail mem=14.58 GB.
[2025-09-13 07:02:04 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 07:02:04 TP6] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.35 GB. avail mem=14.58 GB.
[2025-09-13 07:02:04 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 07:02:04 TP5] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.35 GB. avail mem=14.58 GB.
[2025-09-13 07:02:04 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 07:02:04 TP0] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.36 GB. avail mem=14.62 GB.
[2025-09-13 07:02:04 TP7] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.35 GB. avail mem=14.81 GB.
[2025-09-13 07:02:04 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.62 GB
[2025-09-13 07:02:04 TP2] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.35 GB. avail mem=14.58 GB.
[2025-09-13 07:02:04 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.81 GB
[2025-09-13 07:02:04 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 07:02:04 TP1] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.35 GB. avail mem=14.58 GB.
[2025-09-13 07:02:04 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
Capturing batches (bs=1 avail_mem=14.45 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:00<00:00, 33.76it/s][2025-09-13 07:02:05 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:02:05 TP4] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.45 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 28.97it/s]
[2025-09-13 07:02:05 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:02:05 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:02:05 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:02:05 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:02:05 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:02:05 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:02:05 TP0] Capture draft extend cuda graph end. Time elapsed: 1.02 s. mem usage=0.17 GB. avail mem=14.45 GB.
[2025-09-13 07:02:05 TP0] max_total_num_tokens=620185, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.45 GB
[2025-09-13 07:02:05 TP7] Capture draft extend cuda graph end. Time elapsed: 1.03 s. mem usage=0.17 GB. avail mem=14.64 GB.
[2025-09-13 07:02:05 TP4] Capture draft extend cuda graph end. Time elapsed: 1.03 s. mem usage=0.17 GB. avail mem=14.41 GB.
[2025-09-13 07:02:05 TP6] Capture draft extend cuda graph end. Time elapsed: 1.03 s. mem usage=0.17 GB. avail mem=14.41 GB.
[2025-09-13 07:02:05 TP3] Capture draft extend cuda graph end. Time elapsed: 1.03 s. mem usage=0.17 GB. avail mem=14.41 GB.
[2025-09-13 07:02:05 TP5] Capture draft extend cuda graph end. Time elapsed: 1.03 s. mem usage=0.17 GB. avail mem=14.41 GB.
[2025-09-13 07:02:05 TP2] Capture draft extend cuda graph end. Time elapsed: 1.03 s. mem usage=0.17 GB. avail mem=14.41 GB.
[2025-09-13 07:02:05 TP1] Capture draft extend cuda graph end. Time elapsed: 1.03 s. mem usage=0.17 GB. avail mem=14.41 GB.
[2025-09-13 07:02:05] INFO:     Started server process [205519]
[2025-09-13 07:02:05] INFO:     Waiting for application startup.
[2025-09-13 07:02:05] INFO:     Application startup complete.
[2025-09-13 07:02:05] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:02:05] INFO:     127.0.0.1:39688 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:02:06] INFO:     127.0.0.1:39690 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:02:06 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:02:06 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:02:06 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28866.61it/s]
[2025-09-13 07:02:07] INFO:     127.0.0.1:39702 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:07] The server is fired up and ready to roll!
[2025-09-13 07:02:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:02:16] INFO:     127.0.0.1:47062 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:02:17] INFO:     127.0.0.1:47070 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:17 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:02:18] INFO:     127.0.0.1:55274 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:18] INFO:     127.0.0.1:55290 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:18 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:02:18] INFO:     127.0.0.1:55306 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:18] INFO:     127.0.0.1:55308 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:18] INFO:     127.0.0.1:55316 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:18] INFO:     127.0.0.1:55326 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:18] INFO:     127.0.0.1:55342 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:18] INFO:     127.0.0.1:55358 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:18 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:02:19 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:02:19 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:02:19 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:02:19 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:02:19 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:02:19 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:02:19 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:02:19 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:02:19 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:02:20 TP0] Decode batch. #running-req: 8, #token: 14458, token usage: 0.02, accept len: 2.58, cuda graph: True, gen throughput (token/s): 37.81, #queue-req: 0, 
[2025-09-13 07:02:21 TP0] Decode batch. #running-req: 8, #token: 15377, token usage: 0.02, accept len: 2.87, cuda graph: True, gen throughput (token/s): 770.22, #queue-req: 0, 
[2025-09-13 07:02:22 TP0] Decode batch. #running-req: 8, #token: 16362, token usage: 0.03, accept len: 3.08, cuda graph: True, gen throughput (token/s): 820.25, #queue-req: 0, 
[2025-09-13 07:02:23 TP0] Decode batch. #running-req: 8, #token: 17330, token usage: 0.03, accept len: 3.02, cuda graph: True, gen throughput (token/s): 806.72, #queue-req: 0, 
 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 7/8 [00:06<00:00,  2.29it/s][2025-09-13 07:02:25 TP0] Decode batch. #running-req: 1, #token: 1450, token usage: 0.00, accept len: 3.02, cuda graph: True, gen throughput (token/s): 492.56, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.17it/s]
[2025-09-13 07:02:25] INFO:     127.0.0.1:55364 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.86      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4070      
Request throughput (req/s):              1.17      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         596.99    
Total token throughput (tok/s):          596.99    
Concurrency:                             6.98      
Accept length:                           2.93      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5986.40   
Median E2E Latency (ms):                 5927.83   
---------------Time to First Token----------------
Mean TTFT (ms):                          617.66    
Median TTFT (ms):                        729.40    
P99 TTFT (ms):                           729.82    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.51     
Median ITL (ms):                         7.54      
P95 ITL (ms):                            28.41     
P99 ITL (ms):                            31.46     
Max ITL (ms):                            747.13    
==================================================
[2025-09-13 07:02:25] INFO:     127.0.0.1:55370 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:02:25] INFO:     127.0.0.1:55382 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:02:26] INFO:     127.0.0.1:55384 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:26] INFO:     127.0.0.1:55400 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:02:26] INFO:     127.0.0.1:55412 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:26] INFO:     127.0.0.1:55424 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:26] INFO:     127.0.0.1:55430 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:26] INFO:     127.0.0.1:55446 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:26] INFO:     127.0.0.1:55454 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:26] INFO:     127.0.0.1:55464 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:27 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:02:27 TP0] Decode batch. #running-req: 8, #token: 13966, token usage: 0.02, accept len: 2.38, cuda graph: True, gen throughput (token/s): 65.75, #queue-req: 0, 
[2025-09-13 07:02:28 TP0] Decode batch. #running-req: 8, #token: 14838, token usage: 0.02, accept len: 2.73, cuda graph: True, gen throughput (token/s): 756.88, #queue-req: 0, 
[2025-09-13 07:02:29 TP0] Decode batch. #running-req: 8, #token: 15803, token usage: 0.03, accept len: 3.02, cuda graph: True, gen throughput (token/s): 804.89, #queue-req: 0, 
[2025-09-13 07:02:30 TP0] Decode batch. #running-req: 8, #token: 16777, token usage: 0.03, accept len: 3.04, cuda graph: True, gen throughput (token/s): 810.55, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:11,  4.74s/it][2025-09-13 07:02:31] INFO:     127.0.0.1:58660 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:31 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:05<00:31,  2.28s/it][2025-09-13 07:02:32] INFO:     127.0.0.1:58674 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:02:32] INFO:     127.0.0.1:58686 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:32 TP0] Decode batch. #running-req: 7, #token: 11901, token usage: 0.02, accept len: 3.07, cuda graph: True, gen throughput (token/s): 613.53, #queue-req: 1, 
[2025-09-13 07:02:32 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:12,  1.01s/it][2025-09-13 07:02:32] INFO:     127.0.0.1:58694 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:32 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:06<00:08,  1.26it/s][2025-09-13 07:02:33] INFO:     127.0.0.1:58698 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:33 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:06<00:06,  1.47it/s][2025-09-13 07:02:33] INFO:     127.0.0.1:58706 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:33 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:02:33] INFO:     127.0.0.1:58718 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:02:34 TP0] Decode batch. #running-req: 8, #token: 10545, token usage: 0.02, accept len: 2.72, cuda graph: True, gen throughput (token/s): 455.93, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:07<00:05,  1.59it/s][2025-09-13 07:02:34] INFO:     127.0.0.1:58728 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:02:34 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:02:35 TP0] Decode batch. #running-req: 8, #token: 14988, token usage: 0.02, accept len: 2.89, cuda graph: True, gen throughput (token/s): 651.29, #queue-req: 0, 
[2025-09-13 07:02:36 TP0] Decode batch. #running-req: 8, #token: 16042, token usage: 0.03, accept len: 3.29, cuda graph: True, gen throughput (token/s): 887.42, #queue-req: 0, 
 62%|████████████████████████████████████████████████████████████████████████████████▋                                                | 10/16 [00:10<00:05,  1.04it/s][2025-09-13 07:02:38 TP0] Decode batch. #running-req: 5, #token: 12630, token usage: 0.02, accept len: 3.39, cuda graph: True, gen throughput (token/s): 862.87, #queue-req: 0, 
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 13/16 [00:11<00:01,  2.00it/s][2025-09-13 07:02:38 TP0] Decode batch. #running-req: 3, #token: 7837, token usage: 0.01, accept len: 3.16, cuda graph: True, gen throughput (token/s): 477.66, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:12<00:00,  1.28it/s]
[2025-09-13 07:02:39] INFO:     127.0.0.1:55832 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  12.49     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8126      
Request throughput (req/s):              1.28      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         655.95    
Total token throughput (tok/s):          655.95    
Concurrency:                             7.36      
Accept length:                           2.98      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5747.91   
Median E2E Latency (ms):                 5530.42   
---------------Time to First Token----------------
Mean TTFT (ms):                          244.38    
Median TTFT (ms):                        290.32    
P99 TTFT (ms):                           301.84    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.77     
Median ITL (ms):                         7.50      
P95 ITL (ms):                            29.43     
P99 ITL (ms):                            66.40     
Max ITL (ms):                            265.61    
==================================================
[2025-09-13 07:02:39] INFO:     127.0.0.1:55846 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=14: batch_size=8, steps=4, topk=3, num_draft_tokens=4, speed=99.90 token/s, step_time=29.83 ms
Start i=15: batch_size=8, steps=4, topk=3, num_draft_tokens=6
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 4 --speculative-eagle-topk 3 --speculative-num-draft-tokens 6 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:02:50.178000 211134 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:02:50.178000 211134 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:02:50] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=948386802, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=4, speculative_eagle_topk=3, speculative_num_draft_tokens=6, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:02:50] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:02:59.496000 211391 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:02:59.496000 211391 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:02:59.509000 211387 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:02:59.509000 211387 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:02:59.551000 211386 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:02:59.551000 211386 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:02:59.585000 211388 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:02:59.585000 211388 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:02:59.609000 211393 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:02:59.609000 211393 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:02:59.625000 211392 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:02:59.625000 211392 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:02:59.628000 211389 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:02:59.628000 211389 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 07:02:59.765000 211390 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:02:59.765000 211390 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:02:59.806000 211394 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:02:59.806000 211394 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:03:00 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:03:00 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:03:00 TP0] Init torch distributed begin.
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:03:02 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:03:05 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:03:06 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:03:06 TP0] Detected fp8 checkpoint.
[2025-09-13 07:03:06 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 22/1024 [00:00<00:04, 214.27it/s]
Loading safetensors checkpoint shards:   4% Completed | 44/1024 [00:00<00:14, 65.76it/s]
Loading safetensors checkpoint shards:   5% Completed | 56/1024 [00:00<00:16, 57.44it/s]
Loading safetensors checkpoint shards:   6% Completed | 65/1024 [00:01<00:20, 45.83it/s]
Loading safetensors checkpoint shards:   7% Completed | 72/1024 [00:01<00:20, 45.55it/s]
Loading safetensors checkpoint shards:   8% Completed | 78/1024 [00:01<00:23, 40.76it/s]
Loading safetensors checkpoint shards:   8% Completed | 83/1024 [00:01<00:22, 41.28it/s]
Loading safetensors checkpoint shards:   9% Completed | 88/1024 [00:01<00:23, 40.03it/s]
Loading safetensors checkpoint shards:   9% Completed | 93/1024 [00:01<00:23, 38.99it/s]
Loading safetensors checkpoint shards:  10% Completed | 98/1024 [00:02<00:23, 39.02it/s]
Loading safetensors checkpoint shards:  10% Completed | 103/1024 [00:02<00:23, 39.37it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:02<00:22, 40.69it/s]
Loading safetensors checkpoint shards:  11% Completed | 113/1024 [00:02<00:22, 40.65it/s]
Loading safetensors checkpoint shards:  12% Completed | 118/1024 [00:02<00:21, 41.61it/s]
Loading safetensors checkpoint shards:  12% Completed | 123/1024 [00:02<00:39, 22.97it/s]
Loading safetensors checkpoint shards:  12% Completed | 128/1024 [00:03<00:33, 26.83it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:03<00:31, 28.31it/s]
Loading safetensors checkpoint shards:  13% Completed | 136/1024 [00:03<00:29, 30.16it/s]
Loading safetensors checkpoint shards:  14% Completed | 142/1024 [00:03<00:25, 34.78it/s]
Loading safetensors checkpoint shards:  14% Completed | 146/1024 [00:03<00:24, 35.34it/s]
Loading safetensors checkpoint shards:  15% Completed | 151/1024 [00:03<00:23, 37.36it/s]
Loading safetensors checkpoint shards:  15% Completed | 155/1024 [00:03<00:23, 36.55it/s]
Loading safetensors checkpoint shards:  16% Completed | 159/1024 [00:03<00:23, 36.47it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:04<00:23, 37.31it/s]
Loading safetensors checkpoint shards:  16% Completed | 168/1024 [00:04<00:23, 36.92it/s]
Loading safetensors checkpoint shards:  17% Completed | 173/1024 [00:04<00:21, 39.20it/s]
Loading safetensors checkpoint shards:  17% Completed | 177/1024 [00:04<00:21, 38.99it/s]
Loading safetensors checkpoint shards:  18% Completed | 181/1024 [00:04<00:22, 37.41it/s]
Loading safetensors checkpoint shards:  18% Completed | 186/1024 [00:04<00:21, 39.08it/s]
Loading safetensors checkpoint shards:  19% Completed | 190/1024 [00:04<00:21, 38.30it/s]
Loading safetensors checkpoint shards:  19% Completed | 195/1024 [00:04<00:20, 40.01it/s]
Loading safetensors checkpoint shards:  20% Completed | 200/1024 [00:04<00:20, 39.77it/s]
Loading safetensors checkpoint shards:  20% Completed | 204/1024 [00:05<00:20, 39.80it/s]
Loading safetensors checkpoint shards:  20% Completed | 208/1024 [00:05<00:21, 38.74it/s]
Loading safetensors checkpoint shards:  21% Completed | 212/1024 [00:05<00:21, 37.25it/s]
Loading safetensors checkpoint shards:  21% Completed | 217/1024 [00:05<00:20, 38.72it/s]
Loading safetensors checkpoint shards:  22% Completed | 221/1024 [00:05<00:21, 37.29it/s]
Loading safetensors checkpoint shards:  22% Completed | 225/1024 [00:05<00:21, 36.87it/s]
Loading safetensors checkpoint shards:  22% Completed | 229/1024 [00:05<00:21, 37.60it/s]
Loading safetensors checkpoint shards:  23% Completed | 233/1024 [00:05<00:21, 37.39it/s]
Loading safetensors checkpoint shards:  23% Completed | 238/1024 [00:05<00:20, 38.60it/s]
Loading safetensors checkpoint shards:  24% Completed | 242/1024 [00:06<00:20, 38.65it/s]
Loading safetensors checkpoint shards:  24% Completed | 246/1024 [00:06<00:20, 38.08it/s]
Loading safetensors checkpoint shards:  25% Completed | 251/1024 [00:06<00:19, 40.37it/s]
Loading safetensors checkpoint shards:  25% Completed | 256/1024 [00:06<00:19, 39.24it/s]
Loading safetensors checkpoint shards:  25% Completed | 261/1024 [00:06<00:18, 40.27it/s]
Loading safetensors checkpoint shards:  26% Completed | 266/1024 [00:06<00:19, 39.07it/s]
Loading safetensors checkpoint shards:  26% Completed | 270/1024 [00:06<00:19, 38.59it/s]
Loading safetensors checkpoint shards:  27% Completed | 275/1024 [00:06<00:18, 41.12it/s]
Loading safetensors checkpoint shards:  27% Completed | 280/1024 [00:07<00:19, 39.04it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:07<00:18, 40.15it/s]
Loading safetensors checkpoint shards:  28% Completed | 290/1024 [00:07<00:19, 38.45it/s]
Loading safetensors checkpoint shards:  29% Completed | 295/1024 [00:07<00:18, 40.32it/s]
Loading safetensors checkpoint shards:  29% Completed | 300/1024 [00:07<00:18, 39.44it/s]
Loading safetensors checkpoint shards:  30% Completed | 305/1024 [00:07<00:17, 40.82it/s]
Loading safetensors checkpoint shards:  30% Completed | 310/1024 [00:07<00:18, 38.25it/s]
Loading safetensors checkpoint shards:  31% Completed | 314/1024 [00:07<00:18, 37.90it/s]
Loading safetensors checkpoint shards:  31% Completed | 319/1024 [00:07<00:17, 39.95it/s]
Loading safetensors checkpoint shards:  32% Completed | 324/1024 [00:08<00:35, 19.79it/s]
Loading safetensors checkpoint shards:  32% Completed | 329/1024 [00:08<00:29, 23.91it/s]
Loading safetensors checkpoint shards:  33% Completed | 333/1024 [00:08<00:26, 26.45it/s]
Loading safetensors checkpoint shards:  33% Completed | 338/1024 [00:08<00:22, 30.48it/s]
Loading safetensors checkpoint shards:  33% Completed | 342/1024 [00:08<00:21, 32.26it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:09<00:20, 32.93it/s]
Loading safetensors checkpoint shards:  34% Completed | 351/1024 [00:09<00:18, 36.39it/s]
Loading safetensors checkpoint shards:  35% Completed | 356/1024 [00:09<00:18, 36.52it/s]
Loading safetensors checkpoint shards:  35% Completed | 361/1024 [00:09<00:17, 38.13it/s]
Loading safetensors checkpoint shards:  36% Completed | 366/1024 [00:09<00:17, 37.48it/s]
Loading safetensors checkpoint shards:  36% Completed | 370/1024 [00:09<00:17, 37.88it/s]
Loading safetensors checkpoint shards:  37% Completed | 375/1024 [00:09<00:16, 40.10it/s]
Loading safetensors checkpoint shards:  37% Completed | 380/1024 [00:09<00:16, 39.23it/s]
Loading safetensors checkpoint shards:  38% Completed | 386/1024 [00:10<00:14, 42.81it/s]
Loading safetensors checkpoint shards:  38% Completed | 392/1024 [00:10<00:14, 44.29it/s]
Loading safetensors checkpoint shards:  39% Completed | 399/1024 [00:10<00:12, 49.75it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:10<00:11, 53.85it/s]
Loading safetensors checkpoint shards:  40% Completed | 412/1024 [00:10<00:11, 53.68it/s]
Loading safetensors checkpoint shards:  41% Completed | 418/1024 [00:10<00:11, 52.33it/s]
Loading safetensors checkpoint shards:  41% Completed | 424/1024 [00:10<00:12, 48.83it/s]
Loading safetensors checkpoint shards:  42% Completed | 429/1024 [00:10<00:12, 48.37it/s]
Loading safetensors checkpoint shards:  42% Completed | 434/1024 [00:11<00:14, 41.82it/s]
Loading safetensors checkpoint shards:  43% Completed | 439/1024 [00:11<00:14, 41.71it/s]
Loading safetensors checkpoint shards:  43% Completed | 444/1024 [00:11<00:14, 39.41it/s]
Loading safetensors checkpoint shards:  44% Completed | 449/1024 [00:11<00:13, 41.86it/s]
Loading safetensors checkpoint shards:  44% Completed | 454/1024 [00:11<00:15, 35.93it/s]
Loading safetensors checkpoint shards:  45% Completed | 458/1024 [00:11<00:15, 36.57it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:11<00:14, 37.83it/s]
Loading safetensors checkpoint shards:  46% Completed | 467/1024 [00:11<00:14, 37.98it/s]
Loading safetensors checkpoint shards:  46% Completed | 473/1024 [00:12<00:13, 41.99it/s]
Loading safetensors checkpoint shards:  47% Completed | 478/1024 [00:12<00:13, 41.23it/s]
Loading safetensors checkpoint shards:  47% Completed | 483/1024 [00:12<00:12, 42.26it/s]
Loading safetensors checkpoint shards:  48% Completed | 488/1024 [00:12<00:13, 39.98it/s]
Loading safetensors checkpoint shards:  48% Completed | 493/1024 [00:12<00:12, 41.22it/s]
Loading safetensors checkpoint shards:  49% Completed | 498/1024 [00:12<00:13, 40.37it/s]
Loading safetensors checkpoint shards:  49% Completed | 503/1024 [00:12<00:13, 38.59it/s]
Loading safetensors checkpoint shards:  50% Completed | 508/1024 [00:12<00:12, 39.90it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:13<00:13, 38.95it/s]
Loading safetensors checkpoint shards:  51% Completed | 518/1024 [00:13<00:12, 39.87it/s]
Loading safetensors checkpoint shards:  51% Completed | 523/1024 [00:13<00:13, 38.09it/s]
Loading safetensors checkpoint shards:  52% Completed | 528/1024 [00:13<00:12, 39.40it/s]
Loading safetensors checkpoint shards:  52% Completed | 532/1024 [00:13<00:12, 39.17it/s]
Loading safetensors checkpoint shards:  52% Completed | 536/1024 [00:13<00:12, 37.75it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:13<00:12, 39.94it/s]
Loading safetensors checkpoint shards:  53% Completed | 546/1024 [00:13<00:12, 38.67it/s]
Loading safetensors checkpoint shards:  54% Completed | 551/1024 [00:14<00:11, 39.66it/s]
Loading safetensors checkpoint shards:  54% Completed | 555/1024 [00:14<00:12, 38.66it/s]
Loading safetensors checkpoint shards:  55% Completed | 559/1024 [00:14<00:24, 18.74it/s]
Loading safetensors checkpoint shards:  55% Completed | 563/1024 [00:14<00:21, 21.78it/s]
Loading safetensors checkpoint shards:  55% Completed | 567/1024 [00:14<00:18, 24.67it/s]
Loading safetensors checkpoint shards:  56% Completed | 572/1024 [00:14<00:15, 29.17it/s]
Loading safetensors checkpoint shards:  56% Completed | 576/1024 [00:15<00:14, 30.53it/s]
Loading safetensors checkpoint shards:  57% Completed | 580/1024 [00:15<00:13, 31.79it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:15<00:12, 36.20it/s]
Loading safetensors checkpoint shards:  58% Completed | 590/1024 [00:15<00:12, 35.48it/s]
Loading safetensors checkpoint shards:  58% Completed | 595/1024 [00:15<00:11, 37.29it/s]
Loading safetensors checkpoint shards:  58% Completed | 599/1024 [00:15<00:11, 36.77it/s]
Loading safetensors checkpoint shards:  59% Completed | 603/1024 [00:15<00:11, 36.70it/s]
Loading safetensors checkpoint shards:  59% Completed | 608/1024 [00:15<00:11, 37.72it/s]
Loading safetensors checkpoint shards:  60% Completed | 612/1024 [00:16<00:11, 36.96it/s]
Loading safetensors checkpoint shards:  60% Completed | 617/1024 [00:16<00:10, 38.29it/s]
Loading safetensors checkpoint shards:  61% Completed | 621/1024 [00:16<00:10, 37.36it/s]
Loading safetensors checkpoint shards:  61% Completed | 625/1024 [00:16<00:10, 37.37it/s]
Loading safetensors checkpoint shards:  61% Completed | 629/1024 [00:16<00:10, 37.60it/s]
Loading safetensors checkpoint shards:  62% Completed | 633/1024 [00:16<00:10, 36.12it/s]
Loading safetensors checkpoint shards:  62% Completed | 637/1024 [00:16<00:10, 36.27it/s]
Loading safetensors checkpoint shards:  63% Completed | 641/1024 [00:16<00:10, 36.91it/s]
Loading safetensors checkpoint shards:  63% Completed | 645/1024 [00:16<00:10, 36.10it/s]
Loading safetensors checkpoint shards:  63% Completed | 649/1024 [00:17<00:10, 36.34it/s]
Loading safetensors checkpoint shards:  64% Completed | 653/1024 [00:17<00:10, 36.18it/s]
Loading safetensors checkpoint shards:  64% Completed | 657/1024 [00:17<00:10, 36.20it/s]
Loading safetensors checkpoint shards:  65% Completed | 661/1024 [00:17<00:10, 34.97it/s]
Loading safetensors checkpoint shards:  65% Completed | 665/1024 [00:17<00:10, 35.01it/s]
Loading safetensors checkpoint shards:  65% Completed | 669/1024 [00:17<00:10, 35.13it/s]
Loading safetensors checkpoint shards:  66% Completed | 673/1024 [00:17<00:09, 35.66it/s]
Loading safetensors checkpoint shards:  66% Completed | 677/1024 [00:17<00:09, 35.11it/s]
Loading safetensors checkpoint shards:  67% Completed | 681/1024 [00:17<00:09, 35.10it/s]
Loading safetensors checkpoint shards:  67% Completed | 685/1024 [00:18<00:09, 35.28it/s]
Loading safetensors checkpoint shards:  67% Completed | 689/1024 [00:18<00:09, 35.63it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:18<00:08, 37.89it/s]
Loading safetensors checkpoint shards:  68% Completed | 698/1024 [00:18<00:08, 37.98it/s]
Loading safetensors checkpoint shards:  69% Completed | 702/1024 [00:18<00:08, 36.50it/s]
Loading safetensors checkpoint shards:  69% Completed | 706/1024 [00:18<00:08, 36.67it/s]
Loading safetensors checkpoint shards:  69% Completed | 710/1024 [00:18<00:08, 36.40it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:18<00:08, 36.33it/s]
Loading safetensors checkpoint shards:  70% Completed | 718/1024 [00:18<00:08, 34.68it/s]
Loading safetensors checkpoint shards:  71% Completed | 722/1024 [00:19<00:08, 35.06it/s]
Loading safetensors checkpoint shards:  71% Completed | 726/1024 [00:19<00:08, 36.09it/s]
Loading safetensors checkpoint shards:  71% Completed | 730/1024 [00:19<00:07, 36.80it/s]
Loading safetensors checkpoint shards:  72% Completed | 734/1024 [00:19<00:08, 35.78it/s]
Loading safetensors checkpoint shards:  72% Completed | 738/1024 [00:19<00:07, 36.02it/s]
Loading safetensors checkpoint shards:  72% Completed | 742/1024 [00:19<00:07, 36.55it/s]
Loading safetensors checkpoint shards:  73% Completed | 746/1024 [00:19<00:07, 36.43it/s]
Loading safetensors checkpoint shards:  73% Completed | 750/1024 [00:19<00:07, 35.30it/s]
Loading safetensors checkpoint shards:  74% Completed | 754/1024 [00:19<00:07, 35.63it/s]
Loading safetensors checkpoint shards:  74% Completed | 758/1024 [00:20<00:07, 35.92it/s]
Loading safetensors checkpoint shards:  74% Completed | 762/1024 [00:20<00:07, 35.94it/s]
Loading safetensors checkpoint shards:  75% Completed | 766/1024 [00:20<00:07, 36.51it/s]
Loading safetensors checkpoint shards:  75% Completed | 770/1024 [00:20<00:06, 36.37it/s]
Loading safetensors checkpoint shards:  76% Completed | 774/1024 [00:20<00:07, 35.03it/s]
Loading safetensors checkpoint shards:  76% Completed | 778/1024 [00:20<00:06, 35.31it/s]
Loading safetensors checkpoint shards:  76% Completed | 782/1024 [00:20<00:06, 35.52it/s]
Loading safetensors checkpoint shards:  77% Completed | 786/1024 [00:20<00:06, 36.18it/s]
Loading safetensors checkpoint shards:  77% Completed | 790/1024 [00:20<00:06, 34.64it/s]
Loading safetensors checkpoint shards:  78% Completed | 794/1024 [00:21<00:06, 35.27it/s]
Loading safetensors checkpoint shards:  78% Completed | 798/1024 [00:21<00:06, 35.94it/s]
Loading safetensors checkpoint shards:  78% Completed | 802/1024 [00:21<00:06, 35.75it/s]
Loading safetensors checkpoint shards:  79% Completed | 807/1024 [00:21<00:05, 37.59it/s]
Loading safetensors checkpoint shards:  79% Completed | 811/1024 [00:21<00:05, 37.00it/s]
Loading safetensors checkpoint shards:  80% Completed | 815/1024 [00:21<00:05, 36.24it/s]
Loading safetensors checkpoint shards:  80% Completed | 819/1024 [00:21<00:05, 35.67it/s]
Loading safetensors checkpoint shards:  80% Completed | 823/1024 [00:21<00:05, 36.37it/s]
Loading safetensors checkpoint shards:  81% Completed | 827/1024 [00:21<00:05, 37.01it/s]
Loading safetensors checkpoint shards:  81% Completed | 831/1024 [00:22<00:05, 36.67it/s]
Loading safetensors checkpoint shards:  82% Completed | 835/1024 [00:22<00:05, 37.04it/s]
Loading safetensors checkpoint shards:  82% Completed | 839/1024 [00:22<00:04, 37.12it/s]
Loading safetensors checkpoint shards:  82% Completed | 843/1024 [00:22<00:04, 36.20it/s]
Loading safetensors checkpoint shards:  83% Completed | 847/1024 [00:22<00:04, 37.01it/s]
Loading safetensors checkpoint shards:  83% Completed | 851/1024 [00:22<00:04, 37.07it/s]
Loading safetensors checkpoint shards:  83% Completed | 855/1024 [00:23<00:10, 15.54it/s]
Loading safetensors checkpoint shards:  84% Completed | 859/1024 [00:23<00:08, 18.48it/s]
Loading safetensors checkpoint shards:  84% Completed | 863/1024 [00:23<00:07, 21.64it/s]
Loading safetensors checkpoint shards:  85% Completed | 867/1024 [00:23<00:06, 24.63it/s]
Loading safetensors checkpoint shards:  85% Completed | 871/1024 [00:23<00:05, 27.32it/s]
Loading safetensors checkpoint shards:  85% Completed | 875/1024 [00:23<00:05, 28.53it/s]
Loading safetensors checkpoint shards:  86% Completed | 879/1024 [00:23<00:04, 30.61it/s]
Loading safetensors checkpoint shards:  86% Completed | 883/1024 [00:24<00:04, 32.35it/s]
Loading safetensors checkpoint shards:  87% Completed | 887/1024 [00:24<00:04, 33.48it/s]
Loading safetensors checkpoint shards:  87% Completed | 891/1024 [00:24<00:03, 33.57it/s]
Loading safetensors checkpoint shards:  87% Completed | 895/1024 [00:24<00:03, 34.65it/s]
Loading safetensors checkpoint shards:  88% Completed | 899/1024 [00:24<00:03, 35.81it/s]
Loading safetensors checkpoint shards:  88% Completed | 903/1024 [00:24<00:03, 36.21it/s]
Loading safetensors checkpoint shards:  89% Completed | 907/1024 [00:24<00:03, 36.51it/s]
Loading safetensors checkpoint shards:  89% Completed | 911/1024 [00:24<00:03, 37.39it/s]
Loading safetensors checkpoint shards:  89% Completed | 916/1024 [00:24<00:02, 38.11it/s]
Loading safetensors checkpoint shards:  90% Completed | 920/1024 [00:25<00:02, 37.02it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:25<00:02, 36.86it/s]
Loading safetensors checkpoint shards:  91% Completed | 928/1024 [00:25<00:02, 36.67it/s]
Loading safetensors checkpoint shards:  91% Completed | 932/1024 [00:25<00:02, 35.68it/s]
Loading safetensors checkpoint shards:  91% Completed | 936/1024 [00:25<00:02, 35.48it/s]
Loading safetensors checkpoint shards:  92% Completed | 940/1024 [00:25<00:02, 34.66it/s]
Loading safetensors checkpoint shards:  92% Completed | 944/1024 [00:25<00:02, 35.32it/s]
Loading safetensors checkpoint shards:  93% Completed | 948/1024 [00:25<00:02, 34.91it/s]
Loading safetensors checkpoint shards:  93% Completed | 952/1024 [00:25<00:02, 35.94it/s]
Loading safetensors checkpoint shards:  93% Completed | 957/1024 [00:26<00:01, 37.14it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:26<00:01, 36.93it/s]
Loading safetensors checkpoint shards:  94% Completed | 966/1024 [00:26<00:01, 38.46it/s]
Loading safetensors checkpoint shards:  95% Completed | 970/1024 [00:26<00:01, 38.24it/s]
Loading safetensors checkpoint shards:  95% Completed | 975/1024 [00:26<00:01, 39.35it/s]
Loading safetensors checkpoint shards:  96% Completed | 980/1024 [00:26<00:01, 40.34it/s]
Loading safetensors checkpoint shards:  98% Completed | 1001/1024 [00:26<00:00, 85.85it/s]
Loading safetensors checkpoint shards:  99% Completed | 1011/1024 [00:26<00:00, 81.12it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:26<00:00, 38.03it/s]

[2025-09-13 07:03:34 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:03:34 TP7] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:03:34 TP4] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:03:34 TP5] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:03:34 TP3] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:03:34 TP2] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:03:34 TP1] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:03:34 TP0] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:03:34 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:03:34 TP6] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:03:34 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:03:34 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.52 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:03:35 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:03:35 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:03:35 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:03:35 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:03:36 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:03:36 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:03:36 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:03:36 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:03:36 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26024.77it/s]
[2025-09-13 07:03:36 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:03:36 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27040.54it/s]
[2025-09-13 07:03:37 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:03:37 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28070.39it/s]
[2025-09-13 07:03:37 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:03:37 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26259.00it/s]
[2025-09-13 07:03:38 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:03:38 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27317.52it/s]
[2025-09-13 07:03:39 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.23 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.79it/s][2025-09-13 07:03:42 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:03:42 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:03:42 TP6] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.23 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.12it/s]
[2025-09-13 07:03:42 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:03:42 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:03:42 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:03:42 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:03:42 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:03:42 TP0] Capture cuda graph end. Time elapsed: 7.85 s. mem usage=0.35 GB. avail mem=17.21 GB.
[2025-09-13 07:03:42 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:03:42 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:03:42 TP0] Init torch distributed begin.
[2025-09-13 07:03:42 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:03:42 TP0] Load weight begin. avail mem=17.21 GB
[2025-09-13 07:03:42 TP0] Detected fp8 checkpoint.
[2025-09-13 07:03:42 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 19/1024 [00:00<00:05, 180.72it/s]
Loading safetensors checkpoint shards:   5% Completed | 47/1024 [00:00<00:04, 235.58it/s]
Loading safetensors checkpoint shards:  10% Completed | 106/1024 [00:00<00:02, 392.60it/s]
Loading safetensors checkpoint shards:  17% Completed | 169/1024 [00:00<00:01, 482.24it/s]
Loading safetensors checkpoint shards:  23% Completed | 233/1024 [00:00<00:01, 535.22it/s]
Loading safetensors checkpoint shards:  28% Completed | 287/1024 [00:00<00:01, 513.19it/s]
Loading safetensors checkpoint shards:  33% Completed | 339/1024 [00:00<00:01, 439.12it/s]
Loading safetensors checkpoint shards:  38% Completed | 385/1024 [00:00<00:01, 439.78it/s]
Loading safetensors checkpoint shards:  44% Completed | 447/1024 [00:00<00:01, 488.04it/s]
Loading safetensors checkpoint shards:  50% Completed | 510/1024 [00:01<00:00, 527.40it/s]
Loading safetensors checkpoint shards:  56% Completed | 573/1024 [00:01<00:00, 554.93it/s]
Loading safetensors checkpoint shards:  62% Completed | 635/1024 [00:01<00:00, 572.71it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:01<00:00, 577.32it/s]
Loading safetensors checkpoint shards:  74% Completed | 753/1024 [00:01<00:00, 577.43it/s]
Loading safetensors checkpoint shards:  79% Completed | 812/1024 [00:01<00:00, 580.91it/s]
Loading safetensors checkpoint shards:  85% Completed | 871/1024 [00:01<00:00, 581.90it/s]
Loading safetensors checkpoint shards:  91% Completed | 930/1024 [00:01<00:00, 573.10it/s]
Loading safetensors checkpoint shards:  96% Completed | 988/1024 [00:01<00:00, 497.36it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 479.57it/s]

[2025-09-13 07:03:45 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.22 GB, mem usage=1.99 GB.
[2025-09-13 07:03:45 TP0] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:03:45 TP4] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:03:45 TP6] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:03:45 TP3] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:03:45 TP1] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:03:45 TP0] Memory pool end. avail mem=14.55 GB
[2025-09-13 07:03:45 TP5] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:03:45 TP7] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:03:45 TP2] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:03:45 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:03:45 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:03:45 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:03:45 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:03:45 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:03:45 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.99 GB
[2025-09-13 07:03:45 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:03:45 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.18 GB
Capturing batches (bs=1 avail_mem=14.63 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  3.19it/s][2025-09-13 07:03:51 TP4] Registering 72 cuda graph addresses
[2025-09-13 07:03:51 TP3] Registering 72 cuda graph addresses
[2025-09-13 07:03:51 TP2] Registering 72 cuda graph addresses
[2025-09-13 07:03:51 TP1] Registering 72 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.63 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.48it/s]
[2025-09-13 07:03:51 TP5] Registering 72 cuda graph addresses
[2025-09-13 07:03:51 TP7] Registering 72 cuda graph addresses
[2025-09-13 07:03:51 TP6] Registering 72 cuda graph addresses
[2025-09-13 07:03:51 TP0] Registering 72 cuda graph addresses
[2025-09-13 07:03:51 TP1] Capture draft cuda graph end. Time elapsed: 6.36 s. mem usage=0.35 GB. avail mem=14.59 GB.
[2025-09-13 07:03:51 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.59 GB
[2025-09-13 07:03:51 TP5] Capture draft cuda graph end. Time elapsed: 6.36 s. mem usage=0.35 GB. avail mem=14.59 GB.
[2025-09-13 07:03:51 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.59 GB
[2025-09-13 07:03:51 TP3] Capture draft cuda graph end. Time elapsed: 6.36 s. mem usage=0.35 GB. avail mem=14.59 GB.
[2025-09-13 07:03:51 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.59 GB
[2025-09-13 07:03:51 TP4] Capture draft cuda graph end. Time elapsed: 6.40 s. mem usage=0.35 GB. avail mem=14.59 GB.
[2025-09-13 07:03:51 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.59 GB
[2025-09-13 07:03:51 TP0] Capture draft cuda graph end. Time elapsed: 6.36 s. mem usage=0.35 GB. avail mem=14.63 GB.
[2025-09-13 07:03:51 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.63 GB
[2025-09-13 07:03:51 TP6] Capture draft cuda graph end. Time elapsed: 6.40 s. mem usage=0.35 GB. avail mem=14.59 GB.
[2025-09-13 07:03:51 TP7] Capture draft cuda graph end. Time elapsed: 6.35 s. mem usage=0.35 GB. avail mem=14.83 GB.
[2025-09-13 07:03:51 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.59 GB
[2025-09-13 07:03:51 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.83 GB
[2025-09-13 07:03:51 TP2] Capture draft cuda graph end. Time elapsed: 6.40 s. mem usage=0.35 GB. avail mem=14.59 GB.
[2025-09-13 07:03:51 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.59 GB
Capturing batches (bs=1 avail_mem=14.46 GB):  12%|██████████▊                                                                           | 1/8 [00:00<00:00,  9.75it/s][2025-09-13 07:03:52 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:03:52 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:03:52 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:03:52 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:03:52 TP6] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.46 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 37.48it/s][2025-09-13 07:03:52 TP7] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.46 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 33.84it/s]
[2025-09-13 07:03:52 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:03:52 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:03:52 TP1] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.18 GB. avail mem=14.42 GB.
[2025-09-13 07:03:52 TP3] Capture draft extend cuda graph end. Time elapsed: 1.08 s. mem usage=0.18 GB. avail mem=14.42 GB.
[2025-09-13 07:03:52 TP7] Capture draft extend cuda graph end. Time elapsed: 1.08 s. mem usage=0.18 GB. avail mem=14.65 GB.
[2025-09-13 07:03:52 TP5] Capture draft extend cuda graph end. Time elapsed: 1.08 s. mem usage=0.18 GB. avail mem=14.42 GB.
[2025-09-13 07:03:52 TP4] Capture draft extend cuda graph end. Time elapsed: 1.08 s. mem usage=0.18 GB. avail mem=14.42 GB.
[2025-09-13 07:03:52 TP2] Capture draft extend cuda graph end. Time elapsed: 1.08 s. mem usage=0.18 GB. avail mem=14.42 GB.
[2025-09-13 07:03:52 TP6] Capture draft extend cuda graph end. Time elapsed: 1.08 s. mem usage=0.18 GB. avail mem=14.42 GB.
[2025-09-13 07:03:52 TP0] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.18 GB. avail mem=14.46 GB.
[2025-09-13 07:03:52 TP0] max_total_num_tokens=620201, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.46 GB
[2025-09-13 07:03:53] INFO:     Started server process [211134]
[2025-09-13 07:03:53] INFO:     Waiting for application startup.
[2025-09-13 07:03:53] INFO:     Application startup complete.
[2025-09-13 07:03:53] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:03:54] INFO:     127.0.0.1:51862 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:03:54 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:03:54 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:03:54 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup:  12%|████████████▌                                                                                           | 1986/16384 [00:00<00:00, 19856.99it/s][2025-09-13 07:03:54] INFO:     127.0.0.1:51880 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27900.47it/s]
[2025-09-13 07:03:55] INFO:     127.0.0.1:51878 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:03:55] The server is fired up and ready to roll!
[2025-09-13 07:04:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:04:05] INFO:     127.0.0.1:38932 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:04:05] INFO:     127.0.0.1:38940 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:05 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:04:07] INFO:     127.0.0.1:38954 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:07] INFO:     127.0.0.1:38970 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:04:07] INFO:     127.0.0.1:38974 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:07] INFO:     127.0.0.1:38982 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:07] INFO:     127.0.0.1:38998 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:07] INFO:     127.0.0.1:39002 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:07] INFO:     127.0.0.1:39006 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:07] INFO:     127.0.0.1:39018 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:07 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:04:08 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:04:08 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:04:08 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:04:08 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:04:08 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:04:08 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:04:08 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:04:08 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:04:08 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:04:09 TP0] Decode batch. #running-req: 8, #token: 14598, token usage: 0.02, accept len: 3.10, cuda graph: True, gen throughput (token/s): 44.20, #queue-req: 0, 
[2025-09-13 07:04:10 TP0] Decode batch. #running-req: 8, #token: 15702, token usage: 0.03, accept len: 3.45, cuda graph: True, gen throughput (token/s): 896.77, #queue-req: 0, 
[2025-09-13 07:04:11 TP0] Decode batch. #running-req: 8, #token: 16915, token usage: 0.03, accept len: 3.79, cuda graph: True, gen throughput (token/s): 963.49, #queue-req: 0, 
 62%|█████████████████████████████████████████████████████████████████████████████████▉                                                 | 5/8 [00:05<00:02,  1.50it/s][2025-09-13 07:04:12 TP0] Decode batch. #running-req: 3, #token: 3878, token usage: 0.01, accept len: 3.78, cuda graph: True, gen throughput (token/s): 727.13, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.34it/s]
[2025-09-13 07:04:13] INFO:     127.0.0.1:49046 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  5.95      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4087      
Request throughput (req/s):              1.34      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         687.85    
Total token throughput (tok/s):          687.85    
Concurrency:                             7.01      
Accept length:                           3.55      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5216.59   
Median E2E Latency (ms):                 5149.37   
---------------Time to First Token----------------
Mean TTFT (ms):                          613.95    
Median TTFT (ms):                        725.14    
P99 TTFT (ms):                           725.77    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.01      
Median ITL (ms):                         6.34      
P95 ITL (ms):                            15.83     
P99 ITL (ms):                            31.42     
Max ITL (ms):                            729.95    
==================================================
[2025-09-13 07:04:13] INFO:     127.0.0.1:49054 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:04:13] INFO:     127.0.0.1:49066 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:04:14] INFO:     127.0.0.1:49074 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:14] INFO:     127.0.0.1:49082 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:14 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:04:14] INFO:     127.0.0.1:49092 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:14] INFO:     127.0.0.1:49096 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:14] INFO:     127.0.0.1:49106 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:14] INFO:     127.0.0.1:49110 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:14] INFO:     127.0.0.1:49116 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:14] INFO:     127.0.0.1:49122 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:14 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:04:15 TP0] Decode batch. #running-req: 8, #token: 14051, token usage: 0.02, accept len: 3.17, cuda graph: True, gen throughput (token/s): 130.89, #queue-req: 0, 
[2025-09-13 07:04:16 TP0] Decode batch. #running-req: 8, #token: 15109, token usage: 0.02, accept len: 3.31, cuda graph: True, gen throughput (token/s): 877.76, #queue-req: 0, 
[2025-09-13 07:04:17 TP0] Decode batch. #running-req: 8, #token: 16280, token usage: 0.03, accept len: 3.66, cuda graph: True, gen throughput (token/s): 926.07, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:01,  4.08s/it][2025-09-13 07:04:18] INFO:     127.0.0.1:33860 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:18 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:04:19 TP0] Decode batch. #running-req: 8, #token: 17687, token usage: 0.03, accept len: 3.82, cuda graph: True, gen throughput (token/s): 804.05, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:27,  1.96s/it][2025-09-13 07:04:19] INFO:     127.0.0.1:33862 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:19 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:04<00:15,  1.18s/it][2025-09-13 07:04:19] INFO:     127.0.0.1:33874 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:19] INFO:     127.0.0.1:33876 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:19 TP0] Prefill batch. #new-seq: 2, #new-token: 487, #cached-token: 1742, token usage: 0.01, #running-req: 6, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:07,  1.55it/s][2025-09-13 07:04:19] INFO:     127.0.0.1:33882 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:20 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.80it/s][2025-09-13 07:04:20] INFO:     127.0.0.1:33884 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:20 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:05<00:04,  1.99it/s][2025-09-13 07:04:20] INFO:     127.0.0.1:33894 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:04:21 TP0] Decode batch. #running-req: 8, #token: 10517, token usage: 0.02, accept len: 3.42, cuda graph: True, gen throughput (token/s): 562.99, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:04,  1.93it/s][2025-09-13 07:04:21] INFO:     127.0.0.1:33906 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:04:21 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:04:22 TP0] Decode batch. #running-req: 8, #token: 15083, token usage: 0.02, accept len: 3.27, cuda graph: True, gen throughput (token/s): 726.66, #queue-req: 0, 
[2025-09-13 07:04:23 TP0] Decode batch. #running-req: 8, #token: 16320, token usage: 0.03, accept len: 3.87, cuda graph: True, gen throughput (token/s): 993.70, #queue-req: 0, 
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 13/16 [00:10<00:01,  2.27it/s][2025-09-13 07:04:24 TP0] Decode batch. #running-req: 3, #token: 8635, token usage: 0.01, accept len: 3.73, cuda graph: True, gen throughput (token/s): 777.41, #queue-req: 0, 
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 15/16 [00:10<00:00,  2.20it/s][2025-09-13 07:04:25 TP0] Decode batch. #running-req: 1, #token: 5516, token usage: 0.01, accept len: 3.41, cuda graph: True, gen throughput (token/s): 367.60, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.44it/s]
[2025-09-13 07:04:25] INFO:     127.0.0.1:33920 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.12     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8139      
Request throughput (req/s):              1.44      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         736.66    
Total token throughput (tok/s):          736.66    
Concurrency:                             7.33      
Accept length:                           3.55      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5096.00   
Median E2E Latency (ms):                 4971.49   
---------------Time to First Token----------------
Mean TTFT (ms):                          228.48    
Median TTFT (ms):                        234.68    
P99 TTFT (ms):                           296.42    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.53      
Median ITL (ms):                         6.38      
P95 ITL (ms):                            18.14     
P99 ITL (ms):                            52.86     
Max ITL (ms):                            281.75    
==================================================
[2025-09-13 07:04:25] INFO:     127.0.0.1:33932 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=15: batch_size=8, steps=4, topk=3, num_draft_tokens=6, speed=114.39 token/s, step_time=31.05 ms
Start i=16: batch_size=8, steps=4, topk=3, num_draft_tokens=8
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 4 --speculative-eagle-topk 3 --speculative-num-draft-tokens 8 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:04:36.649000 216715 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:04:36.649000 216715 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:04:36] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=181671063, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=4, speculative_eagle_topk=3, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:04:37] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:04:45.925000 216923 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:04:45.925000 216923 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:04:45.926000 216925 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:04:45.926000 216925 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:04:45.944000 216921 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:04:45.944000 216921 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:04:46.086000 216922 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:04:46.086000 216922 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:04:46.107000 216920 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:04:46.107000 216920 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:04:46.142000 216928 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:04:46.142000 216928 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:04:46.188000 216927 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:04:46.188000 216927 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:04:46.188000 216926 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:04:46.188000 216926 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:04:46.306000 216924 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:04:46.306000 216924 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:04:46 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:04:46 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:04:46 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:04:48 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:04:51 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:04:53 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:04:53 TP0] Detected fp8 checkpoint.
[2025-09-13 07:04:53 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:05, 191.24it/s]
Loading safetensors checkpoint shards:   4% Completed | 46/1024 [00:00<00:14, 69.66it/s]
Loading safetensors checkpoint shards:   6% Completed | 57/1024 [00:00<00:16, 59.83it/s]
Loading safetensors checkpoint shards:   6% Completed | 65/1024 [00:01<00:18, 52.51it/s]
Loading safetensors checkpoint shards:   7% Completed | 72/1024 [00:01<00:18, 52.86it/s]
Loading safetensors checkpoint shards:   8% Completed | 78/1024 [00:01<00:19, 47.66it/s]
Loading safetensors checkpoint shards:   8% Completed | 84/1024 [00:01<00:19, 47.33it/s]
Loading safetensors checkpoint shards:   9% Completed | 89/1024 [00:01<00:20, 46.63it/s]
Loading safetensors checkpoint shards:   9% Completed | 94/1024 [00:01<00:20, 44.54it/s]
Loading safetensors checkpoint shards:  10% Completed | 99/1024 [00:01<00:21, 43.65it/s]
Loading safetensors checkpoint shards:  10% Completed | 105/1024 [00:01<00:20, 45.13it/s]
Loading safetensors checkpoint shards:  11% Completed | 110/1024 [00:02<00:21, 43.18it/s]
Loading safetensors checkpoint shards:  11% Completed | 116/1024 [00:02<00:20, 45.11it/s]
Loading safetensors checkpoint shards:  12% Completed | 121/1024 [00:02<00:36, 24.96it/s]
Loading safetensors checkpoint shards:  12% Completed | 127/1024 [00:02<00:30, 29.72it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:02<00:27, 31.97it/s]
Loading safetensors checkpoint shards:  13% Completed | 137/1024 [00:03<00:25, 35.47it/s]
Loading safetensors checkpoint shards:  14% Completed | 142/1024 [00:03<00:23, 38.32it/s]
Loading safetensors checkpoint shards:  14% Completed | 147/1024 [00:03<00:22, 39.20it/s]
Loading safetensors checkpoint shards:  15% Completed | 152/1024 [00:03<00:21, 40.92it/s]
Loading safetensors checkpoint shards:  15% Completed | 157/1024 [00:03<00:21, 41.26it/s]
Loading safetensors checkpoint shards:  16% Completed | 163/1024 [00:03<00:19, 43.78it/s]
Loading safetensors checkpoint shards:  16% Completed | 168/1024 [00:03<00:20, 42.49it/s]
Loading safetensors checkpoint shards:  17% Completed | 174/1024 [00:03<00:19, 44.55it/s]
Loading safetensors checkpoint shards:  17% Completed | 179/1024 [00:03<00:19, 43.48it/s]
Loading safetensors checkpoint shards:  18% Completed | 185/1024 [00:04<00:18, 45.02it/s]
Loading safetensors checkpoint shards:  19% Completed | 190/1024 [00:04<00:18, 44.79it/s]
Loading safetensors checkpoint shards:  19% Completed | 196/1024 [00:04<00:17, 46.57it/s]
Loading safetensors checkpoint shards:  20% Completed | 201/1024 [00:04<00:17, 45.77it/s]
Loading safetensors checkpoint shards:  20% Completed | 206/1024 [00:04<00:17, 45.54it/s]
Loading safetensors checkpoint shards:  21% Completed | 211/1024 [00:04<00:18, 44.59it/s]
Loading safetensors checkpoint shards:  21% Completed | 216/1024 [00:04<00:17, 45.93it/s]
Loading safetensors checkpoint shards:  22% Completed | 221/1024 [00:04<00:18, 44.13it/s]
Loading safetensors checkpoint shards:  22% Completed | 226/1024 [00:04<00:17, 44.58it/s]
Loading safetensors checkpoint shards:  23% Completed | 231/1024 [00:05<00:17, 44.35it/s]
Loading safetensors checkpoint shards:  23% Completed | 236/1024 [00:05<00:18, 43.53it/s]
Loading safetensors checkpoint shards:  24% Completed | 241/1024 [00:05<00:17, 45.17it/s]
Loading safetensors checkpoint shards:  24% Completed | 246/1024 [00:05<00:17, 44.70it/s]
Loading safetensors checkpoint shards:  25% Completed | 252/1024 [00:05<00:16, 46.97it/s]
Loading safetensors checkpoint shards:  25% Completed | 257/1024 [00:05<00:16, 45.31it/s]
Loading safetensors checkpoint shards:  26% Completed | 263/1024 [00:05<00:16, 46.87it/s]
Loading safetensors checkpoint shards:  26% Completed | 268/1024 [00:05<00:16, 46.05it/s]
Loading safetensors checkpoint shards:  27% Completed | 274/1024 [00:06<00:15, 47.21it/s]
Loading safetensors checkpoint shards:  27% Completed | 279/1024 [00:06<00:16, 44.58it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:06<00:16, 46.04it/s]
Loading safetensors checkpoint shards:  28% Completed | 290/1024 [00:06<00:16, 43.65it/s]
Loading safetensors checkpoint shards:  29% Completed | 295/1024 [00:06<00:16, 44.57it/s]
Loading safetensors checkpoint shards:  29% Completed | 300/1024 [00:06<00:16, 42.90it/s]
Loading safetensors checkpoint shards:  30% Completed | 305/1024 [00:06<00:16, 42.76it/s]
Loading safetensors checkpoint shards:  30% Completed | 310/1024 [00:06<00:17, 40.31it/s]
Loading safetensors checkpoint shards:  31% Completed | 315/1024 [00:07<00:17, 41.19it/s]
Loading safetensors checkpoint shards:  31% Completed | 320/1024 [00:07<00:17, 40.86it/s]
Loading safetensors checkpoint shards:  32% Completed | 325/1024 [00:07<00:32, 21.73it/s]
Loading safetensors checkpoint shards:  32% Completed | 330/1024 [00:07<00:27, 25.63it/s]
Loading safetensors checkpoint shards:  33% Completed | 335/1024 [00:07<00:23, 28.78it/s]
Loading safetensors checkpoint shards:  33% Completed | 340/1024 [00:07<00:21, 32.46it/s]
Loading safetensors checkpoint shards:  34% Completed | 344/1024 [00:08<00:20, 33.79it/s]
Loading safetensors checkpoint shards:  34% Completed | 349/1024 [00:08<00:18, 35.96it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:08<00:18, 36.59it/s]
Loading safetensors checkpoint shards:  35% Completed | 359/1024 [00:08<00:17, 38.17it/s]
Loading safetensors checkpoint shards:  36% Completed | 364/1024 [00:08<00:16, 39.29it/s]
Loading safetensors checkpoint shards:  36% Completed | 369/1024 [00:08<00:16, 39.49it/s]
Loading safetensors checkpoint shards:  37% Completed | 374/1024 [00:08<00:15, 42.00it/s]
Loading safetensors checkpoint shards:  37% Completed | 379/1024 [00:08<00:15, 40.65it/s]
Loading safetensors checkpoint shards:  38% Completed | 384/1024 [00:09<00:15, 42.37it/s]
Loading safetensors checkpoint shards:  38% Completed | 389/1024 [00:09<00:15, 41.91it/s]
Loading safetensors checkpoint shards:  38% Completed | 394/1024 [00:09<00:14, 43.02it/s]
Loading safetensors checkpoint shards:  39% Completed | 399/1024 [00:09<00:14, 42.48it/s]
Loading safetensors checkpoint shards:  40% Completed | 405/1024 [00:09<00:13, 44.37it/s]
Loading safetensors checkpoint shards:  40% Completed | 410/1024 [00:09<00:13, 44.12it/s]
Loading safetensors checkpoint shards:  41% Completed | 416/1024 [00:09<00:13, 45.61it/s]
Loading safetensors checkpoint shards:  41% Completed | 421/1024 [00:09<00:13, 43.62it/s]
Loading safetensors checkpoint shards:  42% Completed | 426/1024 [00:09<00:13, 44.83it/s]
Loading safetensors checkpoint shards:  42% Completed | 431/1024 [00:10<00:13, 43.87it/s]
Loading safetensors checkpoint shards:  43% Completed | 436/1024 [00:10<00:14, 41.96it/s]
Loading safetensors checkpoint shards:  43% Completed | 441/1024 [00:10<00:13, 42.89it/s]
Loading safetensors checkpoint shards:  44% Completed | 446/1024 [00:10<00:14, 41.01it/s]
Loading safetensors checkpoint shards:  44% Completed | 451/1024 [00:10<00:14, 40.69it/s]
Loading safetensors checkpoint shards:  45% Completed | 456/1024 [00:10<00:14, 40.04it/s]
Loading safetensors checkpoint shards:  45% Completed | 461/1024 [00:10<00:13, 40.84it/s]
Loading safetensors checkpoint shards:  46% Completed | 466/1024 [00:10<00:14, 38.93it/s]
Loading safetensors checkpoint shards:  46% Completed | 472/1024 [00:11<00:13, 42.03it/s]
Loading safetensors checkpoint shards:  47% Completed | 477/1024 [00:11<00:13, 40.44it/s]
Loading safetensors checkpoint shards:  47% Completed | 482/1024 [00:11<00:13, 40.54it/s]
Loading safetensors checkpoint shards:  48% Completed | 487/1024 [00:11<00:13, 39.89it/s]
Loading safetensors checkpoint shards:  48% Completed | 492/1024 [00:11<00:14, 37.35it/s]
Loading safetensors checkpoint shards:  49% Completed | 497/1024 [00:11<00:13, 38.93it/s]
Loading safetensors checkpoint shards:  49% Completed | 503/1024 [00:11<00:12, 40.82it/s]
Loading safetensors checkpoint shards:  50% Completed | 508/1024 [00:11<00:12, 42.11it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:12<00:12, 41.40it/s]
Loading safetensors checkpoint shards:  51% Completed | 518/1024 [00:12<00:12, 41.30it/s]
Loading safetensors checkpoint shards:  51% Completed | 523/1024 [00:12<00:12, 39.48it/s]
Loading safetensors checkpoint shards:  52% Completed | 528/1024 [00:12<00:12, 40.57it/s]
Loading safetensors checkpoint shards:  52% Completed | 533/1024 [00:12<00:12, 39.64it/s]
Loading safetensors checkpoint shards:  53% Completed | 538/1024 [00:12<00:12, 39.92it/s]
Loading safetensors checkpoint shards:  53% Completed | 543/1024 [00:12<00:12, 39.41it/s]
Loading safetensors checkpoint shards:  53% Completed | 547/1024 [00:12<00:12, 39.15it/s]
Loading safetensors checkpoint shards:  54% Completed | 552/1024 [00:13<00:11, 41.00it/s]
Loading safetensors checkpoint shards:  54% Completed | 557/1024 [00:13<00:11, 39.91it/s]
Loading safetensors checkpoint shards:  55% Completed | 562/1024 [00:13<00:11, 40.20it/s]
Loading safetensors checkpoint shards:  55% Completed | 567/1024 [00:13<00:11, 38.96it/s]
Loading safetensors checkpoint shards:  56% Completed | 572/1024 [00:13<00:11, 40.65it/s]
Loading safetensors checkpoint shards:  56% Completed | 577/1024 [00:14<00:22, 19.75it/s]
Loading safetensors checkpoint shards:  57% Completed | 583/1024 [00:14<00:17, 24.72it/s]
Loading safetensors checkpoint shards:  57% Completed | 587/1024 [00:14<00:16, 27.21it/s]
Loading safetensors checkpoint shards:  58% Completed | 591/1024 [00:14<00:14, 28.91it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:14<00:12, 33.06it/s]
Loading safetensors checkpoint shards:  59% Completed | 601/1024 [00:14<00:12, 34.71it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:14<00:11, 36.81it/s]
Loading safetensors checkpoint shards:  60% Completed | 611/1024 [00:14<00:11, 37.31it/s]
Loading safetensors checkpoint shards:  60% Completed | 616/1024 [00:15<00:10, 39.39it/s]
Loading safetensors checkpoint shards:  61% Completed | 621/1024 [00:15<00:10, 38.88it/s]
Loading safetensors checkpoint shards:  61% Completed | 626/1024 [00:15<00:10, 38.94it/s]
Loading safetensors checkpoint shards:  62% Completed | 631/1024 [00:15<00:10, 37.67it/s]
Loading safetensors checkpoint shards:  62% Completed | 635/1024 [00:15<00:10, 37.69it/s]
Loading safetensors checkpoint shards:  62% Completed | 639/1024 [00:15<00:10, 37.87it/s]
Loading safetensors checkpoint shards:  63% Completed | 643/1024 [00:15<00:10, 37.82it/s]
Loading safetensors checkpoint shards:  63% Completed | 647/1024 [00:15<00:10, 35.99it/s]
Loading safetensors checkpoint shards:  64% Completed | 651/1024 [00:16<00:10, 36.19it/s]
Loading safetensors checkpoint shards:  64% Completed | 655/1024 [00:16<00:10, 36.32it/s]
Loading safetensors checkpoint shards:  64% Completed | 659/1024 [00:16<00:10, 35.42it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:16<00:10, 35.43it/s]
Loading safetensors checkpoint shards:  65% Completed | 667/1024 [00:16<00:10, 35.39it/s]
Loading safetensors checkpoint shards:  66% Completed | 671/1024 [00:16<00:09, 35.48it/s]
Loading safetensors checkpoint shards:  66% Completed | 675/1024 [00:16<00:09, 35.84it/s]
Loading safetensors checkpoint shards:  66% Completed | 679/1024 [00:16<00:10, 34.39it/s]
Loading safetensors checkpoint shards:  67% Completed | 683/1024 [00:16<00:09, 35.13it/s]
Loading safetensors checkpoint shards:  67% Completed | 687/1024 [00:17<00:09, 35.59it/s]
Loading safetensors checkpoint shards:  67% Completed | 691/1024 [00:17<00:09, 35.91it/s]
Loading safetensors checkpoint shards:  68% Completed | 696/1024 [00:17<00:08, 38.27it/s]
Loading safetensors checkpoint shards:  68% Completed | 700/1024 [00:17<00:08, 37.97it/s]
Loading safetensors checkpoint shards:  69% Completed | 704/1024 [00:17<00:08, 36.63it/s]
Loading safetensors checkpoint shards:  69% Completed | 708/1024 [00:17<00:08, 36.91it/s]
Loading safetensors checkpoint shards:  70% Completed | 712/1024 [00:17<00:08, 37.04it/s]
Loading safetensors checkpoint shards:  70% Completed | 716/1024 [00:17<00:08, 36.88it/s]
Loading safetensors checkpoint shards:  70% Completed | 720/1024 [00:17<00:08, 36.06it/s]
Loading safetensors checkpoint shards:  71% Completed | 724/1024 [00:18<00:08, 36.20it/s]
Loading safetensors checkpoint shards:  71% Completed | 728/1024 [00:18<00:08, 36.77it/s]
Loading safetensors checkpoint shards:  71% Completed | 732/1024 [00:18<00:07, 36.59it/s]
Loading safetensors checkpoint shards:  72% Completed | 737/1024 [00:18<00:07, 38.40it/s]
Loading safetensors checkpoint shards:  72% Completed | 742/1024 [00:18<00:06, 41.36it/s]
Loading safetensors checkpoint shards:  73% Completed | 747/1024 [00:18<00:07, 39.18it/s]
Loading safetensors checkpoint shards:  73% Completed | 752/1024 [00:18<00:06, 39.73it/s]
Loading safetensors checkpoint shards:  74% Completed | 757/1024 [00:18<00:06, 40.70it/s]
Loading safetensors checkpoint shards:  74% Completed | 762/1024 [00:18<00:06, 41.42it/s]
Loading safetensors checkpoint shards:  75% Completed | 767/1024 [00:19<00:06, 41.95it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:19<00:06, 39.71it/s]
Loading safetensors checkpoint shards:  76% Completed | 777/1024 [00:19<00:06, 38.65it/s]
Loading safetensors checkpoint shards:  76% Completed | 781/1024 [00:19<00:06, 38.25it/s]
Loading safetensors checkpoint shards:  77% Completed | 785/1024 [00:19<00:06, 37.86it/s]
Loading safetensors checkpoint shards:  77% Completed | 789/1024 [00:19<00:06, 36.56it/s]
Loading safetensors checkpoint shards:  77% Completed | 793/1024 [00:19<00:06, 36.78it/s]
Loading safetensors checkpoint shards:  78% Completed | 797/1024 [00:19<00:06, 36.95it/s]
Loading safetensors checkpoint shards:  78% Completed | 801/1024 [00:20<00:06, 36.73it/s]
Loading safetensors checkpoint shards:  79% Completed | 805/1024 [00:20<00:05, 36.76it/s]
Loading safetensors checkpoint shards:  79% Completed | 809/1024 [00:20<00:05, 35.98it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:20<00:05, 36.10it/s]
Loading safetensors checkpoint shards:  80% Completed | 817/1024 [00:20<00:05, 34.75it/s]
Loading safetensors checkpoint shards:  80% Completed | 821/1024 [00:20<00:05, 34.34it/s]
Loading safetensors checkpoint shards:  81% Completed | 825/1024 [00:20<00:05, 34.48it/s]
Loading safetensors checkpoint shards:  81% Completed | 829/1024 [00:20<00:05, 34.37it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:20<00:05, 35.00it/s]
Loading safetensors checkpoint shards:  82% Completed | 837/1024 [00:21<00:05, 35.65it/s]
Loading safetensors checkpoint shards:  82% Completed | 841/1024 [00:21<00:05, 35.67it/s]
Loading safetensors checkpoint shards:  83% Completed | 845/1024 [00:21<00:05, 33.75it/s]
Loading safetensors checkpoint shards:  83% Completed | 849/1024 [00:21<00:05, 34.09it/s]
Loading safetensors checkpoint shards:  83% Completed | 853/1024 [00:21<00:05, 34.13it/s]
Loading safetensors checkpoint shards:  84% Completed | 857/1024 [00:21<00:04, 34.75it/s]
Loading safetensors checkpoint shards:  84% Completed | 861/1024 [00:21<00:04, 34.94it/s]
Loading safetensors checkpoint shards:  84% Completed | 865/1024 [00:21<00:04, 35.63it/s]
Loading safetensors checkpoint shards:  85% Completed | 869/1024 [00:21<00:04, 36.30it/s]
Loading safetensors checkpoint shards:  85% Completed | 873/1024 [00:22<00:09, 16.26it/s]
Loading safetensors checkpoint shards:  86% Completed | 877/1024 [00:22<00:07, 19.18it/s]
Loading safetensors checkpoint shards:  86% Completed | 881/1024 [00:22<00:06, 22.27it/s]
Loading safetensors checkpoint shards:  86% Completed | 885/1024 [00:22<00:05, 25.28it/s]
Loading safetensors checkpoint shards:  87% Completed | 889/1024 [00:23<00:04, 27.27it/s]
Loading safetensors checkpoint shards:  87% Completed | 893/1024 [00:23<00:04, 29.43it/s]
Loading safetensors checkpoint shards:  88% Completed | 897/1024 [00:23<00:04, 31.24it/s]
Loading safetensors checkpoint shards:  88% Completed | 901/1024 [00:23<00:03, 33.35it/s]
Loading safetensors checkpoint shards:  88% Completed | 905/1024 [00:23<00:03, 34.69it/s]
Loading safetensors checkpoint shards:  89% Completed | 909/1024 [00:23<00:03, 35.92it/s]
Loading safetensors checkpoint shards:  89% Completed | 913/1024 [00:23<00:03, 35.55it/s]
Loading safetensors checkpoint shards:  90% Completed | 918/1024 [00:23<00:02, 38.62it/s]
Loading safetensors checkpoint shards:  90% Completed | 922/1024 [00:23<00:02, 38.67it/s]
Loading safetensors checkpoint shards:  90% Completed | 926/1024 [00:23<00:02, 39.00it/s]
Loading safetensors checkpoint shards:  91% Completed | 930/1024 [00:24<00:02, 37.53it/s]
Loading safetensors checkpoint shards:  91% Completed | 935/1024 [00:24<00:02, 38.24it/s]
Loading safetensors checkpoint shards:  92% Completed | 940/1024 [00:24<00:02, 40.48it/s]
Loading safetensors checkpoint shards:  92% Completed | 945/1024 [00:24<00:02, 39.31it/s]
Loading safetensors checkpoint shards:  93% Completed | 950/1024 [00:24<00:01, 40.45it/s]
Loading safetensors checkpoint shards:  93% Completed | 955/1024 [00:24<00:01, 39.31it/s]
Loading safetensors checkpoint shards:  94% Completed | 960/1024 [00:24<00:01, 40.74it/s]
Loading safetensors checkpoint shards:  94% Completed | 965/1024 [00:24<00:01, 41.61it/s]
Loading safetensors checkpoint shards:  95% Completed | 971/1024 [00:25<00:01, 45.15it/s]
Loading safetensors checkpoint shards:  95% Completed | 977/1024 [00:25<00:01, 46.79it/s]
Loading safetensors checkpoint shards:  96% Completed | 982/1024 [00:25<00:00, 47.65it/s]
Loading safetensors checkpoint shards:  97% Completed | 990/1024 [00:25<00:00, 56.34it/s]
Loading safetensors checkpoint shards:  99% Completed | 1010/1024 [00:25<00:00, 96.82it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 40.13it/s]

[2025-09-13 07:05:19 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:05:20 TP1] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:05:20 TP2] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:05:20 TP5] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:05:20 TP7] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:05:20 TP3] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:05:20 TP4] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:05:20 TP0] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:05:20 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:05:20 TP6] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:05:20 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:05:21 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.51 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:05:21 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:05:21 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:05:22 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:05:22 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:05:22 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:05:22 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:05:22 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:05:22 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:05:22 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26304.47it/s]
[2025-09-13 07:05:22 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:05:22 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27078.40it/s]
[2025-09-13 07:05:23 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:05:23 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28640.71it/s]
[2025-09-13 07:05:23 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:05:23 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27840.14it/s]
[2025-09-13 07:05:24 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:05:24 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28807.94it/s]
[2025-09-13 07:05:25 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.20 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.16it/s]
[2025-09-13 07:05:28 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:05:28 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:05:28 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:05:28 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:05:28 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:05:28 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:05:28 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:05:28 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:05:28 TP0] Capture cuda graph end. Time elapsed: 7.62 s. mem usage=0.39 GB. avail mem=17.17 GB.
[2025-09-13 07:05:28 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:05:28 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:05:28 TP0] Init torch distributed begin.
[2025-09-13 07:05:28 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:05:28 TP0] Load weight begin. avail mem=17.17 GB
[2025-09-13 07:05:28 TP0] Detected fp8 checkpoint.
[2025-09-13 07:05:28 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 175.81it/s]
Loading safetensors checkpoint shards:   4% Completed | 43/1024 [00:00<00:04, 218.96it/s]
Loading safetensors checkpoint shards:  10% Completed | 103/1024 [00:00<00:02, 390.68it/s]
Loading safetensors checkpoint shards:  16% Completed | 165/1024 [00:00<00:01, 478.62it/s]
Loading safetensors checkpoint shards:  22% Completed | 226/1024 [00:00<00:01, 525.58it/s]
Loading safetensors checkpoint shards:  28% Completed | 287/1024 [00:00<00:01, 553.12it/s]
Loading safetensors checkpoint shards:  34% Completed | 347/1024 [00:00<00:01, 568.02it/s]
Loading safetensors checkpoint shards:  40% Completed | 409/1024 [00:00<00:01, 583.01it/s]
Loading safetensors checkpoint shards:  46% Completed | 469/1024 [00:00<00:00, 588.29it/s]
Loading safetensors checkpoint shards:  52% Completed | 531/1024 [00:01<00:00, 597.85it/s]
Loading safetensors checkpoint shards:  58% Completed | 593/1024 [00:01<00:00, 604.29it/s]
Loading safetensors checkpoint shards:  64% Completed | 654/1024 [00:01<00:00, 597.56it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:01<00:00, 591.03it/s]
Loading safetensors checkpoint shards:  76% Completed | 774/1024 [00:01<00:00, 584.95it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:01<00:00, 582.59it/s]
Loading safetensors checkpoint shards:  87% Completed | 892/1024 [00:01<00:00, 579.92it/s]
Loading safetensors checkpoint shards:  93% Completed | 951/1024 [00:01<00:00, 579.82it/s]
Loading safetensors checkpoint shards:  99% Completed | 1009/1024 [00:01<00:00, 399.09it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 498.61it/s]

[2025-09-13 07:05:30 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.18 GB, mem usage=1.99 GB.
[2025-09-13 07:05:30 TP1] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:05:30 TP3] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:05:30 TP0] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:05:30 TP5] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:05:30 TP0] Memory pool end. avail mem=14.52 GB
[2025-09-13 07:05:30 TP7] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:05:30 TP6] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:05:30 TP4] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:05:30 TP2] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:05:31 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:05:31 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.95 GB
[2025-09-13 07:05:31 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:05:31 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:05:31 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:05:31 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:05:31 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:05:31 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.14 GB
Capturing batches (bs=1 avail_mem=14.60 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.43it/s]
[2025-09-13 07:05:37 TP0] Registering 72 cuda graph addresses
[2025-09-13 07:05:37 TP4] Registering 72 cuda graph addresses
[2025-09-13 07:05:37 TP3] Registering 72 cuda graph addresses
[2025-09-13 07:05:37 TP1] Registering 72 cuda graph addresses
[2025-09-13 07:05:37 TP5] Registering 72 cuda graph addresses
[2025-09-13 07:05:37 TP7] Registering 72 cuda graph addresses
[2025-09-13 07:05:37 TP6] Registering 72 cuda graph addresses
[2025-09-13 07:05:37 TP2] Registering 72 cuda graph addresses
[2025-09-13 07:05:37 TP3] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.35 GB. avail mem=14.55 GB.
[2025-09-13 07:05:37 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.55 GB
[2025-09-13 07:05:37 TP0] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.36 GB. avail mem=14.59 GB.
[2025-09-13 07:05:37 TP1] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.35 GB. avail mem=14.55 GB.
[2025-09-13 07:05:37 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.59 GB
[2025-09-13 07:05:37 TP6] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.35 GB. avail mem=14.55 GB.
[2025-09-13 07:05:37 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.55 GB
[2025-09-13 07:05:37 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.55 GB
[2025-09-13 07:05:37 TP4] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.35 GB. avail mem=14.55 GB.
[2025-09-13 07:05:37 TP2] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.35 GB. avail mem=14.55 GB.
[2025-09-13 07:05:37 TP7] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.35 GB. avail mem=14.79 GB.
[2025-09-13 07:05:37 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.55 GB
[2025-09-13 07:05:37 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.55 GB
[2025-09-13 07:05:37 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 07:05:37 TP5] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.35 GB. avail mem=14.55 GB.
[2025-09-13 07:05:37 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.55 GB
Capturing batches (bs=1 avail_mem=14.42 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:00<00:00, 26.62it/s][2025-09-13 07:05:38 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:05:38 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:05:38 TP3] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.42 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 22.77it/s]
[2025-09-13 07:05:38 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:05:38 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:05:38 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:05:38 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:05:38 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:05:38 TP5] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.18 GB. avail mem=14.38 GB.
[2025-09-13 07:05:38 TP2] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.18 GB. avail mem=14.38 GB.
[2025-09-13 07:05:38 TP1] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.18 GB. avail mem=14.38 GB.
[2025-09-13 07:05:38 TP4] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.18 GB. avail mem=14.38 GB.
[2025-09-13 07:05:38 TP6] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.18 GB. avail mem=14.38 GB.
[2025-09-13 07:05:38 TP0] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.18 GB. avail mem=14.42 GB.
[2025-09-13 07:05:38 TP0] max_total_num_tokens=620217, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.42 GB
[2025-09-13 07:05:38 TP3] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.18 GB. avail mem=14.38 GB.
[2025-09-13 07:05:38 TP7] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.18 GB. avail mem=14.61 GB.
[2025-09-13 07:05:39] INFO:     Started server process [216715]
[2025-09-13 07:05:39] INFO:     Waiting for application startup.
[2025-09-13 07:05:39] INFO:     Application startup complete.
[2025-09-13 07:05:39] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:05:40] INFO:     127.0.0.1:55048 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:05:40 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:05:40 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:05:40 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup:  88%|██████████████████████████████████████████████████████████████████████████████████████████▊            | 14453/16384 [00:00<00:00, 27229.72it/s][2025-09-13 07:05:40] INFO:     127.0.0.1:55066 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 24792.99it/s]
[2025-09-13 07:05:41] INFO:     127.0.0.1:55052 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:05:41] The server is fired up and ready to roll!
[2025-09-13 07:05:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:05:51] INFO:     127.0.0.1:37110 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:05:52] INFO:     127.0.0.1:37114 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:05:52 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:05:53] INFO:     127.0.0.1:37116 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:05:53] INFO:     127.0.0.1:37118 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:05:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:05:53] INFO:     127.0.0.1:37130 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:05:53] INFO:     127.0.0.1:37134 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:05:53] INFO:     127.0.0.1:37138 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:05:53] INFO:     127.0.0.1:37142 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:05:53] INFO:     127.0.0.1:37144 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:05:53] INFO:     127.0.0.1:37160 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:05:53 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:05:54 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:05:54 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:05:54 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:05:54 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:05:54 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:05:54 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:05:54 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:05:54 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:05:54 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:05:55 TP0] Decode batch. #running-req: 8, #token: 14617, token usage: 0.02, accept len: 3.18, cuda graph: True, gen throughput (token/s): 43.52, #queue-req: 0, 
[2025-09-13 07:05:56 TP0] Decode batch. #running-req: 8, #token: 15744, token usage: 0.03, accept len: 3.52, cuda graph: True, gen throughput (token/s): 865.83, #queue-req: 0, 
[2025-09-13 07:05:58 TP0] Decode batch. #running-req: 8, #token: 17032, token usage: 0.03, accept len: 4.03, cuda graph: True, gen throughput (token/s): 976.66, #queue-req: 0, 
 75%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 6/8 [00:05<00:01,  1.93it/s][2025-09-13 07:05:59 TP0] Decode batch. #running-req: 2, #token: 1418, token usage: 0.00, accept len: 3.76, cuda graph: True, gen throughput (token/s): 621.44, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.28it/s]
[2025-09-13 07:06:00] INFO:     127.0.0.1:42102 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.26      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4081      
Request throughput (req/s):              1.28      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         654.53    
Total token throughput (tok/s):          654.53    
Concurrency:                             6.83      
Accept length:                           3.65      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5342.08   
Median E2E Latency (ms):                 5285.06   
---------------Time to First Token----------------
Mean TTFT (ms):                          629.85    
Median TTFT (ms):                        742.88    
P99 TTFT (ms):                           743.35    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.22      
Median ITL (ms):                         6.61      
P95 ITL (ms):                            16.47     
P99 ITL (ms):                            32.83     
Max ITL (ms):                            748.81    
==================================================
[2025-09-13 07:06:00] INFO:     127.0.0.1:42116 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:06:00] INFO:     127.0.0.1:42128 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:06:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:06:00 TP0] Decode batch. #running-req: 1, #token: 4692, token usage: 0.01, accept len: 3.07, cuda graph: True, gen throughput (token/s): 146.04, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:06:01] INFO:     127.0.0.1:42130 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:06:01] INFO:     127.0.0.1:42134 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:06:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:06:01] INFO:     127.0.0.1:42138 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:06:01] INFO:     127.0.0.1:42148 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:06:01] INFO:     127.0.0.1:42164 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:06:01] INFO:     127.0.0.1:42168 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:06:01] INFO:     127.0.0.1:42184 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:06:01] INFO:     127.0.0.1:42198 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:06:01 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:06:02 TP0] Decode batch. #running-req: 8, #token: 14951, token usage: 0.02, accept len: 3.32, cuda graph: True, gen throughput (token/s): 410.07, #queue-req: 0, 
[2025-09-13 07:06:04 TP0] Decode batch. #running-req: 8, #token: 16131, token usage: 0.03, accept len: 3.69, cuda graph: True, gen throughput (token/s): 896.46, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:03<00:59,  3.99s/it][2025-09-13 07:06:05] INFO:     127.0.0.1:42212 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:06:05 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:06:05 TP0] Decode batch. #running-req: 8, #token: 17577, token usage: 0.03, accept len: 4.00, cuda graph: True, gen throughput (token/s): 813.54, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:29,  2.10s/it][2025-09-13 07:06:06] INFO:     127.0.0.1:42218 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:06:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:06:06] INFO:     127.0.0.1:42222 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:06:06 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:11,  1.08it/s][2025-09-13 07:06:06] INFO:     127.0.0.1:42234 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:06:06 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:07,  1.41it/s][2025-09-13 07:06:06] INFO:     127.0.0.1:42248 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:06:06 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.73it/s][2025-09-13 07:06:07] INFO:     127.0.0.1:42264 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:06:07 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:05<00:04,  2.08it/s][2025-09-13 07:06:07] INFO:     127.0.0.1:42270 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:06:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:06:07 TP0] Decode batch. #running-req: 8, #token: 10473, token usage: 0.02, accept len: 3.57, cuda graph: True, gen throughput (token/s): 534.10, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:04,  1.76it/s][2025-09-13 07:06:08] INFO:     127.0.0.1:51314 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:06:08 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:06:09 TP0] Decode batch. #running-req: 8, #token: 15059, token usage: 0.02, accept len: 3.34, cuda graph: True, gen throughput (token/s): 696.16, #queue-req: 0, 
[2025-09-13 07:06:10 TP0] Decode batch. #running-req: 8, #token: 16317, token usage: 0.03, accept len: 3.93, cuda graph: True, gen throughput (token/s): 971.29, #queue-req: 0, 
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 13/16 [00:10<00:01,  1.91it/s][2025-09-13 07:06:12 TP0] Decode batch. #running-req: 3, #token: 8409, token usage: 0.01, accept len: 4.35, cuda graph: True, gen throughput (token/s): 898.16, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.47it/s]
[2025-09-13 07:06:12] INFO:     127.0.0.1:51316 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  10.89     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8109      
Request throughput (req/s):              1.47      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         752.16    
Total token throughput (tok/s):          752.16    
Concurrency:                             7.66      
Accept length:                           3.69      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5215.27   
Median E2E Latency (ms):                 5284.83   
---------------Time to First Token----------------
Mean TTFT (ms):                          234.31    
Median TTFT (ms):                        277.53    
P99 TTFT (ms):                           297.51    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.75      
Median ITL (ms):                         6.59      
P95 ITL (ms):                            30.57     
P99 ITL (ms):                            53.52     
Max ITL (ms):                            267.62    
==================================================
[2025-09-13 07:06:12] INFO:     127.0.0.1:51332 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-09-13 07:06:12 TP7] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2612, in run_scheduler_process
    scheduler.event_loop_normal()
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 811, in event_loop_normal
    recv_reqs = self.recv_requests()
                ^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 1095, in recv_requests
    recv_reqs = broadcast_pyobj(
                ^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/utils.py", line 1059, in broadcast_pyobj
    dist.broadcast(tensor_size, src=src, group=dist_group)
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
    work.wait()
RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [172.17.0.8]:42142

[2025-09-13 07:06:12] Received sigquit from a child process. It usually means the child failed.
Finish i=16: batch_size=8, steps=4, topk=3, num_draft_tokens=8, speed=112.66 token/s, step_time=32.76 ms
Start i=17: batch_size=8, steps=4, topk=3, num_draft_tokens=12
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 4 --speculative-eagle-topk 3 --speculative-num-draft-tokens 12 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:06:23.092000 222319 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:06:23.092000 222319 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:06:23] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=450557896, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=4, speculative_eagle_topk=3, speculative_num_draft_tokens=12, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:06:23] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:06:32.340000 222576 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:06:32.340000 222576 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:06:32.348000 222582 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:06:32.348000 222582 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:06:32.351000 222578 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:06:32.351000 222578 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:06:32.456000 222577 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:06:32.456000 222577 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:06:32.507000 222574 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:06:32.507000 222574 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:06:32.521000 222580 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:06:32.521000 222580 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:06:32.538000 222575 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:06:32.538000 222575 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 07:06:32.588000 222579 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:06:32.588000 222579 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:06:32.637000 222581 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:06:32.637000 222581 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:06:33 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:06:33 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:06:33 TP0] Init torch distributed begin.
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:06:34 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:06:37 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:06:39 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:06:39 TP0] Detected fp8 checkpoint.
[2025-09-13 07:06:39 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 23/1024 [00:00<00:05, 184.07it/s]
Loading safetensors checkpoint shards:   4% Completed | 42/1024 [00:00<00:10, 90.47it/s]
Loading safetensors checkpoint shards:   5% Completed | 54/1024 [00:00<00:12, 75.70it/s]
Loading safetensors checkpoint shards:   6% Completed | 63/1024 [00:00<00:15, 62.24it/s]
Loading safetensors checkpoint shards:   7% Completed | 70/1024 [00:00<00:15, 61.95it/s]
Loading safetensors checkpoint shards:   8% Completed | 77/1024 [00:01<00:16, 57.67it/s]
Loading safetensors checkpoint shards:   8% Completed | 83/1024 [00:01<00:16, 55.38it/s]
Loading safetensors checkpoint shards:   9% Completed | 89/1024 [00:01<00:18, 49.57it/s]
Loading safetensors checkpoint shards:   9% Completed | 95/1024 [00:01<00:32, 28.36it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:01<00:26, 34.25it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:02<00:24, 37.99it/s]
Loading safetensors checkpoint shards:  11% Completed | 114/1024 [00:02<00:22, 41.29it/s]
Loading safetensors checkpoint shards:  12% Completed | 120/1024 [00:02<00:20, 45.02it/s]
Loading safetensors checkpoint shards:  12% Completed | 127/1024 [00:02<00:17, 50.55it/s]
Loading safetensors checkpoint shards:  13% Completed | 133/1024 [00:02<00:18, 48.54it/s]
Loading safetensors checkpoint shards:  14% Completed | 142/1024 [00:02<00:15, 56.95it/s]
Loading safetensors checkpoint shards:  15% Completed | 149/1024 [00:02<00:14, 58.37it/s]
Loading safetensors checkpoint shards:  15% Completed | 156/1024 [00:02<00:14, 60.15it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:02<00:13, 63.29it/s]
Loading safetensors checkpoint shards:  17% Completed | 173/1024 [00:03<00:12, 68.27it/s]
Loading safetensors checkpoint shards:  18% Completed | 181/1024 [00:03<00:12, 70.03it/s]
Loading safetensors checkpoint shards:  19% Completed | 191/1024 [00:03<00:10, 76.76it/s]
Loading safetensors checkpoint shards:  20% Completed | 201/1024 [00:03<00:09, 83.21it/s]
Loading safetensors checkpoint shards:  21% Completed | 210/1024 [00:03<00:10, 80.80it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:03<00:11, 71.83it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:03<00:12, 65.24it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:04<00:25, 31.11it/s]
Loading safetensors checkpoint shards:  24% Completed | 241/1024 [00:04<00:21, 35.78it/s]
Loading safetensors checkpoint shards:  24% Completed | 249/1024 [00:04<00:18, 42.87it/s]
Loading safetensors checkpoint shards:  25% Completed | 256/1024 [00:04<00:16, 46.84it/s]
Loading safetensors checkpoint shards:  26% Completed | 263/1024 [00:04<00:14, 50.96it/s]
Loading safetensors checkpoint shards:  26% Completed | 270/1024 [00:04<00:14, 51.87it/s]
Loading safetensors checkpoint shards:  27% Completed | 277/1024 [00:05<00:14, 52.32it/s]
Loading safetensors checkpoint shards:  28% Completed | 283/1024 [00:05<00:14, 52.45it/s]
Loading safetensors checkpoint shards:  28% Completed | 289/1024 [00:05<00:14, 52.24it/s]
Loading safetensors checkpoint shards:  29% Completed | 296/1024 [00:05<00:13, 55.36it/s]
Loading safetensors checkpoint shards:  29% Completed | 302/1024 [00:05<00:13, 53.04it/s]
Loading safetensors checkpoint shards:  30% Completed | 308/1024 [00:05<00:13, 54.17it/s]
Loading safetensors checkpoint shards:  31% Completed | 314/1024 [00:05<00:14, 49.31it/s]
Loading safetensors checkpoint shards:  31% Completed | 320/1024 [00:05<00:14, 49.05it/s]
Loading safetensors checkpoint shards:  32% Completed | 326/1024 [00:06<00:14, 47.08it/s]
Loading safetensors checkpoint shards:  32% Completed | 331/1024 [00:06<00:15, 44.22it/s]
Loading safetensors checkpoint shards:  33% Completed | 336/1024 [00:06<00:16, 42.28it/s]
Loading safetensors checkpoint shards:  33% Completed | 342/1024 [00:06<00:15, 45.18it/s]
Loading safetensors checkpoint shards:  34% Completed | 347/1024 [00:06<00:15, 44.32it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:06<00:13, 49.43it/s]
Loading safetensors checkpoint shards:  35% Completed | 360/1024 [00:06<00:13, 50.52it/s]
Loading safetensors checkpoint shards:  36% Completed | 366/1024 [00:06<00:13, 47.98it/s]
Loading safetensors checkpoint shards:  36% Completed | 372/1024 [00:07<00:12, 50.35it/s]
Loading safetensors checkpoint shards:  37% Completed | 378/1024 [00:07<00:13, 48.01it/s]
Loading safetensors checkpoint shards:  38% Completed | 384/1024 [00:07<00:12, 50.70it/s]
Loading safetensors checkpoint shards:  38% Completed | 390/1024 [00:07<00:13, 48.01it/s]
Loading safetensors checkpoint shards:  39% Completed | 395/1024 [00:07<00:13, 46.62it/s]
Loading safetensors checkpoint shards:  39% Completed | 400/1024 [00:07<00:13, 45.44it/s]
Loading safetensors checkpoint shards:  40% Completed | 405/1024 [00:08<00:27, 22.13it/s]
Loading safetensors checkpoint shards:  40% Completed | 412/1024 [00:08<00:21, 28.48it/s]
Loading safetensors checkpoint shards:  41% Completed | 419/1024 [00:08<00:17, 35.19it/s]
Loading safetensors checkpoint shards:  42% Completed | 425/1024 [00:08<00:15, 39.27it/s]
Loading safetensors checkpoint shards:  42% Completed | 431/1024 [00:08<00:13, 42.91it/s]
Loading safetensors checkpoint shards:  43% Completed | 437/1024 [00:08<00:12, 45.98it/s]
Loading safetensors checkpoint shards:  43% Completed | 443/1024 [00:08<00:13, 44.53it/s]
Loading safetensors checkpoint shards:  44% Completed | 448/1024 [00:09<00:13, 42.34it/s]
Loading safetensors checkpoint shards:  44% Completed | 453/1024 [00:09<00:14, 38.94it/s]
Loading safetensors checkpoint shards:  45% Completed | 458/1024 [00:09<00:14, 39.66it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:09<00:14, 37.53it/s]
Loading safetensors checkpoint shards:  46% Completed | 467/1024 [00:09<00:15, 36.53it/s]
Loading safetensors checkpoint shards:  46% Completed | 473/1024 [00:09<00:13, 41.76it/s]
Loading safetensors checkpoint shards:  47% Completed | 478/1024 [00:09<00:13, 40.29it/s]
Loading safetensors checkpoint shards:  47% Completed | 484/1024 [00:09<00:12, 43.64it/s]
Loading safetensors checkpoint shards:  48% Completed | 489/1024 [00:10<00:13, 40.91it/s]
Loading safetensors checkpoint shards:  48% Completed | 494/1024 [00:10<00:12, 42.48it/s]
Loading safetensors checkpoint shards:  49% Completed | 499/1024 [00:10<00:12, 41.93it/s]
Loading safetensors checkpoint shards:  49% Completed | 504/1024 [00:10<00:12, 42.52it/s]
Loading safetensors checkpoint shards:  50% Completed | 509/1024 [00:10<00:12, 41.76it/s]
Loading safetensors checkpoint shards:  50% Completed | 514/1024 [00:10<00:12, 41.67it/s]
Loading safetensors checkpoint shards:  51% Completed | 519/1024 [00:10<00:12, 41.84it/s]
Loading safetensors checkpoint shards:  51% Completed | 525/1024 [00:10<00:11, 44.78it/s]
Loading safetensors checkpoint shards:  52% Completed | 532/1024 [00:11<00:09, 49.91it/s]
Loading safetensors checkpoint shards:  53% Completed | 538/1024 [00:11<00:09, 51.69it/s]
Loading safetensors checkpoint shards:  53% Completed | 545/1024 [00:11<00:08, 53.74it/s]
Loading safetensors checkpoint shards:  54% Completed | 552/1024 [00:11<00:08, 57.94it/s]
Loading safetensors checkpoint shards:  54% Completed | 558/1024 [00:11<00:08, 56.17it/s]
Loading safetensors checkpoint shards:  55% Completed | 564/1024 [00:11<00:08, 55.33it/s]
Loading safetensors checkpoint shards:  56% Completed | 571/1024 [00:11<00:07, 56.86it/s]
Loading safetensors checkpoint shards:  56% Completed | 577/1024 [00:11<00:08, 54.42it/s]
Loading safetensors checkpoint shards:  57% Completed | 584/1024 [00:11<00:07, 56.56it/s]
Loading safetensors checkpoint shards:  58% Completed | 590/1024 [00:12<00:07, 55.44it/s]
Loading safetensors checkpoint shards:  58% Completed | 597/1024 [00:12<00:07, 56.78it/s]
Loading safetensors checkpoint shards:  59% Completed | 603/1024 [00:12<00:16, 25.00it/s]
Loading safetensors checkpoint shards:  60% Completed | 610/1024 [00:12<00:13, 30.84it/s]
Loading safetensors checkpoint shards:  60% Completed | 616/1024 [00:12<00:11, 35.63it/s]
Loading safetensors checkpoint shards:  61% Completed | 622/1024 [00:13<00:10, 38.55it/s]
Loading safetensors checkpoint shards:  61% Completed | 628/1024 [00:13<00:09, 42.03it/s]
Loading safetensors checkpoint shards:  62% Completed | 634/1024 [00:13<00:08, 43.99it/s]
Loading safetensors checkpoint shards:  62% Completed | 640/1024 [00:13<00:08, 46.55it/s]
Loading safetensors checkpoint shards:  63% Completed | 646/1024 [00:13<00:08, 46.23it/s]
Loading safetensors checkpoint shards:  64% Completed | 652/1024 [00:13<00:08, 44.65it/s]
Loading safetensors checkpoint shards:  64% Completed | 657/1024 [00:13<00:09, 39.66it/s]
Loading safetensors checkpoint shards:  65% Completed | 662/1024 [00:14<00:10, 34.02it/s]
Loading safetensors checkpoint shards:  65% Completed | 666/1024 [00:14<00:10, 32.59it/s]
Loading safetensors checkpoint shards:  65% Completed | 670/1024 [00:14<00:12, 28.70it/s]
Loading safetensors checkpoint shards:  66% Completed | 674/1024 [00:14<00:12, 27.95it/s]
Loading safetensors checkpoint shards:  66% Completed | 678/1024 [00:14<00:12, 27.65it/s]
Loading safetensors checkpoint shards:  67% Completed | 681/1024 [00:14<00:14, 23.89it/s]
Loading safetensors checkpoint shards:  67% Completed | 684/1024 [00:14<00:13, 24.68it/s]
Loading safetensors checkpoint shards:  67% Completed | 687/1024 [00:15<00:13, 24.17it/s]
Loading safetensors checkpoint shards:  67% Completed | 691/1024 [00:15<00:12, 26.06it/s]
Loading safetensors checkpoint shards:  68% Completed | 695/1024 [00:15<00:12, 27.00it/s]
Loading safetensors checkpoint shards:  68% Completed | 698/1024 [00:15<00:13, 25.04it/s]
Loading safetensors checkpoint shards:  69% Completed | 702/1024 [00:15<00:11, 28.02it/s]
Loading safetensors checkpoint shards:  69% Completed | 705/1024 [00:15<00:11, 28.25it/s]
Loading safetensors checkpoint shards:  69% Completed | 709/1024 [00:15<00:10, 30.02it/s]
Loading safetensors checkpoint shards:  70% Completed | 713/1024 [00:15<00:09, 32.54it/s]
Loading safetensors checkpoint shards:  70% Completed | 717/1024 [00:16<00:09, 33.59it/s]
Loading safetensors checkpoint shards:  70% Completed | 721/1024 [00:16<00:09, 30.65it/s]
Loading safetensors checkpoint shards:  71% Completed | 725/1024 [00:16<00:10, 29.15it/s]
Loading safetensors checkpoint shards:  71% Completed | 728/1024 [00:16<00:10, 29.14it/s]
Loading safetensors checkpoint shards:  71% Completed | 731/1024 [00:16<00:10, 28.80it/s]
Loading safetensors checkpoint shards:  72% Completed | 735/1024 [00:16<00:09, 29.83it/s]
Loading safetensors checkpoint shards:  72% Completed | 739/1024 [00:16<00:09, 30.16it/s]
Loading safetensors checkpoint shards:  73% Completed | 743/1024 [00:16<00:09, 30.24it/s]
Loading safetensors checkpoint shards:  73% Completed | 747/1024 [00:17<00:09, 29.96it/s]
Loading safetensors checkpoint shards:  73% Completed | 751/1024 [00:17<00:08, 30.37it/s]
Loading safetensors checkpoint shards:  74% Completed | 755/1024 [00:17<00:09, 29.60it/s]
Loading safetensors checkpoint shards:  74% Completed | 759/1024 [00:17<00:08, 31.42it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:17<00:07, 32.69it/s]
Loading safetensors checkpoint shards:  75% Completed | 767/1024 [00:17<00:07, 32.32it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:17<00:07, 33.73it/s]
Loading safetensors checkpoint shards:  76% Completed | 776/1024 [00:18<00:07, 31.31it/s]
Loading safetensors checkpoint shards:  76% Completed | 780/1024 [00:18<00:08, 28.12it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:18<00:09, 26.51it/s]
Loading safetensors checkpoint shards:  77% Completed | 786/1024 [00:18<00:09, 26.13it/s]
Loading safetensors checkpoint shards:  77% Completed | 789/1024 [00:18<00:09, 25.03it/s]
Loading safetensors checkpoint shards:  77% Completed | 792/1024 [00:18<00:09, 24.83it/s]
Loading safetensors checkpoint shards:  78% Completed | 796/1024 [00:18<00:08, 26.58it/s]
Loading safetensors checkpoint shards:  78% Completed | 800/1024 [00:18<00:07, 28.43it/s]
Loading safetensors checkpoint shards:  79% Completed | 804/1024 [00:19<00:07, 28.74it/s]
Loading safetensors checkpoint shards:  79% Completed | 807/1024 [00:19<00:08, 26.55it/s]
Loading safetensors checkpoint shards:  79% Completed | 810/1024 [00:19<00:08, 25.95it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:19<00:09, 23.37it/s]
Loading safetensors checkpoint shards:  80% Completed | 816/1024 [00:19<00:09, 21.82it/s]
Loading safetensors checkpoint shards:  80% Completed | 819/1024 [00:19<00:09, 20.91it/s]
Loading safetensors checkpoint shards:  80% Completed | 822/1024 [00:19<00:08, 22.61it/s]
Loading safetensors checkpoint shards:  81% Completed | 825/1024 [00:20<00:20,  9.66it/s]
Loading safetensors checkpoint shards:  81% Completed | 828/1024 [00:20<00:16, 12.01it/s]
Loading safetensors checkpoint shards:  81% Completed | 832/1024 [00:20<00:12, 15.40it/s]
Loading safetensors checkpoint shards:  82% Completed | 836/1024 [00:21<00:10, 18.03it/s]
Loading safetensors checkpoint shards:  82% Completed | 839/1024 [00:21<00:09, 19.81it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:21<00:08, 21.38it/s]
Loading safetensors checkpoint shards:  83% Completed | 845/1024 [00:21<00:08, 22.04it/s]
Loading safetensors checkpoint shards:  83% Completed | 848/1024 [00:21<00:07, 22.77it/s]
Loading safetensors checkpoint shards:  83% Completed | 852/1024 [00:21<00:06, 25.64it/s]
Loading safetensors checkpoint shards:  83% Completed | 855/1024 [00:21<00:06, 26.66it/s]
Loading safetensors checkpoint shards:  84% Completed | 858/1024 [00:21<00:06, 25.95it/s]
Loading safetensors checkpoint shards:  84% Completed | 861/1024 [00:21<00:06, 26.26it/s]
Loading safetensors checkpoint shards:  84% Completed | 865/1024 [00:22<00:05, 27.40it/s]
Loading safetensors checkpoint shards:  85% Completed | 869/1024 [00:22<00:05, 27.97it/s]
Loading safetensors checkpoint shards:  85% Completed | 872/1024 [00:22<00:05, 27.40it/s]
Loading safetensors checkpoint shards:  85% Completed | 875/1024 [00:22<00:05, 27.40it/s]
Loading safetensors checkpoint shards:  86% Completed | 878/1024 [00:22<00:05, 26.88it/s]
Loading safetensors checkpoint shards:  86% Completed | 882/1024 [00:22<00:04, 28.71it/s]
Loading safetensors checkpoint shards:  86% Completed | 885/1024 [00:22<00:04, 28.81it/s]
Loading safetensors checkpoint shards:  87% Completed | 888/1024 [00:22<00:04, 28.25it/s]
Loading safetensors checkpoint shards:  87% Completed | 891/1024 [00:23<00:04, 28.13it/s]
Loading safetensors checkpoint shards:  87% Completed | 894/1024 [00:23<00:04, 27.16it/s]
Loading safetensors checkpoint shards:  88% Completed | 897/1024 [00:23<00:04, 27.02it/s]
Loading safetensors checkpoint shards:  88% Completed | 900/1024 [00:23<00:04, 26.68it/s]
Loading safetensors checkpoint shards:  88% Completed | 903/1024 [00:23<00:04, 26.84it/s]
Loading safetensors checkpoint shards:  88% Completed | 906/1024 [00:23<00:04, 26.36it/s]
Loading safetensors checkpoint shards:  89% Completed | 910/1024 [00:23<00:03, 29.60it/s]
Loading safetensors checkpoint shards:  89% Completed | 915/1024 [00:23<00:03, 34.27it/s]
Loading safetensors checkpoint shards:  90% Completed | 920/1024 [00:23<00:02, 37.00it/s]
Loading safetensors checkpoint shards:  90% Completed | 925/1024 [00:24<00:02, 38.95it/s]
Loading safetensors checkpoint shards:  91% Completed | 930/1024 [00:24<00:02, 38.49it/s]
Loading safetensors checkpoint shards:  91% Completed | 935/1024 [00:24<00:02, 40.34it/s]
Loading safetensors checkpoint shards:  92% Completed | 940/1024 [00:24<00:02, 41.70it/s]
Loading safetensors checkpoint shards:  92% Completed | 945/1024 [00:24<00:01, 41.57it/s]
Loading safetensors checkpoint shards:  93% Completed | 950/1024 [00:24<00:01, 42.67it/s]
Loading safetensors checkpoint shards:  93% Completed | 955/1024 [00:24<00:01, 43.15it/s]
Loading safetensors checkpoint shards:  94% Completed | 960/1024 [00:24<00:01, 42.67it/s]
Loading safetensors checkpoint shards:  94% Completed | 965/1024 [00:24<00:01, 43.09it/s]
Loading safetensors checkpoint shards:  95% Completed | 970/1024 [00:25<00:01, 42.88it/s]
Loading safetensors checkpoint shards:  95% Completed | 975/1024 [00:25<00:01, 44.14it/s]
Loading safetensors checkpoint shards:  96% Completed | 980/1024 [00:25<00:00, 44.93it/s]
Loading safetensors checkpoint shards:  98% Completed | 1001/1024 [00:25<00:00, 90.71it/s]
Loading safetensors checkpoint shards:  99% Completed | 1011/1024 [00:25<00:00, 89.54it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 39.97it/s]

[2025-09-13 07:07:05 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:07:09 TP3] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:07:09 TP1] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:07:09 TP4] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:07:09 TP5] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:07:09 TP6] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:07:09 TP7] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:07:09 TP0] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:07:09 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:07:09 TP2] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:07:09 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:07:09 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.50 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:07:10 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:07:10 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:07:10 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:07:10 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:07:10 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:07:10 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:07:10 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:07:10 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:07:10 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26148.12it/s]
[2025-09-13 07:07:11 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:07:11 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27229.68it/s]
[2025-09-13 07:07:11 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:07:11 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28716.42it/s]
[2025-09-13 07:07:12 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:07:12 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27796.80it/s]
[2025-09-13 07:07:13 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:07:13 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28625.61it/s]
[2025-09-13 07:07:13 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.16 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.18it/s]
[2025-09-13 07:07:16 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:07:16 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:07:16 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:07:16 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:07:16 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:07:16 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:07:16 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:07:16 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:07:16 TP0] Capture cuda graph end. Time elapsed: 7.48 s. mem usage=0.43 GB. avail mem=17.14 GB.
[2025-09-13 07:07:17 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:07:17 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:07:17 TP0] Init torch distributed begin.
[2025-09-13 07:07:17 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:07:17 TP0] Load weight begin. avail mem=17.14 GB
[2025-09-13 07:07:17 TP0] Detected fp8 checkpoint.
[2025-09-13 07:07:17 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 168.28it/s]
Loading safetensors checkpoint shards:   4% Completed | 45/1024 [00:00<00:04, 224.40it/s]
Loading safetensors checkpoint shards:  10% Completed | 106/1024 [00:00<00:02, 396.03it/s]
Loading safetensors checkpoint shards:  16% Completed | 168/1024 [00:00<00:01, 482.30it/s]
Loading safetensors checkpoint shards:  22% Completed | 230/1024 [00:00<00:01, 531.05it/s]
Loading safetensors checkpoint shards:  29% Completed | 292/1024 [00:00<00:01, 560.14it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:00<00:01, 577.31it/s]
Loading safetensors checkpoint shards:  41% Completed | 417/1024 [00:00<00:01, 590.98it/s]
Loading safetensors checkpoint shards:  47% Completed | 479/1024 [00:00<00:00, 596.84it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:01<00:00, 601.49it/s]
Loading safetensors checkpoint shards:  59% Completed | 603/1024 [00:01<00:00, 605.06it/s]
Loading safetensors checkpoint shards:  65% Completed | 664/1024 [00:01<00:00, 599.71it/s]
Loading safetensors checkpoint shards:  71% Completed | 724/1024 [00:01<00:00, 593.98it/s]
Loading safetensors checkpoint shards:  77% Completed | 784/1024 [00:01<00:00, 588.29it/s]
Loading safetensors checkpoint shards:  82% Completed | 843/1024 [00:01<00:00, 584.97it/s]
Loading safetensors checkpoint shards:  88% Completed | 902/1024 [00:01<00:00, 580.82it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:01<00:00, 580.21it/s]
Loading safetensors checkpoint shards: 100% Completed | 1020/1024 [00:02<00:00, 389.68it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 509.02it/s]

[2025-09-13 07:07:19 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.15 GB, mem usage=1.99 GB.
[2025-09-13 07:07:19 TP4] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:07:19 TP2] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:07:19 TP0] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:07:19 TP6] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:07:19 TP0] Memory pool end. avail mem=14.48 GB
[2025-09-13 07:07:19 TP1] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:07:19 TP5] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:07:19 TP3] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:07:19 TP7] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:07:19 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:07:19 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:07:19 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:07:19 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:07:19 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:07:19 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:07:19 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:07:19 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.11 GB
Capturing batches (bs=1 avail_mem=14.56 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  3.07it/s][2025-09-13 07:07:26 TP3] Registering 72 cuda graph addresses
[2025-09-13 07:07:26 TP5] Registering 72 cuda graph addresses
[2025-09-13 07:07:26 TP4] Registering 72 cuda graph addresses
[2025-09-13 07:07:26 TP1] Registering 72 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.56 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.42it/s]
[2025-09-13 07:07:26 TP6] Registering 72 cuda graph addresses
[2025-09-13 07:07:26 TP0] Registering 72 cuda graph addresses
[2025-09-13 07:07:26 TP2] Registering 72 cuda graph addresses
[2025-09-13 07:07:26 TP7] Registering 72 cuda graph addresses
[2025-09-13 07:07:26 TP2] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.35 GB. avail mem=14.52 GB.
[2025-09-13 07:07:26 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:07:26 TP6] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.35 GB. avail mem=14.52 GB.
[2025-09-13 07:07:26 TP0] Capture draft cuda graph end. Time elapsed: 6.28 s. mem usage=0.36 GB. avail mem=14.56 GB.
[2025-09-13 07:07:26 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.56 GB
[2025-09-13 07:07:26 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:07:26 TP5] Capture draft cuda graph end. Time elapsed: 6.27 s. mem usage=0.35 GB. avail mem=14.52 GB.
[2025-09-13 07:07:26 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:07:26 TP4] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.35 GB. avail mem=14.52 GB.
[2025-09-13 07:07:26 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:07:26 TP3] Capture draft cuda graph end. Time elapsed: 6.26 s. mem usage=0.35 GB. avail mem=14.52 GB.
[2025-09-13 07:07:26 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:07:26 TP7] Capture draft cuda graph end. Time elapsed: 6.25 s. mem usage=0.35 GB. avail mem=14.75 GB.
[2025-09-13 07:07:26 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.75 GB
[2025-09-13 07:07:26 TP1] Capture draft cuda graph end. Time elapsed: 6.26 s. mem usage=0.35 GB. avail mem=14.52 GB.
[2025-09-13 07:07:26 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
Capturing batches (bs=1 avail_mem=14.38 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:00<00:00, 27.05it/s][2025-09-13 07:07:27 TP5] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.38 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 23.54it/s][2025-09-13 07:07:27 TP2] Registering 24 cuda graph addresses

[2025-09-13 07:07:27 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:07:27 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:07:27 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:07:27 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:07:27 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:07:27 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:07:27 TP3] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.18 GB. avail mem=14.34 GB.
[2025-09-13 07:07:27 TP2] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.18 GB. avail mem=14.34 GB.
[2025-09-13 07:07:27 TP0] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.18 GB. avail mem=14.38 GB.
[2025-09-13 07:07:27 TP0] max_total_num_tokens=620249, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.38 GB
[2025-09-13 07:07:27 TP7] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.18 GB. avail mem=14.57 GB.
[2025-09-13 07:07:27 TP5] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.18 GB. avail mem=14.34 GB.
[2025-09-13 07:07:27 TP4] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.18 GB. avail mem=14.34 GB.
[2025-09-13 07:07:27 TP6] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.18 GB. avail mem=14.34 GB.
[2025-09-13 07:07:27 TP1] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.18 GB. avail mem=14.34 GB.
[2025-09-13 07:07:27] INFO:     Started server process [222319]
[2025-09-13 07:07:27] INFO:     Waiting for application startup.
[2025-09-13 07:07:27] INFO:     Application startup complete.
[2025-09-13 07:07:27] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:07:28] INFO:     127.0.0.1:48286 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:07:28 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:07:28 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:07:28 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25044.59it/s]
[2025-09-13 07:07:30] INFO:     127.0.0.1:48300 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:30] The server is fired up and ready to roll!
[2025-09-13 07:07:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:07:38] INFO:     127.0.0.1:48310 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:07:38] INFO:     127.0.0.1:33544 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:38 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:07:40] INFO:     127.0.0.1:33546 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:40] INFO:     127.0.0.1:33558 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:07:40] INFO:     127.0.0.1:33564 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:40] INFO:     127.0.0.1:33566 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:40] INFO:     127.0.0.1:33572 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:40] INFO:     127.0.0.1:33576 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:40] INFO:     127.0.0.1:33582 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:40] INFO:     127.0.0.1:33594 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:40 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:07:40 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:07:40 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:07:40 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:07:40 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:07:40 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:07:40 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:07:40 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:07:40 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:07:40 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:07:42 TP0] Decode batch. #running-req: 8, #token: 14700, token usage: 0.02, accept len: 3.43, cuda graph: True, gen throughput (token/s): 54.58, #queue-req: 0, 
[2025-09-13 07:07:43 TP0] Decode batch. #running-req: 8, #token: 15952, token usage: 0.03, accept len: 3.91, cuda graph: True, gen throughput (token/s): 891.70, #queue-req: 0, 
[2025-09-13 07:07:44 TP0] Decode batch. #running-req: 8, #token: 17285, token usage: 0.03, accept len: 4.17, cuda graph: True, gen throughput (token/s): 945.17, #queue-req: 0, 
 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 7/8 [00:05<00:00,  2.28it/s][2025-09-13 07:07:46 TP0] Decode batch. #running-req: 1, #token: 1506, token usage: 0.00, accept len: 4.11, cuda graph: True, gen throughput (token/s): 515.05, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.33it/s]
[2025-09-13 07:07:46] INFO:     127.0.0.1:33606 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.02      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4078      
Request throughput (req/s):              1.33      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         680.01    
Total token throughput (tok/s):          680.01    
Concurrency:                             7.13      
Accept length:                           3.91      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5371.68   
Median E2E Latency (ms):                 5380.75   
---------------Time to First Token----------------
Mean TTFT (ms):                          611.71    
Median TTFT (ms):                        723.89    
P99 TTFT (ms):                           724.45    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.31      
Median ITL (ms):                         7.07      
P95 ITL (ms):                            17.56     
P99 ITL (ms):                            35.02     
Max ITL (ms):                            737.30    
==================================================
[2025-09-13 07:07:46] INFO:     127.0.0.1:33612 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:07:46] INFO:     127.0.0.1:33616 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:07:47] INFO:     127.0.0.1:33618 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:47] INFO:     127.0.0.1:33628 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:07:47] INFO:     127.0.0.1:33640 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:47] INFO:     127.0.0.1:33644 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:47] INFO:     127.0.0.1:33660 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:47] INFO:     127.0.0.1:33676 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:47] INFO:     127.0.0.1:33682 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:47] INFO:     127.0.0.1:33694 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:47 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:07:48 TP0] Decode batch. #running-req: 8, #token: 14700, token usage: 0.02, accept len: 3.48, cuda graph: True, gen throughput (token/s): 305.45, #queue-req: 0, 
[2025-09-13 07:07:50 TP0] Decode batch. #running-req: 8, #token: 15938, token usage: 0.03, accept len: 3.87, cuda graph: True, gen throughput (token/s): 883.47, #queue-req: 0, 
[2025-09-13 07:07:51 TP0] Decode batch. #running-req: 8, #token: 17262, token usage: 0.03, accept len: 4.14, cuda graph: True, gen throughput (token/s): 939.84, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:03,  4.21s/it][2025-09-13 07:07:51] INFO:     127.0.0.1:44688 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:51 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:28,  2.05s/it][2025-09-13 07:07:52] INFO:     127.0.0.1:44704 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:04<00:15,  1.22s/it][2025-09-13 07:07:52] INFO:     127.0.0.1:44708 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:52 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.12it/s][2025-09-13 07:07:53] INFO:     127.0.0.1:44714 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:53 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:07:53] INFO:     127.0.0.1:44728 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:53 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.88it/s][2025-09-13 07:07:53] INFO:     127.0.0.1:44742 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:53 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:04,  1.96it/s][2025-09-13 07:07:54] INFO:     127.0.0.1:44756 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:54 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:07:54 TP0] Decode batch. #running-req: 8, #token: 10414, token usage: 0.02, accept len: 3.86, cuda graph: True, gen throughput (token/s): 486.00, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:04,  1.91it/s][2025-09-13 07:07:54] INFO:     127.0.0.1:44766 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:07:54 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:07:56 TP0] Decode batch. #running-req: 8, #token: 15050, token usage: 0.02, accept len: 3.49, cuda graph: True, gen throughput (token/s): 641.08, #queue-req: 0, 
[2025-09-13 07:07:57 TP0] Decode batch. #running-req: 8, #token: 16332, token usage: 0.03, accept len: 4.01, cuda graph: True, gen throughput (token/s): 910.27, #queue-req: 0, 
 56%|█████████████████████████████████████████████████████████████████████████▏                                                        | 9/16 [00:10<00:10,  1.43s/it][2025-09-13 07:07:58 TP0] Decode batch. #running-req: 4, #token: 9414, token usage: 0.02, accept len: 4.20, cuda graph: True, gen throughput (token/s): 813.72, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.39it/s]
[2025-09-13 07:07:59] INFO:     127.0.0.1:40576 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.55     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8084      
Request throughput (req/s):              1.39      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         709.34    
Total token throughput (tok/s):          709.34    
Concurrency:                             7.55      
Accept length:                           3.88      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5449.73   
Median E2E Latency (ms):                 5464.32   
---------------Time to First Token----------------
Mean TTFT (ms):                          243.07    
Median TTFT (ms):                        287.08    
P99 TTFT (ms):                           322.15    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.19     
Median ITL (ms):                         7.06      
P95 ITL (ms):                            19.03     
P99 ITL (ms):                            50.99     
Max ITL (ms):                            273.14    
==================================================
[2025-09-13 07:07:59] INFO:     127.0.0.1:40580 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=17: batch_size=8, steps=4, topk=3, num_draft_tokens=12, speed=110.40 token/s, step_time=35.17 ms
Start i=18: batch_size=8, steps=4, topk=4, num_draft_tokens=4
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 4 --speculative-eagle-topk 4 --speculative-num-draft-tokens 4 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:08:10.159000 227973 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:08:10.159000 227973 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:08:10] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=1025409680, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=4, speculative_eagle_topk=4, speculative_num_draft_tokens=4, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:08:10] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:08:19.504000 228183 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:08:19.504000 228183 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:08:19.511000 228187 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:08:19.511000 228187 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:08:19.533000 228188 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:08:19.533000 228188 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:08:19.547000 228184 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:08:19.547000 228184 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:08:19.588000 228186 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:08:19.588000 228186 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:08:19.725000 228182 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:08:19.725000 228182 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:08:19.728000 228189 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:08:19.728000 228189 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:08:19.743000 228185 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:08:19.743000 228185 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:08:19.758000 228181 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:08:19.758000 228181 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:08:20 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:08:20 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:08:20 TP0] Init torch distributed begin.
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:08:22 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:08:25 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:08:26 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:08:26 TP0] Detected fp8 checkpoint.
[2025-09-13 07:08:26 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 27/1024 [00:00<00:03, 260.20it/s]
Loading safetensors checkpoint shards:   5% Completed | 54/1024 [00:00<00:12, 75.72it/s]
Loading safetensors checkpoint shards:   7% Completed | 68/1024 [00:00<00:15, 62.10it/s]
Loading safetensors checkpoint shards:   8% Completed | 78/1024 [00:01<00:16, 58.27it/s]
Loading safetensors checkpoint shards:   8% Completed | 87/1024 [00:01<00:15, 62.37it/s]
Loading safetensors checkpoint shards:   9% Completed | 95/1024 [00:01<00:17, 52.63it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:02<00:29, 31.38it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:02<00:26, 34.05it/s]
Loading safetensors checkpoint shards:  11% Completed | 113/1024 [00:02<00:27, 32.77it/s]
Loading safetensors checkpoint shards:  12% Completed | 118/1024 [00:02<00:27, 33.25it/s]
Loading safetensors checkpoint shards:  12% Completed | 122/1024 [00:02<00:27, 33.08it/s]
Loading safetensors checkpoint shards:  12% Completed | 127/1024 [00:02<00:24, 36.35it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:02<00:24, 36.84it/s]
Loading safetensors checkpoint shards:  13% Completed | 137/1024 [00:02<00:22, 39.30it/s]
Loading safetensors checkpoint shards:  14% Completed | 142/1024 [00:03<00:21, 41.11it/s]
Loading safetensors checkpoint shards:  14% Completed | 147/1024 [00:03<00:21, 40.12it/s]
Loading safetensors checkpoint shards:  15% Completed | 152/1024 [00:03<00:21, 39.98it/s]
Loading safetensors checkpoint shards:  15% Completed | 157/1024 [00:03<00:22, 38.94it/s]
Loading safetensors checkpoint shards:  16% Completed | 162/1024 [00:03<00:21, 40.50it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:03<00:22, 38.39it/s]
Loading safetensors checkpoint shards:  17% Completed | 172/1024 [00:03<00:21, 39.64it/s]
Loading safetensors checkpoint shards:  17% Completed | 177/1024 [00:03<00:21, 38.96it/s]
Loading safetensors checkpoint shards:  18% Completed | 181/1024 [00:04<00:22, 37.49it/s]
Loading safetensors checkpoint shards:  18% Completed | 186/1024 [00:04<00:21, 39.21it/s]
Loading safetensors checkpoint shards:  19% Completed | 190/1024 [00:04<00:21, 38.50it/s]
Loading safetensors checkpoint shards:  19% Completed | 195/1024 [00:04<00:20, 39.94it/s]
Loading safetensors checkpoint shards:  20% Completed | 200/1024 [00:04<00:21, 38.78it/s]
Loading safetensors checkpoint shards:  20% Completed | 204/1024 [00:04<00:21, 38.01it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:04<00:20, 40.28it/s]
Loading safetensors checkpoint shards:  21% Completed | 214/1024 [00:04<00:21, 38.08it/s]
Loading safetensors checkpoint shards:  21% Completed | 218/1024 [00:05<00:20, 38.56it/s]
Loading safetensors checkpoint shards:  22% Completed | 222/1024 [00:05<00:21, 37.22it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:05<00:20, 38.05it/s]
Loading safetensors checkpoint shards:  23% Completed | 231/1024 [00:05<00:20, 37.85it/s]
Loading safetensors checkpoint shards:  23% Completed | 235/1024 [00:05<00:21, 36.82it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:05<00:20, 38.43it/s]
Loading safetensors checkpoint shards:  24% Completed | 244/1024 [00:05<00:20, 37.97it/s]
Loading safetensors checkpoint shards:  24% Completed | 250/1024 [00:05<00:18, 41.42it/s]
Loading safetensors checkpoint shards:  25% Completed | 255/1024 [00:05<00:18, 42.58it/s]
Loading safetensors checkpoint shards:  26% Completed | 263/1024 [00:06<00:14, 52.06it/s]
Loading safetensors checkpoint shards:  26% Completed | 270/1024 [00:06<00:13, 56.45it/s]
Loading safetensors checkpoint shards:  27% Completed | 276/1024 [00:06<00:13, 55.69it/s]
Loading safetensors checkpoint shards:  28% Completed | 282/1024 [00:06<00:14, 51.48it/s]
Loading safetensors checkpoint shards:  28% Completed | 288/1024 [00:06<00:30, 24.21it/s]
Loading safetensors checkpoint shards:  29% Completed | 294/1024 [00:07<00:25, 28.96it/s]
Loading safetensors checkpoint shards:  29% Completed | 299/1024 [00:07<00:23, 30.55it/s]
Loading safetensors checkpoint shards:  30% Completed | 305/1024 [00:07<00:20, 34.37it/s]
Loading safetensors checkpoint shards:  30% Completed | 310/1024 [00:07<00:22, 32.10it/s]
Loading safetensors checkpoint shards:  31% Completed | 314/1024 [00:07<00:24, 29.16it/s]
Loading safetensors checkpoint shards:  31% Completed | 319/1024 [00:07<00:21, 32.33it/s]
Loading safetensors checkpoint shards:  32% Completed | 323/1024 [00:07<00:20, 33.41it/s]
Loading safetensors checkpoint shards:  32% Completed | 330/1024 [00:08<00:16, 41.28it/s]
Loading safetensors checkpoint shards:  33% Completed | 336/1024 [00:08<00:15, 44.66it/s]
Loading safetensors checkpoint shards:  33% Completed | 343/1024 [00:08<00:13, 48.80it/s]
Loading safetensors checkpoint shards:  34% Completed | 350/1024 [00:08<00:13, 51.27it/s]
Loading safetensors checkpoint shards:  35% Completed | 356/1024 [00:08<00:12, 52.38it/s]
Loading safetensors checkpoint shards:  35% Completed | 362/1024 [00:08<00:14, 46.48it/s]
Loading safetensors checkpoint shards:  36% Completed | 368/1024 [00:08<00:13, 48.43it/s]
Loading safetensors checkpoint shards:  37% Completed | 377/1024 [00:08<00:11, 55.58it/s]
Loading safetensors checkpoint shards:  38% Completed | 385/1024 [00:08<00:10, 59.79it/s]
Loading safetensors checkpoint shards:  38% Completed | 392/1024 [00:09<00:12, 51.92it/s]
Loading safetensors checkpoint shards:  39% Completed | 398/1024 [00:09<00:12, 51.49it/s]
Loading safetensors checkpoint shards:  39% Completed | 404/1024 [00:09<00:12, 51.05it/s]
Loading safetensors checkpoint shards:  40% Completed | 410/1024 [00:09<00:14, 42.85it/s]
Loading safetensors checkpoint shards:  41% Completed | 415/1024 [00:09<00:13, 43.72it/s]
Loading safetensors checkpoint shards:  41% Completed | 420/1024 [00:09<00:15, 39.85it/s]
Loading safetensors checkpoint shards:  42% Completed | 425/1024 [00:10<00:15, 38.43it/s]
Loading safetensors checkpoint shards:  42% Completed | 429/1024 [00:10<00:16, 36.18it/s]
Loading safetensors checkpoint shards:  42% Completed | 433/1024 [00:10<00:20, 29.02it/s]
Loading safetensors checkpoint shards:  43% Completed | 438/1024 [00:10<00:18, 32.31it/s]
Loading safetensors checkpoint shards:  43% Completed | 442/1024 [00:10<00:17, 33.45it/s]
Loading safetensors checkpoint shards:  44% Completed | 446/1024 [00:10<00:16, 34.11it/s]
Loading safetensors checkpoint shards:  44% Completed | 451/1024 [00:10<00:15, 36.50it/s]
Loading safetensors checkpoint shards:  45% Completed | 456/1024 [00:10<00:14, 37.88it/s]
Loading safetensors checkpoint shards:  45% Completed | 461/1024 [00:11<00:14, 39.68it/s]
Loading safetensors checkpoint shards:  46% Completed | 466/1024 [00:11<00:14, 38.70it/s]
Loading safetensors checkpoint shards:  46% Completed | 470/1024 [00:11<00:28, 19.29it/s]
Loading safetensors checkpoint shards:  46% Completed | 475/1024 [00:11<00:23, 23.72it/s]
Loading safetensors checkpoint shards:  47% Completed | 480/1024 [00:11<00:19, 27.76it/s]
Loading safetensors checkpoint shards:  47% Completed | 486/1024 [00:12<00:16, 33.09it/s]
Loading safetensors checkpoint shards:  48% Completed | 491/1024 [00:12<00:15, 34.26it/s]
Loading safetensors checkpoint shards:  49% Completed | 497/1024 [00:12<00:13, 38.38it/s]
Loading safetensors checkpoint shards:  49% Completed | 502/1024 [00:12<00:13, 40.13it/s]
Loading safetensors checkpoint shards:  50% Completed | 507/1024 [00:12<00:12, 41.86it/s]
Loading safetensors checkpoint shards:  50% Completed | 512/1024 [00:12<00:12, 42.15it/s]
Loading safetensors checkpoint shards:  50% Completed | 517/1024 [00:12<00:11, 43.35it/s]
Loading safetensors checkpoint shards:  51% Completed | 522/1024 [00:12<00:11, 42.14it/s]
Loading safetensors checkpoint shards:  52% Completed | 528/1024 [00:12<00:11, 44.63it/s]
Loading safetensors checkpoint shards:  52% Completed | 533/1024 [00:13<00:11, 44.01it/s]
Loading safetensors checkpoint shards:  53% Completed | 538/1024 [00:13<00:10, 44.18it/s]
Loading safetensors checkpoint shards:  53% Completed | 543/1024 [00:13<00:11, 43.20it/s]
Loading safetensors checkpoint shards:  54% Completed | 549/1024 [00:13<00:10, 45.29it/s]
Loading safetensors checkpoint shards:  54% Completed | 554/1024 [00:13<00:10, 44.65it/s]
Loading safetensors checkpoint shards:  55% Completed | 559/1024 [00:13<00:10, 44.38it/s]
Loading safetensors checkpoint shards:  55% Completed | 564/1024 [00:13<00:10, 43.27it/s]
Loading safetensors checkpoint shards:  56% Completed | 569/1024 [00:13<00:10, 43.09it/s]
Loading safetensors checkpoint shards:  56% Completed | 574/1024 [00:14<00:10, 43.61it/s]
Loading safetensors checkpoint shards:  57% Completed | 579/1024 [00:14<00:10, 43.49it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:14<00:09, 47.30it/s]
Loading safetensors checkpoint shards:  58% Completed | 590/1024 [00:14<00:09, 44.74it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:14<00:09, 46.54it/s]
Loading safetensors checkpoint shards:  59% Completed | 601/1024 [00:14<00:09, 45.51it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:14<00:09, 45.47it/s]
Loading safetensors checkpoint shards:  60% Completed | 611/1024 [00:14<00:09, 45.00it/s]
Loading safetensors checkpoint shards:  60% Completed | 616/1024 [00:14<00:08, 46.26it/s]
Loading safetensors checkpoint shards:  61% Completed | 621/1024 [00:15<00:08, 45.03it/s]
Loading safetensors checkpoint shards:  61% Completed | 626/1024 [00:15<00:09, 43.26it/s]
Loading safetensors checkpoint shards:  62% Completed | 631/1024 [00:15<00:09, 40.63it/s]
Loading safetensors checkpoint shards:  62% Completed | 636/1024 [00:15<00:09, 40.58it/s]
Loading safetensors checkpoint shards:  63% Completed | 641/1024 [00:15<00:09, 41.58it/s]
Loading safetensors checkpoint shards:  63% Completed | 646/1024 [00:15<00:09, 40.92it/s]
Loading safetensors checkpoint shards:  64% Completed | 651/1024 [00:15<00:09, 41.18it/s]
Loading safetensors checkpoint shards:  64% Completed | 656/1024 [00:15<00:09, 40.71it/s]
Loading safetensors checkpoint shards:  65% Completed | 661/1024 [00:16<00:09, 38.45it/s]
Loading safetensors checkpoint shards:  65% Completed | 665/1024 [00:16<00:09, 37.97it/s]
Loading safetensors checkpoint shards:  65% Completed | 669/1024 [00:16<00:09, 38.28it/s]
Loading safetensors checkpoint shards:  66% Completed | 673/1024 [00:16<00:09, 38.22it/s]
Loading safetensors checkpoint shards:  66% Completed | 677/1024 [00:16<00:08, 38.61it/s]
Loading safetensors checkpoint shards:  67% Completed | 682/1024 [00:16<00:08, 39.31it/s]
Loading safetensors checkpoint shards:  67% Completed | 687/1024 [00:16<00:08, 40.24it/s]
Loading safetensors checkpoint shards:  68% Completed | 692/1024 [00:16<00:07, 42.61it/s]
Loading safetensors checkpoint shards:  68% Completed | 697/1024 [00:16<00:07, 42.90it/s]
Loading safetensors checkpoint shards:  69% Completed | 702/1024 [00:17<00:07, 41.07it/s]
Loading safetensors checkpoint shards:  69% Completed | 707/1024 [00:17<00:07, 40.51it/s]
Loading safetensors checkpoint shards:  70% Completed | 712/1024 [00:17<00:07, 40.58it/s]
Loading safetensors checkpoint shards:  70% Completed | 717/1024 [00:17<00:07, 39.26it/s]
Loading safetensors checkpoint shards:  70% Completed | 721/1024 [00:17<00:07, 38.58it/s]
Loading safetensors checkpoint shards:  71% Completed | 725/1024 [00:17<00:07, 38.52it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:17<00:07, 38.52it/s]
Loading safetensors checkpoint shards:  72% Completed | 733/1024 [00:17<00:07, 37.68it/s]
Loading safetensors checkpoint shards:  72% Completed | 737/1024 [00:17<00:07, 37.80it/s]
Loading safetensors checkpoint shards:  72% Completed | 741/1024 [00:18<00:07, 37.08it/s]
Loading safetensors checkpoint shards:  73% Completed | 745/1024 [00:18<00:07, 37.40it/s]
Loading safetensors checkpoint shards:  73% Completed | 749/1024 [00:18<00:16, 16.27it/s]
Loading safetensors checkpoint shards:  74% Completed | 753/1024 [00:18<00:13, 19.66it/s]
Loading safetensors checkpoint shards:  74% Completed | 758/1024 [00:19<00:11, 24.01it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:19<00:09, 27.85it/s]
Loading safetensors checkpoint shards:  75% Completed | 768/1024 [00:19<00:08, 30.82it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:19<00:07, 32.35it/s]
Loading safetensors checkpoint shards:  76% Completed | 777/1024 [00:19<00:07, 34.90it/s]
Loading safetensors checkpoint shards:  76% Completed | 782/1024 [00:19<00:06, 36.49it/s]
Loading safetensors checkpoint shards:  77% Completed | 786/1024 [00:19<00:06, 37.31it/s]
Loading safetensors checkpoint shards:  77% Completed | 790/1024 [00:19<00:06, 36.93it/s]
Loading safetensors checkpoint shards:  78% Completed | 794/1024 [00:19<00:06, 37.22it/s]
Loading safetensors checkpoint shards:  78% Completed | 798/1024 [00:20<00:05, 37.87it/s]
Loading safetensors checkpoint shards:  78% Completed | 802/1024 [00:20<00:05, 37.41it/s]
Loading safetensors checkpoint shards:  79% Completed | 807/1024 [00:20<00:05, 40.35it/s]
Loading safetensors checkpoint shards:  79% Completed | 812/1024 [00:20<00:05, 40.74it/s]
Loading safetensors checkpoint shards:  80% Completed | 817/1024 [00:20<00:05, 39.58it/s]
Loading safetensors checkpoint shards:  80% Completed | 821/1024 [00:20<00:05, 38.88it/s]
Loading safetensors checkpoint shards:  81% Completed | 825/1024 [00:20<00:05, 39.10it/s]
Loading safetensors checkpoint shards:  81% Completed | 830/1024 [00:20<00:04, 39.41it/s]
Loading safetensors checkpoint shards:  82% Completed | 835/1024 [00:20<00:04, 39.94it/s]
Loading safetensors checkpoint shards:  82% Completed | 840/1024 [00:21<00:04, 40.29it/s]
Loading safetensors checkpoint shards:  83% Completed | 845/1024 [00:21<00:04, 40.15it/s]
Loading safetensors checkpoint shards:  83% Completed | 850/1024 [00:21<00:04, 40.05it/s]
Loading safetensors checkpoint shards:  83% Completed | 855/1024 [00:21<00:04, 39.24it/s]
Loading safetensors checkpoint shards:  84% Completed | 859/1024 [00:21<00:04, 37.05it/s]
Loading safetensors checkpoint shards:  84% Completed | 863/1024 [00:21<00:04, 36.28it/s]
Loading safetensors checkpoint shards:  85% Completed | 867/1024 [00:21<00:04, 36.09it/s]
Loading safetensors checkpoint shards:  85% Completed | 871/1024 [00:21<00:04, 36.66it/s]
Loading safetensors checkpoint shards:  85% Completed | 875/1024 [00:22<00:04, 35.86it/s]
Loading safetensors checkpoint shards:  86% Completed | 879/1024 [00:22<00:03, 36.60it/s]
Loading safetensors checkpoint shards:  86% Completed | 883/1024 [00:22<00:03, 36.21it/s]
Loading safetensors checkpoint shards:  87% Completed | 887/1024 [00:22<00:03, 36.87it/s]
Loading safetensors checkpoint shards:  87% Completed | 891/1024 [00:22<00:03, 36.47it/s]
Loading safetensors checkpoint shards:  87% Completed | 895/1024 [00:22<00:03, 36.23it/s]
Loading safetensors checkpoint shards:  88% Completed | 899/1024 [00:22<00:03, 35.80it/s]
Loading safetensors checkpoint shards:  88% Completed | 903/1024 [00:22<00:03, 36.18it/s]
Loading safetensors checkpoint shards:  89% Completed | 907/1024 [00:22<00:03, 36.79it/s]
Loading safetensors checkpoint shards:  89% Completed | 911/1024 [00:23<00:03, 37.11it/s]
Loading safetensors checkpoint shards:  89% Completed | 916/1024 [00:23<00:02, 38.52it/s]
Loading safetensors checkpoint shards:  90% Completed | 920/1024 [00:23<00:02, 38.58it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:23<00:02, 38.37it/s]
Loading safetensors checkpoint shards:  91% Completed | 928/1024 [00:23<00:02, 37.51it/s]
Loading safetensors checkpoint shards:  91% Completed | 932/1024 [00:23<00:02, 36.44it/s]
Loading safetensors checkpoint shards:  91% Completed | 936/1024 [00:23<00:02, 36.99it/s]
Loading safetensors checkpoint shards:  92% Completed | 940/1024 [00:23<00:02, 36.40it/s]
Loading safetensors checkpoint shards:  92% Completed | 944/1024 [00:23<00:02, 35.83it/s]
Loading safetensors checkpoint shards:  93% Completed | 948/1024 [00:24<00:02, 34.03it/s]
Loading safetensors checkpoint shards:  93% Completed | 952/1024 [00:24<00:02, 35.54it/s]
Loading safetensors checkpoint shards:  93% Completed | 957/1024 [00:24<00:01, 38.62it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:24<00:01, 37.96it/s]
Loading safetensors checkpoint shards:  94% Completed | 967/1024 [00:24<00:01, 42.86it/s]
Loading safetensors checkpoint shards:  95% Completed | 972/1024 [00:24<00:01, 44.13it/s]
Loading safetensors checkpoint shards:  95% Completed | 977/1024 [00:24<00:01, 44.30it/s]
Loading safetensors checkpoint shards:  96% Completed | 985/1024 [00:24<00:00, 53.84it/s]
Loading safetensors checkpoint shards:  97% Completed | 993/1024 [00:24<00:00, 60.00it/s]
Loading safetensors checkpoint shards:  98% Completed | 1001/1024 [00:25<00:00, 64.86it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 40.85it/s]

[2025-09-13 07:08:52 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:08:54 TP5] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:08:54 TP0] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:08:54 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:08:54 TP3] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:08:54 TP2] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:08:54 TP6] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:08:54 TP1] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:08:54 TP4] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:08:54 TP7] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:08:54 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:08:54 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.53 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:08:55 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:08:55 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:08:55 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:08:56 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:08:56 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:08:56 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:08:56 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:08:56 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:08:56 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25135.58it/s]
[2025-09-13 07:08:56 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:08:56 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26252.11it/s]
[2025-09-13 07:08:57 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:08:57 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27624.75it/s]
[2025-09-13 07:08:57 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:08:57 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27553.84it/s]
[2025-09-13 07:08:58 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:08:58 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28672.85it/s]
[2025-09-13 07:08:59 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.22 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.90it/s][2025-09-13 07:09:02 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:09:02 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:09:02 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:09:02 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:09:02 TP5] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.22 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.11it/s]
[2025-09-13 07:09:02 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:09:02 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:09:02 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:09:02 TP0] Capture cuda graph end. Time elapsed: 7.82 s. mem usage=0.36 GB. avail mem=17.20 GB.
[2025-09-13 07:09:02 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:09:02 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:09:02 TP0] Init torch distributed begin.
[2025-09-13 07:09:02 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:09:02 TP0] Load weight begin. avail mem=17.20 GB
[2025-09-13 07:09:02 TP0] Detected fp8 checkpoint.
[2025-09-13 07:09:02 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 19/1024 [00:00<00:05, 179.97it/s]
Loading safetensors checkpoint shards:   5% Completed | 49/1024 [00:00<00:03, 248.29it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:00<00:02, 400.69it/s]
Loading safetensors checkpoint shards:  16% Completed | 168/1024 [00:00<00:01, 477.13it/s]
Loading safetensors checkpoint shards:  22% Completed | 228/1024 [00:00<00:01, 519.78it/s]
Loading safetensors checkpoint shards:  28% Completed | 288/1024 [00:00<00:01, 546.40it/s]
Loading safetensors checkpoint shards:  34% Completed | 348/1024 [00:00<00:01, 563.01it/s]
Loading safetensors checkpoint shards:  40% Completed | 408/1024 [00:00<00:01, 574.58it/s]
Loading safetensors checkpoint shards:  46% Completed | 467/1024 [00:00<00:00, 579.36it/s]
Loading safetensors checkpoint shards:  52% Completed | 528/1024 [00:01<00:00, 588.31it/s]
Loading safetensors checkpoint shards:  58% Completed | 589/1024 [00:01<00:00, 592.68it/s]
Loading safetensors checkpoint shards:  63% Completed | 649/1024 [00:01<00:00, 587.87it/s]
Loading safetensors checkpoint shards:  69% Completed | 708/1024 [00:01<00:00, 579.87it/s]
Loading safetensors checkpoint shards:  75% Completed | 767/1024 [00:01<00:00, 572.14it/s]
Loading safetensors checkpoint shards:  81% Completed | 825/1024 [00:01<00:00, 568.57it/s]
Loading safetensors checkpoint shards:  86% Completed | 882/1024 [00:01<00:00, 565.55it/s]
Loading safetensors checkpoint shards:  92% Completed | 940/1024 [00:01<00:00, 567.93it/s]
Loading safetensors checkpoint shards:  97% Completed | 997/1024 [00:01<00:00, 469.80it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 502.33it/s]

[2025-09-13 07:09:04 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.21 GB, mem usage=1.99 GB.
[2025-09-13 07:09:04 TP0] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:09:04 TP0] Memory pool end. avail mem=14.54 GB
[2025-09-13 07:09:04 TP5] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:09:04 TP4] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:09:04 TP6] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:09:04 TP2] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:09:04 TP3] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:09:04 TP1] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:09:04 TP7] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:09:05 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:09:05 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:09:05 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:09:05 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:09:05 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:09:05 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:09:05 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.17 GB
[2025-09-13 07:09:05 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
Capturing batches (bs=1 avail_mem=14.56 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:03<00:00,  3.80it/s][2025-09-13 07:09:11 TP2] Registering 72 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.56 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.45it/s]
[2025-09-13 07:09:11 TP1] Registering 72 cuda graph addresses
[2025-09-13 07:09:11 TP6] Registering 72 cuda graph addresses
[2025-09-13 07:09:11 TP4] Registering 72 cuda graph addresses
[2025-09-13 07:09:11 TP0] Registering 72 cuda graph addresses
[2025-09-13 07:09:11 TP5] Registering 72 cuda graph addresses
[2025-09-13 07:09:11 TP7] Registering 72 cuda graph addresses
[2025-09-13 07:09:11 TP3] Registering 72 cuda graph addresses
[2025-09-13 07:09:11 TP2] Capture draft cuda graph end. Time elapsed: 6.32 s. mem usage=0.41 GB. avail mem=14.52 GB.
[2025-09-13 07:09:11 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:09:11 TP4] Capture draft cuda graph end. Time elapsed: 6.32 s. mem usage=0.41 GB. avail mem=14.52 GB.
[2025-09-13 07:09:11 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:09:11 TP0] Capture draft cuda graph end. Time elapsed: 6.27 s. mem usage=0.41 GB. avail mem=14.56 GB.
[2025-09-13 07:09:11 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.56 GB
[2025-09-13 07:09:11 TP1] Capture draft cuda graph end. Time elapsed: 6.26 s. mem usage=0.41 GB. avail mem=14.52 GB.
[2025-09-13 07:09:11 TP5] Capture draft cuda graph end. Time elapsed: 6.27 s. mem usage=0.41 GB. avail mem=14.52 GB.
[2025-09-13 07:09:11 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:09:11 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:09:11 TP6] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.41 GB. avail mem=14.52 GB.
[2025-09-13 07:09:11 TP7] Capture draft cuda graph end. Time elapsed: 6.25 s. mem usage=0.41 GB. avail mem=14.76 GB.
[2025-09-13 07:09:11 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:09:11 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.76 GB
[2025-09-13 07:09:11 TP3] Capture draft cuda graph end. Time elapsed: 6.25 s. mem usage=0.41 GB. avail mem=14.52 GB.
[2025-09-13 07:09:11 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
Capturing batches (bs=1 avail_mem=14.39 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 19.23it/s]
[2025-09-13 07:09:12 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:09:12 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:09:12 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:09:12 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:09:12 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:09:12 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:09:12 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:09:12 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:09:12 TP3] Capture draft extend cuda graph end. Time elapsed: 1.16 s. mem usage=0.18 GB. avail mem=14.35 GB.
[2025-09-13 07:09:12 TP1] Capture draft extend cuda graph end. Time elapsed: 1.17 s. mem usage=0.18 GB. avail mem=14.35 GB.
[2025-09-13 07:09:12 TP4] Capture draft extend cuda graph end. Time elapsed: 1.17 s. mem usage=0.18 GB. avail mem=14.35 GB.
[2025-09-13 07:09:12 TP2] Capture draft extend cuda graph end. Time elapsed: 1.17 s. mem usage=0.18 GB. avail mem=14.35 GB.
[2025-09-13 07:09:12 TP6] Capture draft extend cuda graph end. Time elapsed: 1.17 s. mem usage=0.18 GB. avail mem=14.35 GB.
[2025-09-13 07:09:12 TP5] Capture draft extend cuda graph end. Time elapsed: 1.17 s. mem usage=0.18 GB. avail mem=14.35 GB.
[2025-09-13 07:09:12 TP7] Capture draft extend cuda graph end. Time elapsed: 1.17 s. mem usage=0.18 GB. avail mem=14.58 GB.
[2025-09-13 07:09:12 TP0] Capture draft extend cuda graph end. Time elapsed: 1.17 s. mem usage=0.18 GB. avail mem=14.39 GB.
[2025-09-13 07:09:12 TP0] max_total_num_tokens=620217, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.39 GB
[2025-09-13 07:09:13] INFO:     Started server process [227973]
[2025-09-13 07:09:13] INFO:     Waiting for application startup.
[2025-09-13 07:09:13] INFO:     Application startup complete.
[2025-09-13 07:09:13] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:09:14] INFO:     127.0.0.1:59130 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:09:14 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:09:14 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:09:14 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup:  13%|█████████████▍                                                                                          | 2109/16384 [00:00<00:00, 21086.35it/s][2025-09-13 07:09:14] INFO:     127.0.0.1:59142 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28582.01it/s]
[2025-09-13 07:09:15] INFO:     127.0.0.1:59136 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:15] The server is fired up and ready to roll!
[2025-09-13 07:09:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:09:25] INFO:     127.0.0.1:42450 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:09:25] INFO:     127.0.0.1:42454 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:25 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:09:27] INFO:     127.0.0.1:42456 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:27] INFO:     127.0.0.1:42460 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:09:27] INFO:     127.0.0.1:42476 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:27] INFO:     127.0.0.1:42484 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:27] INFO:     127.0.0.1:42492 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:27] INFO:     127.0.0.1:42498 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:27] INFO:     127.0.0.1:42510 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:27] INFO:     127.0.0.1:42526 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:27 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:09:27 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:09:27 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:09:27 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:09:27 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:09:27 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:09:27 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:09:27 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:09:27 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:09:27 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:09:28 TP0] Decode batch. #running-req: 8, #token: 14467, token usage: 0.02, accept len: 2.62, cuda graph: True, gen throughput (token/s): 36.03, #queue-req: 0, 
[2025-09-13 07:09:30 TP0] Decode batch. #running-req: 8, #token: 15394, token usage: 0.02, accept len: 2.90, cuda graph: True, gen throughput (token/s): 779.24, #queue-req: 0, 
[2025-09-13 07:09:31 TP0] Decode batch. #running-req: 8, #token: 16296, token usage: 0.03, accept len: 2.82, cuda graph: True, gen throughput (token/s): 752.22, #queue-req: 0, 
[2025-09-13 07:09:32 TP0] Decode batch. #running-req: 8, #token: 17281, token usage: 0.03, accept len: 3.08, cuda graph: True, gen throughput (token/s): 821.54, #queue-req: 0, 
 62%|█████████████████████████████████████████████████████████████████████████████████▉                                                 | 5/8 [00:06<00:02,  1.42it/s][2025-09-13 07:09:33 TP0] Decode batch. #running-req: 2, #token: 2183, token usage: 0.00, accept len: 3.17, cuda graph: True, gen throughput (token/s): 548.14, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.23it/s]
[2025-09-13 07:09:33] INFO:     127.0.0.1:52180 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.53      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4068      
Request throughput (req/s):              1.23      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         627.43    
Total token throughput (tok/s):          627.43    
Concurrency:                             7.36      
Accept length:                           2.92      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   6005.41   
Median E2E Latency (ms):                 6034.21   
---------------Time to First Token----------------
Mean TTFT (ms):                          610.73    
Median TTFT (ms):                        721.55    
P99 TTFT (ms):                           722.12    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.56     
Median ITL (ms):                         7.53      
P95 ITL (ms):                            29.13     
P99 ITL (ms):                            31.26     
Max ITL (ms):                            727.22    
==================================================
[2025-09-13 07:09:33] INFO:     127.0.0.1:52196 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:09:33] INFO:     127.0.0.1:52208 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:09:35] INFO:     127.0.0.1:52222 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:35] INFO:     127.0.0.1:52236 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:09:35] INFO:     127.0.0.1:52242 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:35] INFO:     127.0.0.1:52258 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:35] INFO:     127.0.0.1:52264 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:35] INFO:     127.0.0.1:52276 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:35] INFO:     127.0.0.1:52278 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:35] INFO:     127.0.0.1:52284 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:35 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:09:36 TP0] Decode batch. #running-req: 8, #token: 14393, token usage: 0.02, accept len: 2.60, cuda graph: True, gen throughput (token/s): 218.30, #queue-req: 0, 
[2025-09-13 07:09:37 TP0] Decode batch. #running-req: 8, #token: 15326, token usage: 0.02, accept len: 2.92, cuda graph: True, gen throughput (token/s): 781.44, #queue-req: 0, 
[2025-09-13 07:09:38 TP0] Decode batch. #running-req: 8, #token: 16224, token usage: 0.03, accept len: 2.81, cuda graph: True, gen throughput (token/s): 753.07, #queue-req: 0, 
[2025-09-13 07:09:39 TP0] Decode batch. #running-req: 8, #token: 17207, token usage: 0.03, accept len: 3.07, cuda graph: True, gen throughput (token/s): 824.43, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:12,  4.80s/it][2025-09-13 07:09:40] INFO:     127.0.0.1:55346 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:40 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:05<00:32,  2.30s/it][2025-09-13 07:09:40] INFO:     127.0.0.1:55354 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:18,  1.40s/it][2025-09-13 07:09:40] INFO:     127.0.0.1:55358 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:40 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:11,  1.05it/s][2025-09-13 07:09:41] INFO:     127.0.0.1:55372 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:41 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:06<00:08,  1.36it/s][2025-09-13 07:09:41] INFO:     127.0.0.1:55388 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:41 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:09:41 TP0] Decode batch. #running-req: 8, #token: 8396, token usage: 0.01, accept len: 3.03, cuda graph: True, gen throughput (token/s): 468.69, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:06<00:05,  1.74it/s][2025-09-13 07:09:41] INFO:     127.0.0.1:55398 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:41 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:04,  2.03it/s][2025-09-13 07:09:42] INFO:     127.0.0.1:55414 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:07<00:03,  2.46it/s][2025-09-13 07:09:42] INFO:     127.0.0.1:55418 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:09:42 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:09:43 TP0] Decode batch. #running-req: 8, #token: 14464, token usage: 0.02, accept len: 2.66, cuda graph: True, gen throughput (token/s): 502.71, #queue-req: 0, 
[2025-09-13 07:09:44 TP0] Decode batch. #running-req: 8, #token: 15369, token usage: 0.02, accept len: 2.83, cuda graph: True, gen throughput (token/s): 756.09, #queue-req: 0, 
[2025-09-13 07:09:45 TP0] Decode batch. #running-req: 8, #token: 16354, token usage: 0.03, accept len: 3.08, cuda graph: True, gen throughput (token/s): 817.84, #queue-req: 0, 
 62%|████████████████████████████████████████████████████████████████████████████████▋                                                | 10/16 [00:11<00:07,  1.18s/it][2025-09-13 07:09:47 TP0] Decode batch. #running-req: 6, #token: 11580, token usage: 0.02, accept len: 3.23, cuda graph: True, gen throughput (token/s): 833.83, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:12<00:00,  1.29it/s]
[2025-09-13 07:09:47] INFO:     127.0.0.1:55430 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  12.38     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8070      
Request throughput (req/s):              1.29      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         661.93    
Total token throughput (tok/s):          661.93    
Concurrency:                             7.72      
Accept length:                           2.92      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5971.03   
Median E2E Latency (ms):                 5921.62   
---------------Time to First Token----------------
Mean TTFT (ms):                          235.60    
Median TTFT (ms):                        234.38    
P99 TTFT (ms):                           305.11    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           11.22     
Median ITL (ms):                         7.53      
P95 ITL (ms):                            29.78     
P99 ITL (ms):                            58.74     
Max ITL (ms):                            265.48    
==================================================
[2025-09-13 07:09:47] INFO:     127.0.0.1:55434 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=18: batch_size=8, steps=4, topk=4, num_draft_tokens=4, speed=98.00 token/s, step_time=29.82 ms
Start i=19: batch_size=8, steps=4, topk=4, num_draft_tokens=6
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 4 --speculative-eagle-topk 4 --speculative-num-draft-tokens 6 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:09:58.422000 233648 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:09:58.422000 233648 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:09:58] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=1068022584, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=4, speculative_eagle_topk=4, speculative_num_draft_tokens=6, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:09:59] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:10:07.659000 233861 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:10:07.659000 233861 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:10:07.691000 233859 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:10:07.691000 233859 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:10:07.854000 233867 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:10:07.854000 233867 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:10:07.856000 233865 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:10:07.856000 233865 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:10:07.938000 233860 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:10:07.938000 233860 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:10:08.078000 233862 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:10:08.078000 233862 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 07:10:08.109000 233866 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:10:08.109000 233866 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:10:08.169000 233864 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:10:08.169000 233864 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:10:08.182000 233863 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:10:08.182000 233863 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:10:08 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:10:08 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:10:08 TP0] Init torch distributed begin.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:10:09 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:10:13 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:10:14 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:10:14 TP0] Detected fp8 checkpoint.
[2025-09-13 07:10:15 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 28/1024 [00:00<00:04, 233.90it/s]
Loading safetensors checkpoint shards:   5% Completed | 52/1024 [00:00<00:14, 69.07it/s]
Loading safetensors checkpoint shards:   6% Completed | 65/1024 [00:00<00:16, 56.74it/s]
Loading safetensors checkpoint shards:   7% Completed | 74/1024 [00:01<00:17, 53.96it/s]
Loading safetensors checkpoint shards:   8% Completed | 81/1024 [00:01<00:19, 49.04it/s]
Loading safetensors checkpoint shards:   9% Completed | 88/1024 [00:01<00:17, 52.42it/s]
Loading safetensors checkpoint shards:   9% Completed | 95/1024 [00:01<00:17, 52.12it/s]
Loading safetensors checkpoint shards:  10% Completed | 101/1024 [00:02<00:28, 32.00it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:02<00:25, 35.97it/s]
Loading safetensors checkpoint shards:  11% Completed | 117/1024 [00:02<00:20, 44.88it/s]
Loading safetensors checkpoint shards:  12% Completed | 125/1024 [00:02<00:17, 51.26it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:02<00:18, 48.92it/s]
Loading safetensors checkpoint shards:  13% Completed | 138/1024 [00:02<00:17, 50.64it/s]
Loading safetensors checkpoint shards:  14% Completed | 144/1024 [00:02<00:16, 52.34it/s]
Loading safetensors checkpoint shards:  15% Completed | 151/1024 [00:02<00:15, 56.62it/s]
Loading safetensors checkpoint shards:  15% Completed | 158/1024 [00:02<00:15, 56.22it/s]
Loading safetensors checkpoint shards:  16% Completed | 166/1024 [00:03<00:14, 58.57it/s]
Loading safetensors checkpoint shards:  17% Completed | 173/1024 [00:03<00:14, 59.58it/s]
Loading safetensors checkpoint shards:  18% Completed | 180/1024 [00:03<00:14, 58.67it/s]
Loading safetensors checkpoint shards:  18% Completed | 187/1024 [00:03<00:13, 60.74it/s]
Loading safetensors checkpoint shards:  19% Completed | 195/1024 [00:03<00:12, 63.95it/s]
Loading safetensors checkpoint shards:  20% Completed | 202/1024 [00:03<00:12, 65.05it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:03<00:13, 62.48it/s]
Loading safetensors checkpoint shards:  21% Completed | 216/1024 [00:03<00:12, 62.85it/s]
Loading safetensors checkpoint shards:  22% Completed | 223/1024 [00:04<00:13, 58.34it/s]
Loading safetensors checkpoint shards:  22% Completed | 229/1024 [00:04<00:14, 53.10it/s]
Loading safetensors checkpoint shards:  23% Completed | 235/1024 [00:04<00:32, 24.65it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:04<00:28, 27.90it/s]
Loading safetensors checkpoint shards:  24% Completed | 245/1024 [00:04<00:25, 30.36it/s]
Loading safetensors checkpoint shards:  25% Completed | 251/1024 [00:05<00:22, 35.04it/s]
Loading safetensors checkpoint shards:  25% Completed | 256/1024 [00:05<00:20, 37.66it/s]
Loading safetensors checkpoint shards:  26% Completed | 262/1024 [00:05<00:18, 41.42it/s]
Loading safetensors checkpoint shards:  26% Completed | 267/1024 [00:05<00:18, 41.41it/s]
Loading safetensors checkpoint shards:  27% Completed | 272/1024 [00:05<00:17, 42.99it/s]
Loading safetensors checkpoint shards:  27% Completed | 277/1024 [00:05<00:18, 40.88it/s]
Loading safetensors checkpoint shards:  28% Completed | 283/1024 [00:05<00:17, 43.21it/s]
Loading safetensors checkpoint shards:  28% Completed | 289/1024 [00:05<00:16, 44.60it/s]
Loading safetensors checkpoint shards:  29% Completed | 294/1024 [00:06<00:16, 44.79it/s]
Loading safetensors checkpoint shards:  29% Completed | 299/1024 [00:06<00:15, 45.41it/s]
Loading safetensors checkpoint shards:  30% Completed | 305/1024 [00:06<00:15, 45.02it/s]
Loading safetensors checkpoint shards:  30% Completed | 310/1024 [00:06<00:17, 39.83it/s]
Loading safetensors checkpoint shards:  31% Completed | 315/1024 [00:06<00:17, 39.60it/s]
Loading safetensors checkpoint shards:  31% Completed | 320/1024 [00:06<00:19, 36.35it/s]
Loading safetensors checkpoint shards:  32% Completed | 324/1024 [00:06<00:20, 34.13it/s]
Loading safetensors checkpoint shards:  32% Completed | 328/1024 [00:07<00:23, 30.22it/s]
Loading safetensors checkpoint shards:  32% Completed | 332/1024 [00:07<00:26, 25.90it/s]
Loading safetensors checkpoint shards:  33% Completed | 335/1024 [00:07<00:28, 24.58it/s]
Loading safetensors checkpoint shards:  33% Completed | 338/1024 [00:07<00:26, 25.52it/s]
Loading safetensors checkpoint shards:  33% Completed | 341/1024 [00:07<00:26, 25.79it/s]
Loading safetensors checkpoint shards:  34% Completed | 344/1024 [00:07<00:26, 26.03it/s]
Loading safetensors checkpoint shards:  34% Completed | 347/1024 [00:07<00:26, 25.24it/s]
Loading safetensors checkpoint shards:  34% Completed | 351/1024 [00:08<00:24, 27.28it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:08<00:26, 25.00it/s]
Loading safetensors checkpoint shards:  35% Completed | 357/1024 [00:08<00:27, 24.47it/s]
Loading safetensors checkpoint shards:  35% Completed | 361/1024 [00:08<00:27, 24.39it/s]
Loading safetensors checkpoint shards:  36% Completed | 364/1024 [00:08<00:30, 21.74it/s]
Loading safetensors checkpoint shards:  36% Completed | 367/1024 [00:08<00:32, 20.23it/s]
Loading safetensors checkpoint shards:  36% Completed | 370/1024 [00:08<00:31, 20.57it/s]
Loading safetensors checkpoint shards:  36% Completed | 373/1024 [00:09<00:29, 21.94it/s]
Loading safetensors checkpoint shards:  37% Completed | 376/1024 [00:09<00:31, 20.47it/s]
Loading safetensors checkpoint shards:  37% Completed | 380/1024 [00:09<00:27, 23.85it/s]
Loading safetensors checkpoint shards:  38% Completed | 385/1024 [00:09<00:22, 28.58it/s]
Loading safetensors checkpoint shards:  38% Completed | 389/1024 [00:09<00:20, 30.54it/s]
Loading safetensors checkpoint shards:  38% Completed | 393/1024 [00:09<00:19, 32.82it/s]
Loading safetensors checkpoint shards:  39% Completed | 397/1024 [00:09<00:18, 33.36it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:09<00:18, 34.58it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:10<00:16, 37.07it/s]
Loading safetensors checkpoint shards:  40% Completed | 410/1024 [00:10<00:16, 36.91it/s]
Loading safetensors checkpoint shards:  40% Completed | 414/1024 [00:10<00:16, 36.92it/s]
Loading safetensors checkpoint shards:  41% Completed | 418/1024 [00:10<00:36, 16.59it/s]
Loading safetensors checkpoint shards:  41% Completed | 422/1024 [00:10<00:30, 19.77it/s]
Loading safetensors checkpoint shards:  42% Completed | 427/1024 [00:11<00:24, 24.31it/s]
Loading safetensors checkpoint shards:  42% Completed | 431/1024 [00:11<00:22, 26.84it/s]
Loading safetensors checkpoint shards:  42% Completed | 435/1024 [00:11<00:20, 28.51it/s]
Loading safetensors checkpoint shards:  43% Completed | 440/1024 [00:11<00:17, 32.69it/s]
Loading safetensors checkpoint shards:  43% Completed | 444/1024 [00:11<00:17, 33.29it/s]
Loading safetensors checkpoint shards:  44% Completed | 449/1024 [00:11<00:16, 35.24it/s]
Loading safetensors checkpoint shards:  44% Completed | 453/1024 [00:11<00:15, 35.79it/s]
Loading safetensors checkpoint shards:  45% Completed | 457/1024 [00:11<00:15, 36.46it/s]
Loading safetensors checkpoint shards:  45% Completed | 462/1024 [00:11<00:14, 38.56it/s]
Loading safetensors checkpoint shards:  46% Completed | 466/1024 [00:12<00:14, 37.74it/s]
Loading safetensors checkpoint shards:  46% Completed | 472/1024 [00:12<00:13, 41.92it/s]
Loading safetensors checkpoint shards:  47% Completed | 477/1024 [00:12<00:13, 40.37it/s]
Loading safetensors checkpoint shards:  47% Completed | 482/1024 [00:12<00:12, 41.97it/s]
Loading safetensors checkpoint shards:  48% Completed | 487/1024 [00:12<00:13, 40.58it/s]
Loading safetensors checkpoint shards:  48% Completed | 492/1024 [00:12<00:13, 38.45it/s]
Loading safetensors checkpoint shards:  49% Completed | 497/1024 [00:12<00:13, 39.98it/s]
Loading safetensors checkpoint shards:  49% Completed | 502/1024 [00:12<00:13, 39.73it/s]
Loading safetensors checkpoint shards:  50% Completed | 507/1024 [00:13<00:12, 40.03it/s]
Loading safetensors checkpoint shards:  50% Completed | 512/1024 [00:13<00:13, 39.10it/s]
Loading safetensors checkpoint shards:  50% Completed | 517/1024 [00:13<00:12, 40.59it/s]
Loading safetensors checkpoint shards:  51% Completed | 522/1024 [00:13<00:12, 39.00it/s]
Loading safetensors checkpoint shards:  51% Completed | 527/1024 [00:13<00:12, 40.52it/s]
Loading safetensors checkpoint shards:  52% Completed | 532/1024 [00:13<00:12, 40.20it/s]
Loading safetensors checkpoint shards:  52% Completed | 537/1024 [00:13<00:11, 41.13it/s]
Loading safetensors checkpoint shards:  53% Completed | 542/1024 [00:13<00:11, 41.06it/s]
Loading safetensors checkpoint shards:  53% Completed | 547/1024 [00:14<00:11, 40.75it/s]
Loading safetensors checkpoint shards:  54% Completed | 552/1024 [00:14<00:10, 42.95it/s]
Loading safetensors checkpoint shards:  54% Completed | 557/1024 [00:14<00:10, 43.05it/s]
Loading safetensors checkpoint shards:  55% Completed | 562/1024 [00:14<00:10, 43.87it/s]
Loading safetensors checkpoint shards:  55% Completed | 567/1024 [00:14<00:10, 43.56it/s]
Loading safetensors checkpoint shards:  56% Completed | 573/1024 [00:14<00:10, 44.84it/s]
Loading safetensors checkpoint shards:  56% Completed | 578/1024 [00:14<00:10, 42.52it/s]
Loading safetensors checkpoint shards:  57% Completed | 584/1024 [00:14<00:09, 45.72it/s]
Loading safetensors checkpoint shards:  58% Completed | 589/1024 [00:14<00:09, 44.35it/s]
Loading safetensors checkpoint shards:  58% Completed | 594/1024 [00:15<00:09, 44.57it/s]
Loading safetensors checkpoint shards:  58% Completed | 599/1024 [00:15<00:09, 44.24it/s]
Loading safetensors checkpoint shards:  59% Completed | 604/1024 [00:15<00:09, 44.94it/s]
Loading safetensors checkpoint shards:  59% Completed | 609/1024 [00:15<00:09, 42.02it/s]
Loading safetensors checkpoint shards:  60% Completed | 614/1024 [00:15<00:09, 41.32it/s]
Loading safetensors checkpoint shards:  60% Completed | 619/1024 [00:15<00:09, 43.06it/s]
Loading safetensors checkpoint shards:  61% Completed | 624/1024 [00:15<00:09, 42.74it/s]
Loading safetensors checkpoint shards:  61% Completed | 629/1024 [00:15<00:09, 42.05it/s]
Loading safetensors checkpoint shards:  62% Completed | 634/1024 [00:16<00:09, 40.12it/s]
Loading safetensors checkpoint shards:  62% Completed | 639/1024 [00:16<00:10, 38.40it/s]
Loading safetensors checkpoint shards:  63% Completed | 643/1024 [00:16<00:09, 38.25it/s]
Loading safetensors checkpoint shards:  63% Completed | 648/1024 [00:16<00:09, 39.34it/s]
Loading safetensors checkpoint shards:  64% Completed | 652/1024 [00:16<00:09, 39.20it/s]
Loading safetensors checkpoint shards:  64% Completed | 656/1024 [00:16<00:09, 38.29it/s]
Loading safetensors checkpoint shards:  64% Completed | 660/1024 [00:16<00:09, 37.51it/s]
Loading safetensors checkpoint shards:  65% Completed | 664/1024 [00:16<00:09, 36.01it/s]
Loading safetensors checkpoint shards:  65% Completed | 668/1024 [00:16<00:09, 36.01it/s]
Loading safetensors checkpoint shards:  66% Completed | 672/1024 [00:17<00:09, 36.32it/s]
Loading safetensors checkpoint shards:  66% Completed | 676/1024 [00:17<00:09, 35.29it/s]
Loading safetensors checkpoint shards:  66% Completed | 680/1024 [00:17<00:09, 35.68it/s]
Loading safetensors checkpoint shards:  67% Completed | 684/1024 [00:17<00:09, 35.06it/s]
Loading safetensors checkpoint shards:  67% Completed | 689/1024 [00:17<00:08, 37.70it/s]
Loading safetensors checkpoint shards:  68% Completed | 693/1024 [00:18<00:19, 16.61it/s]
Loading safetensors checkpoint shards:  68% Completed | 699/1024 [00:18<00:14, 22.74it/s]
Loading safetensors checkpoint shards:  69% Completed | 704/1024 [00:18<00:11, 27.06it/s]
Loading safetensors checkpoint shards:  69% Completed | 710/1024 [00:18<00:09, 32.30it/s]
Loading safetensors checkpoint shards:  70% Completed | 717/1024 [00:18<00:08, 38.29it/s]
Loading safetensors checkpoint shards:  71% Completed | 722/1024 [00:18<00:07, 40.70it/s]
Loading safetensors checkpoint shards:  71% Completed | 727/1024 [00:18<00:06, 42.71it/s]
Loading safetensors checkpoint shards:  72% Completed | 733/1024 [00:18<00:06, 45.46it/s]
Loading safetensors checkpoint shards:  72% Completed | 739/1024 [00:18<00:05, 48.40it/s]
Loading safetensors checkpoint shards:  73% Completed | 745/1024 [00:19<00:05, 49.87it/s]
Loading safetensors checkpoint shards:  73% Completed | 751/1024 [00:19<00:05, 49.81it/s]
Loading safetensors checkpoint shards:  74% Completed | 757/1024 [00:19<00:05, 49.14it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:19<00:05, 48.39it/s]
Loading safetensors checkpoint shards:  75% Completed | 768/1024 [00:19<00:05, 47.93it/s]
Loading safetensors checkpoint shards:  75% Completed | 773/1024 [00:19<00:05, 42.82it/s]
Loading safetensors checkpoint shards:  76% Completed | 778/1024 [00:19<00:05, 41.74it/s]
Loading safetensors checkpoint shards:  77% Completed | 784/1024 [00:19<00:05, 44.17it/s]
Loading safetensors checkpoint shards:  77% Completed | 790/1024 [00:20<00:05, 46.11it/s]
Loading safetensors checkpoint shards:  78% Completed | 796/1024 [00:20<00:04, 48.95it/s]
Loading safetensors checkpoint shards:  78% Completed | 801/1024 [00:20<00:04, 48.28it/s]
Loading safetensors checkpoint shards:  79% Completed | 807/1024 [00:20<00:04, 51.01it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:20<00:03, 53.51it/s]
Loading safetensors checkpoint shards:  80% Completed | 819/1024 [00:20<00:03, 54.88it/s]
Loading safetensors checkpoint shards:  81% Completed | 826/1024 [00:20<00:03, 57.26it/s]
Loading safetensors checkpoint shards:  81% Completed | 832/1024 [00:20<00:03, 56.08it/s]
Loading safetensors checkpoint shards:  82% Completed | 840/1024 [00:20<00:03, 60.99it/s]
Loading safetensors checkpoint shards:  83% Completed | 847/1024 [00:21<00:03, 57.73it/s]
Loading safetensors checkpoint shards:  83% Completed | 854/1024 [00:21<00:02, 59.43it/s]
Loading safetensors checkpoint shards:  84% Completed | 861/1024 [00:21<00:02, 59.40it/s]
Loading safetensors checkpoint shards:  85% Completed | 867/1024 [00:21<00:02, 59.50it/s]
Loading safetensors checkpoint shards:  85% Completed | 873/1024 [00:21<00:02, 55.70it/s]
Loading safetensors checkpoint shards:  86% Completed | 879/1024 [00:21<00:02, 55.50it/s]
Loading safetensors checkpoint shards:  86% Completed | 885/1024 [00:21<00:02, 55.74it/s]
Loading safetensors checkpoint shards:  87% Completed | 891/1024 [00:21<00:02, 49.56it/s]
Loading safetensors checkpoint shards:  88% Completed | 897/1024 [00:22<00:02, 49.79it/s]
Loading safetensors checkpoint shards:  88% Completed | 904/1024 [00:22<00:02, 54.24it/s]
Loading safetensors checkpoint shards:  89% Completed | 910/1024 [00:22<00:02, 53.45it/s]
Loading safetensors checkpoint shards:  89% Completed | 916/1024 [00:22<00:04, 23.09it/s]
Loading safetensors checkpoint shards:  90% Completed | 921/1024 [00:22<00:03, 26.71it/s]
Loading safetensors checkpoint shards:  90% Completed | 926/1024 [00:23<00:03, 30.12it/s]
Loading safetensors checkpoint shards:  91% Completed | 932/1024 [00:23<00:02, 35.08it/s]
Loading safetensors checkpoint shards:  92% Completed | 939/1024 [00:23<00:02, 41.52it/s]
Loading safetensors checkpoint shards:  92% Completed | 946/1024 [00:23<00:01, 46.99it/s]
Loading safetensors checkpoint shards:  93% Completed | 954/1024 [00:23<00:01, 54.10it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:23<00:01, 56.91it/s]
Loading safetensors checkpoint shards:  95% Completed | 969/1024 [00:23<00:00, 61.23it/s]
Loading safetensors checkpoint shards:  95% Completed | 976/1024 [00:23<00:00, 58.64it/s]
Loading safetensors checkpoint shards:  96% Completed | 986/1024 [00:23<00:00, 68.26it/s]
Loading safetensors checkpoint shards:  98% Completed | 1001/1024 [00:24<00:00, 89.89it/s]
Loading safetensors checkpoint shards:  99% Completed | 1015/1024 [00:24<00:00, 103.52it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:24<00:00, 42.27it/s]
 
[2025-09-13 07:10:43 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:10:43 TP5] KV Cache is allocated. #tokens: 620233, KV size: 40.59 GB
[2025-09-13 07:10:43 TP7] KV Cache is allocated. #tokens: 620233, KV size: 40.59 GB
[2025-09-13 07:10:43 TP0] KV Cache is allocated. #tokens: 620233, KV size: 40.59 GB
[2025-09-13 07:10:43 TP4] KV Cache is allocated. #tokens: 620233, KV size: 40.59 GB
[2025-09-13 07:10:43 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:10:43 TP6] KV Cache is allocated. #tokens: 620233, KV size: 40.59 GB
[2025-09-13 07:10:43 TP3] KV Cache is allocated. #tokens: 620233, KV size: 40.59 GB
[2025-09-13 07:10:43 TP2] KV Cache is allocated. #tokens: 620233, KV size: 40.59 GB
[2025-09-13 07:10:43 TP1] KV Cache is allocated. #tokens: 620233, KV size: 40.59 GB
[2025-09-13 07:10:43 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:10:44 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.52 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:10:45 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:10:45 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:10:45 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:10:45 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:10:45 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:10:45 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:10:45 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:10:45 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:10:45 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26301.99it/s]
[2025-09-13 07:10:45 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:10:45 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27526.03it/s]
[2025-09-13 07:10:46 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:10:46 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28394.42it/s]
[2025-09-13 07:10:46 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:10:46 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27263.59it/s]
[2025-09-13 07:10:47 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:10:47 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28391.15it/s]
[2025-09-13 07:10:48 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.23 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.73it/s][2025-09-13 07:10:51 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:10:51 TP1] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.23 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.94it/s][2025-09-13 07:10:51 TP7] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.23 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.11it/s]
[2025-09-13 07:10:51 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:10:51 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:10:51 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:10:51 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:10:51 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:10:51 TP0] Capture cuda graph end. Time elapsed: 7.97 s. mem usage=0.35 GB. avail mem=17.21 GB.
[2025-09-13 07:10:52 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:10:52 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:10:52 TP0] Init torch distributed begin.
[2025-09-13 07:10:52 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:10:52 TP0] Load weight begin. avail mem=17.21 GB
[2025-09-13 07:10:52 TP0] Detected fp8 checkpoint.
[2025-09-13 07:10:52 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 175.27it/s]
Loading safetensors checkpoint shards:   4% Completed | 44/1024 [00:00<00:04, 224.12it/s]
Loading safetensors checkpoint shards:  10% Completed | 106/1024 [00:00<00:02, 402.40it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:00<00:01, 481.04it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:00<00:01, 522.13it/s]
Loading safetensors checkpoint shards:  28% Completed | 287/1024 [00:00<00:01, 547.91it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:00<00:01, 560.33it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:00<00:01, 571.53it/s]
Loading safetensors checkpoint shards:  46% Completed | 466/1024 [00:00<00:00, 579.22it/s]
Loading safetensors checkpoint shards:  51% Completed | 527/1024 [00:01<00:00, 587.96it/s]
Loading safetensors checkpoint shards:  57% Completed | 587/1024 [00:01<00:00, 589.75it/s]
Loading safetensors checkpoint shards:  63% Completed | 646/1024 [00:01<00:00, 587.03it/s]
Loading safetensors checkpoint shards:  69% Completed | 705/1024 [00:01<00:00, 582.47it/s]
Loading safetensors checkpoint shards:  75% Completed | 764/1024 [00:01<00:00, 575.90it/s]
Loading safetensors checkpoint shards:  80% Completed | 822/1024 [00:01<00:00, 574.69it/s]
Loading safetensors checkpoint shards:  86% Completed | 880/1024 [00:01<00:00, 571.40it/s]
Loading safetensors checkpoint shards:  92% Completed | 938/1024 [00:01<00:00, 571.57it/s]
Loading safetensors checkpoint shards:  97% Completed | 996/1024 [00:01<00:00, 475.59it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 502.29it/s]

[2025-09-13 07:10:54 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.22 GB, mem usage=1.99 GB.
[2025-09-13 07:10:54 TP2] KV Cache is allocated. #tokens: 620233, KV size: 0.67 GB
[2025-09-13 07:10:54 TP3] KV Cache is allocated. #tokens: 620233, KV size: 0.67 GB
[2025-09-13 07:10:54 TP6] KV Cache is allocated. #tokens: 620233, KV size: 0.67 GB
[2025-09-13 07:10:54 TP0] KV Cache is allocated. #tokens: 620233, KV size: 0.67 GB
[2025-09-13 07:10:54 TP4] KV Cache is allocated. #tokens: 620233, KV size: 0.67 GB
[2025-09-13 07:10:54 TP0] Memory pool end. avail mem=14.55 GB
[2025-09-13 07:10:54 TP7] KV Cache is allocated. #tokens: 620233, KV size: 0.67 GB
[2025-09-13 07:10:54 TP5] KV Cache is allocated. #tokens: 620233, KV size: 0.67 GB
[2025-09-13 07:10:54 TP1] KV Cache is allocated. #tokens: 620233, KV size: 0.67 GB
[2025-09-13 07:10:54 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:10:54 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:10:54 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:10:54 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.99 GB
[2025-09-13 07:10:54 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:10:54 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:10:54 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.18 GB
[2025-09-13 07:10:54 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
Capturing batches (bs=1 avail_mem=14.58 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.44it/s]
[2025-09-13 07:11:00 TP0] Registering 72 cuda graph addresses
[2025-09-13 07:11:00 TP1] Registering 72 cuda graph addresses
[2025-09-13 07:11:00 TP2] Registering 72 cuda graph addresses
[2025-09-13 07:11:00 TP6] Registering 72 cuda graph addresses
[2025-09-13 07:11:00 TP3] Registering 72 cuda graph addresses
[2025-09-13 07:11:00 TP4] Registering 72 cuda graph addresses
[2025-09-13 07:11:00 TP7] Registering 72 cuda graph addresses
[2025-09-13 07:11:00 TP5] Registering 72 cuda graph addresses
[2025-09-13 07:11:00 TP5] Capture draft cuda graph end. Time elapsed: 6.24 s. mem usage=0.41 GB. avail mem=14.54 GB.
[2025-09-13 07:11:00 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 07:11:00 TP2] Capture draft cuda graph end. Time elapsed: 6.31 s. mem usage=0.41 GB. avail mem=14.54 GB.
[2025-09-13 07:11:00 TP4] Capture draft cuda graph end. Time elapsed: 6.31 s. mem usage=0.41 GB. avail mem=14.54 GB.
[2025-09-13 07:11:00 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 07:11:00 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 07:11:00 TP1] Capture draft cuda graph end. Time elapsed: 6.25 s. mem usage=0.41 GB. avail mem=14.54 GB.
[2025-09-13 07:11:00 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 07:11:00 TP0] Capture draft cuda graph end. Time elapsed: 6.27 s. mem usage=0.41 GB. avail mem=14.58 GB.
[2025-09-13 07:11:00 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 07:11:00 TP6] Capture draft cuda graph end. Time elapsed: 6.31 s. mem usage=0.41 GB. avail mem=14.54 GB.
[2025-09-13 07:11:00 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 07:11:00 TP7] Capture draft cuda graph end. Time elapsed: 6.26 s. mem usage=0.41 GB. avail mem=14.77 GB.
[2025-09-13 07:11:00 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.77 GB
[2025-09-13 07:11:00 TP3] Capture draft cuda graph end. Time elapsed: 6.26 s. mem usage=0.41 GB. avail mem=14.54 GB.
[2025-09-13 07:11:00 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
Capturing batches (bs=1 avail_mem=14.40 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 21.47it/s]
[2025-09-13 07:11:02 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:11:02 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:11:02 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:11:02 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:11:02 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:11:02 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:11:02 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:11:02 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:11:02 TP2] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.18 GB. avail mem=14.36 GB.
[2025-09-13 07:11:02 TP6] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.18 GB. avail mem=14.36 GB.
[2025-09-13 07:11:02 TP3] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.18 GB. avail mem=14.36 GB.
[2025-09-13 07:11:02 TP4] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.18 GB. avail mem=14.36 GB.
[2025-09-13 07:11:02 TP7] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.18 GB. avail mem=14.59 GB.
[2025-09-13 07:11:02 TP1] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.18 GB. avail mem=14.36 GB.
[2025-09-13 07:11:02 TP0] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.18 GB. avail mem=14.40 GB.
[2025-09-13 07:11:02 TP5] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.18 GB. avail mem=14.36 GB.
[2025-09-13 07:11:02 TP0] max_total_num_tokens=620233, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.40 GB
[2025-09-13 07:11:02] INFO:     Started server process [233648]
[2025-09-13 07:11:02] INFO:     Waiting for application startup.
[2025-09-13 07:11:02] INFO:     Application startup complete.
[2025-09-13 07:11:02] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:11:02] INFO:     127.0.0.1:38552 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:11:03] INFO:     127.0.0.1:38562 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:11:03 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:11:03 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:11:03 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28783.87it/s]
[2025-09-13 07:11:04] INFO:     127.0.0.1:38566 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:04] The server is fired up and ready to roll!
[2025-09-13 07:11:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:11:13] INFO:     127.0.0.1:42856 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:11:14] INFO:     127.0.0.1:42872 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:14 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:11:15] INFO:     127.0.0.1:42888 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:15] INFO:     127.0.0.1:42894 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:11:15] INFO:     127.0.0.1:42906 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:15] INFO:     127.0.0.1:42914 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:15] INFO:     127.0.0.1:42928 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:15] INFO:     127.0.0.1:42942 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:15] INFO:     127.0.0.1:42944 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:15] INFO:     127.0.0.1:42956 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:15 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:11:16 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:11:16 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:11:16 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:11:16 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:11:16 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:11:16 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:11:16 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:11:16 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:11:16 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:11:17 TP0] Decode batch. #running-req: 8, #token: 14577, token usage: 0.02, accept len: 3.01, cuda graph: True, gen throughput (token/s): 45.71, #queue-req: 0, 
[2025-09-13 07:11:18 TP0] Decode batch. #running-req: 8, #token: 15655, token usage: 0.03, accept len: 3.37, cuda graph: True, gen throughput (token/s): 883.50, #queue-req: 0, 
[2025-09-13 07:11:19 TP0] Decode batch. #running-req: 8, #token: 16902, token usage: 0.03, accept len: 3.90, cuda graph: True, gen throughput (token/s): 994.97, #queue-req: 0, 
 62%|█████████████████████████████████████████████████████████████████████████████████▉                                                 | 5/8 [00:05<00:01,  1.51it/s][2025-09-13 07:11:21 TP0] Decode batch. #running-req: 3, #token: 7569, token usage: 0.01, accept len: 3.86, cuda graph: True, gen throughput (token/s): 753.93, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.37it/s]
[2025-09-13 07:11:21] INFO:     127.0.0.1:57100 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  5.83      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4082      
Request throughput (req/s):              1.37      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         702.70    
Total token throughput (tok/s):          702.70    
Concurrency:                             7.11      
Accept length:                           3.56      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5183.96   
Median E2E Latency (ms):                 5229.90   
---------------Time to First Token----------------
Mean TTFT (ms):                          615.89    
Median TTFT (ms):                        728.62    
P99 TTFT (ms):                           729.13    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           8.94      
Median ITL (ms):                         6.35      
P95 ITL (ms):                            15.69     
P99 ITL (ms):                            31.13     
Max ITL (ms):                            734.17    
==================================================
[2025-09-13 07:11:21] INFO:     127.0.0.1:57116 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:11:21] INFO:     127.0.0.1:57124 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:11:22] INFO:     127.0.0.1:57132 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:22] INFO:     127.0.0.1:57144 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:11:22] INFO:     127.0.0.1:57156 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:22] INFO:     127.0.0.1:57158 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:22] INFO:     127.0.0.1:57170 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:22] INFO:     127.0.0.1:57174 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:22] INFO:     127.0.0.1:57186 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:22] INFO:     127.0.0.1:57188 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:22 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:11:23 TP0] Decode batch. #running-req: 8, #token: 14051, token usage: 0.02, accept len: 3.19, cuda graph: True, gen throughput (token/s): 120.85, #queue-req: 0, 
[2025-09-13 07:11:24 TP0] Decode batch. #running-req: 8, #token: 15066, token usage: 0.02, accept len: 3.17, cuda graph: True, gen throughput (token/s): 853.73, #queue-req: 0, 
[2025-09-13 07:11:25 TP0] Decode batch. #running-req: 8, #token: 16233, token usage: 0.03, accept len: 3.65, cuda graph: True, gen throughput (token/s): 936.35, #queue-req: 0, 
[2025-09-13 07:11:26 TP0] Decode batch. #running-req: 8, #token: 16889, token usage: 0.03, accept len: 3.96, cuda graph: True, gen throughput (token/s): 1008.87, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:01,  4.12s/it][2025-09-13 07:11:26] INFO:     127.0.0.1:57202 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:26 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:26,  1.90s/it][2025-09-13 07:11:27] INFO:     127.0.0.1:57216 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:04<00:14,  1.15s/it][2025-09-13 07:11:27] INFO:     127.0.0.1:57228 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:27 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.19it/s][2025-09-13 07:11:27] INFO:     127.0.0.1:57232 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:27 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:07,  1.49it/s][2025-09-13 07:11:28] INFO:     127.0.0.1:33320 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:28] INFO:     127.0.0.1:33324 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:28] INFO:     127.0.0.1:33328 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:28 TP0] Prefill batch. #new-seq: 3, #new-token: 5108, #cached-token: 2599, token usage: 0.01, #running-req: 5, #queue-req: 0, 
[2025-09-13 07:11:29 TP0] Decode batch. #running-req: 8, #token: 10508, token usage: 0.02, accept len: 3.40, cuda graph: True, gen throughput (token/s): 502.17, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:03,  2.17it/s][2025-09-13 07:11:29] INFO:     127.0.0.1:33330 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:11:29 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:11:30 TP0] Decode batch. #running-req: 8, #token: 15078, token usage: 0.02, accept len: 3.29, cuda graph: True, gen throughput (token/s): 704.54, #queue-req: 0, 
[2025-09-13 07:11:31 TP0] Decode batch. #running-req: 8, #token: 16254, token usage: 0.03, accept len: 3.67, cuda graph: True, gen throughput (token/s): 936.24, #queue-req: 0, 
 69%|████████████████████████████████████████████████████████████████████████████████████████▋                                        | 11/16 [00:10<00:03,  1.38it/s][2025-09-13 07:11:33 TP0] Decode batch. #running-req: 4, #token: 10921, token usage: 0.02, accept len: 3.75, cuda graph: True, gen throughput (token/s): 869.85, #queue-req: 0, 
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 15/16 [00:10<00:00,  2.71it/s][2025-09-13 07:11:33 TP0] Decode batch. #running-req: 1, #token: 5490, token usage: 0.01, accept len: 3.44, cuda graph: True, gen throughput (token/s): 202.94, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.41it/s]
[2025-09-13 07:11:34] INFO:     127.0.0.1:33340 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.32     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8100      
Request throughput (req/s):              1.41      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         723.36    
Total token throughput (tok/s):          723.36    
Concurrency:                             7.29      
Accept length:                           3.54      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5156.62   
Median E2E Latency (ms):                 5032.14   
---------------Time to First Token----------------
Mean TTFT (ms):                          248.82    
Median TTFT (ms):                        290.45    
P99 TTFT (ms):                           293.15    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.60      
Median ITL (ms):                         6.37      
P95 ITL (ms):                            16.15     
P99 ITL (ms):                            54.13     
Max ITL (ms):                            293.37    
==================================================
[2025-09-13 07:11:34] INFO:     127.0.0.1:33346 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=19: batch_size=8, steps=4, topk=4, num_draft_tokens=6, speed=114.21 token/s, step_time=31.03 ms
Start i=20: batch_size=8, steps=4, topk=4, num_draft_tokens=8
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 4 --speculative-eagle-topk 4 --speculative-num-draft-tokens 8 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:11:44.928000 239184 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:11:44.928000 239184 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:11:45] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=962720789, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=4, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:11:45] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:11:53.986000 239396 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:11:53.986000 239396 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:11:54.124000 239398 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:11:54.124000 239398 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:11:54.209000 239400 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:11:54.209000 239400 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:11:54.265000 239395 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:11:54.265000 239395 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:11:54.376000 239392 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:11:54.376000 239392 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:11:54.402000 239394 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:11:54.402000 239394 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:11:54.403000 239397 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:11:54.403000 239397 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 07:11:54.584000 239393 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:11:54.584000 239393 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 07:11:54.745000 239399 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:11:54.745000 239399 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:11:54 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:11:54 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:11:54 TP0] Init torch distributed begin.
`torch_dtype` is deprecated! Use `dtype` instead!
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:11:56 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:11:59 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:12:01 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:12:01 TP0] Detected fp8 checkpoint.
[2025-09-13 07:12:01 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 28/1024 [00:00<00:03, 272.38it/s]
Loading safetensors checkpoint shards:   5% Completed | 56/1024 [00:00<00:13, 71.22it/s]
Loading safetensors checkpoint shards:   7% Completed | 70/1024 [00:01<00:15, 61.04it/s]
Loading safetensors checkpoint shards:   8% Completed | 80/1024 [00:01<00:16, 58.74it/s]
Loading safetensors checkpoint shards:   9% Completed | 88/1024 [00:01<00:16, 55.18it/s]
Loading safetensors checkpoint shards:   9% Completed | 95/1024 [00:01<00:19, 48.80it/s]
Loading safetensors checkpoint shards:  10% Completed | 101/1024 [00:02<00:29, 31.22it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:02<00:25, 36.16it/s]
Loading safetensors checkpoint shards:  11% Completed | 114/1024 [00:02<00:24, 36.98it/s]
Loading safetensors checkpoint shards:  12% Completed | 119/1024 [00:02<00:23, 38.77it/s]
Loading safetensors checkpoint shards:  12% Completed | 124/1024 [00:02<00:23, 38.48it/s]
Loading safetensors checkpoint shards:  13% Completed | 129/1024 [00:02<00:22, 39.57it/s]
Loading safetensors checkpoint shards:  13% Completed | 134/1024 [00:02<00:23, 38.34it/s]
Loading safetensors checkpoint shards:  14% Completed | 139/1024 [00:02<00:21, 40.96it/s]
Loading safetensors checkpoint shards:  14% Completed | 144/1024 [00:03<00:20, 42.04it/s]
Loading safetensors checkpoint shards:  15% Completed | 149/1024 [00:03<00:20, 42.39it/s]
Loading safetensors checkpoint shards:  15% Completed | 154/1024 [00:03<00:20, 42.76it/s]
Loading safetensors checkpoint shards:  16% Completed | 159/1024 [00:03<00:20, 43.06it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:03<00:19, 43.75it/s]
Loading safetensors checkpoint shards:  17% Completed | 169/1024 [00:03<00:19, 43.41it/s]
Loading safetensors checkpoint shards:  17% Completed | 175/1024 [00:03<00:18, 45.06it/s]
Loading safetensors checkpoint shards:  18% Completed | 180/1024 [00:03<00:19, 44.00it/s]
Loading safetensors checkpoint shards:  18% Completed | 185/1024 [00:03<00:18, 45.41it/s]
Loading safetensors checkpoint shards:  19% Completed | 190/1024 [00:04<00:18, 44.63it/s]
Loading safetensors checkpoint shards:  19% Completed | 195/1024 [00:04<00:19, 41.60it/s]
Loading safetensors checkpoint shards:  20% Completed | 200/1024 [00:04<00:20, 39.76it/s]
Loading safetensors checkpoint shards:  20% Completed | 205/1024 [00:04<00:21, 37.96it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:04<00:21, 37.41it/s]
Loading safetensors checkpoint shards:  21% Completed | 213/1024 [00:04<00:22, 36.61it/s]
Loading safetensors checkpoint shards:  21% Completed | 218/1024 [00:04<00:20, 38.54it/s]
Loading safetensors checkpoint shards:  22% Completed | 222/1024 [00:04<00:20, 38.31it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:05<00:19, 40.06it/s]
Loading safetensors checkpoint shards:  23% Completed | 232/1024 [00:05<00:19, 41.33it/s]
Loading safetensors checkpoint shards:  23% Completed | 237/1024 [00:05<00:18, 43.40it/s]
Loading safetensors checkpoint shards:  24% Completed | 242/1024 [00:05<00:17, 43.54it/s]
Loading safetensors checkpoint shards:  24% Completed | 247/1024 [00:05<00:17, 43.57it/s]
Loading safetensors checkpoint shards:  25% Completed | 253/1024 [00:05<00:16, 46.53it/s]
Loading safetensors checkpoint shards:  25% Completed | 258/1024 [00:05<00:16, 46.23it/s]
Loading safetensors checkpoint shards:  26% Completed | 264/1024 [00:05<00:16, 47.45it/s]
Loading safetensors checkpoint shards:  26% Completed | 269/1024 [00:05<00:16, 46.96it/s]
Loading safetensors checkpoint shards:  27% Completed | 275/1024 [00:06<00:16, 46.47it/s]
Loading safetensors checkpoint shards:  27% Completed | 280/1024 [00:06<00:16, 44.87it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:06<00:15, 46.22it/s]
Loading safetensors checkpoint shards:  28% Completed | 290/1024 [00:06<00:32, 22.63it/s]
Loading safetensors checkpoint shards:  29% Completed | 296/1024 [00:06<00:26, 27.92it/s]
Loading safetensors checkpoint shards:  29% Completed | 301/1024 [00:06<00:23, 31.29it/s]
Loading safetensors checkpoint shards:  30% Completed | 306/1024 [00:07<00:20, 34.51it/s]
Loading safetensors checkpoint shards:  30% Completed | 311/1024 [00:07<00:19, 36.81it/s]
Loading safetensors checkpoint shards:  31% Completed | 317/1024 [00:07<00:17, 40.31it/s]
Loading safetensors checkpoint shards:  31% Completed | 322/1024 [00:07<00:17, 40.46it/s]
Loading safetensors checkpoint shards:  32% Completed | 328/1024 [00:07<00:16, 42.98it/s]
Loading safetensors checkpoint shards:  33% Completed | 333/1024 [00:07<00:15, 43.47it/s]
Loading safetensors checkpoint shards:  33% Completed | 339/1024 [00:07<00:14, 45.91it/s]
Loading safetensors checkpoint shards:  34% Completed | 344/1024 [00:07<00:15, 45.20it/s]
Loading safetensors checkpoint shards:  34% Completed | 349/1024 [00:08<00:14, 45.33it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:08<00:14, 45.01it/s]
Loading safetensors checkpoint shards:  35% Completed | 359/1024 [00:08<00:14, 45.34it/s]
Loading safetensors checkpoint shards:  36% Completed | 364/1024 [00:08<00:14, 45.54it/s]
Loading safetensors checkpoint shards:  36% Completed | 369/1024 [00:08<00:14, 44.52it/s]
Loading safetensors checkpoint shards:  37% Completed | 375/1024 [00:08<00:14, 46.19it/s]
Loading safetensors checkpoint shards:  37% Completed | 380/1024 [00:08<00:14, 44.53it/s]
Loading safetensors checkpoint shards:  38% Completed | 386/1024 [00:08<00:13, 46.29it/s]
Loading safetensors checkpoint shards:  38% Completed | 391/1024 [00:08<00:13, 45.78it/s]
Loading safetensors checkpoint shards:  39% Completed | 396/1024 [00:09<00:13, 46.13it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:09<00:13, 45.64it/s]
Loading safetensors checkpoint shards:  40% Completed | 407/1024 [00:09<00:13, 46.90it/s]
Loading safetensors checkpoint shards:  40% Completed | 412/1024 [00:09<00:13, 46.33it/s]
Loading safetensors checkpoint shards:  41% Completed | 417/1024 [00:09<00:13, 46.42it/s]
Loading safetensors checkpoint shards:  41% Completed | 422/1024 [00:09<00:13, 46.05it/s]
Loading safetensors checkpoint shards:  42% Completed | 428/1024 [00:09<00:12, 46.79it/s]
Loading safetensors checkpoint shards:  42% Completed | 433/1024 [00:09<00:13, 44.70it/s]
Loading safetensors checkpoint shards:  43% Completed | 439/1024 [00:09<00:12, 46.41it/s]
Loading safetensors checkpoint shards:  43% Completed | 444/1024 [00:10<00:12, 45.40it/s]
Loading safetensors checkpoint shards:  44% Completed | 449/1024 [00:10<00:12, 45.29it/s]
Loading safetensors checkpoint shards:  44% Completed | 454/1024 [00:10<00:12, 44.86it/s]
Loading safetensors checkpoint shards:  45% Completed | 459/1024 [00:10<00:12, 45.98it/s]
Loading safetensors checkpoint shards:  45% Completed | 464/1024 [00:10<00:12, 43.83it/s]
Loading safetensors checkpoint shards:  46% Completed | 469/1024 [00:10<00:12, 42.76it/s]
Loading safetensors checkpoint shards:  46% Completed | 475/1024 [00:10<00:11, 45.77it/s]
Loading safetensors checkpoint shards:  47% Completed | 480/1024 [00:10<00:12, 44.17it/s]
Loading safetensors checkpoint shards:  47% Completed | 485/1024 [00:11<00:12, 44.35it/s]
Loading safetensors checkpoint shards:  48% Completed | 490/1024 [00:11<00:12, 41.09it/s]
Loading safetensors checkpoint shards:  48% Completed | 495/1024 [00:11<00:12, 42.03it/s]
Loading safetensors checkpoint shards:  49% Completed | 500/1024 [00:11<00:12, 40.74it/s]
Loading safetensors checkpoint shards:  49% Completed | 505/1024 [00:11<00:12, 40.56it/s]
Loading safetensors checkpoint shards:  50% Completed | 510/1024 [00:11<00:13, 38.38it/s]
Loading safetensors checkpoint shards:  50% Completed | 514/1024 [00:11<00:13, 37.89it/s]
Loading safetensors checkpoint shards:  51% Completed | 519/1024 [00:11<00:13, 38.66it/s]
Loading safetensors checkpoint shards:  51% Completed | 523/1024 [00:12<00:12, 38.64it/s]
Loading safetensors checkpoint shards:  52% Completed | 528/1024 [00:12<00:12, 39.88it/s]
Loading safetensors checkpoint shards:  52% Completed | 532/1024 [00:12<00:12, 39.63it/s]
Loading safetensors checkpoint shards:  52% Completed | 536/1024 [00:12<00:27, 17.83it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:12<00:21, 22.25it/s]
Loading safetensors checkpoint shards:  53% Completed | 545/1024 [00:13<00:18, 25.28it/s]
Loading safetensors checkpoint shards:  54% Completed | 550/1024 [00:13<00:15, 29.90it/s]
Loading safetensors checkpoint shards:  54% Completed | 555/1024 [00:13<00:14, 32.49it/s]
Loading safetensors checkpoint shards:  55% Completed | 560/1024 [00:13<00:13, 34.66it/s]
Loading safetensors checkpoint shards:  55% Completed | 564/1024 [00:13<00:13, 35.20it/s]
Loading safetensors checkpoint shards:  55% Completed | 568/1024 [00:13<00:12, 35.63it/s]
Loading safetensors checkpoint shards:  56% Completed | 573/1024 [00:13<00:11, 38.10it/s]
Loading safetensors checkpoint shards:  56% Completed | 578/1024 [00:13<00:11, 37.20it/s]
Loading safetensors checkpoint shards:  57% Completed | 584/1024 [00:13<00:10, 40.89it/s]
Loading safetensors checkpoint shards:  58% Completed | 589/1024 [00:14<00:10, 39.83it/s]
Loading safetensors checkpoint shards:  58% Completed | 594/1024 [00:14<00:10, 39.90it/s]
Loading safetensors checkpoint shards:  58% Completed | 599/1024 [00:14<00:10, 41.37it/s]
Loading safetensors checkpoint shards:  59% Completed | 604/1024 [00:14<00:10, 40.82it/s]
Loading safetensors checkpoint shards:  59% Completed | 609/1024 [00:14<00:11, 37.54it/s]
Loading safetensors checkpoint shards:  60% Completed | 614/1024 [00:14<00:10, 39.59it/s]
Loading safetensors checkpoint shards:  61% Completed | 620/1024 [00:14<00:09, 43.24it/s]
Loading safetensors checkpoint shards:  61% Completed | 626/1024 [00:14<00:08, 45.13it/s]
Loading safetensors checkpoint shards:  62% Completed | 631/1024 [00:15<00:09, 42.34it/s]
Loading safetensors checkpoint shards:  62% Completed | 636/1024 [00:15<00:09, 41.82it/s]
Loading safetensors checkpoint shards:  63% Completed | 641/1024 [00:15<00:09, 42.30it/s]
Loading safetensors checkpoint shards:  63% Completed | 646/1024 [00:15<00:10, 37.75it/s]
Loading safetensors checkpoint shards:  63% Completed | 650/1024 [00:15<00:09, 37.62it/s]
Loading safetensors checkpoint shards:  64% Completed | 654/1024 [00:15<00:10, 36.42it/s]
Loading safetensors checkpoint shards:  64% Completed | 658/1024 [00:15<00:10, 36.10it/s]
Loading safetensors checkpoint shards:  65% Completed | 662/1024 [00:15<00:10, 35.53it/s]
Loading safetensors checkpoint shards:  65% Completed | 667/1024 [00:16<00:09, 38.50it/s]
Loading safetensors checkpoint shards:  66% Completed | 671/1024 [00:16<00:10, 34.40it/s]
Loading safetensors checkpoint shards:  66% Completed | 675/1024 [00:16<00:10, 33.31it/s]
Loading safetensors checkpoint shards:  66% Completed | 679/1024 [00:16<00:10, 34.04it/s]
Loading safetensors checkpoint shards:  67% Completed | 683/1024 [00:16<00:09, 34.95it/s]
Loading safetensors checkpoint shards:  67% Completed | 687/1024 [00:16<00:09, 35.74it/s]
Loading safetensors checkpoint shards:  68% Completed | 692/1024 [00:16<00:08, 39.02it/s]
Loading safetensors checkpoint shards:  68% Completed | 697/1024 [00:16<00:08, 39.69it/s]
Loading safetensors checkpoint shards:  68% Completed | 701/1024 [00:17<00:08, 38.74it/s]
Loading safetensors checkpoint shards:  69% Completed | 706/1024 [00:17<00:08, 39.40it/s]
Loading safetensors checkpoint shards:  69% Completed | 710/1024 [00:17<00:07, 39.48it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:17<00:07, 39.49it/s]
Loading safetensors checkpoint shards:  70% Completed | 718/1024 [00:17<00:07, 38.29it/s]
Loading safetensors checkpoint shards:  71% Completed | 722/1024 [00:17<00:07, 38.29it/s]
Loading safetensors checkpoint shards:  71% Completed | 726/1024 [00:17<00:07, 38.68it/s]
Loading safetensors checkpoint shards:  71% Completed | 730/1024 [00:17<00:07, 38.95it/s]
Loading safetensors checkpoint shards:  72% Completed | 734/1024 [00:17<00:07, 38.73it/s]
Loading safetensors checkpoint shards:  72% Completed | 739/1024 [00:17<00:07, 39.56it/s]
Loading safetensors checkpoint shards:  73% Completed | 744/1024 [00:18<00:06, 41.34it/s]
Loading safetensors checkpoint shards:  73% Completed | 749/1024 [00:18<00:06, 39.93it/s]
Loading safetensors checkpoint shards:  74% Completed | 754/1024 [00:18<00:06, 39.97it/s]
Loading safetensors checkpoint shards:  74% Completed | 759/1024 [00:18<00:06, 40.10it/s]
Loading safetensors checkpoint shards:  75% Completed | 764/1024 [00:18<00:06, 40.21it/s]
Loading safetensors checkpoint shards:  75% Completed | 769/1024 [00:18<00:06, 40.45it/s]
Loading safetensors checkpoint shards:  76% Completed | 774/1024 [00:18<00:06, 39.51it/s]
Loading safetensors checkpoint shards:  76% Completed | 778/1024 [00:18<00:06, 39.63it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:19<00:05, 40.87it/s]
Loading safetensors checkpoint shards:  77% Completed | 788/1024 [00:19<00:05, 40.37it/s]
Loading safetensors checkpoint shards:  77% Completed | 793/1024 [00:19<00:05, 40.17it/s]
Loading safetensors checkpoint shards:  78% Completed | 798/1024 [00:19<00:05, 40.49it/s]
Loading safetensors checkpoint shards:  78% Completed | 803/1024 [00:19<00:05, 41.53it/s]
Loading safetensors checkpoint shards:  79% Completed | 808/1024 [00:20<00:11, 19.25it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:20<00:09, 22.92it/s]
Loading safetensors checkpoint shards:  80% Completed | 817/1024 [00:20<00:08, 25.43it/s]
Loading safetensors checkpoint shards:  80% Completed | 821/1024 [00:20<00:07, 27.91it/s]
Loading safetensors checkpoint shards:  81% Completed | 826/1024 [00:20<00:06, 31.36it/s]
Loading safetensors checkpoint shards:  81% Completed | 831/1024 [00:20<00:05, 34.55it/s]
Loading safetensors checkpoint shards:  82% Completed | 836/1024 [00:20<00:05, 37.00it/s]
Loading safetensors checkpoint shards:  82% Completed | 841/1024 [00:20<00:04, 38.80it/s]
Loading safetensors checkpoint shards:  83% Completed | 846/1024 [00:21<00:04, 38.97it/s]
Loading safetensors checkpoint shards:  83% Completed | 851/1024 [00:21<00:04, 39.95it/s]
Loading safetensors checkpoint shards:  84% Completed | 856/1024 [00:21<00:04, 40.84it/s]
Loading safetensors checkpoint shards:  84% Completed | 861/1024 [00:21<00:04, 39.94it/s]
Loading safetensors checkpoint shards:  85% Completed | 866/1024 [00:21<00:03, 40.39it/s]
Loading safetensors checkpoint shards:  85% Completed | 871/1024 [00:21<00:03, 40.67it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:21<00:03, 39.50it/s]
Loading safetensors checkpoint shards:  86% Completed | 881/1024 [00:21<00:03, 40.25it/s]
Loading safetensors checkpoint shards:  87% Completed | 886/1024 [00:22<00:03, 41.32it/s]
Loading safetensors checkpoint shards:  87% Completed | 891/1024 [00:22<00:03, 41.33it/s]
Loading safetensors checkpoint shards:  88% Completed | 896/1024 [00:22<00:03, 42.04it/s]
Loading safetensors checkpoint shards:  88% Completed | 901/1024 [00:22<00:02, 43.04it/s]
Loading safetensors checkpoint shards:  88% Completed | 906/1024 [00:22<00:02, 43.53it/s]
Loading safetensors checkpoint shards:  89% Completed | 911/1024 [00:22<00:02, 43.48it/s]
Loading safetensors checkpoint shards:  89% Completed | 916/1024 [00:22<00:02, 42.67it/s]
Loading safetensors checkpoint shards:  90% Completed | 921/1024 [00:22<00:02, 42.68it/s]
Loading safetensors checkpoint shards:  90% Completed | 926/1024 [00:22<00:02, 41.65it/s]
Loading safetensors checkpoint shards:  91% Completed | 931/1024 [00:23<00:02, 40.12it/s]
Loading safetensors checkpoint shards:  91% Completed | 936/1024 [00:23<00:02, 39.61it/s]
Loading safetensors checkpoint shards:  92% Completed | 940/1024 [00:23<00:02, 39.70it/s]
Loading safetensors checkpoint shards:  92% Completed | 944/1024 [00:23<00:02, 39.60it/s]
Loading safetensors checkpoint shards:  93% Completed | 948/1024 [00:23<00:01, 38.73it/s]
Loading safetensors checkpoint shards:  93% Completed | 953/1024 [00:23<00:01, 39.47it/s]
Loading safetensors checkpoint shards:  94% Completed | 958/1024 [00:23<00:01, 40.44it/s]
Loading safetensors checkpoint shards:  94% Completed | 963/1024 [00:23<00:01, 40.10it/s]
Loading safetensors checkpoint shards:  95% Completed | 968/1024 [00:24<00:01, 41.11it/s]
Loading safetensors checkpoint shards:  95% Completed | 973/1024 [00:24<00:01, 40.14it/s]
Loading safetensors checkpoint shards:  96% Completed | 978/1024 [00:24<00:01, 40.40it/s]
Loading safetensors checkpoint shards:  96% Completed | 986/1024 [00:24<00:00, 50.14it/s]
Loading safetensors checkpoint shards:  98% Completed | 1004/1024 [00:24<00:00, 83.72it/s]
Loading safetensors checkpoint shards:  99% Completed | 1013/1024 [00:24<00:00, 85.06it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:24<00:00, 41.54it/s]

[2025-09-13 07:12:26 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:12:30 TP2] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:12:30 TP5] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:12:30 TP4] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:12:30 TP6] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:12:30 TP3] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:12:30 TP7] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:12:30 TP1] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:12:30 TP0] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:12:30 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:12:30 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:12:30 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.51 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:12:31 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:12:31 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:12:31 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:12:31 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:12:31 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:12:31 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:12:31 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:12:31 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:12:31 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26143.86it/s]
[2025-09-13 07:12:31 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:12:31 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27148.83it/s]
[2025-09-13 07:12:32 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:12:32 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28486.68it/s]
[2025-09-13 07:12:33 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:12:33 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28036.26it/s]
[2025-09-13 07:12:33 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:12:33 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28802.33it/s]
[2025-09-13 07:12:34 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.20 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.17it/s]
[2025-09-13 07:12:37 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:12:37 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:12:37 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:12:37 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:12:37 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:12:37 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:12:37 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:12:37 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:12:37 TP0] Capture cuda graph end. Time elapsed: 7.56 s. mem usage=0.39 GB. avail mem=17.17 GB.
[2025-09-13 07:12:38 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:12:38 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:12:38 TP0] Init torch distributed begin.
[2025-09-13 07:12:38 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:12:38 TP0] Load weight begin. avail mem=17.17 GB
[2025-09-13 07:12:38 TP0] Detected fp8 checkpoint.
[2025-09-13 07:12:38 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 172.98it/s]
Loading safetensors checkpoint shards:   4% Completed | 43/1024 [00:00<00:04, 217.06it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:00<00:02, 384.28it/s]
Loading safetensors checkpoint shards:  16% Completed | 162/1024 [00:00<00:01, 467.74it/s]
Loading safetensors checkpoint shards:  22% Completed | 221/1024 [00:00<00:01, 509.07it/s]
Loading safetensors checkpoint shards:  27% Completed | 281/1024 [00:00<00:01, 536.93it/s]
Loading safetensors checkpoint shards:  33% Completed | 341/1024 [00:00<00:01, 554.18it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:00<00:01, 565.74it/s]
Loading safetensors checkpoint shards:  45% Completed | 461/1024 [00:00<00:00, 573.70it/s]
Loading safetensors checkpoint shards:  51% Completed | 521/1024 [00:01<00:00, 579.22it/s]
Loading safetensors checkpoint shards:  57% Completed | 580/1024 [00:01<00:00, 581.90it/s]
Loading safetensors checkpoint shards:  62% Completed | 639/1024 [00:01<00:00, 583.54it/s]
Loading safetensors checkpoint shards:  68% Completed | 698/1024 [00:01<00:00, 574.93it/s]
Loading safetensors checkpoint shards:  74% Completed | 756/1024 [00:01<00:00, 567.10it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:01<00:00, 564.55it/s]
Loading safetensors checkpoint shards:  85% Completed | 870/1024 [00:01<00:00, 561.09it/s]
Loading safetensors checkpoint shards:  91% Completed | 927/1024 [00:01<00:00, 563.05it/s]
Loading safetensors checkpoint shards:  96% Completed | 984/1024 [00:01<00:00, 541.10it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 497.70it/s]

[2025-09-13 07:12:40 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.18 GB, mem usage=1.99 GB.
[2025-09-13 07:12:40 TP0] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:12:40 TP4] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:12:40 TP0] Memory pool end. avail mem=14.52 GB
[2025-09-13 07:12:40 TP7] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:12:40 TP3] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:12:40 TP2] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:12:40 TP6] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:12:40 TP5] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:12:40 TP1] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:12:40 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:12:40 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:12:40 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:12:40 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.14 GB
[2025-09-13 07:12:40 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:12:40 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:12:40 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:12:40 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.95 GB
Capturing batches (bs=1 avail_mem=14.54 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  3.04it/s][2025-09-13 07:12:47 TP6] Registering 72 cuda graph addresses
[2025-09-13 07:12:47 TP3] Registering 72 cuda graph addresses
[2025-09-13 07:12:47 TP4] Registering 72 cuda graph addresses
[2025-09-13 07:12:47 TP5] Registering 72 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.54 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.42it/s]
[2025-09-13 07:12:47 TP0] Registering 72 cuda graph addresses
[2025-09-13 07:12:47 TP1] Registering 72 cuda graph addresses
[2025-09-13 07:12:47 TP2] Registering 72 cuda graph addresses
[2025-09-13 07:12:47 TP7] Registering 72 cuda graph addresses
[2025-09-13 07:12:47 TP0] Capture draft cuda graph end. Time elapsed: 6.32 s. mem usage=0.41 GB. avail mem=14.54 GB.
[2025-09-13 07:12:47 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 07:12:47 TP5] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.41 GB. avail mem=14.50 GB.
[2025-09-13 07:12:47 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 07:12:47 TP7] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.41 GB. avail mem=14.73 GB.
[2025-09-13 07:12:47 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.73 GB
[2025-09-13 07:12:47 TP3] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.41 GB. avail mem=14.50 GB.
[2025-09-13 07:12:47 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 07:12:47 TP6] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.41 GB. avail mem=14.50 GB.
[2025-09-13 07:12:47 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 07:12:47 TP2] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.41 GB. avail mem=14.50 GB.
[2025-09-13 07:12:47 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 07:12:47 TP1] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.41 GB. avail mem=14.50 GB.
[2025-09-13 07:12:47 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 07:12:47 TP4] Capture draft cuda graph end. Time elapsed: 6.33 s. mem usage=0.41 GB. avail mem=14.50 GB.
[2025-09-13 07:12:47 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
Capturing batches (bs=1 avail_mem=14.37 GB):  12%|██████████▊                                                                           | 1/8 [00:00<00:01,  4.78it/s][2025-09-13 07:12:48 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:12:48 TP6] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.37 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 27.83it/s][2025-09-13 07:12:48 TP2] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.37 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 23.55it/s]
[2025-09-13 07:12:48 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:12:48 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:12:48 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:12:48 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:12:48 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:12:48 TP0] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.17 GB. avail mem=14.36 GB.
[2025-09-13 07:12:48 TP0] max_total_num_tokens=620249, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.36 GB
[2025-09-13 07:12:48 TP2] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.17 GB. avail mem=14.32 GB.
[2025-09-13 07:12:48 TP5] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.17 GB. avail mem=14.32 GB.
[2025-09-13 07:12:48 TP1] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.17 GB. avail mem=14.32 GB.
[2025-09-13 07:12:48 TP3] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.17 GB. avail mem=14.32 GB.
[2025-09-13 07:12:48 TP6] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.17 GB. avail mem=14.32 GB.
[2025-09-13 07:12:48 TP4] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.17 GB. avail mem=14.32 GB.
[2025-09-13 07:12:48 TP7] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.17 GB. avail mem=14.56 GB.
[2025-09-13 07:12:48] INFO:     Started server process [239184]
[2025-09-13 07:12:48] INFO:     Waiting for application startup.
[2025-09-13 07:12:48] INFO:     Application startup complete.
[2025-09-13 07:12:48] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:12:49] INFO:     127.0.0.1:39596 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:12:49] INFO:     127.0.0.1:39612 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:12:49 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:12:49 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:12:49 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27784.37it/s]
[2025-09-13 07:12:51] INFO:     127.0.0.1:39618 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:12:51] The server is fired up and ready to roll!
[2025-09-13 07:12:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:13:00] INFO:     127.0.0.1:58364 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:13:00] INFO:     127.0.0.1:58378 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:00 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:13:02] INFO:     127.0.0.1:58380 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:02] INFO:     127.0.0.1:58382 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:13:02] INFO:     127.0.0.1:58388 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:02] INFO:     127.0.0.1:58402 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:02] INFO:     127.0.0.1:58416 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:02] INFO:     127.0.0.1:58428 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:02] INFO:     127.0.0.1:58444 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:02] INFO:     127.0.0.1:58446 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:02 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:13:02 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:13:02 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:13:02 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:13:02 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:13:02 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:13:02 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:13:02 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:13:02 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:13:02 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:13:03 TP0] Decode batch. #running-req: 8, #token: 14625, token usage: 0.02, accept len: 3.21, cuda graph: True, gen throughput (token/s): 47.69, #queue-req: 0, 
[2025-09-13 07:13:05 TP0] Decode batch. #running-req: 8, #token: 15796, token usage: 0.03, accept len: 3.66, cuda graph: True, gen throughput (token/s): 898.81, #queue-req: 0, 
[2025-09-13 07:13:06 TP0] Decode batch. #running-req: 8, #token: 17089, token usage: 0.03, accept len: 4.04, cuda graph: True, gen throughput (token/s): 977.96, #queue-req: 0, 
 75%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 6/8 [00:05<00:00,  2.09it/s][2025-09-13 07:13:07 TP0] Decode batch. #running-req: 1, #token: 1441, token usage: 0.00, accept len: 3.68, cuda graph: True, gen throughput (token/s): 644.45, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.35it/s]
[2025-09-13 07:13:08] INFO:     127.0.0.1:44670 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  5.93      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4085      
Request throughput (req/s):              1.35      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         691.20    
Total token throughput (tok/s):          691.20    
Concurrency:                             7.14      
Accept length:                           3.68      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5290.41   
Median E2E Latency (ms):                 5327.07   
---------------Time to First Token----------------
Mean TTFT (ms):                          613.42    
Median TTFT (ms):                        724.99    
P99 TTFT (ms):                           725.44    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.15      
Median ITL (ms):                         6.62      
P95 ITL (ms):                            16.52     
P99 ITL (ms):                            32.96     
Max ITL (ms):                            734.26    
==================================================
[2025-09-13 07:13:08] INFO:     127.0.0.1:44686 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:13:08] INFO:     127.0.0.1:44692 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:13:09] INFO:     127.0.0.1:44694 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:09] INFO:     127.0.0.1:44702 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:09 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:13:09] INFO:     127.0.0.1:44708 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:09] INFO:     127.0.0.1:44724 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:09] INFO:     127.0.0.1:44728 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:09] INFO:     127.0.0.1:44732 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:09] INFO:     127.0.0.1:44744 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:09] INFO:     127.0.0.1:44760 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:09 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:13:09 TP0] Decode batch. #running-req: 8, #token: 14207, token usage: 0.02, accept len: 3.17, cuda graph: True, gen throughput (token/s): 171.27, #queue-req: 0, 
[2025-09-13 07:13:11 TP0] Decode batch. #running-req: 8, #token: 15358, token usage: 0.02, accept len: 3.60, cuda graph: True, gen throughput (token/s): 889.94, #queue-req: 0, 
[2025-09-13 07:13:12 TP0] Decode batch. #running-req: 8, #token: 16613, token usage: 0.03, accept len: 3.92, cuda graph: True, gen throughput (token/s): 951.26, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:03<00:59,  4.00s/it][2025-09-13 07:13:13] INFO:     127.0.0.1:44768 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:13 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:28,  2.03s/it][2025-09-13 07:13:14] INFO:     127.0.0.1:44774 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:14 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:13:14 TP0] Decode batch. #running-req: 8, #token: 19390, token usage: 0.03, accept len: 3.84, cuda graph: True, gen throughput (token/s): 716.86, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:16,  1.30s/it][2025-09-13 07:13:14] INFO:     127.0.0.1:44784 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:14 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.16it/s][2025-09-13 07:13:14] INFO:     127.0.0.1:44800 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:14 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:13:14] INFO:     127.0.0.1:44806 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:14] INFO:     127.0.0.1:44822 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:14 TP0] Prefill batch. #new-seq: 2, #new-token: 3259, #cached-token: 1724, token usage: 0.01, #running-req: 6, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:05<00:03,  2.77it/s][2025-09-13 07:13:14] INFO:     127.0.0.1:44824 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:04,  1.86it/s][2025-09-13 07:13:15] INFO:     127.0.0.1:44836 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:13:16 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:13:16 TP0] Decode batch. #running-req: 8, #token: 14344, token usage: 0.02, accept len: 3.33, cuda graph: True, gen throughput (token/s): 501.05, #queue-req: 0, 
[2025-09-13 07:13:17 TP0] Decode batch. #running-req: 8, #token: 15466, token usage: 0.02, accept len: 3.51, cuda graph: True, gen throughput (token/s): 859.25, #queue-req: 0, 
[2025-09-13 07:13:19 TP0] Decode batch. #running-req: 8, #token: 16710, token usage: 0.03, accept len: 3.89, cuda graph: True, gen throughput (token/s): 950.18, #queue-req: 0, 
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 14/16 [00:10<00:00,  2.54it/s][2025-09-13 07:13:20 TP0] Decode batch. #running-req: 2, #token: 4475, token usage: 0.01, accept len: 3.64, cuda graph: True, gen throughput (token/s): 595.84, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.42it/s]
[2025-09-13 07:13:20] INFO:     127.0.0.1:52762 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.30     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8127      
Request throughput (req/s):              1.42      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         725.14    
Total token throughput (tok/s):          725.14    
Concurrency:                             7.48      
Accept length:                           3.66      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5282.81   
Median E2E Latency (ms):                 5289.06   
---------------Time to First Token----------------
Mean TTFT (ms):                          255.87    
Median TTFT (ms):                        282.05    
P99 TTFT (ms):                           354.09    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.84      
Median ITL (ms):                         6.62      
P95 ITL (ms):                            16.67     
P99 ITL (ms):                            52.89     
Max ITL (ms):                            268.21    
==================================================
[2025-09-13 07:13:20] INFO:     127.0.0.1:52768 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=20: batch_size=8, steps=4, topk=4, num_draft_tokens=8, speed=112.13 token/s, step_time=32.63 ms
Start i=21: batch_size=8, steps=4, topk=4, num_draft_tokens=12
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 4 --speculative-eagle-topk 4 --speculative-num-draft-tokens 12 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:13:31.432000 244776 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:13:31.432000 244776 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:13:31] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=841547620, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=4, speculative_eagle_topk=4, speculative_num_draft_tokens=12, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:13:32] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:13:40.503000 244981 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:13:40.503000 244981 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:13:40.767000 244982 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:13:40.767000 244982 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:13:40.817000 244988 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:13:40.817000 244988 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:13:41.022000 244984 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:13:41.022000 244984 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 07:13:41.047000 244989 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:13:41.047000 244989 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:13:41.073000 244983 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:13:41.073000 244983 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:13:41.076000 244987 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:13:41.076000 244987 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:13:41.096000 244985 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:13:41.096000 244985 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[2025-09-13 07:13:41 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:13:41 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:13:41 TP0] Init torch distributed begin.
W0913 07:13:41.140000 244986 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:13:41.140000 244986 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:13:42 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:13:46 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:13:47 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:13:47 TP0] Detected fp8 checkpoint.
[2025-09-13 07:13:48 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:05, 189.89it/s]
Loading safetensors checkpoint shards:   4% Completed | 45/1024 [00:00<00:09, 102.82it/s]
Loading safetensors checkpoint shards:   6% Completed | 58/1024 [00:00<00:12, 75.19it/s]
Loading safetensors checkpoint shards:   7% Completed | 67/1024 [00:00<00:15, 60.41it/s]
Loading safetensors checkpoint shards:   7% Completed | 74/1024 [00:01<00:16, 57.80it/s]
Loading safetensors checkpoint shards:   8% Completed | 81/1024 [00:01<00:19, 47.70it/s]
Loading safetensors checkpoint shards:   8% Completed | 87/1024 [00:01<00:20, 45.24it/s]
Loading safetensors checkpoint shards:   9% Completed | 92/1024 [00:01<00:20, 44.92it/s]
Loading safetensors checkpoint shards:   9% Completed | 97/1024 [00:02<00:35, 26.01it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:02<00:32, 28.71it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:02<00:29, 31.28it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:30, 30.20it/s]
Loading safetensors checkpoint shards:  11% Completed | 116/1024 [00:02<00:28, 32.02it/s]
Loading safetensors checkpoint shards:  12% Completed | 121/1024 [00:02<00:26, 34.03it/s]
Loading safetensors checkpoint shards:  12% Completed | 125/1024 [00:02<00:26, 34.41it/s]
Loading safetensors checkpoint shards:  13% Completed | 130/1024 [00:02<00:24, 35.95it/s]
Loading safetensors checkpoint shards:  13% Completed | 134/1024 [00:03<00:24, 35.87it/s]
Loading safetensors checkpoint shards:  14% Completed | 140/1024 [00:03<00:22, 39.73it/s]
Loading safetensors checkpoint shards:  14% Completed | 145/1024 [00:03<00:23, 37.98it/s]
Loading safetensors checkpoint shards:  15% Completed | 149/1024 [00:03<00:23, 37.96it/s]
Loading safetensors checkpoint shards:  15% Completed | 155/1024 [00:03<00:21, 41.12it/s]
Loading safetensors checkpoint shards:  16% Completed | 160/1024 [00:03<00:21, 40.08it/s]
Loading safetensors checkpoint shards:  16% Completed | 165/1024 [00:03<00:23, 36.93it/s]
Loading safetensors checkpoint shards:  17% Completed | 169/1024 [00:03<00:23, 36.86it/s]
Loading safetensors checkpoint shards:  17% Completed | 174/1024 [00:04<00:21, 39.41it/s]
Loading safetensors checkpoint shards:  17% Completed | 179/1024 [00:04<00:21, 38.46it/s]
Loading safetensors checkpoint shards:  18% Completed | 184/1024 [00:04<00:20, 40.08it/s]
Loading safetensors checkpoint shards:  18% Completed | 189/1024 [00:04<00:20, 40.73it/s]
Loading safetensors checkpoint shards:  19% Completed | 194/1024 [00:04<00:19, 42.85it/s]
Loading safetensors checkpoint shards:  19% Completed | 199/1024 [00:04<00:19, 42.46it/s]
Loading safetensors checkpoint shards:  20% Completed | 204/1024 [00:04<00:19, 42.72it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:04<00:20, 40.57it/s]
Loading safetensors checkpoint shards:  21% Completed | 214/1024 [00:04<00:20, 39.53it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:05<00:20, 39.68it/s]
Loading safetensors checkpoint shards:  22% Completed | 223/1024 [00:05<00:20, 39.58it/s]
Loading safetensors checkpoint shards:  22% Completed | 228/1024 [00:05<00:19, 40.05it/s]
Loading safetensors checkpoint shards:  23% Completed | 233/1024 [00:05<00:19, 40.13it/s]
Loading safetensors checkpoint shards:  23% Completed | 238/1024 [00:05<00:19, 41.13it/s]
Loading safetensors checkpoint shards:  24% Completed | 243/1024 [00:05<00:19, 40.86it/s]
Loading safetensors checkpoint shards:  24% Completed | 248/1024 [00:05<00:18, 42.94it/s]
Loading safetensors checkpoint shards:  25% Completed | 253/1024 [00:05<00:17, 43.22it/s]
Loading safetensors checkpoint shards:  25% Completed | 258/1024 [00:06<00:18, 42.08it/s]
Loading safetensors checkpoint shards:  26% Completed | 263/1024 [00:06<00:17, 43.65it/s]
Loading safetensors checkpoint shards:  26% Completed | 268/1024 [00:06<00:17, 43.65it/s]
Loading safetensors checkpoint shards:  27% Completed | 273/1024 [00:06<00:16, 45.13it/s]
Loading safetensors checkpoint shards:  27% Completed | 278/1024 [00:06<00:17, 42.23it/s]
Loading safetensors checkpoint shards:  28% Completed | 283/1024 [00:06<00:32, 23.07it/s]
Loading safetensors checkpoint shards:  28% Completed | 287/1024 [00:07<00:28, 25.71it/s]
Loading safetensors checkpoint shards:  28% Completed | 291/1024 [00:07<00:26, 28.08it/s]
Loading safetensors checkpoint shards:  29% Completed | 296/1024 [00:07<00:22, 32.29it/s]
Loading safetensors checkpoint shards:  29% Completed | 301/1024 [00:07<00:20, 34.89it/s]
Loading safetensors checkpoint shards:  30% Completed | 306/1024 [00:07<00:19, 37.63it/s]
Loading safetensors checkpoint shards:  30% Completed | 311/1024 [00:07<00:18, 39.01it/s]
Loading safetensors checkpoint shards:  31% Completed | 316/1024 [00:07<00:17, 41.35it/s]
Loading safetensors checkpoint shards:  31% Completed | 321/1024 [00:07<00:17, 39.58it/s]
Loading safetensors checkpoint shards:  32% Completed | 326/1024 [00:07<00:16, 41.42it/s]
Loading safetensors checkpoint shards:  32% Completed | 331/1024 [00:08<00:16, 41.05it/s]
Loading safetensors checkpoint shards:  33% Completed | 336/1024 [00:08<00:16, 40.52it/s]
Loading safetensors checkpoint shards:  33% Completed | 341/1024 [00:08<00:16, 42.46it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:08<00:17, 39.38it/s]
Loading safetensors checkpoint shards:  34% Completed | 351/1024 [00:08<00:16, 41.68it/s]
Loading safetensors checkpoint shards:  35% Completed | 356/1024 [00:08<00:16, 41.34it/s]
Loading safetensors checkpoint shards:  35% Completed | 361/1024 [00:08<00:15, 42.95it/s]
Loading safetensors checkpoint shards:  36% Completed | 366/1024 [00:08<00:15, 42.37it/s]
Loading safetensors checkpoint shards:  36% Completed | 372/1024 [00:09<00:14, 45.08it/s]
Loading safetensors checkpoint shards:  37% Completed | 377/1024 [00:09<00:14, 43.51it/s]
Loading safetensors checkpoint shards:  37% Completed | 382/1024 [00:09<00:14, 44.98it/s]
Loading safetensors checkpoint shards:  38% Completed | 387/1024 [00:09<00:14, 42.55it/s]
Loading safetensors checkpoint shards:  38% Completed | 392/1024 [00:09<00:15, 40.65it/s]
Loading safetensors checkpoint shards:  39% Completed | 397/1024 [00:09<00:14, 42.78it/s]
Loading safetensors checkpoint shards:  39% Completed | 402/1024 [00:09<00:15, 40.79it/s]
Loading safetensors checkpoint shards:  40% Completed | 407/1024 [00:09<00:14, 41.61it/s]
Loading safetensors checkpoint shards:  40% Completed | 412/1024 [00:10<00:14, 40.91it/s]
Loading safetensors checkpoint shards:  41% Completed | 417/1024 [00:10<00:14, 42.65it/s]
Loading safetensors checkpoint shards:  41% Completed | 423/1024 [00:10<00:13, 46.12it/s]
Loading safetensors checkpoint shards:  42% Completed | 430/1024 [00:10<00:11, 50.59it/s]
Loading safetensors checkpoint shards:  43% Completed | 436/1024 [00:10<00:11, 49.20it/s]
Loading safetensors checkpoint shards:  43% Completed | 442/1024 [00:10<00:11, 50.44it/s]
Loading safetensors checkpoint shards:  44% Completed | 448/1024 [00:10<00:11, 49.64it/s]
Loading safetensors checkpoint shards:  44% Completed | 453/1024 [00:10<00:11, 49.14it/s]
Loading safetensors checkpoint shards:  45% Completed | 458/1024 [00:10<00:12, 45.42it/s]
Loading safetensors checkpoint shards:  45% Completed | 464/1024 [00:11<00:11, 49.06it/s]
Loading safetensors checkpoint shards:  46% Completed | 470/1024 [00:11<00:10, 51.40it/s]
Loading safetensors checkpoint shards:  46% Completed | 476/1024 [00:11<00:10, 52.46it/s]
Loading safetensors checkpoint shards:  47% Completed | 482/1024 [00:11<00:10, 53.06it/s]
Loading safetensors checkpoint shards:  48% Completed | 488/1024 [00:11<00:22, 23.59it/s]
Loading safetensors checkpoint shards:  48% Completed | 493/1024 [00:12<00:20, 26.17it/s]
Loading safetensors checkpoint shards:  49% Completed | 497/1024 [00:12<00:20, 25.78it/s]
Loading safetensors checkpoint shards:  49% Completed | 501/1024 [00:12<00:20, 26.02it/s]
Loading safetensors checkpoint shards:  49% Completed | 505/1024 [00:12<00:19, 26.50it/s]
Loading safetensors checkpoint shards:  50% Completed | 509/1024 [00:12<00:18, 27.35it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:12<00:18, 28.38it/s]
Loading safetensors checkpoint shards:  50% Completed | 517/1024 [00:12<00:17, 28.86it/s]
Loading safetensors checkpoint shards:  51% Completed | 521/1024 [00:13<00:17, 27.98it/s]
Loading safetensors checkpoint shards:  51% Completed | 525/1024 [00:13<00:16, 30.34it/s]
Loading safetensors checkpoint shards:  52% Completed | 530/1024 [00:13<00:14, 33.46it/s]
Loading safetensors checkpoint shards:  52% Completed | 534/1024 [00:13<00:14, 33.10it/s]
Loading safetensors checkpoint shards:  53% Completed | 539/1024 [00:13<00:13, 36.23it/s]
Loading safetensors checkpoint shards:  53% Completed | 543/1024 [00:13<00:13, 36.49it/s]
Loading safetensors checkpoint shards:  54% Completed | 549/1024 [00:13<00:11, 40.77it/s]
Loading safetensors checkpoint shards:  54% Completed | 554/1024 [00:13<00:12, 39.09it/s]
Loading safetensors checkpoint shards:  54% Completed | 558/1024 [00:14<00:11, 39.17it/s]
Loading safetensors checkpoint shards:  55% Completed | 564/1024 [00:14<00:10, 43.78it/s]
Loading safetensors checkpoint shards:  56% Completed | 571/1024 [00:14<00:09, 48.04it/s]
Loading safetensors checkpoint shards:  56% Completed | 576/1024 [00:14<00:10, 43.60it/s]
Loading safetensors checkpoint shards:  57% Completed | 584/1024 [00:14<00:08, 50.92it/s]
Loading safetensors checkpoint shards:  58% Completed | 590/1024 [00:14<00:09, 47.99it/s]
Loading safetensors checkpoint shards:  58% Completed | 595/1024 [00:14<00:09, 47.01it/s]
Loading safetensors checkpoint shards:  59% Completed | 600/1024 [00:14<00:09, 46.55it/s]
Loading safetensors checkpoint shards:  59% Completed | 605/1024 [00:14<00:09, 46.42it/s]
Loading safetensors checkpoint shards:  60% Completed | 610/1024 [00:15<00:09, 43.17it/s]
Loading safetensors checkpoint shards:  60% Completed | 616/1024 [00:15<00:08, 47.09it/s]
Loading safetensors checkpoint shards:  61% Completed | 621/1024 [00:15<00:08, 46.60it/s]
Loading safetensors checkpoint shards:  61% Completed | 626/1024 [00:15<00:09, 43.21it/s]
Loading safetensors checkpoint shards:  62% Completed | 631/1024 [00:15<00:10, 38.67it/s]
Loading safetensors checkpoint shards:  62% Completed | 636/1024 [00:15<00:09, 39.74it/s]
Loading safetensors checkpoint shards:  63% Completed | 641/1024 [00:15<00:09, 41.44it/s]
Loading safetensors checkpoint shards:  63% Completed | 646/1024 [00:15<00:09, 38.92it/s]
Loading safetensors checkpoint shards:  63% Completed | 650/1024 [00:16<00:09, 38.80it/s]
Loading safetensors checkpoint shards:  64% Completed | 655/1024 [00:16<00:08, 41.13it/s]
Loading safetensors checkpoint shards:  64% Completed | 660/1024 [00:16<00:09, 39.16it/s]
Loading safetensors checkpoint shards:  65% Completed | 664/1024 [00:16<00:09, 36.63it/s]
Loading safetensors checkpoint shards:  65% Completed | 670/1024 [00:16<00:08, 41.68it/s]
Loading safetensors checkpoint shards:  66% Completed | 676/1024 [00:16<00:07, 44.48it/s]
Loading safetensors checkpoint shards:  67% Completed | 683/1024 [00:16<00:06, 49.91it/s]
Loading safetensors checkpoint shards:  67% Completed | 690/1024 [00:16<00:06, 54.85it/s]
Loading safetensors checkpoint shards:  68% Completed | 697/1024 [00:17<00:05, 58.21it/s]
Loading safetensors checkpoint shards:  69% Completed | 703/1024 [00:17<00:05, 55.35it/s]
Loading safetensors checkpoint shards:  69% Completed | 709/1024 [00:17<00:15, 19.72it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:18<00:13, 22.16it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:18<00:11, 25.47it/s]
Loading safetensors checkpoint shards:  71% Completed | 724/1024 [00:18<00:10, 28.71it/s]
Loading safetensors checkpoint shards:  71% Completed | 730/1024 [00:18<00:08, 33.30it/s]
Loading safetensors checkpoint shards:  72% Completed | 735/1024 [00:18<00:08, 32.98it/s]
Loading safetensors checkpoint shards:  72% Completed | 740/1024 [00:18<00:08, 32.46it/s]
Loading safetensors checkpoint shards:  73% Completed | 744/1024 [00:18<00:08, 32.54it/s]
Loading safetensors checkpoint shards:  73% Completed | 748/1024 [00:18<00:08, 31.95it/s]
Loading safetensors checkpoint shards:  73% Completed | 752/1024 [00:19<00:08, 33.34it/s]
Loading safetensors checkpoint shards:  74% Completed | 756/1024 [00:19<00:08, 33.38it/s]
Loading safetensors checkpoint shards:  74% Completed | 760/1024 [00:19<00:07, 34.81it/s]
Loading safetensors checkpoint shards:  75% Completed | 764/1024 [00:19<00:07, 33.85it/s]
Loading safetensors checkpoint shards:  75% Completed | 768/1024 [00:19<00:07, 32.54it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:19<00:08, 30.95it/s]
Loading safetensors checkpoint shards:  76% Completed | 776/1024 [00:19<00:08, 29.79it/s]
Loading safetensors checkpoint shards:  76% Completed | 780/1024 [00:20<00:08, 29.05it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:20<00:08, 28.93it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:20<00:08, 28.45it/s]
Loading safetensors checkpoint shards:  77% Completed | 790/1024 [00:20<00:08, 26.76it/s]
Loading safetensors checkpoint shards:  77% Completed | 793/1024 [00:20<00:08, 26.66it/s]
Loading safetensors checkpoint shards:  78% Completed | 796/1024 [00:20<00:08, 27.29it/s]
Loading safetensors checkpoint shards:  78% Completed | 799/1024 [00:20<00:08, 26.83it/s]
Loading safetensors checkpoint shards:  78% Completed | 803/1024 [00:20<00:07, 29.99it/s]
Loading safetensors checkpoint shards:  79% Completed | 807/1024 [00:20<00:06, 32.15it/s]
Loading safetensors checkpoint shards:  79% Completed | 811/1024 [00:21<00:06, 32.97it/s]
Loading safetensors checkpoint shards:  80% Completed | 815/1024 [00:21<00:06, 32.82it/s]
Loading safetensors checkpoint shards:  80% Completed | 819/1024 [00:21<00:06, 32.73it/s]
Loading safetensors checkpoint shards:  80% Completed | 823/1024 [00:21<00:05, 34.16it/s]
Loading safetensors checkpoint shards:  81% Completed | 827/1024 [00:21<00:05, 35.18it/s]
Loading safetensors checkpoint shards:  81% Completed | 831/1024 [00:21<00:05, 35.95it/s]
Loading safetensors checkpoint shards:  82% Completed | 835/1024 [00:21<00:05, 36.94it/s]
Loading safetensors checkpoint shards:  82% Completed | 840/1024 [00:21<00:04, 37.99it/s]
Loading safetensors checkpoint shards:  82% Completed | 844/1024 [00:21<00:04, 37.51it/s]
Loading safetensors checkpoint shards:  83% Completed | 848/1024 [00:22<00:04, 37.93it/s]
Loading safetensors checkpoint shards:  83% Completed | 852/1024 [00:22<00:04, 37.82it/s]
Loading safetensors checkpoint shards:  84% Completed | 856/1024 [00:22<00:04, 37.53it/s]
Loading safetensors checkpoint shards:  84% Completed | 861/1024 [00:22<00:04, 39.25it/s]
Loading safetensors checkpoint shards:  85% Completed | 868/1024 [00:22<00:03, 47.08it/s]
Loading safetensors checkpoint shards:  85% Completed | 873/1024 [00:22<00:03, 44.00it/s]
Loading safetensors checkpoint shards:  86% Completed | 878/1024 [00:22<00:03, 44.69it/s]
Loading safetensors checkpoint shards:  86% Completed | 884/1024 [00:22<00:02, 48.84it/s]
Loading safetensors checkpoint shards:  87% Completed | 889/1024 [00:22<00:02, 47.96it/s]
Loading safetensors checkpoint shards:  88% Completed | 896/1024 [00:23<00:02, 51.25it/s]
Loading safetensors checkpoint shards:  88% Completed | 902/1024 [00:23<00:02, 52.85it/s]
Loading safetensors checkpoint shards:  89% Completed | 910/1024 [00:23<00:01, 59.29it/s]
Loading safetensors checkpoint shards:  90% Completed | 918/1024 [00:23<00:01, 64.65it/s]
Loading safetensors checkpoint shards:  91% Completed | 927/1024 [00:23<00:01, 70.67it/s]
Loading safetensors checkpoint shards:  91% Completed | 935/1024 [00:23<00:01, 72.80it/s]
Loading safetensors checkpoint shards:  92% Completed | 944/1024 [00:23<00:01, 77.69it/s]
Loading safetensors checkpoint shards:  93% Completed | 952/1024 [00:23<00:00, 73.67it/s]
Loading safetensors checkpoint shards:  94% Completed | 960/1024 [00:24<00:02, 23.44it/s]
Loading safetensors checkpoint shards:  94% Completed | 966/1024 [00:24<00:02, 27.10it/s]
Loading safetensors checkpoint shards:  95% Completed | 972/1024 [00:24<00:01, 30.69it/s]
Loading safetensors checkpoint shards:  96% Completed | 980/1024 [00:25<00:01, 38.04it/s]
Loading safetensors checkpoint shards:  97% Completed | 991/1024 [00:25<00:00, 50.79it/s]
Loading safetensors checkpoint shards:  98% Completed | 1003/1024 [00:25<00:00, 64.79it/s]
Loading safetensors checkpoint shards: 100% Completed | 1019/1024 [00:25<00:00, 85.71it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 40.35it/s]

[2025-09-13 07:14:15 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:14:16 TP0] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:14:16 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:14:16 TP7] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:14:16 TP2] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:14:16 TP3] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:14:16 TP4] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:14:16 TP5] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:14:16 TP6] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:14:16 TP1] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:14:16 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:14:16 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.50 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:14:17 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:14:17 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:14:17 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:14:17 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:14:17 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:14:17 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:14:17 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:14:17 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:14:18 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25401.37it/s]
[2025-09-13 07:14:18 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:14:18 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26691.61it/s]
[2025-09-13 07:14:19 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:14:19 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27730.35it/s]
[2025-09-13 07:14:19 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:14:19 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27285.05it/s]
[2025-09-13 07:14:20 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:14:20 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28300.54it/s]
[2025-09-13 07:14:20 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.16 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.77it/s][2025-09-13 07:14:24 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:14:24 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:14:24 TP5] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.16 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.11it/s]
[2025-09-13 07:14:24 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:14:24 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:14:24 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:14:24 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:14:24 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:14:24 TP0] Capture cuda graph end. Time elapsed: 7.99 s. mem usage=0.43 GB. avail mem=17.14 GB.
[2025-09-13 07:14:24 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:14:24 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:14:24 TP0] Init torch distributed begin.
[2025-09-13 07:14:24 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:14:24 TP0] Load weight begin. avail mem=17.14 GB
[2025-09-13 07:14:24 TP0] Detected fp8 checkpoint.
[2025-09-13 07:14:24 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 178.59it/s]
Loading safetensors checkpoint shards:   4% Completed | 36/1024 [00:00<00:05, 177.49it/s]
Loading safetensors checkpoint shards:   7% Completed | 67/1024 [00:00<00:04, 235.22it/s]
Loading safetensors checkpoint shards:  12% Completed | 121/1024 [00:00<00:02, 352.13it/s]
Loading safetensors checkpoint shards:  18% Completed | 185/1024 [00:00<00:01, 452.45it/s]
Loading safetensors checkpoint shards:  24% Completed | 247/1024 [00:00<00:01, 507.15it/s]
Loading safetensors checkpoint shards:  30% Completed | 311/1024 [00:00<00:01, 547.93it/s]
Loading safetensors checkpoint shards:  37% Completed | 375/1024 [00:00<00:01, 575.28it/s]
Loading safetensors checkpoint shards:  43% Completed | 438/1024 [00:00<00:00, 591.75it/s]
Loading safetensors checkpoint shards:  49% Completed | 500/1024 [00:01<00:00, 599.58it/s]
Loading safetensors checkpoint shards:  55% Completed | 562/1024 [00:01<00:00, 604.08it/s]
Loading safetensors checkpoint shards:  61% Completed | 623/1024 [00:01<00:00, 605.13it/s]
Loading safetensors checkpoint shards:  67% Completed | 684/1024 [00:01<00:00, 593.79it/s]
Loading safetensors checkpoint shards:  73% Completed | 744/1024 [00:01<00:00, 588.71it/s]
Loading safetensors checkpoint shards:  78% Completed | 803/1024 [00:01<00:00, 586.29it/s]
Loading safetensors checkpoint shards:  84% Completed | 862/1024 [00:01<00:00, 578.91it/s]
Loading safetensors checkpoint shards:  90% Completed | 921/1024 [00:01<00:00, 580.71it/s]
Loading safetensors checkpoint shards:  96% Completed | 980/1024 [00:01<00:00, 579.88it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 493.29it/s]

[2025-09-13 07:14:26 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.15 GB, mem usage=1.99 GB.
[2025-09-13 07:14:27 TP3] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:14:27 TP2] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:14:27 TP7] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:14:27 TP1] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:14:27 TP4] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:14:27 TP0] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:14:27 TP0] Memory pool end. avail mem=14.48 GB
[2025-09-13 07:14:27 TP5] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:14:27 TP6] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:14:27 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:14:27 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:14:27 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.11 GB
[2025-09-13 07:14:27 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:14:27 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:14:27 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:14:27 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:14:27 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
Capturing batches (bs=1 avail_mem=14.50 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  3.23it/s][2025-09-13 07:14:33 TP7] Registering 72 cuda graph addresses
[2025-09-13 07:14:33 TP2] Registering 72 cuda graph addresses
[2025-09-13 07:14:33 TP1] Registering 72 cuda graph addresses
[2025-09-13 07:14:33 TP4] Registering 72 cuda graph addresses
[2025-09-13 07:14:33 TP5] Registering 72 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.50 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.48it/s]
[2025-09-13 07:14:33 TP3] Registering 72 cuda graph addresses
[2025-09-13 07:14:33 TP6] Registering 72 cuda graph addresses
[2025-09-13 07:14:33 TP0] Registering 72 cuda graph addresses
[2025-09-13 07:14:33 TP2] Capture draft cuda graph end. Time elapsed: 6.26 s. mem usage=0.41 GB. avail mem=14.46 GB.
[2025-09-13 07:14:33 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
[2025-09-13 07:14:33 TP5] Capture draft cuda graph end. Time elapsed: 6.27 s. mem usage=0.41 GB. avail mem=14.46 GB.
[2025-09-13 07:14:33 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
[2025-09-13 07:14:33 TP1] Capture draft cuda graph end. Time elapsed: 6.27 s. mem usage=0.41 GB. avail mem=14.46 GB.
[2025-09-13 07:14:33 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
[2025-09-13 07:14:33 TP0] Capture draft cuda graph end. Time elapsed: 6.28 s. mem usage=0.41 GB. avail mem=14.50 GB.
[2025-09-13 07:14:33 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 07:14:33 TP4] Capture draft cuda graph end. Time elapsed: 6.28 s. mem usage=0.41 GB. avail mem=14.46 GB.
[2025-09-13 07:14:33 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
[2025-09-13 07:14:33 TP3] Capture draft cuda graph end. Time elapsed: 6.28 s. mem usage=0.41 GB. avail mem=14.46 GB.
[2025-09-13 07:14:33 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
[2025-09-13 07:14:33 TP7] Capture draft cuda graph end. Time elapsed: 6.29 s. mem usage=0.41 GB. avail mem=14.70 GB.
[2025-09-13 07:14:33 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.70 GB
[2025-09-13 07:14:33 TP6] Capture draft cuda graph end. Time elapsed: 6.28 s. mem usage=0.41 GB. avail mem=14.46 GB.
[2025-09-13 07:14:33 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
Capturing batches (bs=1 avail_mem=14.33 GB):  50%|███████████████████████████████████████████                                           | 4/8 [00:00<00:00, 37.86it/s][2025-09-13 07:14:34 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:14:34 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:14:34 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:14:34 TP2] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.33 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 43.92it/s]
[2025-09-13 07:14:34 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:14:34 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:14:34 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:14:34 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:14:34 TP1] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.18 GB. avail mem=14.28 GB.
[2025-09-13 07:14:34 TP6] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.18 GB. avail mem=14.28 GB.
[2025-09-13 07:14:34 TP4] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.18 GB. avail mem=14.28 GB.
[2025-09-13 07:14:34 TP7] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.18 GB. avail mem=14.52 GB.
[2025-09-13 07:14:34 TP3] Capture draft extend cuda graph end. Time elapsed: 1.04 s. mem usage=0.18 GB. avail mem=14.28 GB.
[2025-09-13 07:14:34 TP5] Capture draft extend cuda graph end. Time elapsed: 1.06 s. mem usage=0.18 GB. avail mem=14.28 GB.
[2025-09-13 07:14:34 TP0] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.18 GB. avail mem=14.33 GB.
[2025-09-13 07:14:34 TP2] Capture draft extend cuda graph end. Time elapsed: 1.07 s. mem usage=0.18 GB. avail mem=14.28 GB.
[2025-09-13 07:14:34 TP0] max_total_num_tokens=620281, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.33 GB
[2025-09-13 07:14:35] INFO:     Started server process [244776]
[2025-09-13 07:14:35] INFO:     Waiting for application startup.
[2025-09-13 07:14:35] INFO:     Application startup complete.
[2025-09-13 07:14:35] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:14:35] INFO:     127.0.0.1:48464 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:14:36] INFO:     127.0.0.1:48480 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:14:36 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:14:36 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:14:36 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27877.61it/s]
[2025-09-13 07:14:37] INFO:     127.0.0.1:48494 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:37] The server is fired up and ready to roll!
[2025-09-13 07:14:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:14:46] INFO:     127.0.0.1:50570 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:14:47] INFO:     127.0.0.1:50584 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:47 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:14:48] INFO:     127.0.0.1:44592 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:48] INFO:     127.0.0.1:44596 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:48 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:14:48] INFO:     127.0.0.1:44600 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:48] INFO:     127.0.0.1:44602 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:48] INFO:     127.0.0.1:44618 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:48] INFO:     127.0.0.1:44626 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:48] INFO:     127.0.0.1:44638 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:48] INFO:     127.0.0.1:44642 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:48 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:14:49 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:14:49 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:14:49 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:14:49 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:14:49 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:14:49 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:14:49 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:14:49 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:14:49 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:14:50 TP0] Decode batch. #running-req: 8, #token: 14708, token usage: 0.02, accept len: 3.46, cuda graph: True, gen throughput (token/s): 52.24, #queue-req: 0, 
[2025-09-13 07:14:51 TP0] Decode batch. #running-req: 8, #token: 16018, token usage: 0.03, accept len: 4.09, cuda graph: True, gen throughput (token/s): 927.40, #queue-req: 0, 
[2025-09-13 07:14:53 TP0] Decode batch. #running-req: 8, #token: 17406, token usage: 0.03, accept len: 4.34, cuda graph: True, gen throughput (token/s): 976.68, #queue-req: 0, 
 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 7/8 [00:05<00:00,  2.79it/s][2025-09-13 07:14:54 TP0] Decode batch. #running-req: 1, #token: 1505, token usage: 0.00, accept len: 4.24, cuda graph: True, gen throughput (token/s): 453.38, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.32it/s]
[2025-09-13 07:14:54] INFO:     127.0.0.1:44656 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.04      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4079      
Request throughput (req/s):              1.32      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         677.90    
Total token throughput (tok/s):          677.90    
Concurrency:                             7.07      
Accept length:                           4.04      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5336.03   
Median E2E Latency (ms):                 5299.21   
---------------Time to First Token----------------
Mean TTFT (ms):                          631.12    
Median TTFT (ms):                        754.27    
P99 TTFT (ms):                           754.69    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.21      
Median ITL (ms):                         7.11      
P95 ITL (ms):                            17.62     
P99 ITL (ms):                            36.00     
Max ITL (ms):                            808.68    
==================================================
[2025-09-13 07:14:54] INFO:     127.0.0.1:44658 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:14:54] INFO:     127.0.0.1:44672 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:54 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:14:56] INFO:     127.0.0.1:44678 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:56] INFO:     127.0.0.1:44694 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:14:56] INFO:     127.0.0.1:44708 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:56] INFO:     127.0.0.1:44720 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:56] INFO:     127.0.0.1:44736 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:56] INFO:     127.0.0.1:44744 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:56] INFO:     127.0.0.1:44758 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:56] INFO:     127.0.0.1:44770 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:14:56 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:14:57 TP0] Decode batch. #running-req: 8, #token: 14708, token usage: 0.02, accept len: 3.52, cuda graph: True, gen throughput (token/s): 318.03, #queue-req: 0, 
[2025-09-13 07:14:58 TP0] Decode batch. #running-req: 8, #token: 16018, token usage: 0.03, accept len: 4.09, cuda graph: True, gen throughput (token/s): 931.32, #queue-req: 0, 
[2025-09-13 07:15:00 TP0] Decode batch. #running-req: 8, #token: 17406, token usage: 0.03, accept len: 4.34, cuda graph: True, gen throughput (token/s): 981.59, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:02,  4.17s/it][2025-09-13 07:15:00] INFO:     127.0.0.1:34686 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:15:00 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:26,  1.93s/it][2025-09-13 07:15:00] INFO:     127.0.0.1:34694 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:15:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:04<00:16,  1.24s/it][2025-09-13 07:15:00] INFO:     127.0.0.1:34702 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:15:00] INFO:     127.0.0.1:34706 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:15:00 TP0] Prefill batch. #new-seq: 2, #new-token: 487, #cached-token: 1742, token usage: 0.01, #running-req: 6, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:06,  1.65it/s][2025-09-13 07:15:01] INFO:     127.0.0.1:34708 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:15:01 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.95it/s][2025-09-13 07:15:01] INFO:     127.0.0.1:34710 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:15:01 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:15:01] INFO:     127.0.0.1:34716 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:15:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:15:02 TP0] Decode batch. #running-req: 8, #token: 10532, token usage: 0.02, accept len: 3.77, cuda graph: True, gen throughput (token/s): 511.16, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:04,  1.90it/s][2025-09-13 07:15:02] INFO:     127.0.0.1:34724 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:15:02 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:15:04 TP0] Decode batch. #running-req: 8, #token: 15191, token usage: 0.02, accept len: 3.57, cuda graph: True, gen throughput (token/s): 698.48, #queue-req: 0, 
[2025-09-13 07:15:05 TP0] Decode batch. #running-req: 8, #token: 16580, token usage: 0.03, accept len: 4.34, cuda graph: True, gen throughput (token/s): 992.81, #queue-req: 0, 
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 14/16 [00:10<00:00,  2.45it/s][2025-09-13 07:15:06 TP0] Decode batch. #running-req: 1, #token: 1891, token usage: 0.00, accept len: 4.40, cuda graph: True, gen throughput (token/s): 758.16, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.49it/s]
[2025-09-13 07:15:06] INFO:     127.0.0.1:34738 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  10.76     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8107      
Request throughput (req/s):              1.49      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         761.09    
Total token throughput (tok/s):          761.09    
Concurrency:                             7.66      
Accept length:                           4.02      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5154.77   
Median E2E Latency (ms):                 5238.56   
---------------Time to First Token----------------
Mean TTFT (ms):                          231.59    
Median TTFT (ms):                        275.48    
P99 TTFT (ms):                           289.57    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.63      
Median ITL (ms):                         7.05      
P95 ITL (ms):                            17.68     
P99 ITL (ms):                            42.27     
Max ITL (ms):                            270.68    
==================================================
[2025-09-13 07:15:06] INFO:     127.0.0.1:34748 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=21: batch_size=8, steps=4, topk=4, num_draft_tokens=12, speed=113.92 token/s, step_time=35.25 ms
Start i=22: batch_size=8, steps=5, topk=1, num_draft_tokens=4
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 5 --speculative-eagle-topk 1 --speculative-num-draft-tokens 4 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:15:17.445000 250396 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:15:17.445000 250396 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
WARNING:sglang.srt.server_args:speculative_num_draft_tokens is adjusted to speculative_num_steps + 1 when speculative_eagle_topk == 1
[2025-09-13 07:15:17] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=788204890, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=5, speculative_eagle_topk=1, speculative_num_draft_tokens=6, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:15:18] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:15:26.781000 250608 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:15:26.781000 250608 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:15:26.804000 250601 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:15:26.804000 250601 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:15:26.819000 250609 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:15:26.819000 250609 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:15:26.859000 250602 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:15:26.859000 250602 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:15:26.916000 250604 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:15:26.916000 250604 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:15:26.917000 250606 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:15:26.917000 250606 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:15:27.010000 250603 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:15:27.010000 250603 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:15:27.037000 250605 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:15:27.037000 250605 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:15:27.114000 250607 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:15:27.114000 250607 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:15:27 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:15:27 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:15:27 TP0] Init torch distributed begin.
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:15:29 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:15:32 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:15:33 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:15:33 TP0] Detected fp8 checkpoint.
[2025-09-13 07:15:34 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:05, 180.04it/s]
Loading safetensors checkpoint shards:   4% Completed | 45/1024 [00:00<00:13, 74.71it/s]
Loading safetensors checkpoint shards:   5% Completed | 56/1024 [00:00<00:13, 70.06it/s]
Loading safetensors checkpoint shards:   6% Completed | 65/1024 [00:00<00:15, 61.86it/s]
Loading safetensors checkpoint shards:   7% Completed | 72/1024 [00:01<00:15, 59.63it/s]
Loading safetensors checkpoint shards:   8% Completed | 79/1024 [00:01<00:16, 56.58it/s]
Loading safetensors checkpoint shards:   8% Completed | 85/1024 [00:01<00:17, 52.23it/s]
Loading safetensors checkpoint shards:   9% Completed | 91/1024 [00:01<00:19, 47.55it/s]
Loading safetensors checkpoint shards:   9% Completed | 96/1024 [00:01<00:21, 42.79it/s]
Loading safetensors checkpoint shards:  10% Completed | 101/1024 [00:02<00:38, 23.96it/s]
Loading safetensors checkpoint shards:  10% Completed | 105/1024 [00:02<00:35, 25.91it/s]
Loading safetensors checkpoint shards:  11% Completed | 109/1024 [00:02<00:32, 28.13it/s]
Loading safetensors checkpoint shards:  11% Completed | 114/1024 [00:02<00:28, 31.81it/s]
Loading safetensors checkpoint shards:  12% Completed | 120/1024 [00:02<00:24, 37.03it/s]
Loading safetensors checkpoint shards:  12% Completed | 125/1024 [00:02<00:22, 39.78it/s]
Loading safetensors checkpoint shards:  13% Completed | 131/1024 [00:02<00:20, 42.96it/s]
Loading safetensors checkpoint shards:  13% Completed | 136/1024 [00:02<00:21, 42.20it/s]
Loading safetensors checkpoint shards:  14% Completed | 142/1024 [00:03<00:19, 46.12it/s]
Loading safetensors checkpoint shards:  14% Completed | 147/1024 [00:03<00:19, 45.54it/s]
Loading safetensors checkpoint shards:  15% Completed | 152/1024 [00:03<00:19, 45.72it/s]
Loading safetensors checkpoint shards:  15% Completed | 157/1024 [00:03<00:19, 44.72it/s]
Loading safetensors checkpoint shards:  16% Completed | 163/1024 [00:03<00:18, 46.42it/s]
Loading safetensors checkpoint shards:  16% Completed | 168/1024 [00:03<00:19, 44.62it/s]
Loading safetensors checkpoint shards:  17% Completed | 174/1024 [00:03<00:18, 46.66it/s]
Loading safetensors checkpoint shards:  17% Completed | 179/1024 [00:03<00:18, 45.06it/s]
Loading safetensors checkpoint shards:  18% Completed | 185/1024 [00:03<00:17, 47.19it/s]
Loading safetensors checkpoint shards:  19% Completed | 190/1024 [00:04<00:17, 46.51it/s]
Loading safetensors checkpoint shards:  19% Completed | 196/1024 [00:04<00:17, 47.61it/s]
Loading safetensors checkpoint shards:  20% Completed | 201/1024 [00:04<00:17, 47.07it/s]
Loading safetensors checkpoint shards:  20% Completed | 206/1024 [00:04<00:17, 46.99it/s]
Loading safetensors checkpoint shards:  21% Completed | 211/1024 [00:04<00:17, 45.88it/s]
Loading safetensors checkpoint shards:  21% Completed | 217/1024 [00:04<00:17, 47.10it/s]
Loading safetensors checkpoint shards:  22% Completed | 222/1024 [00:04<00:17, 45.29it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:04<00:17, 45.06it/s]
Loading safetensors checkpoint shards:  23% Completed | 232/1024 [00:04<00:17, 45.07it/s]
Loading safetensors checkpoint shards:  23% Completed | 237/1024 [00:05<00:17, 46.09it/s]
Loading safetensors checkpoint shards:  24% Completed | 242/1024 [00:05<00:17, 44.63it/s]
Loading safetensors checkpoint shards:  24% Completed | 247/1024 [00:05<00:17, 44.06it/s]
Loading safetensors checkpoint shards:  25% Completed | 253/1024 [00:05<00:16, 45.37it/s]
Loading safetensors checkpoint shards:  25% Completed | 258/1024 [00:05<00:17, 43.65it/s]
Loading safetensors checkpoint shards:  26% Completed | 263/1024 [00:05<00:17, 44.76it/s]
Loading safetensors checkpoint shards:  26% Completed | 268/1024 [00:05<00:17, 42.90it/s]
Loading safetensors checkpoint shards:  27% Completed | 273/1024 [00:05<00:17, 41.77it/s]
Loading safetensors checkpoint shards:  27% Completed | 278/1024 [00:06<00:18, 39.68it/s]
Loading safetensors checkpoint shards:  28% Completed | 283/1024 [00:06<00:17, 41.92it/s]
Loading safetensors checkpoint shards:  28% Completed | 288/1024 [00:06<00:17, 41.76it/s]
Loading safetensors checkpoint shards:  29% Completed | 293/1024 [00:06<00:17, 42.20it/s]
Loading safetensors checkpoint shards:  29% Completed | 298/1024 [00:06<00:17, 41.48it/s]
Loading safetensors checkpoint shards:  30% Completed | 303/1024 [00:06<00:17, 42.07it/s]
Loading safetensors checkpoint shards:  30% Completed | 308/1024 [00:07<00:33, 21.28it/s]
Loading safetensors checkpoint shards:  31% Completed | 313/1024 [00:07<00:28, 24.99it/s]
Loading safetensors checkpoint shards:  31% Completed | 318/1024 [00:07<00:24, 29.18it/s]
Loading safetensors checkpoint shards:  31% Completed | 322/1024 [00:07<00:22, 30.88it/s]
Loading safetensors checkpoint shards:  32% Completed | 327/1024 [00:07<00:20, 34.38it/s]
Loading safetensors checkpoint shards:  32% Completed | 332/1024 [00:07<00:19, 36.06it/s]
Loading safetensors checkpoint shards:  33% Completed | 337/1024 [00:07<00:17, 38.72it/s]
Loading safetensors checkpoint shards:  33% Completed | 342/1024 [00:07<00:17, 39.08it/s]
Loading safetensors checkpoint shards:  34% Completed | 347/1024 [00:08<00:17, 39.14it/s]
Loading safetensors checkpoint shards:  34% Completed | 352/1024 [00:08<00:16, 40.62it/s]
Loading safetensors checkpoint shards:  35% Completed | 357/1024 [00:08<00:16, 39.53it/s]
Loading safetensors checkpoint shards:  35% Completed | 362/1024 [00:08<00:16, 40.54it/s]
Loading safetensors checkpoint shards:  36% Completed | 367/1024 [00:08<00:16, 39.74it/s]
Loading safetensors checkpoint shards:  36% Completed | 372/1024 [00:08<00:16, 39.66it/s]
Loading safetensors checkpoint shards:  37% Completed | 377/1024 [00:08<00:17, 37.49it/s]
Loading safetensors checkpoint shards:  37% Completed | 381/1024 [00:08<00:17, 37.30it/s]
Loading safetensors checkpoint shards:  38% Completed | 386/1024 [00:09<00:16, 38.43it/s]
Loading safetensors checkpoint shards:  38% Completed | 390/1024 [00:09<00:16, 37.55it/s]
Loading safetensors checkpoint shards:  39% Completed | 395/1024 [00:09<00:16, 39.07it/s]
Loading safetensors checkpoint shards:  39% Completed | 400/1024 [00:09<00:14, 41.84it/s]
Loading safetensors checkpoint shards:  40% Completed | 405/1024 [00:09<00:14, 42.31it/s]
Loading safetensors checkpoint shards:  40% Completed | 410/1024 [00:09<00:15, 38.97it/s]
Loading safetensors checkpoint shards:  40% Completed | 414/1024 [00:09<00:15, 38.35it/s]
Loading safetensors checkpoint shards:  41% Completed | 418/1024 [00:09<00:15, 38.66it/s]
Loading safetensors checkpoint shards:  41% Completed | 422/1024 [00:10<00:15, 38.00it/s]
Loading safetensors checkpoint shards:  42% Completed | 427/1024 [00:10<00:15, 39.78it/s]
Loading safetensors checkpoint shards:  42% Completed | 431/1024 [00:10<00:14, 39.77it/s]
Loading safetensors checkpoint shards:  42% Completed | 435/1024 [00:10<00:15, 38.09it/s]
Loading safetensors checkpoint shards:  43% Completed | 440/1024 [00:10<00:14, 39.90it/s]
Loading safetensors checkpoint shards:  43% Completed | 444/1024 [00:10<00:14, 39.23it/s]
Loading safetensors checkpoint shards:  44% Completed | 449/1024 [00:10<00:14, 39.90it/s]
Loading safetensors checkpoint shards:  44% Completed | 454/1024 [00:10<00:14, 39.82it/s]
Loading safetensors checkpoint shards:  45% Completed | 458/1024 [00:10<00:14, 39.35it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:11<00:14, 39.17it/s]
Loading safetensors checkpoint shards:  46% Completed | 467/1024 [00:11<00:14, 38.37it/s]
Loading safetensors checkpoint shards:  46% Completed | 473/1024 [00:11<00:12, 43.43it/s]
Loading safetensors checkpoint shards:  47% Completed | 478/1024 [00:11<00:12, 42.28it/s]
Loading safetensors checkpoint shards:  47% Completed | 483/1024 [00:11<00:12, 43.94it/s]
Loading safetensors checkpoint shards:  48% Completed | 488/1024 [00:11<00:13, 40.30it/s]
Loading safetensors checkpoint shards:  48% Completed | 493/1024 [00:11<00:13, 40.40it/s]
Loading safetensors checkpoint shards:  49% Completed | 498/1024 [00:11<00:13, 39.65it/s]
Loading safetensors checkpoint shards:  49% Completed | 503/1024 [00:12<00:13, 38.99it/s]
Loading safetensors checkpoint shards:  50% Completed | 509/1024 [00:12<00:11, 42.96it/s]
Loading safetensors checkpoint shards:  50% Completed | 514/1024 [00:12<00:12, 41.48it/s]
Loading safetensors checkpoint shards:  51% Completed | 519/1024 [00:12<00:12, 39.70it/s]
Loading safetensors checkpoint shards:  51% Completed | 524/1024 [00:12<00:12, 39.40it/s]
Loading safetensors checkpoint shards:  52% Completed | 529/1024 [00:12<00:11, 41.67it/s]
Loading safetensors checkpoint shards:  52% Completed | 534/1024 [00:12<00:12, 38.04it/s]
Loading safetensors checkpoint shards:  53% Completed | 539/1024 [00:12<00:12, 40.00it/s]
Loading safetensors checkpoint shards:  53% Completed | 544/1024 [00:13<00:12, 38.38it/s]
Loading safetensors checkpoint shards:  54% Completed | 549/1024 [00:13<00:11, 39.81it/s]
Loading safetensors checkpoint shards:  54% Completed | 554/1024 [00:13<00:25, 18.12it/s]
Loading safetensors checkpoint shards:  54% Completed | 558/1024 [00:13<00:22, 20.55it/s]
Loading safetensors checkpoint shards:  55% Completed | 563/1024 [00:14<00:18, 24.77it/s]
Loading safetensors checkpoint shards:  55% Completed | 567/1024 [00:14<00:16, 27.22it/s]
Loading safetensors checkpoint shards:  56% Completed | 572/1024 [00:14<00:14, 31.34it/s]
Loading safetensors checkpoint shards:  56% Completed | 576/1024 [00:14<00:13, 32.34it/s]
Loading safetensors checkpoint shards:  57% Completed | 580/1024 [00:14<00:13, 33.42it/s]
Loading safetensors checkpoint shards:  57% Completed | 586/1024 [00:14<00:11, 38.13it/s]
Loading safetensors checkpoint shards:  58% Completed | 591/1024 [00:14<00:11, 37.28it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:14<00:11, 38.51it/s]
Loading safetensors checkpoint shards:  59% Completed | 601/1024 [00:14<00:11, 37.68it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:15<00:11, 37.58it/s]
Loading safetensors checkpoint shards:  60% Completed | 610/1024 [00:15<00:10, 37.89it/s]
Loading safetensors checkpoint shards:  60% Completed | 614/1024 [00:15<00:10, 37.75it/s]
Loading safetensors checkpoint shards:  60% Completed | 619/1024 [00:15<00:10, 39.71it/s]
Loading safetensors checkpoint shards:  61% Completed | 624/1024 [00:15<00:10, 39.28it/s]
Loading safetensors checkpoint shards:  61% Completed | 628/1024 [00:15<00:10, 38.69it/s]
Loading safetensors checkpoint shards:  62% Completed | 632/1024 [00:15<00:10, 37.19it/s]
Loading safetensors checkpoint shards:  62% Completed | 636/1024 [00:15<00:10, 36.82it/s]
Loading safetensors checkpoint shards:  62% Completed | 640/1024 [00:16<00:10, 37.32it/s]
Loading safetensors checkpoint shards:  63% Completed | 644/1024 [00:16<00:10, 37.67it/s]
Loading safetensors checkpoint shards:  63% Completed | 648/1024 [00:16<00:10, 35.84it/s]
Loading safetensors checkpoint shards:  64% Completed | 652/1024 [00:16<00:10, 35.70it/s]
Loading safetensors checkpoint shards:  64% Completed | 656/1024 [00:16<00:10, 36.10it/s]
Loading safetensors checkpoint shards:  64% Completed | 660/1024 [00:16<00:10, 34.22it/s]
Loading safetensors checkpoint shards:  65% Completed | 664/1024 [00:16<00:10, 33.46it/s]
Loading safetensors checkpoint shards:  65% Completed | 668/1024 [00:16<00:10, 34.58it/s]
Loading safetensors checkpoint shards:  66% Completed | 672/1024 [00:16<00:09, 35.35it/s]
Loading safetensors checkpoint shards:  66% Completed | 676/1024 [00:17<00:09, 34.93it/s]
Loading safetensors checkpoint shards:  66% Completed | 680/1024 [00:17<00:09, 35.58it/s]
Loading safetensors checkpoint shards:  67% Completed | 684/1024 [00:17<00:09, 36.11it/s]
Loading safetensors checkpoint shards:  67% Completed | 688/1024 [00:17<00:09, 36.45it/s]
Loading safetensors checkpoint shards:  68% Completed | 693/1024 [00:17<00:08, 39.13it/s]
Loading safetensors checkpoint shards:  68% Completed | 697/1024 [00:17<00:08, 38.72it/s]
Loading safetensors checkpoint shards:  68% Completed | 701/1024 [00:17<00:08, 37.26it/s]
Loading safetensors checkpoint shards:  69% Completed | 705/1024 [00:17<00:08, 37.52it/s]
Loading safetensors checkpoint shards:  69% Completed | 709/1024 [00:17<00:08, 36.75it/s]
Loading safetensors checkpoint shards:  70% Completed | 713/1024 [00:18<00:08, 36.37it/s]
Loading safetensors checkpoint shards:  70% Completed | 717/1024 [00:18<00:08, 35.95it/s]
Loading safetensors checkpoint shards:  71% Completed | 722/1024 [00:18<00:07, 38.04it/s]
Loading safetensors checkpoint shards:  71% Completed | 727/1024 [00:18<00:07, 38.08it/s]
Loading safetensors checkpoint shards:  71% Completed | 732/1024 [00:18<00:07, 38.76it/s]
Loading safetensors checkpoint shards:  72% Completed | 736/1024 [00:18<00:07, 36.60it/s]
Loading safetensors checkpoint shards:  72% Completed | 742/1024 [00:18<00:06, 41.21it/s]
Loading safetensors checkpoint shards:  73% Completed | 747/1024 [00:18<00:06, 41.69it/s]
Loading safetensors checkpoint shards:  73% Completed | 752/1024 [00:18<00:06, 41.33it/s]
Loading safetensors checkpoint shards:  74% Completed | 757/1024 [00:19<00:06, 43.33it/s]
Loading safetensors checkpoint shards:  74% Completed | 762/1024 [00:19<00:05, 43.96it/s]
Loading safetensors checkpoint shards:  75% Completed | 767/1024 [00:19<00:05, 44.66it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:19<00:06, 37.99it/s]
Loading safetensors checkpoint shards:  76% Completed | 776/1024 [00:19<00:06, 38.14it/s]
Loading safetensors checkpoint shards:  76% Completed | 781/1024 [00:19<00:06, 40.49it/s]
Loading safetensors checkpoint shards:  77% Completed | 786/1024 [00:19<00:06, 39.33it/s]
Loading safetensors checkpoint shards:  77% Completed | 791/1024 [00:19<00:05, 41.47it/s]
Loading safetensors checkpoint shards:  78% Completed | 797/1024 [00:20<00:05, 45.17it/s]
Loading safetensors checkpoint shards:  78% Completed | 802/1024 [00:20<00:05, 44.29it/s]
Loading safetensors checkpoint shards:  79% Completed | 809/1024 [00:20<00:04, 48.49it/s]
Loading safetensors checkpoint shards:  79% Completed | 814/1024 [00:20<00:10, 20.48it/s]
Loading safetensors checkpoint shards:  80% Completed | 819/1024 [00:21<00:08, 24.30it/s]
Loading safetensors checkpoint shards:  81% Completed | 826/1024 [00:21<00:06, 31.27it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:21<00:05, 37.78it/s]
Loading safetensors checkpoint shards:  82% Completed | 839/1024 [00:21<00:04, 41.53it/s]
Loading safetensors checkpoint shards:  83% Completed | 845/1024 [00:21<00:04, 39.14it/s]
Loading safetensors checkpoint shards:  83% Completed | 850/1024 [00:21<00:05, 33.67it/s]
Loading safetensors checkpoint shards:  83% Completed | 855/1024 [00:21<00:05, 31.08it/s]
Loading safetensors checkpoint shards:  84% Completed | 859/1024 [00:22<00:05, 31.39it/s]
Loading safetensors checkpoint shards:  84% Completed | 863/1024 [00:22<00:04, 32.22it/s]
Loading safetensors checkpoint shards:  85% Completed | 868/1024 [00:22<00:04, 34.82it/s]
Loading safetensors checkpoint shards:  85% Completed | 872/1024 [00:22<00:04, 35.90it/s]
Loading safetensors checkpoint shards:  86% Completed | 877/1024 [00:22<00:03, 37.26it/s]
Loading safetensors checkpoint shards:  86% Completed | 881/1024 [00:22<00:04, 35.13it/s]
Loading safetensors checkpoint shards:  86% Completed | 885/1024 [00:22<00:04, 33.81it/s]
Loading safetensors checkpoint shards:  87% Completed | 889/1024 [00:22<00:04, 29.21it/s]
Loading safetensors checkpoint shards:  87% Completed | 893/1024 [00:23<00:04, 26.79it/s]
Loading safetensors checkpoint shards:  88% Completed | 896/1024 [00:23<00:05, 25.28it/s]
Loading safetensors checkpoint shards:  88% Completed | 899/1024 [00:23<00:05, 23.64it/s]
Loading safetensors checkpoint shards:  88% Completed | 902/1024 [00:23<00:05, 23.16it/s]
Loading safetensors checkpoint shards:  88% Completed | 906/1024 [00:23<00:04, 26.60it/s]
Loading safetensors checkpoint shards:  89% Completed | 910/1024 [00:23<00:03, 29.78it/s]
Loading safetensors checkpoint shards:  89% Completed | 915/1024 [00:23<00:03, 32.88it/s]
Loading safetensors checkpoint shards:  90% Completed | 919/1024 [00:23<00:03, 34.38it/s]
Loading safetensors checkpoint shards:  90% Completed | 923/1024 [00:24<00:02, 35.28it/s]
Loading safetensors checkpoint shards:  91% Completed | 927/1024 [00:24<00:02, 36.03it/s]
Loading safetensors checkpoint shards:  91% Completed | 931/1024 [00:24<00:02, 35.92it/s]
Loading safetensors checkpoint shards:  91% Completed | 935/1024 [00:24<00:02, 36.95it/s]
Loading safetensors checkpoint shards:  92% Completed | 939/1024 [00:24<00:02, 37.60it/s]
Loading safetensors checkpoint shards:  92% Completed | 943/1024 [00:24<00:02, 38.12it/s]
Loading safetensors checkpoint shards:  92% Completed | 947/1024 [00:24<00:02, 36.99it/s]
Loading safetensors checkpoint shards:  93% Completed | 951/1024 [00:24<00:01, 37.25it/s]
Loading safetensors checkpoint shards:  93% Completed | 955/1024 [00:24<00:01, 37.23it/s]
Loading safetensors checkpoint shards:  94% Completed | 959/1024 [00:25<00:01, 37.86it/s]
Loading safetensors checkpoint shards:  94% Completed | 963/1024 [00:25<00:01, 37.03it/s]
Loading safetensors checkpoint shards:  94% Completed | 967/1024 [00:25<00:01, 37.13it/s]
Loading safetensors checkpoint shards:  95% Completed | 971/1024 [00:25<00:01, 36.68it/s]
Loading safetensors checkpoint shards:  95% Completed | 975/1024 [00:25<00:01, 37.58it/s]
Loading safetensors checkpoint shards:  96% Completed | 979/1024 [00:25<00:01, 38.17it/s]
Loading safetensors checkpoint shards:  97% Completed | 994/1024 [00:25<00:00, 68.67it/s]
Loading safetensors checkpoint shards:  98% Completed | 1002/1024 [00:25<00:00, 70.96it/s]
Loading safetensors checkpoint shards:  99% Completed | 1014/1024 [00:25<00:00, 81.07it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 39.45it/s]

[2025-09-13 07:16:00 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:16:02 TP0] KV Cache is allocated. #tokens: 620145, KV size: 40.59 GB
[2025-09-13 07:16:02 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:16:02 TP4] KV Cache is allocated. #tokens: 620145, KV size: 40.59 GB
[2025-09-13 07:16:02 TP3] KV Cache is allocated. #tokens: 620145, KV size: 40.59 GB
[2025-09-13 07:16:02 TP6] KV Cache is allocated. #tokens: 620145, KV size: 40.59 GB
[2025-09-13 07:16:02 TP7] KV Cache is allocated. #tokens: 620145, KV size: 40.59 GB
[2025-09-13 07:16:02 TP1] KV Cache is allocated. #tokens: 620145, KV size: 40.59 GB
[2025-09-13 07:16:02 TP5] KV Cache is allocated. #tokens: 620145, KV size: 40.59 GB
[2025-09-13 07:16:02 TP2] KV Cache is allocated. #tokens: 620145, KV size: 40.59 GB
[2025-09-13 07:16:02 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:16:03 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.52 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:16:03 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:16:03 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:16:04 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:16:04 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:16:04 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:16:04 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:16:04 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:16:04 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:16:04 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25814.92it/s]
[2025-09-13 07:16:04 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:16:04 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26139.28it/s]
[2025-09-13 07:16:05 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:16:05 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27301.05it/s]
[2025-09-13 07:16:05 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:16:05 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26465.97it/s]
[2025-09-13 07:16:06 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:16:06 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27760.77it/s]
[2025-09-13 07:16:07 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.25 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.88it/s][2025-09-13 07:16:10 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:16:10 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:16:10 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:16:10 TP6] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.25 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.16it/s]
[2025-09-13 07:16:10 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:16:10 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:16:10 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:16:10 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:16:10 TP0] Capture cuda graph end. Time elapsed: 7.66 s. mem usage=0.33 GB. avail mem=17.24 GB.
[2025-09-13 07:16:10 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:16:10 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:16:10 TP0] Init torch distributed begin.
[2025-09-13 07:16:10 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:16:10 TP0] Load weight begin. avail mem=17.24 GB
[2025-09-13 07:16:10 TP0] Detected fp8 checkpoint.
[2025-09-13 07:16:10 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 19/1024 [00:00<00:05, 188.32it/s]
Loading safetensors checkpoint shards:   5% Completed | 48/1024 [00:00<00:03, 247.11it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:00<00:02, 405.97it/s]
Loading safetensors checkpoint shards:  17% Completed | 169/1024 [00:00<00:01, 484.18it/s]
Loading safetensors checkpoint shards:  22% Completed | 230/1024 [00:00<00:01, 529.26it/s]
Loading safetensors checkpoint shards:  29% Completed | 292/1024 [00:00<00:01, 557.73it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:00<00:01, 575.52it/s]
Loading safetensors checkpoint shards:  41% Completed | 418/1024 [00:00<00:01, 593.28it/s]
Loading safetensors checkpoint shards:  47% Completed | 481/1024 [00:00<00:00, 602.27it/s]
Loading safetensors checkpoint shards:  53% Completed | 543/1024 [00:01<00:00, 607.29it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:01<00:00, 611.67it/s]
Loading safetensors checkpoint shards:  65% Completed | 668/1024 [00:01<00:00, 604.43it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:01<00:00, 595.98it/s]
Loading safetensors checkpoint shards:  77% Completed | 789/1024 [00:01<00:00, 591.57it/s]
Loading safetensors checkpoint shards:  83% Completed | 849/1024 [00:01<00:00, 591.76it/s]
Loading safetensors checkpoint shards:  89% Completed | 909/1024 [00:01<00:00, 585.19it/s]
Loading safetensors checkpoint shards:  95% Completed | 968/1024 [00:01<00:00, 579.57it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:01<00:00, 515.74it/s]

[2025-09-13 07:16:12 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.26 GB, mem usage=1.98 GB.
[2025-09-13 07:16:12 TP7] KV Cache is allocated. #tokens: 620145, KV size: 0.67 GB
[2025-09-13 07:16:12 TP0] KV Cache is allocated. #tokens: 620145, KV size: 0.67 GB
[2025-09-13 07:16:12 TP1] KV Cache is allocated. #tokens: 620145, KV size: 0.67 GB
[2025-09-13 07:16:12 TP0] Memory pool end. avail mem=14.59 GB
[2025-09-13 07:16:12 TP4] KV Cache is allocated. #tokens: 620145, KV size: 0.67 GB
[2025-09-13 07:16:12 TP5] KV Cache is allocated. #tokens: 620145, KV size: 0.67 GB
[2025-09-13 07:16:12 TP3] KV Cache is allocated. #tokens: 620145, KV size: 0.67 GB
[2025-09-13 07:16:12 TP2] KV Cache is allocated. #tokens: 620145, KV size: 0.67 GB
[2025-09-13 07:16:12 TP6] KV Cache is allocated. #tokens: 620145, KV size: 0.67 GB
[2025-09-13 07:16:13 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:16:13 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:16:13 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:16:13 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:16:13 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.02 GB
[2025-09-13 07:16:13 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.22 GB
[2025-09-13 07:16:13 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:16:13 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
Capturing batches (bs=1 avail_mem=14.79 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:01<00:00,  6.00it/s][2025-09-13 07:16:16 TP3] Registering 96 cuda graph addresses
[2025-09-13 07:16:16 TP4] Registering 96 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.79 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:02<00:00,  3.18it/s][2025-09-13 07:16:16 TP1] Registering 96 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.79 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:02<00:00,  2.98it/s]
[2025-09-13 07:16:16 TP2] Registering 96 cuda graph addresses
[2025-09-13 07:16:16 TP5] Registering 96 cuda graph addresses
[2025-09-13 07:16:16 TP6] Registering 96 cuda graph addresses
[2025-09-13 07:16:16 TP0] Registering 96 cuda graph addresses
[2025-09-13 07:16:16 TP7] Registering 96 cuda graph addresses
[2025-09-13 07:16:16 TP7] Capture draft cuda graph end. Time elapsed: 3.49 s. mem usage=0.23 GB. avail mem=14.98 GB.
[2025-09-13 07:16:16 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:16:16 TP3] Capture draft cuda graph end. Time elapsed: 3.49 s. mem usage=0.23 GB. avail mem=14.75 GB.
[2025-09-13 07:16:16 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.75 GB
[2025-09-13 07:16:16 TP6] Capture draft cuda graph end. Time elapsed: 3.54 s. mem usage=0.23 GB. avail mem=14.75 GB.
[2025-09-13 07:16:16 TP5] Capture draft cuda graph end. Time elapsed: 3.54 s. mem usage=0.23 GB. avail mem=14.75 GB.
[2025-09-13 07:16:16 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.75 GB
[2025-09-13 07:16:16 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.75 GB
[2025-09-13 07:16:16 TP4] Capture draft cuda graph end. Time elapsed: 3.54 s. mem usage=0.23 GB. avail mem=14.75 GB.
[2025-09-13 07:16:16 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.75 GB
[2025-09-13 07:16:16 TP2] Capture draft cuda graph end. Time elapsed: 3.54 s. mem usage=0.23 GB. avail mem=14.75 GB.
[2025-09-13 07:16:16 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.75 GB
[2025-09-13 07:16:16 TP1] Capture draft cuda graph end. Time elapsed: 3.49 s. mem usage=0.23 GB. avail mem=14.75 GB.
[2025-09-13 07:16:16 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.75 GB
[2025-09-13 07:16:16 TP0] Capture draft cuda graph end. Time elapsed: 3.54 s. mem usage=0.23 GB. avail mem=14.79 GB.
[2025-09-13 07:16:16 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
Capturing batches (bs=1 avail_mem=14.60 GB):  50%|███████████████████████████████████████████                                           | 4/8 [00:00<00:00, 39.99it/s][2025-09-13 07:16:17 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:16:17 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:16:17 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:16:17 TP4] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.60 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 41.39it/s]
[2025-09-13 07:16:17 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:16:17 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:16:17 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:16:17 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:16:17 TP1] Capture draft extend cuda graph end. Time elapsed: 0.99 s. mem usage=0.19 GB. avail mem=14.56 GB.
[2025-09-13 07:16:17 TP6] Capture draft extend cuda graph end. Time elapsed: 1.00 s. mem usage=0.19 GB. avail mem=14.56 GB.
[2025-09-13 07:16:17 TP5] Capture draft extend cuda graph end. Time elapsed: 1.00 s. mem usage=0.19 GB. avail mem=14.56 GB.
[2025-09-13 07:16:17 TP2] Capture draft extend cuda graph end. Time elapsed: 1.00 s. mem usage=0.19 GB. avail mem=14.56 GB.
[2025-09-13 07:16:17 TP4] Capture draft extend cuda graph end. Time elapsed: 1.00 s. mem usage=0.19 GB. avail mem=14.56 GB.
[2025-09-13 07:16:17 TP0] Capture draft extend cuda graph end. Time elapsed: 1.00 s. mem usage=0.19 GB. avail mem=14.60 GB.
[2025-09-13 07:16:17 TP3] Capture draft extend cuda graph end. Time elapsed: 1.00 s. mem usage=0.19 GB. avail mem=14.56 GB.
[2025-09-13 07:16:17 TP0] max_total_num_tokens=620145, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.60 GB
[2025-09-13 07:16:17 TP7] Capture draft extend cuda graph end. Time elapsed: 1.00 s. mem usage=0.19 GB. avail mem=14.80 GB.
[2025-09-13 07:16:18] INFO:     Started server process [250396]
[2025-09-13 07:16:18] INFO:     Waiting for application startup.
[2025-09-13 07:16:18] INFO:     Application startup complete.
[2025-09-13 07:16:18] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:16:19] INFO:     127.0.0.1:48796 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:16:19 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:16:19 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:16:19 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 24007.63it/s]
[2025-09-13 07:16:20] INFO:     127.0.0.1:48804 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:20] The server is fired up and ready to roll!
[2025-09-13 07:16:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:16:22] INFO:     127.0.0.1:48812 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:16:23] INFO:     127.0.0.1:48820 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:23 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:16:24] INFO:     127.0.0.1:48826 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:24] INFO:     127.0.0.1:48840 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:16:24] INFO:     127.0.0.1:48842 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:24] INFO:     127.0.0.1:48856 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:24] INFO:     127.0.0.1:48868 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:24] INFO:     127.0.0.1:48872 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:24] INFO:     127.0.0.1:48884 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:24] INFO:     127.0.0.1:48888 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:24 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:16:25 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:16:25 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:16:25 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:16:25 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:16:25 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:16:25 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:16:25 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:16:25 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:16:25 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:16:26 TP0] Decode batch. #running-req: 8, #token: 14523, token usage: 0.02, accept len: 2.86, cuda graph: True, gen throughput (token/s): 74.60, #queue-req: 0, 
[2025-09-13 07:16:27 TP0] Decode batch. #running-req: 8, #token: 15655, token usage: 0.03, accept len: 3.54, cuda graph: True, gen throughput (token/s): 941.51, #queue-req: 0, 
[2025-09-13 07:16:28 TP0] Decode batch. #running-req: 8, #token: 16939, token usage: 0.03, accept len: 4.01, cuda graph: True, gen throughput (token/s): 1055.67, #queue-req: 0, 
 62%|█████████████████████████████████████████████████████████████████████████████████▉                                                 | 5/8 [00:05<00:02,  1.32it/s][2025-09-13 07:16:30 TP0] Decode batch. #running-req: 2, #token: 2001, token usage: 0.00, accept len: 3.80, cuda graph: True, gen throughput (token/s): 657.89, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.35it/s]
[2025-09-13 07:16:30] INFO:     127.0.0.1:48434 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  5.95      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4083      
Request throughput (req/s):              1.34      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         688.49    
Total token throughput (tok/s):          688.49    
Concurrency:                             6.70      
Accept length:                           3.59      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   4980.71   
Median E2E Latency (ms):                 4840.33   
---------------Time to First Token----------------
Mean TTFT (ms):                          600.14    
Median TTFT (ms):                        710.80    
P99 TTFT (ms):                           711.34    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           8.57      
Median ITL (ms):                         5.96      
P95 ITL (ms):                            19.43     
P99 ITL (ms):                            30.56     
Max ITL (ms):                            727.49    
==================================================
[2025-09-13 07:16:30] INFO:     127.0.0.1:48446 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:16:30] INFO:     127.0.0.1:48456 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:30 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:16:30 TP0] Decode batch. #running-req: 1, #token: 4671, token usage: 0.01, accept len: 3.40, cuda graph: True, gen throughput (token/s): 239.05, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:16:32] INFO:     127.0.0.1:48462 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:32] INFO:     127.0.0.1:48468 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:16:32] INFO:     127.0.0.1:48482 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:32] INFO:     127.0.0.1:48484 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:32] INFO:     127.0.0.1:48486 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:32] INFO:     127.0.0.1:48492 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:32] INFO:     127.0.0.1:48506 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:32] INFO:     127.0.0.1:48510 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:32 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:16:33 TP0] Decode batch. #running-req: 8, #token: 14687, token usage: 0.02, accept len: 3.01, cuda graph: True, gen throughput (token/s): 341.46, #queue-req: 0, 
[2025-09-13 07:16:34 TP0] Decode batch. #running-req: 8, #token: 15844, token usage: 0.03, accept len: 3.62, cuda graph: True, gen throughput (token/s): 960.20, #queue-req: 0, 
[2025-09-13 07:16:35 TP0] Decode batch. #running-req: 8, #token: 17149, token usage: 0.03, accept len: 4.08, cuda graph: True, gen throughput (token/s): 1071.38, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:03<00:58,  3.89s/it][2025-09-13 07:16:35] INFO:     127.0.0.1:48514 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:36 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:25,  1.79s/it][2025-09-13 07:16:36] INFO:     127.0.0.1:48526 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:36] INFO:     127.0.0.1:48534 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:36 TP0] Prefill batch. #new-seq: 2, #new-token: 2409, #cached-token: 1752, token usage: 0.01, #running-req: 6, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:04<00:09,  1.30it/s][2025-09-13 07:16:36] INFO:     127.0.0.1:48546 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:36 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:04<00:07,  1.49it/s][2025-09-13 07:16:37] INFO:     127.0.0.1:48550 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:37 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.86it/s][2025-09-13 07:16:37] INFO:     127.0.0.1:48566 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:37 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:16:37 TP0] Decode batch. #running-req: 8, #token: 9038, token usage: 0.01, accept len: 3.53, cuda graph: True, gen throughput (token/s): 554.33, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:05<00:04,  1.82it/s][2025-09-13 07:16:37] INFO:     127.0.0.1:48582 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:05,  1.55it/s][2025-09-13 07:16:38] INFO:     127.0.0.1:45332 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:16:38 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:16:39 TP0] Decode batch. #running-req: 8, #token: 14799, token usage: 0.02, accept len: 3.38, cuda graph: True, gen throughput (token/s): 701.07, #queue-req: 0, 
[2025-09-13 07:16:40 TP0] Decode batch. #running-req: 8, #token: 16098, token usage: 0.03, accept len: 4.06, cuda graph: True, gen throughput (token/s): 1100.21, #queue-req: 0, 
 69%|████████████████████████████████████████████████████████████████████████████████████████▋                                        | 11/16 [00:09<00:03,  1.54it/s][2025-09-13 07:16:41 TP0] Decode batch. #running-req: 5, #token: 11980, token usage: 0.02, accept len: 4.40, cuda graph: True, gen throughput (token/s): 951.91, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.57it/s]
[2025-09-13 07:16:42] INFO:     127.0.0.1:45334 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  10.19     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8101      
Request throughput (req/s):              1.57      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         804.23    
Total token throughput (tok/s):          804.23    
Concurrency:                             7.44      
Accept length:                           3.67      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   4734.10   
Median E2E Latency (ms):                 4461.05   
---------------Time to First Token----------------
Mean TTFT (ms):                          226.29    
Median TTFT (ms):                        232.04    
P99 TTFT (ms):                           288.06    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           8.82      
Median ITL (ms):                         5.54      
P95 ITL (ms):                            27.61     
P99 ITL (ms):                            46.78     
Max ITL (ms):                            285.28    
==================================================
[2025-09-13 07:16:42] INFO:     127.0.0.1:45342 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=22: batch_size=8, steps=5, topk=1, num_draft_tokens=4, speed=122.01 token/s, step_time=30.10 ms
Start i=23: batch_size=8, steps=5, topk=1, num_draft_tokens=6
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 5 --speculative-eagle-topk 1 --speculative-num-draft-tokens 6 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:16:53.023000 255926 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:16:53.023000 255926 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:16:53] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=237769539, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=5, speculative_eagle_topk=1, speculative_num_draft_tokens=6, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:16:53] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:17:02.218000 256169 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:17:02.218000 256169 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:17:02.300000 256163 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:17:02.300000 256163 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:17:02.400000 256161 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:17:02.400000 256161 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:17:02.485000 256168 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:17:02.485000 256168 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:17:02.517000 256166 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:17:02.517000 256166 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:17:02.518000 256165 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:17:02.518000 256165 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:17:02.518000 256167 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:17:02.518000 256167 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:17:02.523000 256162 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:17:02.523000 256162 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:17:02.665000 256164 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:17:02.665000 256164 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:17:02 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:17:02 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:17:02 TP0] Init torch distributed begin.
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:17:04 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:17:07 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:17:09 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:17:09 TP0] Detected fp8 checkpoint.
[2025-09-13 07:17:09 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:04, 225.05it/s]
Loading safetensors checkpoint shards:   5% Completed | 49/1024 [00:00<00:15, 62.19it/s]
Loading safetensors checkpoint shards:   6% Completed | 61/1024 [00:00<00:17, 54.57it/s]
Loading safetensors checkpoint shards:   7% Completed | 70/1024 [00:01<00:20, 46.97it/s]
Loading safetensors checkpoint shards:   8% Completed | 77/1024 [00:01<00:21, 44.39it/s]
Loading safetensors checkpoint shards:   8% Completed | 83/1024 [00:01<00:21, 43.90it/s]
Loading safetensors checkpoint shards:   9% Completed | 88/1024 [00:01<00:21, 43.62it/s]
Loading safetensors checkpoint shards:   9% Completed | 93/1024 [00:01<00:22, 41.13it/s]
Loading safetensors checkpoint shards:  10% Completed | 98/1024 [00:01<00:22, 40.58it/s]
Loading safetensors checkpoint shards:  10% Completed | 104/1024 [00:02<00:20, 44.61it/s]
Loading safetensors checkpoint shards:  11% Completed | 109/1024 [00:02<00:20, 44.60it/s]
Loading safetensors checkpoint shards:  12% Completed | 118/1024 [00:02<00:30, 29.38it/s]
Loading safetensors checkpoint shards:  12% Completed | 123/1024 [00:02<00:27, 32.30it/s]
Loading safetensors checkpoint shards:  13% Completed | 129/1024 [00:02<00:24, 36.26it/s]
Loading safetensors checkpoint shards:  13% Completed | 134/1024 [00:03<00:24, 36.54it/s]
Loading safetensors checkpoint shards:  14% Completed | 141/1024 [00:03<00:20, 42.19it/s]
Loading safetensors checkpoint shards:  14% Completed | 146/1024 [00:03<00:20, 42.95it/s]
Loading safetensors checkpoint shards:  15% Completed | 153/1024 [00:03<00:18, 48.00it/s]
Loading safetensors checkpoint shards:  16% Completed | 159/1024 [00:03<00:16, 50.98it/s]
Loading safetensors checkpoint shards:  16% Completed | 165/1024 [00:03<00:16, 53.26it/s]
Loading safetensors checkpoint shards:  17% Completed | 172/1024 [00:03<00:15, 55.66it/s]
Loading safetensors checkpoint shards:  17% Completed | 179/1024 [00:03<00:15, 56.23it/s]
Loading safetensors checkpoint shards:  18% Completed | 186/1024 [00:03<00:14, 59.03it/s]
Loading safetensors checkpoint shards:  19% Completed | 193/1024 [00:04<00:13, 61.00it/s]
Loading safetensors checkpoint shards:  20% Completed | 200/1024 [00:04<00:14, 56.86it/s]
Loading safetensors checkpoint shards:  20% Completed | 206/1024 [00:04<00:14, 55.97it/s]
Loading safetensors checkpoint shards:  21% Completed | 212/1024 [00:04<00:14, 56.94it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:04<00:14, 56.44it/s]
Loading safetensors checkpoint shards:  22% Completed | 225/1024 [00:04<00:14, 55.57it/s]
Loading safetensors checkpoint shards:  23% Completed | 231/1024 [00:04<00:14, 56.59it/s]
Loading safetensors checkpoint shards:  23% Completed | 238/1024 [00:04<00:13, 59.73it/s]
Loading safetensors checkpoint shards:  24% Completed | 246/1024 [00:04<00:12, 62.28it/s]
Loading safetensors checkpoint shards:  25% Completed | 254/1024 [00:05<00:11, 64.72it/s]
Loading safetensors checkpoint shards:  25% Completed | 261/1024 [00:05<00:23, 32.19it/s]
Loading safetensors checkpoint shards:  26% Completed | 266/1024 [00:05<00:21, 34.70it/s]
Loading safetensors checkpoint shards:  27% Completed | 272/1024 [00:05<00:19, 39.11it/s]
Loading safetensors checkpoint shards:  27% Completed | 278/1024 [00:05<00:17, 42.54it/s]
Loading safetensors checkpoint shards:  28% Completed | 286/1024 [00:05<00:14, 49.31it/s]
Loading safetensors checkpoint shards:  29% Completed | 292/1024 [00:06<00:14, 50.45it/s]
Loading safetensors checkpoint shards:  29% Completed | 300/1024 [00:06<00:12, 55.74it/s]
Loading safetensors checkpoint shards:  30% Completed | 308/1024 [00:06<00:11, 60.52it/s]
Loading safetensors checkpoint shards:  31% Completed | 316/1024 [00:06<00:11, 62.14it/s]
Loading safetensors checkpoint shards:  32% Completed | 323/1024 [00:06<00:12, 55.16it/s]
Loading safetensors checkpoint shards:  32% Completed | 329/1024 [00:06<00:13, 50.69it/s]
Loading safetensors checkpoint shards:  33% Completed | 335/1024 [00:06<00:14, 46.03it/s]
Loading safetensors checkpoint shards:  33% Completed | 340/1024 [00:07<00:15, 43.36it/s]
Loading safetensors checkpoint shards:  34% Completed | 345/1024 [00:07<00:16, 40.84it/s]
Loading safetensors checkpoint shards:  34% Completed | 350/1024 [00:07<00:16, 41.94it/s]
Loading safetensors checkpoint shards:  35% Completed | 355/1024 [00:07<00:16, 41.21it/s]
Loading safetensors checkpoint shards:  35% Completed | 360/1024 [00:07<00:15, 42.20it/s]
Loading safetensors checkpoint shards:  36% Completed | 365/1024 [00:07<00:17, 38.26it/s]
Loading safetensors checkpoint shards:  36% Completed | 369/1024 [00:07<00:17, 37.82it/s]
Loading safetensors checkpoint shards:  37% Completed | 374/1024 [00:07<00:16, 40.05it/s]
Loading safetensors checkpoint shards:  37% Completed | 379/1024 [00:08<00:16, 38.17it/s]
Loading safetensors checkpoint shards:  38% Completed | 384/1024 [00:08<00:15, 40.35it/s]
Loading safetensors checkpoint shards:  38% Completed | 389/1024 [00:08<00:15, 40.80it/s]
Loading safetensors checkpoint shards:  38% Completed | 394/1024 [00:08<00:14, 42.57it/s]
Loading safetensors checkpoint shards:  39% Completed | 400/1024 [00:08<00:13, 45.47it/s]
Loading safetensors checkpoint shards:  40% Completed | 405/1024 [00:08<00:13, 45.67it/s]
Loading safetensors checkpoint shards:  40% Completed | 410/1024 [00:08<00:14, 43.58it/s]
Loading safetensors checkpoint shards:  41% Completed | 415/1024 [00:08<00:13, 43.82it/s]
Loading safetensors checkpoint shards:  41% Completed | 420/1024 [00:08<00:15, 39.43it/s]
Loading safetensors checkpoint shards:  42% Completed | 425/1024 [00:09<00:15, 38.60it/s]
Loading safetensors checkpoint shards:  42% Completed | 429/1024 [00:09<00:33, 17.96it/s]
Loading safetensors checkpoint shards:  42% Completed | 434/1024 [00:09<00:27, 21.66it/s]
Loading safetensors checkpoint shards:  43% Completed | 439/1024 [00:09<00:22, 26.24it/s]
Loading safetensors checkpoint shards:  43% Completed | 444/1024 [00:10<00:19, 30.00it/s]
Loading safetensors checkpoint shards:  44% Completed | 449/1024 [00:10<00:16, 34.08it/s]
Loading safetensors checkpoint shards:  44% Completed | 454/1024 [00:10<00:15, 36.34it/s]
Loading safetensors checkpoint shards:  45% Completed | 460/1024 [00:10<00:14, 40.27it/s]
Loading safetensors checkpoint shards:  46% Completed | 466/1024 [00:10<00:13, 42.37it/s]
Loading safetensors checkpoint shards:  46% Completed | 471/1024 [00:10<00:12, 43.61it/s]
Loading safetensors checkpoint shards:  46% Completed | 476/1024 [00:10<00:14, 38.63it/s]
Loading safetensors checkpoint shards:  47% Completed | 481/1024 [00:10<00:14, 36.56it/s]
Loading safetensors checkpoint shards:  47% Completed | 485/1024 [00:11<00:15, 35.05it/s]
Loading safetensors checkpoint shards:  48% Completed | 489/1024 [00:11<00:16, 32.04it/s]
Loading safetensors checkpoint shards:  48% Completed | 493/1024 [00:11<00:16, 32.74it/s]
Loading safetensors checkpoint shards:  49% Completed | 497/1024 [00:11<00:16, 31.26it/s]
Loading safetensors checkpoint shards:  49% Completed | 501/1024 [00:11<00:16, 32.13it/s]
Loading safetensors checkpoint shards:  49% Completed | 505/1024 [00:11<00:15, 32.68it/s]
Loading safetensors checkpoint shards:  50% Completed | 509/1024 [00:11<00:15, 34.17it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:11<00:14, 34.79it/s]
Loading safetensors checkpoint shards:  50% Completed | 517/1024 [00:12<00:14, 35.38it/s]
Loading safetensors checkpoint shards:  51% Completed | 521/1024 [00:12<00:14, 35.13it/s]
Loading safetensors checkpoint shards:  51% Completed | 525/1024 [00:12<00:14, 33.59it/s]
Loading safetensors checkpoint shards:  52% Completed | 530/1024 [00:12<00:13, 37.62it/s]
Loading safetensors checkpoint shards:  52% Completed | 534/1024 [00:12<00:13, 35.21it/s]
Loading safetensors checkpoint shards:  53% Completed | 538/1024 [00:12<00:13, 36.05it/s]
Loading safetensors checkpoint shards:  53% Completed | 542/1024 [00:12<00:13, 36.16it/s]
Loading safetensors checkpoint shards:  53% Completed | 547/1024 [00:12<00:12, 37.40it/s]
Loading safetensors checkpoint shards:  54% Completed | 552/1024 [00:12<00:12, 37.96it/s]
Loading safetensors checkpoint shards:  54% Completed | 556/1024 [00:13<00:13, 35.56it/s]
Loading safetensors checkpoint shards:  55% Completed | 560/1024 [00:13<00:12, 36.00it/s]
Loading safetensors checkpoint shards:  55% Completed | 564/1024 [00:13<00:13, 34.63it/s]
Loading safetensors checkpoint shards:  55% Completed | 568/1024 [00:13<00:13, 33.31it/s]
Loading safetensors checkpoint shards:  56% Completed | 573/1024 [00:13<00:12, 35.20it/s]
Loading safetensors checkpoint shards:  56% Completed | 577/1024 [00:13<00:13, 33.57it/s]
Loading safetensors checkpoint shards:  57% Completed | 581/1024 [00:13<00:13, 33.44it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:13<00:12, 34.98it/s]
Loading safetensors checkpoint shards:  58% Completed | 589/1024 [00:14<00:14, 30.50it/s]
Loading safetensors checkpoint shards:  58% Completed | 593/1024 [00:14<00:14, 30.41it/s]
Loading safetensors checkpoint shards:  58% Completed | 597/1024 [00:14<00:14, 30.16it/s]
Loading safetensors checkpoint shards:  59% Completed | 601/1024 [00:14<00:15, 28.12it/s]
Loading safetensors checkpoint shards:  59% Completed | 605/1024 [00:14<00:14, 29.67it/s]
Loading safetensors checkpoint shards:  59% Completed | 609/1024 [00:14<00:15, 26.53it/s]
Loading safetensors checkpoint shards:  60% Completed | 612/1024 [00:14<00:15, 26.17it/s]
Loading safetensors checkpoint shards:  60% Completed | 616/1024 [00:15<00:14, 28.09it/s]
Loading safetensors checkpoint shards:  60% Completed | 619/1024 [00:15<00:14, 27.84it/s]
Loading safetensors checkpoint shards:  61% Completed | 622/1024 [00:15<00:15, 26.64it/s]
Loading safetensors checkpoint shards:  61% Completed | 626/1024 [00:15<00:13, 29.14it/s]
Loading safetensors checkpoint shards:  62% Completed | 630/1024 [00:15<00:13, 30.24it/s]
Loading safetensors checkpoint shards:  62% Completed | 634/1024 [00:15<00:12, 31.87it/s]
Loading safetensors checkpoint shards:  62% Completed | 638/1024 [00:16<00:32, 11.97it/s]
Loading safetensors checkpoint shards:  63% Completed | 642/1024 [00:16<00:25, 15.19it/s]
Loading safetensors checkpoint shards:  63% Completed | 646/1024 [00:16<00:20, 18.03it/s]
Loading safetensors checkpoint shards:  63% Completed | 650/1024 [00:16<00:17, 21.21it/s]
Loading safetensors checkpoint shards:  64% Completed | 654/1024 [00:16<00:15, 24.20it/s]
Loading safetensors checkpoint shards:  64% Completed | 658/1024 [00:17<00:13, 27.00it/s]
Loading safetensors checkpoint shards:  65% Completed | 662/1024 [00:17<00:12, 28.26it/s]
Loading safetensors checkpoint shards:  65% Completed | 666/1024 [00:17<00:11, 30.07it/s]
Loading safetensors checkpoint shards:  65% Completed | 670/1024 [00:17<00:11, 31.51it/s]
Loading safetensors checkpoint shards:  66% Completed | 674/1024 [00:17<00:10, 32.85it/s]
Loading safetensors checkpoint shards:  66% Completed | 678/1024 [00:17<00:10, 32.74it/s]
Loading safetensors checkpoint shards:  67% Completed | 682/1024 [00:17<00:10, 33.34it/s]
Loading safetensors checkpoint shards:  67% Completed | 686/1024 [00:17<00:09, 34.20it/s]
Loading safetensors checkpoint shards:  67% Completed | 690/1024 [00:17<00:09, 34.74it/s]
Loading safetensors checkpoint shards:  68% Completed | 695/1024 [00:18<00:08, 36.68it/s]
Loading safetensors checkpoint shards:  68% Completed | 699/1024 [00:18<00:08, 36.53it/s]
Loading safetensors checkpoint shards:  69% Completed | 703/1024 [00:18<00:09, 35.01it/s]
Loading safetensors checkpoint shards:  69% Completed | 707/1024 [00:18<00:08, 35.41it/s]
Loading safetensors checkpoint shards:  69% Completed | 711/1024 [00:18<00:08, 35.88it/s]
Loading safetensors checkpoint shards:  70% Completed | 715/1024 [00:18<00:08, 36.50it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:18<00:08, 35.63it/s]
Loading safetensors checkpoint shards:  71% Completed | 723/1024 [00:18<00:08, 36.14it/s]
Loading safetensors checkpoint shards:  71% Completed | 727/1024 [00:18<00:08, 36.60it/s]
Loading safetensors checkpoint shards:  71% Completed | 731/1024 [00:19<00:07, 36.63it/s]
Loading safetensors checkpoint shards:  72% Completed | 735/1024 [00:19<00:08, 35.59it/s]
Loading safetensors checkpoint shards:  72% Completed | 739/1024 [00:19<00:07, 35.91it/s]
Loading safetensors checkpoint shards:  73% Completed | 743/1024 [00:19<00:07, 36.04it/s]
Loading safetensors checkpoint shards:  73% Completed | 747/1024 [00:19<00:07, 35.27it/s]
Loading safetensors checkpoint shards:  73% Completed | 751/1024 [00:19<00:07, 35.22it/s]
Loading safetensors checkpoint shards:  74% Completed | 755/1024 [00:19<00:07, 35.90it/s]
Loading safetensors checkpoint shards:  74% Completed | 759/1024 [00:19<00:07, 35.94it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:19<00:07, 35.52it/s]
Loading safetensors checkpoint shards:  75% Completed | 767/1024 [00:20<00:07, 35.30it/s]
Loading safetensors checkpoint shards:  75% Completed | 771/1024 [00:20<00:07, 35.41it/s]
Loading safetensors checkpoint shards:  76% Completed | 775/1024 [00:20<00:07, 35.52it/s]
Loading safetensors checkpoint shards:  76% Completed | 779/1024 [00:20<00:06, 35.75it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:20<00:06, 36.33it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:20<00:06, 35.86it/s]
Loading safetensors checkpoint shards:  77% Completed | 791/1024 [00:20<00:06, 36.83it/s]
Loading safetensors checkpoint shards:  78% Completed | 796/1024 [00:20<00:06, 37.96it/s]
Loading safetensors checkpoint shards:  78% Completed | 800/1024 [00:20<00:05, 38.24it/s]
Loading safetensors checkpoint shards:  79% Completed | 805/1024 [00:21<00:05, 39.44it/s]
Loading safetensors checkpoint shards:  79% Completed | 809/1024 [00:21<00:05, 39.33it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:21<00:05, 38.89it/s]
Loading safetensors checkpoint shards:  80% Completed | 817/1024 [00:21<00:05, 37.40it/s]
Loading safetensors checkpoint shards:  80% Completed | 821/1024 [00:21<00:05, 36.07it/s]
Loading safetensors checkpoint shards:  81% Completed | 826/1024 [00:21<00:05, 38.05it/s]
Loading safetensors checkpoint shards:  81% Completed | 830/1024 [00:21<00:05, 37.43it/s]
Loading safetensors checkpoint shards:  81% Completed | 834/1024 [00:21<00:05, 37.85it/s]
Loading safetensors checkpoint shards:  82% Completed | 838/1024 [00:21<00:04, 38.19it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:22<00:04, 38.15it/s]
Loading safetensors checkpoint shards:  83% Completed | 846/1024 [00:22<00:04, 37.07it/s]
Loading safetensors checkpoint shards:  83% Completed | 850/1024 [00:22<00:04, 37.18it/s]
Loading safetensors checkpoint shards:  83% Completed | 854/1024 [00:22<00:04, 36.96it/s]
Loading safetensors checkpoint shards:  84% Completed | 858/1024 [00:22<00:04, 35.61it/s]
Loading safetensors checkpoint shards:  84% Completed | 862/1024 [00:22<00:04, 35.97it/s]
Loading safetensors checkpoint shards:  85% Completed | 867/1024 [00:22<00:04, 37.72it/s]
Loading safetensors checkpoint shards:  85% Completed | 872/1024 [00:22<00:03, 39.24it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:23<00:03, 37.64it/s]
Loading safetensors checkpoint shards:  86% Completed | 881/1024 [00:23<00:03, 37.96it/s]
Loading safetensors checkpoint shards:  86% Completed | 885/1024 [00:23<00:03, 37.90it/s]
Loading safetensors checkpoint shards:  87% Completed | 889/1024 [00:23<00:03, 36.63it/s]
Loading safetensors checkpoint shards:  87% Completed | 893/1024 [00:23<00:03, 37.05it/s]
Loading safetensors checkpoint shards:  88% Completed | 897/1024 [00:23<00:03, 37.08it/s]
Loading safetensors checkpoint shards:  88% Completed | 901/1024 [00:23<00:03, 36.72it/s]
Loading safetensors checkpoint shards:  88% Completed | 905/1024 [00:23<00:03, 36.54it/s]
Loading safetensors checkpoint shards:  89% Completed | 909/1024 [00:23<00:03, 36.39it/s]
Loading safetensors checkpoint shards:  89% Completed | 913/1024 [00:24<00:03, 35.36it/s]
Loading safetensors checkpoint shards:  90% Completed | 918/1024 [00:24<00:02, 37.66it/s]
Loading safetensors checkpoint shards:  90% Completed | 922/1024 [00:24<00:02, 37.77it/s]
Loading safetensors checkpoint shards:  90% Completed | 926/1024 [00:24<00:02, 38.13it/s]
Loading safetensors checkpoint shards:  91% Completed | 930/1024 [00:24<00:02, 36.98it/s]
Loading safetensors checkpoint shards:  91% Completed | 934/1024 [00:24<00:02, 37.47it/s]
Loading safetensors checkpoint shards:  92% Completed | 938/1024 [00:24<00:02, 37.83it/s]
Loading safetensors checkpoint shards:  92% Completed | 942/1024 [00:24<00:02, 37.91it/s]
Loading safetensors checkpoint shards:  92% Completed | 946/1024 [00:25<00:06, 11.21it/s]
Loading safetensors checkpoint shards:  93% Completed | 950/1024 [00:25<00:05, 14.23it/s]
Loading safetensors checkpoint shards:  93% Completed | 954/1024 [00:25<00:03, 17.55it/s]
Loading safetensors checkpoint shards:  94% Completed | 959/1024 [00:26<00:02, 21.95it/s]
Loading safetensors checkpoint shards:  94% Completed | 964/1024 [00:26<00:02, 25.85it/s]
Loading safetensors checkpoint shards:  95% Completed | 970/1024 [00:26<00:01, 31.85it/s]
Loading safetensors checkpoint shards:  95% Completed | 975/1024 [00:26<00:01, 34.95it/s]
Loading safetensors checkpoint shards:  96% Completed | 980/1024 [00:26<00:01, 36.75it/s]
Loading safetensors checkpoint shards:  98% Completed | 1003/1024 [00:26<00:00, 79.15it/s]
Loading safetensors checkpoint shards:  99% Completed | 1014/1024 [00:26<00:00, 85.74it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:26<00:00, 89.25it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:26<00:00, 38.14it/s]

[2025-09-13 07:17:37 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:17:37 TP3] KV Cache is allocated. #tokens: 620145, KV size: 40.59 GB
[2025-09-13 07:17:37 TP7] KV Cache is allocated. #tokens: 620145, KV size: 40.59 GB
[2025-09-13 07:17:37 TP5] KV Cache is allocated. #tokens: 620145, KV size: 40.59 GB
[2025-09-13 07:17:37 TP0] KV Cache is allocated. #tokens: 620145, KV size: 40.59 GB
[2025-09-13 07:17:37 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:17:37 TP2] KV Cache is allocated. #tokens: 620145, KV size: 40.59 GB
[2025-09-13 07:17:37 TP1] KV Cache is allocated. #tokens: 620145, KV size: 40.59 GB
[2025-09-13 07:17:37 TP6] KV Cache is allocated. #tokens: 620145, KV size: 40.59 GB
[2025-09-13 07:17:37 TP4] KV Cache is allocated. #tokens: 620145, KV size: 40.59 GB
[2025-09-13 07:17:37 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:17:37 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.52 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:17:38 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:17:38 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:17:38 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:17:38 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:17:38 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:17:39 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:17:39 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:17:39 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:17:39 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25729.62it/s]
[2025-09-13 07:17:39 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:17:39 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26856.79it/s]
[2025-09-13 07:17:40 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:17:40 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28346.01it/s]
[2025-09-13 07:17:40 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:17:40 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28403.18it/s]
[2025-09-13 07:17:41 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:17:41 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 29429.51it/s]
[2025-09-13 07:17:41 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.25 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.17it/s]
[2025-09-13 07:17:45 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:17:45 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:17:45 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:17:45 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:17:45 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:17:45 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:17:45 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:17:45 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:17:45 TP0] Capture cuda graph end. Time elapsed: 7.64 s. mem usage=0.33 GB. avail mem=17.24 GB.
[2025-09-13 07:17:45 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:17:45 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:17:45 TP0] Init torch distributed begin.
[2025-09-13 07:17:45 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:17:45 TP0] Load weight begin. avail mem=17.24 GB
[2025-09-13 07:17:45 TP0] Detected fp8 checkpoint.
[2025-09-13 07:17:45 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 177.88it/s]
Loading safetensors checkpoint shards:   4% Completed | 41/1024 [00:00<00:04, 206.69it/s]
Loading safetensors checkpoint shards:  10% Completed | 105/1024 [00:00<00:02, 403.00it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:00<00:01, 486.95it/s]
Loading safetensors checkpoint shards:  22% Completed | 229/1024 [00:00<00:01, 533.06it/s]
Loading safetensors checkpoint shards:  28% Completed | 291/1024 [00:00<00:01, 561.52it/s]
Loading safetensors checkpoint shards:  34% Completed | 353/1024 [00:00<00:01, 578.77it/s]
Loading safetensors checkpoint shards:  41% Completed | 416/1024 [00:00<00:01, 593.92it/s]
Loading safetensors checkpoint shards:  47% Completed | 478/1024 [00:00<00:00, 601.17it/s]
Loading safetensors checkpoint shards:  53% Completed | 539/1024 [00:01<00:00, 520.72it/s]
Loading safetensors checkpoint shards:  58% Completed | 593/1024 [00:01<00:00, 468.88it/s]
Loading safetensors checkpoint shards:  64% Completed | 655/1024 [00:01<00:00, 506.34it/s]
Loading safetensors checkpoint shards:  70% Completed | 716/1024 [00:01<00:00, 532.62it/s]
Loading safetensors checkpoint shards:  76% Completed | 776/1024 [00:01<00:00, 550.00it/s]
Loading safetensors checkpoint shards:  82% Completed | 836/1024 [00:01<00:00, 563.74it/s]
Loading safetensors checkpoint shards:  88% Completed | 896/1024 [00:01<00:00, 572.06it/s]
Loading safetensors checkpoint shards:  93% Completed | 954/1024 [00:01<00:00, 571.52it/s]
Loading safetensors checkpoint shards:  99% Completed | 1012/1024 [00:02<00:00, 380.64it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 483.07it/s]

[2025-09-13 07:17:47 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.26 GB, mem usage=1.98 GB.
[2025-09-13 07:17:47 TP0] KV Cache is allocated. #tokens: 620145, KV size: 0.67 GB
[2025-09-13 07:17:47 TP2] KV Cache is allocated. #tokens: 620145, KV size: 0.67 GB
[2025-09-13 07:17:47 TP4] KV Cache is allocated. #tokens: 620145, KV size: 0.67 GB
[2025-09-13 07:17:47 TP0] Memory pool end. avail mem=14.59 GB
[2025-09-13 07:17:47 TP6] KV Cache is allocated. #tokens: 620145, KV size: 0.67 GB
[2025-09-13 07:17:47 TP5] KV Cache is allocated. #tokens: 620145, KV size: 0.67 GB
[2025-09-13 07:17:47 TP1] KV Cache is allocated. #tokens: 620145, KV size: 0.67 GB
[2025-09-13 07:17:47 TP7] KV Cache is allocated. #tokens: 620145, KV size: 0.67 GB
[2025-09-13 07:17:47 TP3] KV Cache is allocated. #tokens: 620145, KV size: 0.67 GB
[2025-09-13 07:17:48 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:17:48 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:17:48 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:17:48 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:17:48 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.02 GB
[2025-09-13 07:17:48 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:17:48 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.22 GB
[2025-09-13 07:17:48 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
Capturing batches (bs=1 avail_mem=14.79 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:01<00:00,  6.38it/s][2025-09-13 07:17:51 TP2] Registering 96 cuda graph addresses
[2025-09-13 07:17:51 TP1] Registering 96 cuda graph addresses
[2025-09-13 07:17:51 TP4] Registering 96 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.79 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:02<00:00,  3.20it/s]
[2025-09-13 07:17:51 TP0] Registering 96 cuda graph addresses
[2025-09-13 07:17:51 TP6] Registering 96 cuda graph addresses
[2025-09-13 07:17:51 TP7] Registering 96 cuda graph addresses
[2025-09-13 07:17:51 TP3] Registering 96 cuda graph addresses
[2025-09-13 07:17:51 TP5] Registering 96 cuda graph addresses
[2025-09-13 07:17:51 TP6] Capture draft cuda graph end. Time elapsed: 3.21 s. mem usage=0.23 GB. avail mem=14.75 GB.
[2025-09-13 07:17:51 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.75 GB
[2025-09-13 07:17:51 TP2] Capture draft cuda graph end. Time elapsed: 3.21 s. mem usage=0.23 GB. avail mem=14.75 GB.
[2025-09-13 07:17:51 TP0] Capture draft cuda graph end. Time elapsed: 3.17 s. mem usage=0.23 GB. avail mem=14.79 GB.
[2025-09-13 07:17:51 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 07:17:51 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.75 GB
[2025-09-13 07:17:51 TP1] Capture draft cuda graph end. Time elapsed: 3.18 s. mem usage=0.23 GB. avail mem=14.75 GB.
[2025-09-13 07:17:51 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.75 GB
[2025-09-13 07:17:51 TP7] Capture draft cuda graph end. Time elapsed: 3.16 s. mem usage=0.23 GB. avail mem=14.98 GB.
[2025-09-13 07:17:51 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:17:51 TP5] Capture draft cuda graph end. Time elapsed: 3.17 s. mem usage=0.23 GB. avail mem=14.75 GB.
[2025-09-13 07:17:51 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.75 GB
[2025-09-13 07:17:51 TP4] Capture draft cuda graph end. Time elapsed: 3.21 s. mem usage=0.23 GB. avail mem=14.75 GB.
[2025-09-13 07:17:51 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.75 GB
[2025-09-13 07:17:51 TP3] Capture draft cuda graph end. Time elapsed: 3.16 s. mem usage=0.23 GB. avail mem=14.75 GB.
[2025-09-13 07:17:51 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.75 GB
Capturing batches (bs=1 avail_mem=14.60 GB):  12%|██████████▊                                                                           | 1/8 [00:00<00:01,  4.64it/s][2025-09-13 07:17:52 TP2] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.60 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 27.66it/s][2025-09-13 07:17:52 TP1] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.60 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 23.31it/s]
[2025-09-13 07:17:52 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:17:52 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:17:52 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:17:52 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:17:52 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:17:52 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:17:52 TP1] Capture draft extend cuda graph end. Time elapsed: 1.02 s. mem usage=0.19 GB. avail mem=14.56 GB.
[2025-09-13 07:17:52 TP4] Capture draft extend cuda graph end. Time elapsed: 1.02 s. mem usage=0.19 GB. avail mem=14.56 GB.
[2025-09-13 07:17:52 TP6] Capture draft extend cuda graph end. Time elapsed: 1.03 s. mem usage=0.19 GB. avail mem=14.56 GB.
[2025-09-13 07:17:52 TP3] Capture draft extend cuda graph end. Time elapsed: 1.02 s. mem usage=0.19 GB. avail mem=14.56 GB.
[2025-09-13 07:17:52 TP0] Capture draft extend cuda graph end. Time elapsed: 1.02 s. mem usage=0.19 GB. avail mem=14.60 GB.
[2025-09-13 07:17:52 TP5] Capture draft extend cuda graph end. Time elapsed: 1.02 s. mem usage=0.19 GB. avail mem=14.56 GB.
[2025-09-13 07:17:52 TP7] Capture draft extend cuda graph end. Time elapsed: 1.02 s. mem usage=0.19 GB. avail mem=14.80 GB.
[2025-09-13 07:17:52 TP0] max_total_num_tokens=620145, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.60 GB
[2025-09-13 07:17:52 TP2] Capture draft extend cuda graph end. Time elapsed: 1.03 s. mem usage=0.19 GB. avail mem=14.56 GB.
[2025-09-13 07:17:52] INFO:     Started server process [255926]
[2025-09-13 07:17:52] INFO:     Waiting for application startup.
[2025-09-13 07:17:52] INFO:     Application startup complete.
[2025-09-13 07:17:52] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:17:53] INFO:     127.0.0.1:37548 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:17:53 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:17:53 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:17:53 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28795.94it/s]
[2025-09-13 07:17:55] INFO:     127.0.0.1:37564 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:17:55] The server is fired up and ready to roll!
[2025-09-13 07:17:57 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:17:58] INFO:     127.0.0.1:37570 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:17:58] INFO:     127.0.0.1:33988 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:17:58 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:18:00] INFO:     127.0.0.1:33994 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:00] INFO:     127.0.0.1:34006 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:18:00] INFO:     127.0.0.1:34012 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:00] INFO:     127.0.0.1:34024 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:00] INFO:     127.0.0.1:34030 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:00] INFO:     127.0.0.1:34032 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:00] INFO:     127.0.0.1:34042 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:00] INFO:     127.0.0.1:34052 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:00 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:18:00 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:18:00 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:18:00 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:18:00 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:18:00 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:18:00 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:18:00 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:18:00 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:18:00 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:18:01 TP0] Decode batch. #running-req: 8, #token: 14523, token usage: 0.02, accept len: 2.86, cuda graph: True, gen throughput (token/s): 67.19, #queue-req: 0, 
[2025-09-13 07:18:02 TP0] Decode batch. #running-req: 8, #token: 15655, token usage: 0.03, accept len: 3.54, cuda graph: True, gen throughput (token/s): 939.66, #queue-req: 0, 
[2025-09-13 07:18:04 TP0] Decode batch. #running-req: 8, #token: 16939, token usage: 0.03, accept len: 4.01, cuda graph: True, gen throughput (token/s): 1054.48, #queue-req: 0, 
 62%|█████████████████████████████████████████████████████████████████████████████████▉                                                 | 5/8 [00:04<00:02,  1.39it/s][2025-09-13 07:18:05 TP0] Decode batch. #running-req: 2, #token: 2001, token usage: 0.00, accept len: 3.80, cuda graph: True, gen throughput (token/s): 771.91, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.41it/s]
[2025-09-13 07:18:05] INFO:     127.0.0.1:34060 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  5.68      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4083      
Request throughput (req/s):              1.41      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         721.24    
Total token throughput (tok/s):          721.24    
Concurrency:                             6.81      
Accept length:                           3.59      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   4831.43   
Median E2E Latency (ms):                 4714.93   
---------------Time to First Token----------------
Mean TTFT (ms):                          616.22    
Median TTFT (ms):                        732.61    
P99 TTFT (ms):                           733.06    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           8.25      
Median ITL (ms):                         5.91      
P95 ITL (ms):                            15.39     
P99 ITL (ms):                            30.47     
Max ITL (ms):                            650.80    
==================================================
[2025-09-13 07:18:05] INFO:     127.0.0.1:34074 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:18:05] INFO:     127.0.0.1:34088 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:18:06 TP0] Decode batch. #running-req: 1, #token: 4671, token usage: 0.01, accept len: 3.40, cuda graph: True, gen throughput (token/s): 238.01, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:18:07] INFO:     127.0.0.1:34094 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:07] INFO:     127.0.0.1:34104 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:18:07] INFO:     127.0.0.1:34114 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:07] INFO:     127.0.0.1:34126 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:07] INFO:     127.0.0.1:34138 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:07] INFO:     127.0.0.1:34150 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:07] INFO:     127.0.0.1:34152 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:07] INFO:     127.0.0.1:34164 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:07 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:18:08 TP0] Decode batch. #running-req: 8, #token: 14687, token usage: 0.02, accept len: 3.01, cuda graph: True, gen throughput (token/s): 337.43, #queue-req: 0, 
[2025-09-13 07:18:09 TP0] Decode batch. #running-req: 8, #token: 15844, token usage: 0.03, accept len: 3.62, cuda graph: True, gen throughput (token/s): 947.46, #queue-req: 0, 
[2025-09-13 07:18:10 TP0] Decode batch. #running-req: 8, #token: 17149, token usage: 0.03, accept len: 4.08, cuda graph: True, gen throughput (token/s): 1062.44, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:03<00:59,  3.95s/it][2025-09-13 07:18:11] INFO:     127.0.0.1:34272 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:11 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:24,  1.76s/it][2025-09-13 07:18:11] INFO:     127.0.0.1:34276 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:11] INFO:     127.0.0.1:34282 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:11 TP0] Prefill batch. #new-seq: 2, #new-token: 2409, #cached-token: 1752, token usage: 0.01, #running-req: 6, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:04<00:09,  1.31it/s][2025-09-13 07:18:11] INFO:     127.0.0.1:34284 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:11 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:04<00:07,  1.49it/s][2025-09-13 07:18:12] INFO:     127.0.0.1:34288 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:12 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.86it/s][2025-09-13 07:18:12] INFO:     127.0.0.1:34300 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:12 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:18:12 TP0] Decode batch. #running-req: 8, #token: 9038, token usage: 0.01, accept len: 3.53, cuda graph: True, gen throughput (token/s): 569.85, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:05<00:04,  1.81it/s][2025-09-13 07:18:13] INFO:     127.0.0.1:34304 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:05,  1.55it/s][2025-09-13 07:18:13] INFO:     127.0.0.1:34318 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:18:14 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:18:14 TP0] Decode batch. #running-req: 8, #token: 14799, token usage: 0.02, accept len: 3.38, cuda graph: True, gen throughput (token/s): 699.07, #queue-req: 0, 
[2025-09-13 07:18:15 TP0] Decode batch. #running-req: 8, #token: 16098, token usage: 0.03, accept len: 4.06, cuda graph: True, gen throughput (token/s): 1104.27, #queue-req: 0, 
 69%|████████████████████████████████████████████████████████████████████████████████████████▋                                        | 11/16 [00:09<00:03,  1.54it/s][2025-09-13 07:18:16 TP0] Decode batch. #running-req: 5, #token: 11980, token usage: 0.02, accept len: 4.40, cuda graph: True, gen throughput (token/s): 956.27, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.57it/s]
[2025-09-13 07:18:17] INFO:     127.0.0.1:34330 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  10.17     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8101      
Request throughput (req/s):              1.57      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         805.13    
Total token throughput (tok/s):          805.13    
Concurrency:                             7.44      
Accept length:                           3.67      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   4730.59   
Median E2E Latency (ms):                 4443.75   
---------------Time to First Token----------------
Mean TTFT (ms):                          237.45    
Median TTFT (ms):                        234.60    
P99 TTFT (ms):                           304.85    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           8.79      
Median ITL (ms):                         5.56      
P95 ITL (ms):                            27.65     
P99 ITL (ms):                            38.65     
Max ITL (ms):                            265.39    
==================================================
[2025-09-13 07:18:17] INFO:     127.0.0.1:34346 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=23: batch_size=8, steps=5, topk=1, num_draft_tokens=6, speed=121.15 token/s, step_time=30.31 ms
Start i=24: batch_size=8, steps=5, topk=2, num_draft_tokens=4
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 5 --speculative-eagle-topk 2 --speculative-num-draft-tokens 4 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:18:28.257000 261042 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:18:28.257000 261042 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:18:28] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=1048560523, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=5, speculative_eagle_topk=2, speculative_num_draft_tokens=4, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:18:29] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:18:37.452000 261276 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:18:37.452000 261276 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:18:37.629000 261275 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:18:37.629000 261275 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:18:37.678000 261282 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:18:37.678000 261282 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:18:37.743000 261280 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:18:37.743000 261280 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:18:37.743000 261277 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:18:37.743000 261277 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:18:37.771000 261281 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:18:37.771000 261281 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:18:37.798000 261279 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:18:37.798000 261279 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:18:37.827000 261278 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:18:37.827000 261278 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:18:37.834000 261274 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:18:37.834000 261274 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:18:38 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:18:38 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:18:38 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:18:39 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:18:43 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:18:44 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:18:44 TP0] Detected fp8 checkpoint.
[2025-09-13 07:18:44 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 25/1024 [00:00<00:04, 231.47it/s]
Loading safetensors checkpoint shards:   5% Completed | 49/1024 [00:00<00:16, 60.43it/s]
Loading safetensors checkpoint shards:   6% Completed | 61/1024 [00:01<00:18, 53.20it/s]
Loading safetensors checkpoint shards:   7% Completed | 70/1024 [00:01<00:18, 50.73it/s]
Loading safetensors checkpoint shards:   8% Completed | 77/1024 [00:01<00:20, 46.72it/s]
Loading safetensors checkpoint shards:   8% Completed | 83/1024 [00:01<00:20, 46.68it/s]
Loading safetensors checkpoint shards:   9% Completed | 89/1024 [00:01<00:20, 45.53it/s]
Loading safetensors checkpoint shards:   9% Completed | 94/1024 [00:01<00:21, 43.35it/s]
Loading safetensors checkpoint shards:  10% Completed | 99/1024 [00:01<00:21, 43.83it/s]
Loading safetensors checkpoint shards:  10% Completed | 105/1024 [00:02<00:19, 46.52it/s]
Loading safetensors checkpoint shards:  11% Completed | 110/1024 [00:02<00:19, 45.95it/s]
Loading safetensors checkpoint shards:  11% Completed | 116/1024 [00:02<00:19, 46.63it/s]
Loading safetensors checkpoint shards:  12% Completed | 121/1024 [00:02<00:38, 23.44it/s]
Loading safetensors checkpoint shards:  12% Completed | 127/1024 [00:02<00:32, 27.91it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:03<00:29, 30.03it/s]
Loading safetensors checkpoint shards:  13% Completed | 137/1024 [00:03<00:26, 33.75it/s]
Loading safetensors checkpoint shards:  14% Completed | 142/1024 [00:03<00:23, 36.91it/s]
Loading safetensors checkpoint shards:  14% Completed | 147/1024 [00:03<00:22, 38.22it/s]
Loading safetensors checkpoint shards:  15% Completed | 152/1024 [00:03<00:22, 39.56it/s]
Loading safetensors checkpoint shards:  15% Completed | 157/1024 [00:03<00:21, 40.24it/s]
Loading safetensors checkpoint shards:  16% Completed | 162/1024 [00:03<00:20, 42.24it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:03<00:21, 40.81it/s]
Loading safetensors checkpoint shards:  17% Completed | 173/1024 [00:03<00:19, 43.30it/s]
Loading safetensors checkpoint shards:  17% Completed | 178/1024 [00:04<00:19, 43.03it/s]
Loading safetensors checkpoint shards:  18% Completed | 183/1024 [00:04<00:19, 43.57it/s]
Loading safetensors checkpoint shards:  18% Completed | 188/1024 [00:04<00:19, 43.10it/s]
Loading safetensors checkpoint shards:  19% Completed | 194/1024 [00:04<00:18, 45.03it/s]
Loading safetensors checkpoint shards:  19% Completed | 199/1024 [00:04<00:18, 44.81it/s]
Loading safetensors checkpoint shards:  20% Completed | 204/1024 [00:04<00:18, 44.80it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:04<00:18, 44.24it/s]
Loading safetensors checkpoint shards:  21% Completed | 214/1024 [00:04<00:18, 44.48it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:04<00:17, 44.81it/s]
Loading safetensors checkpoint shards:  22% Completed | 224/1024 [00:05<00:17, 45.00it/s]
Loading safetensors checkpoint shards:  22% Completed | 229/1024 [00:05<00:17, 44.98it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:05<00:18, 43.75it/s]
Loading safetensors checkpoint shards:  23% Completed | 239/1024 [00:05<00:17, 45.32it/s]
Loading safetensors checkpoint shards:  24% Completed | 244/1024 [00:05<00:17, 45.06it/s]
Loading safetensors checkpoint shards:  24% Completed | 250/1024 [00:05<00:16, 48.15it/s]
Loading safetensors checkpoint shards:  25% Completed | 255/1024 [00:05<00:16, 45.41it/s]
Loading safetensors checkpoint shards:  25% Completed | 261/1024 [00:05<00:16, 46.57it/s]
Loading safetensors checkpoint shards:  26% Completed | 266/1024 [00:06<00:16, 46.29it/s]
Loading safetensors checkpoint shards:  27% Completed | 272/1024 [00:06<00:15, 48.24it/s]
Loading safetensors checkpoint shards:  27% Completed | 277/1024 [00:06<00:16, 45.76it/s]
Loading safetensors checkpoint shards:  28% Completed | 283/1024 [00:06<00:15, 47.28it/s]
Loading safetensors checkpoint shards:  28% Completed | 288/1024 [00:06<00:15, 46.95it/s]
Loading safetensors checkpoint shards:  29% Completed | 293/1024 [00:06<00:15, 47.29it/s]
Loading safetensors checkpoint shards:  29% Completed | 298/1024 [00:06<00:15, 46.35it/s]
Loading safetensors checkpoint shards:  30% Completed | 303/1024 [00:06<00:15, 47.23it/s]
Loading safetensors checkpoint shards:  30% Completed | 309/1024 [00:06<00:14, 48.90it/s]
Loading safetensors checkpoint shards:  31% Completed | 315/1024 [00:07<00:13, 51.38it/s]
Loading safetensors checkpoint shards:  31% Completed | 321/1024 [00:07<00:14, 48.18it/s]
Loading safetensors checkpoint shards:  32% Completed | 326/1024 [00:07<00:29, 24.03it/s]
Loading safetensors checkpoint shards:  32% Completed | 331/1024 [00:07<00:25, 27.58it/s]
Loading safetensors checkpoint shards:  33% Completed | 336/1024 [00:07<00:22, 30.78it/s]
Loading safetensors checkpoint shards:  33% Completed | 342/1024 [00:07<00:19, 35.41it/s]
Loading safetensors checkpoint shards:  34% Completed | 347/1024 [00:08<00:18, 35.93it/s]
Loading safetensors checkpoint shards:  34% Completed | 352/1024 [00:08<00:17, 38.82it/s]
Loading safetensors checkpoint shards:  35% Completed | 357/1024 [00:08<00:17, 39.19it/s]
Loading safetensors checkpoint shards:  35% Completed | 362/1024 [00:08<00:16, 41.21it/s]
Loading safetensors checkpoint shards:  36% Completed | 367/1024 [00:08<00:16, 39.69it/s]
Loading safetensors checkpoint shards:  36% Completed | 372/1024 [00:08<00:16, 40.56it/s]
Loading safetensors checkpoint shards:  37% Completed | 377/1024 [00:08<00:16, 38.33it/s]
Loading safetensors checkpoint shards:  37% Completed | 381/1024 [00:08<00:16, 38.29it/s]
Loading safetensors checkpoint shards:  38% Completed | 386/1024 [00:09<00:15, 40.73it/s]
Loading safetensors checkpoint shards:  38% Completed | 391/1024 [00:09<00:15, 40.99it/s]
Loading safetensors checkpoint shards:  39% Completed | 397/1024 [00:09<00:13, 44.87it/s]
Loading safetensors checkpoint shards:  39% Completed | 402/1024 [00:09<00:13, 45.14it/s]
Loading safetensors checkpoint shards:  40% Completed | 407/1024 [00:09<00:13, 44.66it/s]
Loading safetensors checkpoint shards:  40% Completed | 412/1024 [00:09<00:13, 45.53it/s]
Loading safetensors checkpoint shards:  41% Completed | 417/1024 [00:09<00:12, 46.72it/s]
Loading safetensors checkpoint shards:  41% Completed | 422/1024 [00:09<00:13, 45.68it/s]
Loading safetensors checkpoint shards:  42% Completed | 429/1024 [00:09<00:11, 50.66it/s]
Loading safetensors checkpoint shards:  43% Completed | 436/1024 [00:10<00:10, 55.47it/s]
Loading safetensors checkpoint shards:  43% Completed | 445/1024 [00:10<00:09, 63.11it/s]
Loading safetensors checkpoint shards:  44% Completed | 454/1024 [00:10<00:08, 69.25it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:10<00:07, 71.19it/s]
Loading safetensors checkpoint shards:  46% Completed | 473/1024 [00:10<00:07, 77.10it/s]
Loading safetensors checkpoint shards:  47% Completed | 481/1024 [00:10<00:07, 76.07it/s]
Loading safetensors checkpoint shards:  48% Completed | 489/1024 [00:10<00:07, 75.54it/s]
Loading safetensors checkpoint shards:  49% Completed | 498/1024 [00:10<00:06, 77.94it/s]
Loading safetensors checkpoint shards:  49% Completed | 506/1024 [00:10<00:06, 74.19it/s]
Loading safetensors checkpoint shards:  50% Completed | 514/1024 [00:11<00:07, 67.74it/s]
Loading safetensors checkpoint shards:  51% Completed | 521/1024 [00:11<00:07, 63.88it/s]
Loading safetensors checkpoint shards:  52% Completed | 528/1024 [00:11<00:18, 27.28it/s]
Loading safetensors checkpoint shards:  52% Completed | 534/1024 [00:11<00:15, 31.23it/s]
Loading safetensors checkpoint shards:  53% Completed | 542/1024 [00:12<00:12, 38.34it/s]
Loading safetensors checkpoint shards:  54% Completed | 550/1024 [00:12<00:10, 44.82it/s]
Loading safetensors checkpoint shards:  54% Completed | 557/1024 [00:12<00:09, 48.68it/s]
Loading safetensors checkpoint shards:  55% Completed | 564/1024 [00:12<00:08, 52.44it/s]
Loading safetensors checkpoint shards:  56% Completed | 571/1024 [00:12<00:08, 54.22it/s]
Loading safetensors checkpoint shards:  56% Completed | 578/1024 [00:12<00:08, 53.38it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:12<00:07, 57.17it/s]
Loading safetensors checkpoint shards:  58% Completed | 592/1024 [00:12<00:07, 54.42it/s]
Loading safetensors checkpoint shards:  58% Completed | 599/1024 [00:13<00:07, 56.52it/s]
Loading safetensors checkpoint shards:  59% Completed | 605/1024 [00:13<00:07, 54.72it/s]
Loading safetensors checkpoint shards:  60% Completed | 611/1024 [00:13<00:07, 52.24it/s]
Loading safetensors checkpoint shards:  60% Completed | 617/1024 [00:13<00:07, 54.18it/s]
Loading safetensors checkpoint shards:  61% Completed | 623/1024 [00:13<00:07, 55.30it/s]
Loading safetensors checkpoint shards:  61% Completed | 629/1024 [00:13<00:07, 56.28it/s]
Loading safetensors checkpoint shards:  62% Completed | 636/1024 [00:13<00:06, 58.42it/s]
Loading safetensors checkpoint shards:  63% Completed | 643/1024 [00:13<00:06, 60.86it/s]
Loading safetensors checkpoint shards:  64% Completed | 651/1024 [00:13<00:05, 64.75it/s]
Loading safetensors checkpoint shards:  64% Completed | 658/1024 [00:14<00:05, 63.98it/s]
Loading safetensors checkpoint shards:  65% Completed | 665/1024 [00:14<00:06, 58.02it/s]
Loading safetensors checkpoint shards:  66% Completed | 672/1024 [00:14<00:05, 60.97it/s]
Loading safetensors checkpoint shards:  66% Completed | 679/1024 [00:14<00:05, 63.38it/s]
Loading safetensors checkpoint shards:  67% Completed | 686/1024 [00:14<00:05, 64.53it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:14<00:04, 67.57it/s]
Loading safetensors checkpoint shards:  68% Completed | 701/1024 [00:14<00:05, 64.09it/s]
Loading safetensors checkpoint shards:  69% Completed | 708/1024 [00:14<00:05, 62.37it/s]
Loading safetensors checkpoint shards:  70% Completed | 715/1024 [00:14<00:05, 57.28it/s]
Loading safetensors checkpoint shards:  71% Completed | 722/1024 [00:15<00:05, 59.71it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:15<00:11, 24.97it/s]
Loading safetensors checkpoint shards:  72% Completed | 736/1024 [00:15<00:09, 30.76it/s]
Loading safetensors checkpoint shards:  73% Completed | 743/1024 [00:15<00:07, 36.12it/s]
Loading safetensors checkpoint shards:  73% Completed | 749/1024 [00:16<00:07, 39.07it/s]
Loading safetensors checkpoint shards:  74% Completed | 756/1024 [00:16<00:06, 44.28it/s]
Loading safetensors checkpoint shards:  75% Completed | 764/1024 [00:16<00:05, 50.72it/s]
Loading safetensors checkpoint shards:  75% Completed | 771/1024 [00:16<00:04, 50.79it/s]
Loading safetensors checkpoint shards:  76% Completed | 777/1024 [00:16<00:05, 48.57it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:16<00:04, 49.16it/s]
Loading safetensors checkpoint shards:  77% Completed | 789/1024 [00:16<00:04, 47.84it/s]
Loading safetensors checkpoint shards:  78% Completed | 795/1024 [00:16<00:04, 49.14it/s]
Loading safetensors checkpoint shards:  78% Completed | 801/1024 [00:17<00:04, 48.63it/s]
Loading safetensors checkpoint shards:  79% Completed | 806/1024 [00:17<00:04, 45.57it/s]
Loading safetensors checkpoint shards:  79% Completed | 811/1024 [00:17<00:05, 37.94it/s]
Loading safetensors checkpoint shards:  80% Completed | 816/1024 [00:17<00:06, 33.41it/s]
Loading safetensors checkpoint shards:  80% Completed | 820/1024 [00:17<00:06, 29.21it/s]
Loading safetensors checkpoint shards:  80% Completed | 824/1024 [00:17<00:06, 28.89it/s]
Loading safetensors checkpoint shards:  81% Completed | 828/1024 [00:18<00:07, 26.78it/s]
Loading safetensors checkpoint shards:  81% Completed | 832/1024 [00:18<00:06, 28.39it/s]
Loading safetensors checkpoint shards:  82% Completed | 836/1024 [00:18<00:06, 29.86it/s]
Loading safetensors checkpoint shards:  82% Completed | 840/1024 [00:18<00:06, 26.79it/s]
Loading safetensors checkpoint shards:  82% Completed | 843/1024 [00:18<00:06, 26.19it/s]
Loading safetensors checkpoint shards:  83% Completed | 846/1024 [00:18<00:07, 24.77it/s]
Loading safetensors checkpoint shards:  83% Completed | 849/1024 [00:18<00:07, 24.28it/s]
Loading safetensors checkpoint shards:  83% Completed | 852/1024 [00:19<00:07, 23.44it/s]
Loading safetensors checkpoint shards:  84% Completed | 856/1024 [00:19<00:06, 24.81it/s]
Loading safetensors checkpoint shards:  84% Completed | 859/1024 [00:19<00:06, 24.08it/s]
Loading safetensors checkpoint shards:  84% Completed | 862/1024 [00:19<00:06, 25.33it/s]
Loading safetensors checkpoint shards:  85% Completed | 866/1024 [00:19<00:05, 28.62it/s]
Loading safetensors checkpoint shards:  85% Completed | 869/1024 [00:19<00:05, 28.46it/s]
Loading safetensors checkpoint shards:  85% Completed | 872/1024 [00:19<00:05, 27.05it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:19<00:05, 28.29it/s]
Loading safetensors checkpoint shards:  86% Completed | 879/1024 [00:20<00:05, 25.32it/s]
Loading safetensors checkpoint shards:  86% Completed | 882/1024 [00:20<00:05, 25.74it/s]
Loading safetensors checkpoint shards:  86% Completed | 885/1024 [00:20<00:05, 26.78it/s]
Loading safetensors checkpoint shards:  87% Completed | 888/1024 [00:20<00:05, 25.16it/s]
Loading safetensors checkpoint shards:  87% Completed | 891/1024 [00:20<00:05, 24.43it/s]
Loading safetensors checkpoint shards:  87% Completed | 894/1024 [00:20<00:05, 24.42it/s]
Loading safetensors checkpoint shards:  88% Completed | 898/1024 [00:20<00:04, 26.76it/s]
Loading safetensors checkpoint shards:  88% Completed | 901/1024 [00:20<00:05, 24.29it/s]
Loading safetensors checkpoint shards:  88% Completed | 904/1024 [00:21<00:04, 24.95it/s]
Loading safetensors checkpoint shards:  89% Completed | 907/1024 [00:21<00:05, 23.05it/s]
Loading safetensors checkpoint shards:  89% Completed | 910/1024 [00:21<00:04, 22.90it/s]
Loading safetensors checkpoint shards:  89% Completed | 913/1024 [00:21<00:04, 23.01it/s]
Loading safetensors checkpoint shards:  90% Completed | 917/1024 [00:21<00:04, 26.33it/s]
Loading safetensors checkpoint shards:  90% Completed | 920/1024 [00:21<00:03, 27.09it/s]
Loading safetensors checkpoint shards:  90% Completed | 925/1024 [00:21<00:03, 32.27it/s]
Loading safetensors checkpoint shards:  91% Completed | 929/1024 [00:21<00:03, 30.62it/s]
Loading safetensors checkpoint shards:  91% Completed | 933/1024 [00:22<00:02, 30.74it/s]
Loading safetensors checkpoint shards:  92% Completed | 937/1024 [00:22<00:02, 29.60it/s]
Loading safetensors checkpoint shards:  92% Completed | 941/1024 [00:22<00:02, 30.28it/s]
Loading safetensors checkpoint shards:  92% Completed | 945/1024 [00:22<00:02, 28.88it/s]
Loading safetensors checkpoint shards:  93% Completed | 948/1024 [00:22<00:02, 28.96it/s]
Loading safetensors checkpoint shards:  93% Completed | 951/1024 [00:22<00:02, 28.86it/s]
Loading safetensors checkpoint shards:  93% Completed | 954/1024 [00:22<00:02, 29.10it/s]
Loading safetensors checkpoint shards:  93% Completed | 957/1024 [00:22<00:02, 26.63it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:23<00:02, 29.48it/s]
Loading safetensors checkpoint shards:  94% Completed | 966/1024 [00:23<00:01, 31.82it/s]
Loading safetensors checkpoint shards:  95% Completed | 970/1024 [00:23<00:04, 12.22it/s]
Loading safetensors checkpoint shards:  95% Completed | 975/1024 [00:24<00:02, 16.34it/s]
Loading safetensors checkpoint shards:  96% Completed | 979/1024 [00:24<00:02, 18.96it/s]
Loading safetensors checkpoint shards:  96% Completed | 983/1024 [00:24<00:01, 22.12it/s]
Loading safetensors checkpoint shards:  97% Completed | 991/1024 [00:24<00:01, 31.86it/s]
Loading safetensors checkpoint shards:  97% Completed | 998/1024 [00:24<00:00, 39.52it/s]
Loading safetensors checkpoint shards:  98% Completed | 1004/1024 [00:24<00:00, 44.10it/s]
Loading safetensors checkpoint shards:  99% Completed | 1011/1024 [00:24<00:00, 47.91it/s]
Loading safetensors checkpoint shards:  99% Completed | 1017/1024 [00:24<00:00, 47.97it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:24<00:00, 41.03it/s]

[2025-09-13 07:19:11 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:19:12 TP5] KV Cache is allocated. #tokens: 620169, KV size: 40.59 GB
[2025-09-13 07:19:12 TP1] KV Cache is allocated. #tokens: 620169, KV size: 40.59 GB
[2025-09-13 07:19:12 TP0] KV Cache is allocated. #tokens: 620169, KV size: 40.59 GB
[2025-09-13 07:19:12 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:19:12 TP3] KV Cache is allocated. #tokens: 620169, KV size: 40.59 GB
[2025-09-13 07:19:12 TP2] KV Cache is allocated. #tokens: 620169, KV size: 40.59 GB
[2025-09-13 07:19:12 TP6] KV Cache is allocated. #tokens: 620169, KV size: 40.59 GB
[2025-09-13 07:19:12 TP7] KV Cache is allocated. #tokens: 620169, KV size: 40.59 GB
[2025-09-13 07:19:12 TP4] KV Cache is allocated. #tokens: 620169, KV size: 40.59 GB
[2025-09-13 07:19:13 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:19:13 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.53 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:19:14 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:19:14 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
[2025-09-13 07:19:14 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:19:14 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:19:14 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:19:14 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:19:14 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:19:14 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:19:14 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26547.11it/s]
[2025-09-13 07:19:14 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:19:14 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27491.69it/s]
[2025-09-13 07:19:15 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:19:15 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25968.41it/s]
[2025-09-13 07:19:16 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:19:16 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28152.75it/s]
[2025-09-13 07:19:16 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:19:16 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28975.41it/s]
[2025-09-13 07:19:17 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.22 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.97it/s][2025-09-13 07:19:20 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:19:20 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:19:20 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:19:20 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:19:20 TP1] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.22 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.16it/s]
[2025-09-13 07:19:20 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:19:20 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:19:20 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:19:20 TP0] Capture cuda graph end. Time elapsed: 7.59 s. mem usage=0.36 GB. avail mem=17.20 GB.
[2025-09-13 07:19:21 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:19:21 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:19:21 TP0] Init torch distributed begin.
[2025-09-13 07:19:21 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:19:21 TP0] Load weight begin. avail mem=17.20 GB
[2025-09-13 07:19:21 TP0] Detected fp8 checkpoint.
[2025-09-13 07:19:21 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 17/1024 [00:00<00:06, 167.55it/s]
Loading safetensors checkpoint shards:   4% Completed | 39/1024 [00:00<00:05, 196.88it/s]
Loading safetensors checkpoint shards:  10% Completed | 99/1024 [00:00<00:02, 379.10it/s]
Loading safetensors checkpoint shards:  16% Completed | 161/1024 [00:00<00:01, 472.83it/s]
Loading safetensors checkpoint shards:  22% Completed | 222/1024 [00:00<00:01, 520.51it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:00<00:01, 554.32it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:00<00:01, 570.43it/s]
Loading safetensors checkpoint shards:  40% Completed | 408/1024 [00:00<00:01, 585.93it/s]
Loading safetensors checkpoint shards:  46% Completed | 469/1024 [00:00<00:00, 590.70it/s]
Loading safetensors checkpoint shards:  52% Completed | 532/1024 [00:01<00:00, 601.04it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:01<00:00, 609.80it/s]
Loading safetensors checkpoint shards:  64% Completed | 657/1024 [00:01<00:00, 605.18it/s]
Loading safetensors checkpoint shards:  70% Completed | 718/1024 [00:01<00:00, 599.47it/s]
Loading safetensors checkpoint shards:  76% Completed | 778/1024 [00:01<00:00, 594.12it/s]
Loading safetensors checkpoint shards:  82% Completed | 838/1024 [00:01<00:00, 592.28it/s]
Loading safetensors checkpoint shards:  88% Completed | 898/1024 [00:01<00:00, 587.88it/s]
Loading safetensors checkpoint shards:  93% Completed | 957/1024 [00:01<00:00, 586.82it/s]
Loading safetensors checkpoint shards:  99% Completed | 1016/1024 [00:01<00:00, 401.06it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:01<00:00, 512.01it/s]

[2025-09-13 07:19:23 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.21 GB, mem usage=1.99 GB.
[2025-09-13 07:19:23 TP6] KV Cache is allocated. #tokens: 620169, KV size: 0.67 GB
[2025-09-13 07:19:23 TP7] KV Cache is allocated. #tokens: 620169, KV size: 0.67 GB
[2025-09-13 07:19:23 TP2] KV Cache is allocated. #tokens: 620169, KV size: 0.67 GB
[2025-09-13 07:19:23 TP5] KV Cache is allocated. #tokens: 620169, KV size: 0.67 GB
[2025-09-13 07:19:23 TP0] KV Cache is allocated. #tokens: 620169, KV size: 0.67 GB
[2025-09-13 07:19:23 TP3] KV Cache is allocated. #tokens: 620169, KV size: 0.67 GB
[2025-09-13 07:19:23 TP4] KV Cache is allocated. #tokens: 620169, KV size: 0.67 GB
[2025-09-13 07:19:23 TP0] Memory pool end. avail mem=14.54 GB
[2025-09-13 07:19:23 TP1] KV Cache is allocated. #tokens: 620169, KV size: 0.67 GB
[2025-09-13 07:19:23 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.17 GB
[2025-09-13 07:19:23 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:19:23 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:19:23 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:19:23 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:19:23 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:19:23 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:19:23 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
Capturing batches (bs=1 avail_mem=14.62 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  3.15it/s][2025-09-13 07:19:30 TP4] Registering 96 cuda graph addresses
[2025-09-13 07:19:30 TP3] Registering 96 cuda graph addresses
[2025-09-13 07:19:30 TP5] Registering 96 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.62 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.59it/s][2025-09-13 07:19:30 TP2] Registering 96 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.62 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.43it/s]
[2025-09-13 07:19:30 TP6] Registering 96 cuda graph addresses
[2025-09-13 07:19:30 TP1] Registering 96 cuda graph addresses
[2025-09-13 07:19:30 TP7] Registering 96 cuda graph addresses
[2025-09-13 07:19:30 TP0] Registering 96 cuda graph addresses
[2025-09-13 07:19:30 TP5] Capture draft cuda graph end. Time elapsed: 6.39 s. mem usage=0.37 GB. avail mem=14.57 GB.
[2025-09-13 07:19:30 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.57 GB
[2025-09-13 07:19:30 TP7] Capture draft cuda graph end. Time elapsed: 6.39 s. mem usage=0.37 GB. avail mem=14.80 GB.
[2025-09-13 07:19:30 TP0] Capture draft cuda graph end. Time elapsed: 6.39 s. mem usage=0.37 GB. avail mem=14.61 GB.
[2025-09-13 07:19:30 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.61 GB
[2025-09-13 07:19:30 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.80 GB
[2025-09-13 07:19:30 TP1] Capture draft cuda graph end. Time elapsed: 6.39 s. mem usage=0.37 GB. avail mem=14.57 GB.
[2025-09-13 07:19:30 TP4] Capture draft cuda graph end. Time elapsed: 6.39 s. mem usage=0.37 GB. avail mem=14.57 GB.
[2025-09-13 07:19:30 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.57 GB
[2025-09-13 07:19:30 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.57 GB
[2025-09-13 07:19:30 TP3] Capture draft cuda graph end. Time elapsed: 6.39 s. mem usage=0.37 GB. avail mem=14.57 GB.
[2025-09-13 07:19:30 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.57 GB
[2025-09-13 07:19:30 TP6] Capture draft cuda graph end. Time elapsed: 6.39 s. mem usage=0.37 GB. avail mem=14.57 GB.
[2025-09-13 07:19:30 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.57 GB
[2025-09-13 07:19:30 TP2] Capture draft cuda graph end. Time elapsed: 6.39 s. mem usage=0.37 GB. avail mem=14.57 GB.
[2025-09-13 07:19:30 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.57 GB
Capturing batches (bs=1 avail_mem=14.42 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:00<00:00, 21.62it/s][2025-09-13 07:19:31 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:19:31 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:19:31 TP5] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.42 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 21.36it/s]
[2025-09-13 07:19:31 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:19:31 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:19:31 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:19:31 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:19:31 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:19:31 TP1] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.19 GB. avail mem=14.38 GB.
[2025-09-13 07:19:31 TP5] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.19 GB. avail mem=14.38 GB.
[2025-09-13 07:19:31 TP0] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.19 GB. avail mem=14.42 GB.
[2025-09-13 07:19:31 TP7] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.19 GB. avail mem=14.62 GB.
[2025-09-13 07:19:31 TP0] max_total_num_tokens=620169, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.42 GB
[2025-09-13 07:19:31 TP6] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.19 GB. avail mem=14.38 GB.
[2025-09-13 07:19:31 TP4] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.19 GB. avail mem=14.38 GB.
[2025-09-13 07:19:31 TP2] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.19 GB. avail mem=14.38 GB.
[2025-09-13 07:19:31 TP3] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.19 GB. avail mem=14.38 GB.
[2025-09-13 07:19:31] INFO:     Started server process [261042]
[2025-09-13 07:19:31] INFO:     Waiting for application startup.
[2025-09-13 07:19:31] INFO:     Application startup complete.
[2025-09-13 07:19:31] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:19:32] INFO:     127.0.0.1:51756 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:19:32] INFO:     127.0.0.1:51760 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:19:32 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:19:32 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:19:32 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28372.61it/s]
[2025-09-13 07:19:34] INFO:     127.0.0.1:51768 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:34] The server is fired up and ready to roll!
[2025-09-13 07:19:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:19:43] INFO:     127.0.0.1:45338 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:19:43] INFO:     127.0.0.1:45346 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:44 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:19:45] INFO:     127.0.0.1:45352 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:45] INFO:     127.0.0.1:45364 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:19:45] INFO:     127.0.0.1:45376 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:45] INFO:     127.0.0.1:45390 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:45] INFO:     127.0.0.1:45406 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:45] INFO:     127.0.0.1:45418 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:45] INFO:     127.0.0.1:45434 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:45] INFO:     127.0.0.1:45444 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:45 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:19:46 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:19:46 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:19:46 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:19:46 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:19:46 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:19:46 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:19:46 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:19:46 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:19:46 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:19:47 TP0] Decode batch. #running-req: 8, #token: 14458, token usage: 0.02, accept len: 2.58, cuda graph: True, gen throughput (token/s): 36.40, #queue-req: 0, 
[2025-09-13 07:19:48 TP0] Decode batch. #running-req: 8, #token: 15391, token usage: 0.02, accept len: 2.92, cuda graph: True, gen throughput (token/s): 774.32, #queue-req: 0, 
[2025-09-13 07:19:49 TP0] Decode batch. #running-req: 8, #token: 16399, token usage: 0.03, accept len: 3.15, cuda graph: True, gen throughput (token/s): 829.18, #queue-req: 0, 
[2025-09-13 07:19:50 TP0] Decode batch. #running-req: 8, #token: 17399, token usage: 0.03, accept len: 3.12, cuda graph: True, gen throughput (token/s): 822.31, #queue-req: 0, 
 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 7/8 [00:06<00:00,  2.34it/s][2025-09-13 07:19:51 TP0] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, accept len: 3.20, cuda graph: True, gen throughput (token/s): 505.73, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.25it/s]
[2025-09-13 07:19:51] INFO:     127.0.0.1:55148 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.39      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4076      
Request throughput (req/s):              1.25      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         640.69    
Total token throughput (tok/s):          640.69    
Concurrency:                             7.40      
Accept length:                           3.00      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5910.33   
Median E2E Latency (ms):                 5957.63   
---------------Time to First Token----------------
Mean TTFT (ms):                          610.20    
Median TTFT (ms):                        720.74    
P99 TTFT (ms):                           721.26    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.37     
Median ITL (ms):                         7.61      
P95 ITL (ms):                            28.29     
P99 ITL (ms):                            32.12     
Max ITL (ms):                            725.01    
==================================================
[2025-09-13 07:19:51] INFO:     127.0.0.1:55156 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:19:51] INFO:     127.0.0.1:55166 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:19:53] INFO:     127.0.0.1:55170 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:53] INFO:     127.0.0.1:55182 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:19:53] INFO:     127.0.0.1:55192 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:53] INFO:     127.0.0.1:55202 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:53] INFO:     127.0.0.1:55212 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:53] INFO:     127.0.0.1:55228 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:53] INFO:     127.0.0.1:55240 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:53] INFO:     127.0.0.1:55244 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:53 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:19:54 TP0] Decode batch. #running-req: 8, #token: 14531, token usage: 0.02, accept len: 2.64, cuda graph: True, gen throughput (token/s): 260.34, #queue-req: 0, 
[2025-09-13 07:19:55 TP0] Decode batch. #running-req: 8, #token: 15470, token usage: 0.02, accept len: 2.93, cuda graph: True, gen throughput (token/s): 769.44, #queue-req: 0, 
[2025-09-13 07:19:56 TP0] Decode batch. #running-req: 8, #token: 16476, token usage: 0.03, accept len: 3.14, cuda graph: True, gen throughput (token/s): 826.93, #queue-req: 0, 
[2025-09-13 07:19:57 TP0] Decode batch. #running-req: 8, #token: 17474, token usage: 0.03, accept len: 3.12, cuda graph: True, gen throughput (token/s): 820.00, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:12,  4.80s/it][2025-09-13 07:19:58] INFO:     127.0.0.1:40622 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:58 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:05<00:32,  2.30s/it][2025-09-13 07:19:58] INFO:     127.0.0.1:40634 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:19:58] INFO:     127.0.0.1:40640 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:58 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:12,  1.02s/it][2025-09-13 07:19:59] INFO:     127.0.0.1:40642 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:59 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:06<00:08,  1.25it/s][2025-09-13 07:19:59] INFO:     127.0.0.1:40646 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:59 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:06<00:06,  1.60it/s][2025-09-13 07:19:59] INFO:     127.0.0.1:40660 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:59 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:04,  2.03it/s][2025-09-13 07:19:59] INFO:     127.0.0.1:40676 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:19:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:03,  2.29it/s][2025-09-13 07:20:00] INFO:     127.0.0.1:40678 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:20:00 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:20:00 TP0] Decode batch. #running-req: 8, #token: 13870, token usage: 0.02, accept len: 3.00, cuda graph: True, gen throughput (token/s): 379.91, #queue-req: 0, 
[2025-09-13 07:20:01 TP0] Decode batch. #running-req: 8, #token: 14770, token usage: 0.02, accept len: 2.81, cuda graph: True, gen throughput (token/s): 758.55, #queue-req: 0, 
[2025-09-13 07:20:02 TP0] Decode batch. #running-req: 8, #token: 15786, token usage: 0.03, accept len: 3.17, cuda graph: True, gen throughput (token/s): 841.84, #queue-req: 0, 
[2025-09-13 07:20:04 TP0] Decode batch. #running-req: 8, #token: 15863, token usage: 0.03, accept len: 3.10, cuda graph: True, gen throughput (token/s): 818.41, #queue-req: 0, 
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 14/16 [00:11<00:00,  2.21it/s][2025-09-13 07:20:05 TP0] Decode batch. #running-req: 2, #token: 6501, token usage: 0.01, accept len: 3.23, cuda graph: True, gen throughput (token/s): 671.19, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:12<00:00,  1.31it/s]
[2025-09-13 07:20:05] INFO:     127.0.0.1:40686 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  12.24     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8083      
Request throughput (req/s):              1.31      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         669.40    
Total token throughput (tok/s):          669.40    
Concurrency:                             7.60      
Accept length:                           3.01      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5809.80   
Median E2E Latency (ms):                 5653.28   
---------------Time to First Token----------------
Mean TTFT (ms):                          231.46    
Median TTFT (ms):                        274.52    
P99 TTFT (ms):                           291.48    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.92     
Median ITL (ms):                         7.61      
P95 ITL (ms):                            29.75     
P99 ITL (ms):                            65.97     
Max ITL (ms):                            263.87    
==================================================
[2025-09-13 07:20:05] INFO:     127.0.0.1:40688 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=24: batch_size=8, steps=5, topk=2, num_draft_tokens=4, speed=99.82 token/s, step_time=30.19 ms
Start i=25: batch_size=8, steps=5, topk=2, num_draft_tokens=6
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 5 --speculative-eagle-topk 2 --speculative-num-draft-tokens 6 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:20:16.161000 266697 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:20:16.161000 266697 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:20:16] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=707289533, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=5, speculative_eagle_topk=2, speculative_num_draft_tokens=6, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:20:16] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:20:25.288000 266905 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:20:25.288000 266905 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:20:25.359000 266910 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:20:25.359000 266910 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:20:25.554000 266903 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:20:25.554000 266903 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:20:25.629000 266902 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:20:25.629000 266902 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:20:25.633000 266907 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:20:25.633000 266907 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:20:25.675000 266908 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:20:25.675000 266908 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:20:25.695000 266904 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:20:25.695000 266904 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:20:25.780000 266909 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:20:25.780000 266909 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:20:25.807000 266906 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:20:25.807000 266906 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:20:26 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:20:26 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:20:26 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:20:27 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:20:30 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:20:32 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:20:32 TP0] Detected fp8 checkpoint.
[2025-09-13 07:20:32 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:04, 241.31it/s]
Loading safetensors checkpoint shards:   5% Completed | 51/1024 [00:00<00:08, 116.25it/s]
Loading safetensors checkpoint shards:   6% Completed | 66/1024 [00:00<00:10, 93.30it/s]
Loading safetensors checkpoint shards:   8% Completed | 78/1024 [00:00<00:12, 73.67it/s]
Loading safetensors checkpoint shards:   8% Completed | 87/1024 [00:01<00:13, 67.98it/s]
Loading safetensors checkpoint shards:   9% Completed | 95/1024 [00:01<00:16, 56.47it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:01<00:28, 31.80it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:01<00:27, 33.82it/s]
Loading safetensors checkpoint shards:  11% Completed | 117/1024 [00:02<00:21, 41.55it/s]
Loading safetensors checkpoint shards:  12% Completed | 124/1024 [00:02<00:19, 46.12it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:02<00:17, 50.93it/s]
Loading safetensors checkpoint shards:  14% Completed | 141/1024 [00:02<00:14, 58.96it/s]
Loading safetensors checkpoint shards:  15% Completed | 149/1024 [00:02<00:15, 55.61it/s]
Loading safetensors checkpoint shards:  15% Completed | 156/1024 [00:02<00:15, 56.19it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:02<00:13, 61.59it/s]
Loading safetensors checkpoint shards:  17% Completed | 175/1024 [00:02<00:11, 72.15it/s]
Loading safetensors checkpoint shards:  18% Completed | 183/1024 [00:03<00:11, 72.30it/s]
Loading safetensors checkpoint shards:  19% Completed | 191/1024 [00:03<00:11, 74.19it/s]
Loading safetensors checkpoint shards:  20% Completed | 202/1024 [00:03<00:10, 79.30it/s]
Loading safetensors checkpoint shards:  21% Completed | 211/1024 [00:03<00:10, 78.68it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:03<00:10, 78.47it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:03<00:10, 74.39it/s]
Loading safetensors checkpoint shards:  23% Completed | 235/1024 [00:04<00:21, 36.35it/s]
Loading safetensors checkpoint shards:  24% Completed | 243/1024 [00:04<00:18, 42.87it/s]
Loading safetensors checkpoint shards:  25% Completed | 251/1024 [00:04<00:15, 49.25it/s]
Loading safetensors checkpoint shards:  25% Completed | 260/1024 [00:04<00:13, 57.47it/s]
Loading safetensors checkpoint shards:  26% Completed | 268/1024 [00:04<00:12, 60.49it/s]
Loading safetensors checkpoint shards:  27% Completed | 276/1024 [00:04<00:11, 63.98it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:04<00:10, 68.34it/s]
Loading safetensors checkpoint shards:  29% Completed | 293/1024 [00:04<00:10, 69.00it/s]
Loading safetensors checkpoint shards:  29% Completed | 301/1024 [00:04<00:10, 71.05it/s]
Loading safetensors checkpoint shards:  30% Completed | 309/1024 [00:05<00:10, 71.12it/s]
Loading safetensors checkpoint shards:  31% Completed | 317/1024 [00:05<00:09, 73.01it/s]
Loading safetensors checkpoint shards:  32% Completed | 325/1024 [00:05<00:09, 72.90it/s]
Loading safetensors checkpoint shards:  33% Completed | 333/1024 [00:05<00:09, 74.40it/s]
Loading safetensors checkpoint shards:  33% Completed | 341/1024 [00:05<00:09, 72.24it/s]
Loading safetensors checkpoint shards:  34% Completed | 349/1024 [00:05<00:10, 66.88it/s]
Loading safetensors checkpoint shards:  35% Completed | 356/1024 [00:05<00:10, 64.65it/s]
Loading safetensors checkpoint shards:  35% Completed | 363/1024 [00:05<00:11, 57.09it/s]
Loading safetensors checkpoint shards:  36% Completed | 369/1024 [00:06<00:13, 49.05it/s]
Loading safetensors checkpoint shards:  37% Completed | 375/1024 [00:06<00:13, 48.68it/s]
Loading safetensors checkpoint shards:  37% Completed | 381/1024 [00:06<00:13, 49.17it/s]
Loading safetensors checkpoint shards:  38% Completed | 388/1024 [00:06<00:11, 53.16it/s]
Loading safetensors checkpoint shards:  39% Completed | 395/1024 [00:06<00:11, 55.65it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:07<00:28, 21.55it/s]
Loading safetensors checkpoint shards:  40% Completed | 407/1024 [00:07<00:23, 26.10it/s]
Loading safetensors checkpoint shards:  40% Completed | 412/1024 [00:07<00:21, 28.84it/s]
Loading safetensors checkpoint shards:  41% Completed | 417/1024 [00:07<00:19, 31.41it/s]
Loading safetensors checkpoint shards:  41% Completed | 422/1024 [00:07<00:17, 34.93it/s]
Loading safetensors checkpoint shards:  42% Completed | 427/1024 [00:07<00:15, 38.14it/s]
Loading safetensors checkpoint shards:  42% Completed | 432/1024 [00:07<00:15, 38.74it/s]
Loading safetensors checkpoint shards:  43% Completed | 437/1024 [00:08<00:14, 40.82it/s]
Loading safetensors checkpoint shards:  43% Completed | 442/1024 [00:08<00:15, 38.70it/s]
Loading safetensors checkpoint shards:  44% Completed | 447/1024 [00:08<00:16, 34.46it/s]
Loading safetensors checkpoint shards:  44% Completed | 451/1024 [00:08<00:17, 32.92it/s]
Loading safetensors checkpoint shards:  44% Completed | 455/1024 [00:08<00:18, 31.57it/s]
Loading safetensors checkpoint shards:  45% Completed | 459/1024 [00:08<00:17, 32.95it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:08<00:19, 28.96it/s]
Loading safetensors checkpoint shards:  46% Completed | 468/1024 [00:09<00:16, 33.39it/s]
Loading safetensors checkpoint shards:  46% Completed | 474/1024 [00:09<00:14, 38.82it/s]
Loading safetensors checkpoint shards:  47% Completed | 479/1024 [00:09<00:15, 34.76it/s]
Loading safetensors checkpoint shards:  47% Completed | 483/1024 [00:09<00:17, 31.68it/s]
Loading safetensors checkpoint shards:  48% Completed | 487/1024 [00:09<00:16, 32.04it/s]
Loading safetensors checkpoint shards:  48% Completed | 491/1024 [00:09<00:16, 32.04it/s]
Loading safetensors checkpoint shards:  48% Completed | 496/1024 [00:09<00:15, 33.44it/s]
Loading safetensors checkpoint shards:  49% Completed | 500/1024 [00:10<00:16, 32.10it/s]
Loading safetensors checkpoint shards:  49% Completed | 505/1024 [00:10<00:14, 35.34it/s]
Loading safetensors checkpoint shards:  50% Completed | 509/1024 [00:10<00:14, 34.55it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:10<00:14, 35.85it/s]
Loading safetensors checkpoint shards:  51% Completed | 518/1024 [00:10<00:12, 39.37it/s]
Loading safetensors checkpoint shards:  51% Completed | 523/1024 [00:10<00:14, 35.78it/s]
Loading safetensors checkpoint shards:  52% Completed | 528/1024 [00:10<00:13, 36.94it/s]
Loading safetensors checkpoint shards:  52% Completed | 532/1024 [00:10<00:13, 36.18it/s]
Loading safetensors checkpoint shards:  52% Completed | 536/1024 [00:11<00:14, 33.30it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:11<00:13, 36.37it/s]
Loading safetensors checkpoint shards:  53% Completed | 545/1024 [00:11<00:13, 34.69it/s]
Loading safetensors checkpoint shards:  54% Completed | 549/1024 [00:11<00:14, 33.67it/s]
Loading safetensors checkpoint shards:  54% Completed | 554/1024 [00:11<00:13, 34.07it/s]
Loading safetensors checkpoint shards:  54% Completed | 558/1024 [00:11<00:16, 28.85it/s]
Loading safetensors checkpoint shards:  55% Completed | 562/1024 [00:11<00:15, 30.11it/s]
Loading safetensors checkpoint shards:  55% Completed | 566/1024 [00:12<00:16, 27.06it/s]
Loading safetensors checkpoint shards:  56% Completed | 569/1024 [00:12<00:17, 25.98it/s]
Loading safetensors checkpoint shards:  56% Completed | 572/1024 [00:12<00:17, 26.25it/s]
Loading safetensors checkpoint shards:  56% Completed | 575/1024 [00:12<00:18, 23.79it/s]
Loading safetensors checkpoint shards:  56% Completed | 578/1024 [00:12<00:21, 20.39it/s]
Loading safetensors checkpoint shards:  57% Completed | 581/1024 [00:12<00:20, 21.21it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:12<00:18, 23.53it/s]
Loading safetensors checkpoint shards:  57% Completed | 588/1024 [00:13<00:18, 23.67it/s]
Loading safetensors checkpoint shards:  58% Completed | 591/1024 [00:13<00:18, 22.80it/s]
Loading safetensors checkpoint shards:  58% Completed | 595/1024 [00:13<00:17, 24.98it/s]
Loading safetensors checkpoint shards:  58% Completed | 598/1024 [00:13<00:17, 24.48it/s]
Loading safetensors checkpoint shards:  59% Completed | 602/1024 [00:13<00:16, 25.25it/s]
Loading safetensors checkpoint shards:  59% Completed | 605/1024 [00:13<00:15, 26.34it/s]
Loading safetensors checkpoint shards:  59% Completed | 608/1024 [00:14<00:38, 10.68it/s]
Loading safetensors checkpoint shards:  60% Completed | 611/1024 [00:14<00:32, 12.53it/s]
Loading safetensors checkpoint shards:  60% Completed | 616/1024 [00:14<00:23, 17.52it/s]
Loading safetensors checkpoint shards:  60% Completed | 619/1024 [00:14<00:21, 18.90it/s]
Loading safetensors checkpoint shards:  61% Completed | 622/1024 [00:14<00:21, 18.73it/s]
Loading safetensors checkpoint shards:  61% Completed | 625/1024 [00:15<00:22, 17.95it/s]
Loading safetensors checkpoint shards:  61% Completed | 628/1024 [00:15<00:21, 18.60it/s]
Loading safetensors checkpoint shards:  62% Completed | 631/1024 [00:15<00:20, 19.43it/s]
Loading safetensors checkpoint shards:  62% Completed | 634/1024 [00:15<00:18, 21.42it/s]
Loading safetensors checkpoint shards:  62% Completed | 637/1024 [00:15<00:20, 19.28it/s]
Loading safetensors checkpoint shards:  62% Completed | 640/1024 [00:15<00:19, 19.92it/s]
Loading safetensors checkpoint shards:  63% Completed | 643/1024 [00:15<00:18, 20.63it/s]
Loading safetensors checkpoint shards:  63% Completed | 646/1024 [00:16<00:18, 20.75it/s]
Loading safetensors checkpoint shards:  63% Completed | 649/1024 [00:16<00:17, 21.20it/s]
Loading safetensors checkpoint shards:  64% Completed | 652/1024 [00:16<00:17, 21.69it/s]
Loading safetensors checkpoint shards:  64% Completed | 655/1024 [00:16<00:16, 22.62it/s]
Loading safetensors checkpoint shards:  64% Completed | 659/1024 [00:16<00:14, 25.29it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:16<00:13, 27.57it/s]
Loading safetensors checkpoint shards:  65% Completed | 667/1024 [00:16<00:11, 30.46it/s]
Loading safetensors checkpoint shards:  66% Completed | 672/1024 [00:16<00:10, 34.98it/s]
Loading safetensors checkpoint shards:  66% Completed | 677/1024 [00:17<00:08, 38.78it/s]
Loading safetensors checkpoint shards:  67% Completed | 682/1024 [00:17<00:08, 39.71it/s]
Loading safetensors checkpoint shards:  67% Completed | 687/1024 [00:17<00:08, 37.49it/s]
Loading safetensors checkpoint shards:  67% Completed | 691/1024 [00:17<00:10, 32.59it/s]
Loading safetensors checkpoint shards:  68% Completed | 695/1024 [00:17<00:10, 31.39it/s]
Loading safetensors checkpoint shards:  68% Completed | 699/1024 [00:17<00:11, 29.53it/s]
Loading safetensors checkpoint shards:  69% Completed | 703/1024 [00:17<00:11, 27.42it/s]
Loading safetensors checkpoint shards:  69% Completed | 707/1024 [00:18<00:11, 28.48it/s]
Loading safetensors checkpoint shards:  69% Completed | 711/1024 [00:18<00:10, 29.81it/s]
Loading safetensors checkpoint shards:  70% Completed | 715/1024 [00:18<00:09, 31.01it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:18<00:09, 31.30it/s]
Loading safetensors checkpoint shards:  71% Completed | 723/1024 [00:18<00:09, 32.64it/s]
Loading safetensors checkpoint shards:  71% Completed | 727/1024 [00:18<00:08, 33.80it/s]
Loading safetensors checkpoint shards:  71% Completed | 731/1024 [00:18<00:08, 34.90it/s]
Loading safetensors checkpoint shards:  72% Completed | 735/1024 [00:18<00:08, 34.21it/s]
Loading safetensors checkpoint shards:  72% Completed | 739/1024 [00:18<00:08, 34.69it/s]
Loading safetensors checkpoint shards:  73% Completed | 743/1024 [00:19<00:08, 34.98it/s]
Loading safetensors checkpoint shards:  73% Completed | 747/1024 [00:19<00:08, 33.96it/s]
Loading safetensors checkpoint shards:  73% Completed | 751/1024 [00:19<00:07, 34.94it/s]
Loading safetensors checkpoint shards:  74% Completed | 755/1024 [00:19<00:07, 34.40it/s]
Loading safetensors checkpoint shards:  74% Completed | 759/1024 [00:19<00:07, 34.37it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:19<00:07, 35.47it/s]
Loading safetensors checkpoint shards:  75% Completed | 767/1024 [00:19<00:07, 36.20it/s]
Loading safetensors checkpoint shards:  75% Completed | 771/1024 [00:19<00:07, 35.86it/s]
Loading safetensors checkpoint shards:  76% Completed | 775/1024 [00:20<00:07, 34.51it/s]
Loading safetensors checkpoint shards:  76% Completed | 779/1024 [00:20<00:07, 34.49it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:20<00:06, 35.02it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:20<00:06, 34.32it/s]
Loading safetensors checkpoint shards:  77% Completed | 791/1024 [00:20<00:06, 35.24it/s]
Loading safetensors checkpoint shards:  78% Completed | 795/1024 [00:20<00:06, 35.89it/s]
Loading safetensors checkpoint shards:  78% Completed | 799/1024 [00:20<00:06, 35.90it/s]
Loading safetensors checkpoint shards:  79% Completed | 804/1024 [00:20<00:05, 36.87it/s]
Loading safetensors checkpoint shards:  79% Completed | 808/1024 [00:20<00:05, 36.77it/s]
Loading safetensors checkpoint shards:  79% Completed | 812/1024 [00:21<00:05, 35.91it/s]
Loading safetensors checkpoint shards:  80% Completed | 816/1024 [00:21<00:06, 34.59it/s]
Loading safetensors checkpoint shards:  80% Completed | 820/1024 [00:21<00:06, 33.89it/s]
Loading safetensors checkpoint shards:  80% Completed | 824/1024 [00:21<00:05, 34.52it/s]
Loading safetensors checkpoint shards:  81% Completed | 828/1024 [00:21<00:05, 34.98it/s]
Loading safetensors checkpoint shards:  81% Completed | 832/1024 [00:21<00:05, 35.43it/s]
Loading safetensors checkpoint shards:  82% Completed | 836/1024 [00:21<00:05, 36.44it/s]
Loading safetensors checkpoint shards:  82% Completed | 840/1024 [00:21<00:04, 36.97it/s]
Loading safetensors checkpoint shards:  82% Completed | 844/1024 [00:21<00:05, 35.80it/s]
Loading safetensors checkpoint shards:  83% Completed | 848/1024 [00:22<00:04, 36.55it/s]
Loading safetensors checkpoint shards:  83% Completed | 852/1024 [00:22<00:04, 37.09it/s]
Loading safetensors checkpoint shards:  84% Completed | 856/1024 [00:22<00:04, 37.57it/s]
Loading safetensors checkpoint shards:  84% Completed | 860/1024 [00:22<00:04, 35.93it/s]
Loading safetensors checkpoint shards:  84% Completed | 864/1024 [00:22<00:04, 35.84it/s]
Loading safetensors checkpoint shards:  85% Completed | 868/1024 [00:22<00:04, 35.90it/s]
Loading safetensors checkpoint shards:  85% Completed | 872/1024 [00:22<00:04, 35.73it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:22<00:04, 34.53it/s]
Loading safetensors checkpoint shards:  86% Completed | 880/1024 [00:23<00:13, 10.62it/s]
Loading safetensors checkpoint shards:  86% Completed | 884/1024 [00:23<00:10, 13.50it/s]
Loading safetensors checkpoint shards:  87% Completed | 888/1024 [00:24<00:08, 16.65it/s]
Loading safetensors checkpoint shards:  87% Completed | 892/1024 [00:24<00:06, 19.53it/s]
Loading safetensors checkpoint shards:  88% Completed | 896/1024 [00:24<00:05, 22.69it/s]
Loading safetensors checkpoint shards:  88% Completed | 900/1024 [00:24<00:04, 25.63it/s]
Loading safetensors checkpoint shards:  88% Completed | 904/1024 [00:24<00:04, 28.73it/s]
Loading safetensors checkpoint shards:  89% Completed | 908/1024 [00:24<00:03, 30.44it/s]
Loading safetensors checkpoint shards:  89% Completed | 912/1024 [00:24<00:03, 32.13it/s]
Loading safetensors checkpoint shards:  89% Completed | 916/1024 [00:24<00:03, 33.99it/s]
Loading safetensors checkpoint shards:  90% Completed | 920/1024 [00:24<00:03, 34.52it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:25<00:02, 34.34it/s]
Loading safetensors checkpoint shards:  91% Completed | 928/1024 [00:25<00:02, 34.93it/s]
Loading safetensors checkpoint shards:  91% Completed | 932/1024 [00:25<00:02, 35.16it/s]
Loading safetensors checkpoint shards:  91% Completed | 936/1024 [00:25<00:02, 35.14it/s]
Loading safetensors checkpoint shards:  92% Completed | 940/1024 [00:25<00:02, 36.31it/s]
Loading safetensors checkpoint shards:  92% Completed | 944/1024 [00:25<00:02, 36.75it/s]
Loading safetensors checkpoint shards:  93% Completed | 948/1024 [00:25<00:02, 36.73it/s]
Loading safetensors checkpoint shards:  93% Completed | 952/1024 [00:25<00:01, 37.16it/s]
Loading safetensors checkpoint shards:  93% Completed | 957/1024 [00:25<00:01, 38.39it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:26<00:01, 37.85it/s]
Loading safetensors checkpoint shards:  94% Completed | 966/1024 [00:26<00:01, 38.82it/s]
Loading safetensors checkpoint shards:  95% Completed | 970/1024 [00:26<00:01, 38.96it/s]
Loading safetensors checkpoint shards:  95% Completed | 974/1024 [00:26<00:01, 39.23it/s]
Loading safetensors checkpoint shards:  96% Completed | 979/1024 [00:26<00:01, 39.71it/s]
Loading safetensors checkpoint shards:  97% Completed | 994/1024 [00:26<00:00, 68.83it/s]
Loading safetensors checkpoint shards:  98% Completed | 1001/1024 [00:26<00:00, 68.94it/s]
Loading safetensors checkpoint shards:  99% Completed | 1013/1024 [00:26<00:00, 82.36it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:26<00:00, 38.13it/s]

[2025-09-13 07:21:00 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:21:01 TP2] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:21:01 TP7] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:21:01 TP6] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:21:01 TP0] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:21:01 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:21:01 TP5] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:21:01 TP3] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:21:01 TP1] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:21:01 TP4] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:21:01 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:21:01 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.52 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:21:02 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:21:02 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
                                                                                                                                                                     [2025-09-13 07:21:02 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:21:02 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:21:02 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:21:02 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:21:02 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:21:02 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:21:03 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 24200.63it/s]
[2025-09-13 07:21:03 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:21:03 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25331.76it/s]
[2025-09-13 07:21:04 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:21:04 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26838.26it/s]
[2025-09-13 07:21:04 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:21:04 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26073.59it/s]
[2025-09-13 07:21:05 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:21:05 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26935.08it/s]
[2025-09-13 07:21:06 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.23 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.77it/s][2025-09-13 07:21:09 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:21:09 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:21:09 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:21:09 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:21:09 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:21:09 TP7] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.23 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.99it/s][2025-09-13 07:21:09 TP3] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.23 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.11it/s]
[2025-09-13 07:21:09 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:21:09 TP0] Capture cuda graph end. Time elapsed: 7.99 s. mem usage=0.35 GB. avail mem=17.21 GB.
[2025-09-13 07:21:09 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:21:09 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:21:09 TP0] Init torch distributed begin.
[2025-09-13 07:21:09 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:21:09 TP0] Load weight begin. avail mem=17.21 GB
[2025-09-13 07:21:09 TP0] Detected fp8 checkpoint.
[2025-09-13 07:21:09 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 19/1024 [00:00<00:05, 180.53it/s]
Loading safetensors checkpoint shards:   4% Completed | 45/1024 [00:00<00:04, 225.72it/s]
Loading safetensors checkpoint shards:  10% Completed | 106/1024 [00:00<00:02, 395.84it/s]
Loading safetensors checkpoint shards:  16% Completed | 166/1024 [00:00<00:01, 473.43it/s]
Loading safetensors checkpoint shards:  22% Completed | 226/1024 [00:00<00:01, 517.92it/s]
Loading safetensors checkpoint shards:  28% Completed | 286/1024 [00:00<00:01, 544.60it/s]
Loading safetensors checkpoint shards:  34% Completed | 345/1024 [00:00<00:01, 557.59it/s]
Loading safetensors checkpoint shards:  40% Completed | 405/1024 [00:00<00:01, 570.76it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:00<00:00, 573.27it/s]
Loading safetensors checkpoint shards:  51% Completed | 524/1024 [00:01<00:00, 584.46it/s]
Loading safetensors checkpoint shards:  57% Completed | 588/1024 [00:01<00:00, 600.53it/s]
Loading safetensors checkpoint shards:  63% Completed | 649/1024 [00:01<00:00, 597.64it/s]
Loading safetensors checkpoint shards:  69% Completed | 709/1024 [00:01<00:00, 590.73it/s]
Loading safetensors checkpoint shards:  75% Completed | 769/1024 [00:01<00:00, 584.39it/s]
Loading safetensors checkpoint shards:  81% Completed | 828/1024 [00:01<00:00, 583.36it/s]
Loading safetensors checkpoint shards:  87% Completed | 887/1024 [00:01<00:00, 580.01it/s]
Loading safetensors checkpoint shards:  92% Completed | 946/1024 [00:01<00:00, 574.44it/s]
Loading safetensors checkpoint shards:  98% Completed | 1004/1024 [00:01<00:00, 438.84it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 504.91it/s]

[2025-09-13 07:21:12 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.22 GB, mem usage=1.99 GB.
[2025-09-13 07:21:12 TP6] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:21:12 TP0] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:21:12 TP1] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:21:12 TP7] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:21:12 TP3] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:21:12 TP2] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:21:12 TP0] Memory pool end. avail mem=14.55 GB
[2025-09-13 07:21:12 TP5] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:21:12 TP4] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:21:12 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:21:12 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:21:12 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:21:12 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.99 GB
[2025-09-13 07:21:12 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:21:12 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:21:12 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:21:12 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.18 GB
Capturing batches (bs=1 avail_mem=14.63 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.48it/s]
[2025-09-13 07:21:18 TP5] Registering 96 cuda graph addresses
[2025-09-13 07:21:18 TP6] Registering 96 cuda graph addresses
[2025-09-13 07:21:18 TP2] Registering 96 cuda graph addresses
[2025-09-13 07:21:18 TP0] Registering 96 cuda graph addresses
[2025-09-13 07:21:18 TP3] Registering 96 cuda graph addresses
[2025-09-13 07:21:18 TP1] Registering 96 cuda graph addresses
[2025-09-13 07:21:18 TP4] Registering 96 cuda graph addresses
[2025-09-13 07:21:18 TP7] Registering 96 cuda graph addresses
[2025-09-13 07:21:18 TP3] Capture draft cuda graph end. Time elapsed: 6.21 s. mem usage=0.36 GB. avail mem=14.58 GB.
[2025-09-13 07:21:18 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 07:21:18 TP4] Capture draft cuda graph end. Time elapsed: 6.21 s. mem usage=0.36 GB. avail mem=14.58 GB.
[2025-09-13 07:21:18 TP7] Capture draft cuda graph end. Time elapsed: 6.21 s. mem usage=0.36 GB. avail mem=14.81 GB.
[2025-09-13 07:21:18 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 07:21:18 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.81 GB
[2025-09-13 07:21:18 TP1] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.36 GB. avail mem=14.58 GB.
[2025-09-13 07:21:18 TP6] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.36 GB. avail mem=14.58 GB.
[2025-09-13 07:21:18 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 07:21:18 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 07:21:18 TP5] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.36 GB. avail mem=14.58 GB.
[2025-09-13 07:21:18 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 07:21:18 TP2] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.36 GB. avail mem=14.58 GB.
[2025-09-13 07:21:18 TP0] Capture draft cuda graph end. Time elapsed: 6.22 s. mem usage=0.37 GB. avail mem=14.62 GB.
[2025-09-13 07:21:18 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 07:21:18 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.62 GB
Capturing batches (bs=1 avail_mem=14.43 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 37.63it/s]
[2025-09-13 07:21:19 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:21:19 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:21:19 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:21:19 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:21:19 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:21:19 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:21:19 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:21:19 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:21:19 TP2] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.19 GB. avail mem=14.39 GB.
[2025-09-13 07:21:19 TP4] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.19 GB. avail mem=14.39 GB.
[2025-09-13 07:21:19 TP0] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.19 GB. avail mem=14.43 GB.
[2025-09-13 07:21:19 TP7] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.19 GB. avail mem=14.63 GB.
[2025-09-13 07:21:19 TP0] max_total_num_tokens=620185, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.43 GB
[2025-09-13 07:21:19 TP3] Capture draft extend cuda graph end. Time elapsed: 1.06 s. mem usage=0.19 GB. avail mem=14.39 GB.
[2025-09-13 07:21:19 TP6] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.19 GB. avail mem=14.39 GB.
[2025-09-13 07:21:19 TP1] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.19 GB. avail mem=14.39 GB.
[2025-09-13 07:21:19 TP5] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.19 GB. avail mem=14.39 GB.
[2025-09-13 07:21:20] INFO:     Started server process [266697]
[2025-09-13 07:21:20] INFO:     Waiting for application startup.
[2025-09-13 07:21:20] INFO:     Application startup complete.
[2025-09-13 07:21:20] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:21:20] INFO:     127.0.0.1:57418 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:21:21] INFO:     127.0.0.1:57430 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:21:21 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:21:21 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:21:21 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25633.07it/s]
[2025-09-13 07:21:22] INFO:     127.0.0.1:57446 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:22] The server is fired up and ready to roll!
[2025-09-13 07:21:30 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:21:31] INFO:     127.0.0.1:37384 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:21:32] INFO:     127.0.0.1:37396 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:32 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:21:33] INFO:     127.0.0.1:37410 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:33] INFO:     127.0.0.1:37424 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:21:33] INFO:     127.0.0.1:37440 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:33] INFO:     127.0.0.1:37446 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:33] INFO:     127.0.0.1:37454 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:33] INFO:     127.0.0.1:37470 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:33] INFO:     127.0.0.1:37474 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:33] INFO:     127.0.0.1:37482 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:33 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:21:34 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:21:34 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:21:34 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:21:34 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:21:34 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:21:34 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:21:34 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:21:34 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:21:34 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:21:35 TP0] Decode batch. #running-req: 8, #token: 14525, token usage: 0.02, accept len: 2.87, cuda graph: True, gen throughput (token/s): 41.29, #queue-req: 0, 
[2025-09-13 07:21:36 TP0] Decode batch. #running-req: 8, #token: 15632, token usage: 0.03, accept len: 3.46, cuda graph: True, gen throughput (token/s): 885.31, #queue-req: 0, 
[2025-09-13 07:21:37 TP0] Decode batch. #running-req: 8, #token: 16767, token usage: 0.03, accept len: 3.55, cuda graph: True, gen throughput (token/s): 886.95, #queue-req: 0, 
 38%|█████████████████████████████████████████████████▏                                                                                 | 3/8 [00:05<00:06,  1.38s/it][2025-09-13 07:21:38 TP0] Decode batch. #running-req: 5, #token: 11815, token usage: 0.02, accept len: 3.30, cuda graph: True, gen throughput (token/s): 780.19, #queue-req: 0, 
 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 7/8 [00:06<00:00,  1.83it/s][2025-09-13 07:21:39 TP0] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, accept len: 3.33, cuda graph: True, gen throughput (token/s): 237.42, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.25it/s]
[2025-09-13 07:21:40] INFO:     127.0.0.1:52118 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.42      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4083      
Request throughput (req/s):              1.25      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         637.93    
Total token throughput (tok/s):          637.93    
Concurrency:                             6.98      
Accept length:                           3.33      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5600.95   
Median E2E Latency (ms):                 5511.74   
---------------Time to First Token----------------
Mean TTFT (ms):                          620.14    
Median TTFT (ms):                        733.94    
P99 TTFT (ms):                           734.57    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.75      
Median ITL (ms):                         7.54      
P95 ITL (ms):                            26.95     
P99 ITL (ms):                            32.38     
Max ITL (ms):                            736.13    
==================================================
[2025-09-13 07:21:40] INFO:     127.0.0.1:52134 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:21:40] INFO:     127.0.0.1:52148 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:21:41] INFO:     127.0.0.1:52152 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:41] INFO:     127.0.0.1:52154 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:21:41] INFO:     127.0.0.1:52158 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:41] INFO:     127.0.0.1:52166 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:41] INFO:     127.0.0.1:52170 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:41] INFO:     127.0.0.1:52174 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:41] INFO:     127.0.0.1:52184 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:41] INFO:     127.0.0.1:52192 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:41 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:21:42 TP0] Decode batch. #running-req: 8, #token: 14625, token usage: 0.02, accept len: 3.03, cuda graph: True, gen throughput (token/s): 295.36, #queue-req: 0, 
[2025-09-13 07:21:43 TP0] Decode batch. #running-req: 8, #token: 15737, token usage: 0.03, accept len: 3.48, cuda graph: True, gen throughput (token/s): 876.85, #queue-req: 0, 
[2025-09-13 07:21:45 TP0] Decode batch. #running-req: 8, #token: 16877, token usage: 0.03, accept len: 3.56, cuda graph: True, gen throughput (token/s): 886.05, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:04,  4.32s/it][2025-09-13 07:21:45] INFO:     127.0.0.1:52196 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:45 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:30,  2.14s/it][2025-09-13 07:21:46] INFO:     127.0.0.1:52204 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:16,  1.25s/it][2025-09-13 07:21:46] INFO:     127.0.0.1:52212 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:46 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.20it/s][2025-09-13 07:21:46] INFO:     127.0.0.1:52224 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:46 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:21:46 TP0] Decode batch. #running-req: 8, #token: 13438, token usage: 0.02, accept len: 3.27, cuda graph: True, gen throughput (token/s): 539.00, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:07,  1.54it/s][2025-09-13 07:21:46] INFO:     127.0.0.1:52234 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:47] INFO:     127.0.0.1:52248 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:47 TP0] Prefill batch. #new-seq: 2, #new-token: 3259, #cached-token: 1724, token usage: 0.02, #running-req: 6, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:05,  1.76it/s][2025-09-13 07:21:47] INFO:     127.0.0.1:45022 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:48 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:04,  1.96it/s][2025-09-13 07:21:48] INFO:     127.0.0.1:45028 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:21:48 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:21:48 TP0] Decode batch. #running-req: 8, #token: 14377, token usage: 0.02, accept len: 3.18, cuda graph: True, gen throughput (token/s): 556.86, #queue-req: 0, 
[2025-09-13 07:21:50 TP0] Decode batch. #running-req: 8, #token: 15500, token usage: 0.02, accept len: 3.51, cuda graph: True, gen throughput (token/s): 868.67, #queue-req: 0, 
 56%|█████████████████████████████████████████████████████████████████████████▏                                                        | 9/16 [00:09<00:08,  1.16s/it][2025-09-13 07:21:51 TP0] Decode batch. #running-req: 6, #token: 14813, token usage: 0.02, accept len: 3.91, cuda graph: True, gen throughput (token/s): 944.05, #queue-req: 0, 
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 15/16 [00:11<00:00,  2.98it/s][2025-09-13 07:21:52 TP0] Decode batch. #running-req: 1, #token: 3193, token usage: 0.01, accept len: 4.01, cuda graph: True, gen throughput (token/s): 688.54, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.41it/s]
[2025-09-13 07:21:52] INFO:     127.0.0.1:45044 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.32     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8107      
Request throughput (req/s):              1.41      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         723.55    
Total token throughput (tok/s):          723.55    
Concurrency:                             7.58      
Accept length:                           3.43      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5362.36   
Median E2E Latency (ms):                 5401.34   
---------------Time to First Token----------------
Mean TTFT (ms):                          231.10    
Median TTFT (ms):                        244.53    
P99 TTFT (ms):                           290.65    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.04     
Median ITL (ms):                         6.50      
P95 ITL (ms):                            30.87     
P99 ITL (ms):                            55.02     
Max ITL (ms):                            293.36    
==================================================
[2025-09-13 07:21:52] INFO:     127.0.0.1:45048 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=25: batch_size=8, steps=5, topk=2, num_draft_tokens=6, speed=107.51 token/s, step_time=31.88 ms
Start i=26: batch_size=8, steps=5, topk=2, num_draft_tokens=8
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 5 --speculative-eagle-topk 2 --speculative-num-draft-tokens 8 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:22:03.360000 272270 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:22:03.360000 272270 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:22:03] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=158421615, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=5, speculative_eagle_topk=2, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:22:04] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:22:12.547000 272479 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:22:12.547000 272479 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:22:12.729000 272481 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:22:12.729000 272481 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:22:12.744000 272486 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:22:12.744000 272486 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:22:12.880000 272485 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:22:12.880000 272485 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:22:12.899000 272478 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:22:12.899000 272478 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:22:12.938000 272482 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:22:12.938000 272482 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:22:12.955000 272484 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:22:12.955000 272484 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:22:12.971000 272483 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:22:12.971000 272483 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:22:13.040000 272480 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:22:13.040000 272480 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:22:13 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:22:13 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:22:13 TP0] Init torch distributed begin.
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:22:15 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:22:18 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:22:19 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:22:19 TP0] Detected fp8 checkpoint.
[2025-09-13 07:22:20 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 27/1024 [00:00<00:04, 224.80it/s]
Loading safetensors checkpoint shards:   5% Completed | 50/1024 [00:00<00:16, 59.77it/s]
Loading safetensors checkpoint shards:   6% Completed | 62/1024 [00:01<00:18, 51.45it/s]
Loading safetensors checkpoint shards:   7% Completed | 70/1024 [00:01<00:19, 48.85it/s]
Loading safetensors checkpoint shards:   8% Completed | 77/1024 [00:01<00:20, 46.34it/s]
Loading safetensors checkpoint shards:   8% Completed | 83/1024 [00:01<00:19, 47.41it/s]
Loading safetensors checkpoint shards:   9% Completed | 89/1024 [00:01<00:19, 46.80it/s]
Loading safetensors checkpoint shards:   9% Completed | 95/1024 [00:01<00:20, 45.02it/s]
Loading safetensors checkpoint shards:  10% Completed | 100/1024 [00:01<00:20, 44.29it/s]
Loading safetensors checkpoint shards:  10% Completed | 106/1024 [00:02<00:20, 45.52it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:20, 44.13it/s]
Loading safetensors checkpoint shards:  11% Completed | 116/1024 [00:02<00:20, 45.40it/s]
Loading safetensors checkpoint shards:  12% Completed | 121/1024 [00:02<00:36, 25.01it/s]
Loading safetensors checkpoint shards:  12% Completed | 125/1024 [00:02<00:32, 27.25it/s]
Loading safetensors checkpoint shards:  13% Completed | 130/1024 [00:02<00:29, 30.72it/s]
Loading safetensors checkpoint shards:  13% Completed | 134/1024 [00:03<00:28, 31.59it/s]
Loading safetensors checkpoint shards:  14% Completed | 140/1024 [00:03<00:24, 35.78it/s]
Loading safetensors checkpoint shards:  14% Completed | 145/1024 [00:03<00:24, 35.92it/s]
Loading safetensors checkpoint shards:  15% Completed | 150/1024 [00:03<00:23, 37.17it/s]
Loading safetensors checkpoint shards:  15% Completed | 154/1024 [00:03<00:23, 36.96it/s]
Loading safetensors checkpoint shards:  15% Completed | 158/1024 [00:03<00:23, 36.99it/s]
Loading safetensors checkpoint shards:  16% Completed | 163/1024 [00:03<00:22, 38.16it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:03<00:23, 35.91it/s]
Loading safetensors checkpoint shards:  17% Completed | 172/1024 [00:04<00:22, 37.70it/s]
Loading safetensors checkpoint shards:  17% Completed | 176/1024 [00:04<00:22, 37.24it/s]
Loading safetensors checkpoint shards:  18% Completed | 180/1024 [00:04<00:23, 35.78it/s]
Loading safetensors checkpoint shards:  18% Completed | 185/1024 [00:04<00:22, 37.42it/s]
Loading safetensors checkpoint shards:  18% Completed | 189/1024 [00:04<00:22, 37.67it/s]
Loading safetensors checkpoint shards:  19% Completed | 194/1024 [00:04<00:20, 39.84it/s]
Loading safetensors checkpoint shards:  19% Completed | 199/1024 [00:04<00:20, 39.29it/s]
Loading safetensors checkpoint shards:  20% Completed | 203/1024 [00:04<00:21, 37.76it/s]
Loading safetensors checkpoint shards:  20% Completed | 208/1024 [00:04<00:20, 39.01it/s]
Loading safetensors checkpoint shards:  21% Completed | 212/1024 [00:05<00:21, 38.36it/s]
Loading safetensors checkpoint shards:  21% Completed | 217/1024 [00:05<00:20, 40.07it/s]
Loading safetensors checkpoint shards:  22% Completed | 222/1024 [00:05<00:20, 38.21it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:05<00:20, 38.20it/s]
Loading safetensors checkpoint shards:  23% Completed | 231/1024 [00:05<00:20, 38.01it/s]
Loading safetensors checkpoint shards:  23% Completed | 235/1024 [00:05<00:21, 37.14it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:05<00:20, 38.56it/s]
Loading safetensors checkpoint shards:  24% Completed | 244/1024 [00:05<00:20, 38.28it/s]
Loading safetensors checkpoint shards:  24% Completed | 250/1024 [00:06<00:18, 41.74it/s]
Loading safetensors checkpoint shards:  25% Completed | 255/1024 [00:06<00:19, 39.68it/s]
Loading safetensors checkpoint shards:  25% Completed | 260/1024 [00:06<00:18, 41.90it/s]
Loading safetensors checkpoint shards:  26% Completed | 265/1024 [00:06<00:18, 42.10it/s]
Loading safetensors checkpoint shards:  26% Completed | 270/1024 [00:06<00:17, 42.65it/s]
Loading safetensors checkpoint shards:  27% Completed | 275/1024 [00:06<00:17, 42.61it/s]
Loading safetensors checkpoint shards:  27% Completed | 280/1024 [00:06<00:17, 42.63it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:06<00:16, 44.01it/s]
Loading safetensors checkpoint shards:  28% Completed | 290/1024 [00:06<00:17, 42.66it/s]
Loading safetensors checkpoint shards:  29% Completed | 296/1024 [00:07<00:16, 45.08it/s]
Loading safetensors checkpoint shards:  29% Completed | 301/1024 [00:07<00:15, 45.55it/s]
Loading safetensors checkpoint shards:  30% Completed | 306/1024 [00:07<00:15, 46.25it/s]
Loading safetensors checkpoint shards:  30% Completed | 311/1024 [00:07<00:15, 45.42it/s]
Loading safetensors checkpoint shards:  31% Completed | 317/1024 [00:07<00:15, 46.98it/s]
Loading safetensors checkpoint shards:  31% Completed | 322/1024 [00:07<00:15, 45.48it/s]
Loading safetensors checkpoint shards:  32% Completed | 327/1024 [00:08<00:29, 23.51it/s]
Loading safetensors checkpoint shards:  32% Completed | 332/1024 [00:08<00:25, 27.32it/s]
Loading safetensors checkpoint shards:  33% Completed | 338/1024 [00:08<00:21, 32.19it/s]
Loading safetensors checkpoint shards:  33% Completed | 343/1024 [00:08<00:19, 35.02it/s]
Loading safetensors checkpoint shards:  34% Completed | 348/1024 [00:08<00:18, 36.85it/s]
Loading safetensors checkpoint shards:  34% Completed | 353/1024 [00:08<00:17, 38.81it/s]
Loading safetensors checkpoint shards:  35% Completed | 358/1024 [00:08<00:16, 40.33it/s]
Loading safetensors checkpoint shards:  35% Completed | 363/1024 [00:08<00:15, 41.36it/s]
Loading safetensors checkpoint shards:  36% Completed | 368/1024 [00:09<00:15, 42.23it/s]
Loading safetensors checkpoint shards:  37% Completed | 374/1024 [00:09<00:14, 44.97it/s]
Loading safetensors checkpoint shards:  37% Completed | 379/1024 [00:09<00:14, 43.99it/s]
Loading safetensors checkpoint shards:  38% Completed | 385/1024 [00:09<00:13, 45.75it/s]
Loading safetensors checkpoint shards:  38% Completed | 390/1024 [00:09<00:14, 44.74it/s]
Loading safetensors checkpoint shards:  39% Completed | 395/1024 [00:09<00:13, 44.97it/s]
Loading safetensors checkpoint shards:  39% Completed | 400/1024 [00:09<00:14, 44.44it/s]
Loading safetensors checkpoint shards:  40% Completed | 405/1024 [00:09<00:13, 45.63it/s]
Loading safetensors checkpoint shards:  40% Completed | 410/1024 [00:09<00:13, 44.30it/s]
Loading safetensors checkpoint shards:  41% Completed | 415/1024 [00:10<00:13, 44.88it/s]
Loading safetensors checkpoint shards:  41% Completed | 420/1024 [00:10<00:14, 41.34it/s]
Loading safetensors checkpoint shards:  42% Completed | 425/1024 [00:10<00:14, 40.11it/s]
Loading safetensors checkpoint shards:  42% Completed | 430/1024 [00:10<00:14, 40.70it/s]
Loading safetensors checkpoint shards:  42% Completed | 435/1024 [00:10<00:16, 36.34it/s]
Loading safetensors checkpoint shards:  43% Completed | 439/1024 [00:10<00:16, 35.74it/s]
Loading safetensors checkpoint shards:  43% Completed | 443/1024 [00:10<00:16, 34.55it/s]
Loading safetensors checkpoint shards:  44% Completed | 447/1024 [00:11<00:16, 34.27it/s]
Loading safetensors checkpoint shards:  44% Completed | 452/1024 [00:11<00:15, 36.29it/s]
Loading safetensors checkpoint shards:  45% Completed | 457/1024 [00:11<00:14, 37.90it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:11<00:14, 40.05it/s]
Loading safetensors checkpoint shards:  46% Completed | 468/1024 [00:11<00:13, 40.86it/s]
Loading safetensors checkpoint shards:  46% Completed | 474/1024 [00:11<00:12, 45.27it/s]
Loading safetensors checkpoint shards:  47% Completed | 479/1024 [00:11<00:12, 45.01it/s]
Loading safetensors checkpoint shards:  47% Completed | 485/1024 [00:11<00:11, 46.71it/s]
Loading safetensors checkpoint shards:  48% Completed | 490/1024 [00:11<00:11, 44.79it/s]
Loading safetensors checkpoint shards:  48% Completed | 496/1024 [00:12<00:11, 46.43it/s]
Loading safetensors checkpoint shards:  49% Completed | 501/1024 [00:12<00:11, 46.01it/s]
Loading safetensors checkpoint shards:  49% Completed | 506/1024 [00:12<00:11, 46.38it/s]
Loading safetensors checkpoint shards:  50% Completed | 511/1024 [00:12<00:11, 45.86it/s]
Loading safetensors checkpoint shards:  50% Completed | 517/1024 [00:12<00:10, 47.75it/s]
Loading safetensors checkpoint shards:  51% Completed | 522/1024 [00:12<00:10, 45.74it/s]
Loading safetensors checkpoint shards:  52% Completed | 528/1024 [00:12<00:10, 46.99it/s]
Loading safetensors checkpoint shards:  52% Completed | 533/1024 [00:12<00:10, 45.27it/s]
Loading safetensors checkpoint shards:  53% Completed | 538/1024 [00:12<00:10, 45.49it/s]
Loading safetensors checkpoint shards:  53% Completed | 543/1024 [00:13<00:10, 44.55it/s]
Loading safetensors checkpoint shards:  54% Completed | 549/1024 [00:13<00:10, 45.85it/s]
Loading safetensors checkpoint shards:  54% Completed | 554/1024 [00:13<00:10, 45.43it/s]
Loading safetensors checkpoint shards:  55% Completed | 559/1024 [00:13<00:10, 45.73it/s]
Loading safetensors checkpoint shards:  55% Completed | 564/1024 [00:13<00:10, 44.47it/s]
Loading safetensors checkpoint shards:  56% Completed | 569/1024 [00:13<00:10, 43.50it/s]
Loading safetensors checkpoint shards:  56% Completed | 574/1024 [00:13<00:10, 44.30it/s]
Loading safetensors checkpoint shards:  57% Completed | 579/1024 [00:14<00:20, 21.31it/s]
Loading safetensors checkpoint shards:  57% Completed | 586/1024 [00:14<00:15, 27.83it/s]
Loading safetensors checkpoint shards:  58% Completed | 591/1024 [00:14<00:14, 30.52it/s]
Loading safetensors checkpoint shards:  58% Completed | 597/1024 [00:14<00:12, 34.69it/s]
Loading safetensors checkpoint shards:  59% Completed | 602/1024 [00:14<00:11, 37.04it/s]
Loading safetensors checkpoint shards:  59% Completed | 607/1024 [00:14<00:10, 39.85it/s]
Loading safetensors checkpoint shards:  60% Completed | 612/1024 [00:15<00:10, 41.09it/s]
Loading safetensors checkpoint shards:  60% Completed | 618/1024 [00:15<00:09, 43.96it/s]
Loading safetensors checkpoint shards:  61% Completed | 623/1024 [00:15<00:09, 43.65it/s]
Loading safetensors checkpoint shards:  61% Completed | 628/1024 [00:15<00:09, 43.75it/s]
Loading safetensors checkpoint shards:  62% Completed | 633/1024 [00:15<00:09, 41.96it/s]
Loading safetensors checkpoint shards:  62% Completed | 638/1024 [00:15<00:09, 42.16it/s]
Loading safetensors checkpoint shards:  63% Completed | 643/1024 [00:15<00:09, 42.32it/s]
Loading safetensors checkpoint shards:  63% Completed | 648/1024 [00:15<00:09, 41.61it/s]
Loading safetensors checkpoint shards:  64% Completed | 653/1024 [00:15<00:08, 42.10it/s]
Loading safetensors checkpoint shards:  64% Completed | 658/1024 [00:16<00:08, 42.64it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:16<00:08, 41.33it/s]
Loading safetensors checkpoint shards:  65% Completed | 668/1024 [00:16<00:08, 42.03it/s]
Loading safetensors checkpoint shards:  66% Completed | 673/1024 [00:16<00:08, 42.62it/s]
Loading safetensors checkpoint shards:  66% Completed | 678/1024 [00:16<00:08, 41.76it/s]
Loading safetensors checkpoint shards:  67% Completed | 683/1024 [00:16<00:08, 42.18it/s]
Loading safetensors checkpoint shards:  67% Completed | 688/1024 [00:16<00:07, 42.37it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:16<00:07, 44.59it/s]
Loading safetensors checkpoint shards:  68% Completed | 699/1024 [00:17<00:07, 44.02it/s]
Loading safetensors checkpoint shards:  69% Completed | 704/1024 [00:17<00:07, 42.45it/s]
Loading safetensors checkpoint shards:  69% Completed | 709/1024 [00:17<00:07, 41.96it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:17<00:07, 42.43it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:17<00:07, 41.54it/s]
Loading safetensors checkpoint shards:  71% Completed | 724/1024 [00:17<00:07, 41.18it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:17<00:07, 41.51it/s]
Loading safetensors checkpoint shards:  72% Completed | 734/1024 [00:17<00:07, 40.75it/s]
Loading safetensors checkpoint shards:  72% Completed | 739/1024 [00:18<00:07, 40.63it/s]
Loading safetensors checkpoint shards:  73% Completed | 744/1024 [00:18<00:06, 40.12it/s]
Loading safetensors checkpoint shards:  73% Completed | 749/1024 [00:18<00:07, 37.62it/s]
Loading safetensors checkpoint shards:  74% Completed | 753/1024 [00:18<00:07, 37.30it/s]
Loading safetensors checkpoint shards:  74% Completed | 757/1024 [00:18<00:07, 37.36it/s]
Loading safetensors checkpoint shards:  74% Completed | 761/1024 [00:18<00:07, 37.44it/s]
Loading safetensors checkpoint shards:  75% Completed | 765/1024 [00:18<00:06, 37.33it/s]
Loading safetensors checkpoint shards:  75% Completed | 769/1024 [00:18<00:06, 37.24it/s]
Loading safetensors checkpoint shards:  75% Completed | 773/1024 [00:18<00:06, 36.53it/s]
Loading safetensors checkpoint shards:  76% Completed | 777/1024 [00:19<00:06, 36.59it/s]
Loading safetensors checkpoint shards:  76% Completed | 781/1024 [00:19<00:06, 36.96it/s]
Loading safetensors checkpoint shards:  77% Completed | 785/1024 [00:19<00:06, 37.44it/s]
Loading safetensors checkpoint shards:  77% Completed | 789/1024 [00:19<00:06, 36.77it/s]
Loading safetensors checkpoint shards:  77% Completed | 793/1024 [00:19<00:06, 37.47it/s]
Loading safetensors checkpoint shards:  78% Completed | 797/1024 [00:19<00:06, 37.63it/s]
Loading safetensors checkpoint shards:  78% Completed | 801/1024 [00:19<00:05, 38.00it/s]
Loading safetensors checkpoint shards:  79% Completed | 806/1024 [00:19<00:05, 39.47it/s]
Loading safetensors checkpoint shards:  79% Completed | 810/1024 [00:19<00:05, 39.17it/s]
Loading safetensors checkpoint shards:  79% Completed | 814/1024 [00:20<00:05, 39.09it/s]
Loading safetensors checkpoint shards:  80% Completed | 818/1024 [00:20<00:05, 39.13it/s]
Loading safetensors checkpoint shards:  80% Completed | 822/1024 [00:20<00:05, 39.31it/s]
Loading safetensors checkpoint shards:  81% Completed | 827/1024 [00:20<00:04, 40.65it/s]
Loading safetensors checkpoint shards:  81% Completed | 832/1024 [00:20<00:04, 42.21it/s]
Loading safetensors checkpoint shards:  82% Completed | 837/1024 [00:20<00:04, 42.80it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:20<00:04, 42.57it/s]
Loading safetensors checkpoint shards:  83% Completed | 847/1024 [00:20<00:04, 40.27it/s]
Loading safetensors checkpoint shards:  83% Completed | 852/1024 [00:20<00:04, 40.69it/s]
Loading safetensors checkpoint shards:  84% Completed | 857/1024 [00:21<00:04, 40.81it/s]
Loading safetensors checkpoint shards:  84% Completed | 862/1024 [00:21<00:04, 39.64it/s]
Loading safetensors checkpoint shards:  85% Completed | 867/1024 [00:21<00:03, 39.99it/s]
Loading safetensors checkpoint shards:  85% Completed | 872/1024 [00:21<00:08, 17.82it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:22<00:07, 20.37it/s]
Loading safetensors checkpoint shards:  86% Completed | 880/1024 [00:22<00:06, 23.34it/s]
Loading safetensors checkpoint shards:  86% Completed | 884/1024 [00:22<00:05, 26.36it/s]
Loading safetensors checkpoint shards:  87% Completed | 888/1024 [00:22<00:04, 29.01it/s]
Loading safetensors checkpoint shards:  87% Completed | 892/1024 [00:22<00:04, 30.22it/s]
Loading safetensors checkpoint shards:  88% Completed | 896/1024 [00:22<00:03, 32.51it/s]
Loading safetensors checkpoint shards:  88% Completed | 900/1024 [00:22<00:03, 34.14it/s]
Loading safetensors checkpoint shards:  88% Completed | 904/1024 [00:22<00:03, 35.07it/s]
Loading safetensors checkpoint shards:  89% Completed | 908/1024 [00:22<00:03, 36.29it/s]
Loading safetensors checkpoint shards:  89% Completed | 912/1024 [00:23<00:03, 36.68it/s]
Loading safetensors checkpoint shards:  90% Completed | 917/1024 [00:23<00:02, 38.47it/s]
Loading safetensors checkpoint shards:  90% Completed | 921/1024 [00:23<00:02, 38.30it/s]
Loading safetensors checkpoint shards:  90% Completed | 925/1024 [00:23<00:02, 38.16it/s]
Loading safetensors checkpoint shards:  91% Completed | 929/1024 [00:23<00:02, 38.28it/s]
Loading safetensors checkpoint shards:  91% Completed | 933/1024 [00:23<00:02, 36.87it/s]
Loading safetensors checkpoint shards:  92% Completed | 937/1024 [00:23<00:02, 36.84it/s]
Loading safetensors checkpoint shards:  92% Completed | 941/1024 [00:23<00:02, 36.60it/s]
Loading safetensors checkpoint shards:  92% Completed | 945/1024 [00:23<00:02, 34.78it/s]
Loading safetensors checkpoint shards:  93% Completed | 949/1024 [00:24<00:02, 33.84it/s]
Loading safetensors checkpoint shards:  93% Completed | 953/1024 [00:24<00:02, 33.36it/s]
Loading safetensors checkpoint shards:  93% Completed | 957/1024 [00:24<00:01, 34.21it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:24<00:01, 34.42it/s]
Loading safetensors checkpoint shards:  94% Completed | 965/1024 [00:24<00:01, 35.09it/s]
Loading safetensors checkpoint shards:  95% Completed | 969/1024 [00:24<00:01, 35.39it/s]
Loading safetensors checkpoint shards:  95% Completed | 973/1024 [00:24<00:01, 34.74it/s]
Loading safetensors checkpoint shards:  95% Completed | 977/1024 [00:24<00:01, 35.65it/s]
Loading safetensors checkpoint shards:  96% Completed | 981/1024 [00:24<00:01, 36.60it/s]
Loading safetensors checkpoint shards:  98% Completed | 1003/1024 [00:25<00:00, 84.61it/s]
Loading safetensors checkpoint shards:  99% Completed | 1014/1024 [00:25<00:00, 82.20it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 40.55it/s]

[2025-09-13 07:22:45 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:22:47 TP5] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:22:47 TP3] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:22:47 TP7] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:22:47 TP6] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:22:47 TP1] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:22:47 TP4] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:22:47 TP2] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:22:47 TP0] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:22:47 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:22:47 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:22:48 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.51 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s][2025-09-13 07:22:48 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:22:48 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:22:49 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:22:49 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:22:49 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:22:49 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:22:49 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:22:49 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:22:49 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26047.83it/s]
[2025-09-13 07:22:49 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:22:49 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26870.00it/s]
[2025-09-13 07:22:50 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:22:50 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27900.29it/s]
[2025-09-13 07:22:50 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:22:50 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27456.68it/s]
[2025-09-13 07:22:51 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:22:51 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28348.40it/s]
[2025-09-13 07:22:52 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.20 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.14it/s]
[2025-09-13 07:22:55 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:22:55 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:22:55 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:22:55 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:22:55 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:22:55 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:22:55 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:22:55 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:22:55 TP0] Capture cuda graph end. Time elapsed: 7.84 s. mem usage=0.39 GB. avail mem=17.17 GB.
[2025-09-13 07:22:55 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:22:55 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:22:55 TP0] Init torch distributed begin.
[2025-09-13 07:22:55 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:22:55 TP0] Load weight begin. avail mem=17.17 GB
[2025-09-13 07:22:55 TP0] Detected fp8 checkpoint.
[2025-09-13 07:22:55 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 177.65it/s]
Loading safetensors checkpoint shards:   4% Completed | 43/1024 [00:00<00:04, 219.71it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:00<00:02, 385.49it/s]
Loading safetensors checkpoint shards:  16% Completed | 162/1024 [00:00<00:01, 469.20it/s]
Loading safetensors checkpoint shards:  22% Completed | 221/1024 [00:00<00:01, 509.50it/s]
Loading safetensors checkpoint shards:  28% Completed | 282/1024 [00:00<00:01, 543.36it/s]
Loading safetensors checkpoint shards:  33% Completed | 343/1024 [00:00<00:01, 564.40it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:00<00:01, 583.05it/s]
Loading safetensors checkpoint shards:  46% Completed | 467/1024 [00:00<00:00, 590.87it/s]
Loading safetensors checkpoint shards:  52% Completed | 530/1024 [00:01<00:00, 602.04it/s]
Loading safetensors checkpoint shards:  58% Completed | 592/1024 [00:01<00:00, 606.80it/s]
Loading safetensors checkpoint shards:  64% Completed | 653/1024 [00:01<00:00, 604.06it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:01<00:00, 597.72it/s]
Loading safetensors checkpoint shards:  76% Completed | 774/1024 [00:01<00:00, 591.43it/s]
Loading safetensors checkpoint shards:  81% Completed | 834/1024 [00:01<00:00, 589.64it/s]
Loading safetensors checkpoint shards:  87% Completed | 893/1024 [00:01<00:00, 586.39it/s]
Loading safetensors checkpoint shards:  93% Completed | 952/1024 [00:01<00:00, 585.02it/s]
Loading safetensors checkpoint shards:  99% Completed | 1011/1024 [00:01<00:00, 399.15it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 501.85it/s]

[2025-09-13 07:22:58 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.18 GB, mem usage=1.99 GB.
[2025-09-13 07:22:58 TP0] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:22:58 TP4] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:22:58 TP7] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:22:58 TP0] Memory pool end. avail mem=14.52 GB
[2025-09-13 07:22:58 TP5] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:22:58 TP6] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:22:58 TP2] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:22:58 TP1] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:22:58 TP3] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:22:58 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:22:58 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.14 GB
[2025-09-13 07:22:58 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:22:58 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:22:58 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:22:58 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.95 GB
[2025-09-13 07:22:58 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:22:58 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
Capturing batches (bs=1 avail_mem=14.59 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  3.06it/s][2025-09-13 07:23:04 TP1] Registering 96 cuda graph addresses
[2025-09-13 07:23:04 TP7] Registering 96 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.59 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.58it/s][2025-09-13 07:23:04 TP4] Registering 96 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.59 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.41it/s]
[2025-09-13 07:23:04 TP2] Registering 96 cuda graph addresses
[2025-09-13 07:23:04 TP0] Registering 96 cuda graph addresses
[2025-09-13 07:23:04 TP3] Registering 96 cuda graph addresses
[2025-09-13 07:23:04 TP6] Registering 96 cuda graph addresses
[2025-09-13 07:23:04 TP5] Registering 96 cuda graph addresses
[2025-09-13 07:23:04 TP6] Capture draft cuda graph end. Time elapsed: 6.40 s. mem usage=0.36 GB. avail mem=14.54 GB.
[2025-09-13 07:23:04 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 07:23:04 TP4] Capture draft cuda graph end. Time elapsed: 6.40 s. mem usage=0.36 GB. avail mem=14.54 GB.
[2025-09-13 07:23:04 TP3] Capture draft cuda graph end. Time elapsed: 6.40 s. mem usage=0.36 GB. avail mem=14.54 GB.
[2025-09-13 07:23:04 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 07:23:04 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 07:23:04 TP2] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.36 GB. avail mem=14.54 GB.
[2025-09-13 07:23:04 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 07:23:04 TP5] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.36 GB. avail mem=14.54 GB.
[2025-09-13 07:23:04 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 07:23:04 TP7] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.36 GB. avail mem=14.78 GB.
[2025-09-13 07:23:04 TP0] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.37 GB. avail mem=14.58 GB.
[2025-09-13 07:23:04 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.58 GB
[2025-09-13 07:23:04 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.78 GB
[2025-09-13 07:23:04 TP1] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.36 GB. avail mem=14.54 GB.
[2025-09-13 07:23:04 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
Capturing batches (bs=1 avail_mem=14.40 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 21.75it/s]
[2025-09-13 07:23:05 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:23:05 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:23:05 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:23:05 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:23:05 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:23:05 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:23:05 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:23:05 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:23:05 TP7] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.59 GB.
[2025-09-13 07:23:05 TP4] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.36 GB.
[2025-09-13 07:23:05 TP2] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.36 GB.
[2025-09-13 07:23:05 TP0] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.40 GB.
[2025-09-13 07:23:05 TP6] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.19 GB. avail mem=14.36 GB.
[2025-09-13 07:23:05 TP0] max_total_num_tokens=620201, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.40 GB
[2025-09-13 07:23:05 TP1] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.36 GB.
[2025-09-13 07:23:05 TP3] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.19 GB. avail mem=14.36 GB.
[2025-09-13 07:23:05 TP5] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.36 GB.
[2025-09-13 07:23:06] INFO:     Started server process [272270]
[2025-09-13 07:23:06] INFO:     Waiting for application startup.
[2025-09-13 07:23:06] INFO:     Application startup complete.
[2025-09-13 07:23:06] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:23:07] INFO:     127.0.0.1:56300 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:23:07 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:23:07 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:23:07 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup:  29%|█████████████████████████████▊                                                                          | 4693/16384 [00:00<00:00, 23824.88it/s][2025-09-13 07:23:07] INFO:     127.0.0.1:56324 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28698.68it/s]
[2025-09-13 07:23:08] INFO:     127.0.0.1:56314 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:08] The server is fired up and ready to roll!
[2025-09-13 07:23:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:23:18] INFO:     127.0.0.1:41722 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:23:19] INFO:     127.0.0.1:58224 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:19 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:23:20] INFO:     127.0.0.1:58236 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:20] INFO:     127.0.0.1:58240 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:23:20] INFO:     127.0.0.1:58250 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:20] INFO:     127.0.0.1:58266 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:20] INFO:     127.0.0.1:58282 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:20] INFO:     127.0.0.1:58288 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:20] INFO:     127.0.0.1:58290 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:20] INFO:     127.0.0.1:58296 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:20 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:23:21 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:23:21 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:23:21 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:23:21 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:23:21 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:23:21 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:23:21 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:23:21 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:23:21 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:23:22 TP0] Decode batch. #running-req: 8, #token: 14608, token usage: 0.02, accept len: 3.14, cuda graph: True, gen throughput (token/s): 43.96, #queue-req: 0, 
[2025-09-13 07:23:23 TP0] Decode batch. #running-req: 8, #token: 15889, token usage: 0.03, accept len: 4.00, cuda graph: True, gen throughput (token/s): 954.38, #queue-req: 0, 
[2025-09-13 07:23:25 TP0] Decode batch. #running-req: 8, #token: 17301, token usage: 0.03, accept len: 4.41, cuda graph: True, gen throughput (token/s): 1042.34, #queue-req: 0, 
 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 7/8 [00:05<00:00,  2.72it/s][2025-09-13 07:23:26 TP0] Decode batch. #running-req: 1, #token: 1456, token usage: 0.00, accept len: 3.89, cuda graph: True, gen throughput (token/s): 485.13, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.34it/s]
[2025-09-13 07:23:26] INFO:     127.0.0.1:58302 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  5.99      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4085      
Request throughput (req/s):              1.34      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         683.63    
Total token throughput (tok/s):          683.63    
Concurrency:                             6.86      
Accept length:                           3.92      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5135.23   
Median E2E Latency (ms):                 5172.92   
---------------Time to First Token----------------
Mean TTFT (ms):                          613.03    
Median TTFT (ms):                        725.06    
P99 TTFT (ms):                           725.58    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           8.85      
Median ITL (ms):                         6.40      
P95 ITL (ms):                            16.91     
P99 ITL (ms):                            33.69     
Max ITL (ms):                            733.35    
==================================================
[2025-09-13 07:23:26] INFO:     127.0.0.1:58318 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:23:26] INFO:     127.0.0.1:58322 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:23:28] INFO:     127.0.0.1:34648 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:28] INFO:     127.0.0.1:34650 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:23:28] INFO:     127.0.0.1:34652 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:28] INFO:     127.0.0.1:34662 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:28] INFO:     127.0.0.1:34678 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:28] INFO:     127.0.0.1:34682 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:28] INFO:     127.0.0.1:34686 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:28] INFO:     127.0.0.1:34690 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:28 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:23:28 TP0] Decode batch. #running-req: 8, #token: 14273, token usage: 0.02, accept len: 3.07, cuda graph: True, gen throughput (token/s): 186.83, #queue-req: 0, 
[2025-09-13 07:23:30 TP0] Decode batch. #running-req: 8, #token: 15478, token usage: 0.02, accept len: 3.77, cuda graph: True, gen throughput (token/s): 913.19, #queue-req: 0, 
[2025-09-13 07:23:31 TP0] Decode batch. #running-req: 8, #token: 16889, token usage: 0.03, accept len: 4.41, cuda graph: True, gen throughput (token/s): 1046.79, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:03<00:58,  3.88s/it][2025-09-13 07:23:31] INFO:     127.0.0.1:34692 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:31 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:25,  1.82s/it][2025-09-13 07:23:32] INFO:     127.0.0.1:34706 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:04<00:14,  1.14s/it][2025-09-13 07:23:32] INFO:     127.0.0.1:34714 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:32 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.14it/s][2025-09-13 07:23:33] INFO:     127.0.0.1:34718 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:33 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:06,  1.59it/s][2025-09-13 07:23:33] INFO:     127.0.0.1:34722 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:33 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:23:33 TP0] Decode batch. #running-req: 8, #token: 9505, token usage: 0.02, accept len: 3.93, cuda graph: True, gen throughput (token/s): 578.31, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.92it/s][2025-09-13 07:23:33] INFO:     127.0.0.1:34726 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:33 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:05<00:04,  2.23it/s][2025-09-13 07:23:33] INFO:     127.0.0.1:34738 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:04,  1.97it/s][2025-09-13 07:23:34] INFO:     127.0.0.1:34742 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:23:34 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:23:35 TP0] Decode batch. #running-req: 8, #token: 14690, token usage: 0.02, accept len: 3.46, cuda graph: True, gen throughput (token/s): 605.25, #queue-req: 0, 
[2025-09-13 07:23:36 TP0] Decode batch. #running-req: 8, #token: 15949, token usage: 0.03, accept len: 3.93, cuda graph: True, gen throughput (token/s): 942.78, #queue-req: 0, 
 62%|████████████████████████████████████████████████████████████████████████████████▋                                                | 10/16 [00:09<00:05,  1.00it/s][2025-09-13 07:23:38 TP0] Decode batch. #running-req: 6, #token: 10450, token usage: 0.02, accept len: 4.12, cuda graph: True, gen throughput (token/s): 900.18, #queue-req: 0, 
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 15/16 [00:10<00:00,  3.04it/s][2025-09-13 07:23:39 TP0] Decode batch. #running-req: 1, #token: 1886, token usage: 0.00, accept len: 3.24, cuda graph: True, gen throughput (token/s): 392.02, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.40it/s]
[2025-09-13 07:23:39] INFO:     127.0.0.1:49658 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.45     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    7998      
Request throughput (req/s):              1.40      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         715.69    
Total token throughput (tok/s):          715.69    
Concurrency:                             7.24      
Accept length:                           3.86      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5182.05   
Median E2E Latency (ms):                 5137.02   
---------------Time to First Token----------------
Mean TTFT (ms):                          229.34    
Median TTFT (ms):                        238.43    
P99 TTFT (ms):                           295.13    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.69      
Median ITL (ms):                         6.55      
P95 ITL (ms):                            26.90     
P99 ITL (ms):                            53.21     
Max ITL (ms):                            268.26    
==================================================
[2025-09-13 07:23:39] INFO:     127.0.0.1:49662 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=26: batch_size=8, steps=5, topk=2, num_draft_tokens=8, speed=115.31 token/s, step_time=33.49 ms
Start i=27: batch_size=8, steps=5, topk=3, num_draft_tokens=4
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 5 --speculative-eagle-topk 3 --speculative-num-draft-tokens 4 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:23:50.319000 277948 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:23:50.319000 277948 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:23:50] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=71211767, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=5, speculative_eagle_topk=3, speculative_num_draft_tokens=4, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:23:51] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:23:59.386000 278200 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:23:59.386000 278200 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:23:59.463000 278201 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:23:59.463000 278201 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:23:59.649000 278202 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:23:59.649000 278202 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:23:59.789000 278207 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:23:59.789000 278207 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:23:59.822000 278206 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:23:59.822000 278206 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:23:59.826000 278204 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:23:59.826000 278204 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:23:59.838000 278208 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:23:59.838000 278208 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:23:59.887000 278203 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:23:59.887000 278203 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:23:59.911000 278205 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:23:59.911000 278205 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[2025-09-13 07:24:00 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:24:00 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:24:00 TP0] Init torch distributed begin.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:24:01 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:24:04 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:24:06 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:24:06 TP0] Detected fp8 checkpoint.
[2025-09-13 07:24:06 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:04, 221.41it/s]
Loading safetensors checkpoint shards:   5% Completed | 49/1024 [00:00<00:13, 72.52it/s]
Loading safetensors checkpoint shards:   6% Completed | 61/1024 [00:00<00:17, 55.86it/s]
Loading safetensors checkpoint shards:   7% Completed | 70/1024 [00:01<00:20, 47.65it/s]
Loading safetensors checkpoint shards:   8% Completed | 77/1024 [00:01<00:20, 45.14it/s]
Loading safetensors checkpoint shards:   8% Completed | 83/1024 [00:01<00:21, 44.49it/s]
Loading safetensors checkpoint shards:   9% Completed | 88/1024 [00:01<00:21, 43.02it/s]
Loading safetensors checkpoint shards:   9% Completed | 93/1024 [00:01<00:22, 40.77it/s]
Loading safetensors checkpoint shards:  10% Completed | 98/1024 [00:01<00:23, 39.68it/s]
Loading safetensors checkpoint shards:  10% Completed | 103/1024 [00:02<00:23, 39.02it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:02<00:23, 38.92it/s]
Loading safetensors checkpoint shards:  11% Completed | 112/1024 [00:02<00:41, 21.85it/s]
Loading safetensors checkpoint shards:  11% Completed | 117/1024 [00:02<00:35, 25.38it/s]
Loading safetensors checkpoint shards:  12% Completed | 121/1024 [00:02<00:32, 27.48it/s]
Loading safetensors checkpoint shards:  12% Completed | 125/1024 [00:03<00:30, 29.15it/s]
Loading safetensors checkpoint shards:  13% Completed | 130/1024 [00:03<00:27, 32.45it/s]
Loading safetensors checkpoint shards:  13% Completed | 134/1024 [00:03<00:27, 32.23it/s]
Loading safetensors checkpoint shards:  14% Completed | 140/1024 [00:03<00:24, 36.77it/s]
Loading safetensors checkpoint shards:  14% Completed | 144/1024 [00:03<00:23, 37.33it/s]
Loading safetensors checkpoint shards:  14% Completed | 148/1024 [00:03<00:24, 36.13it/s]
Loading safetensors checkpoint shards:  15% Completed | 153/1024 [00:03<00:22, 39.18it/s]
Loading safetensors checkpoint shards:  15% Completed | 158/1024 [00:03<00:22, 39.17it/s]
Loading safetensors checkpoint shards:  16% Completed | 163/1024 [00:03<00:20, 41.28it/s]
Loading safetensors checkpoint shards:  16% Completed | 168/1024 [00:04<00:21, 39.07it/s]
Loading safetensors checkpoint shards:  17% Completed | 173/1024 [00:04<00:20, 41.00it/s]
Loading safetensors checkpoint shards:  17% Completed | 178/1024 [00:04<00:21, 39.85it/s]
Loading safetensors checkpoint shards:  18% Completed | 183/1024 [00:04<00:20, 40.30it/s]
Loading safetensors checkpoint shards:  18% Completed | 188/1024 [00:04<00:21, 39.33it/s]
Loading safetensors checkpoint shards:  19% Completed | 192/1024 [00:04<00:21, 39.06it/s]
Loading safetensors checkpoint shards:  19% Completed | 197/1024 [00:04<00:20, 40.95it/s]
Loading safetensors checkpoint shards:  20% Completed | 202/1024 [00:04<00:20, 39.94it/s]
Loading safetensors checkpoint shards:  20% Completed | 207/1024 [00:05<00:20, 39.43it/s]
Loading safetensors checkpoint shards:  21% Completed | 211/1024 [00:05<00:20, 38.95it/s]
Loading safetensors checkpoint shards:  21% Completed | 216/1024 [00:05<00:19, 41.48it/s]
Loading safetensors checkpoint shards:  22% Completed | 221/1024 [00:05<00:19, 41.92it/s]
Loading safetensors checkpoint shards:  22% Completed | 226/1024 [00:05<00:18, 43.31it/s]
Loading safetensors checkpoint shards:  23% Completed | 231/1024 [00:05<00:18, 43.31it/s]
Loading safetensors checkpoint shards:  23% Completed | 236/1024 [00:05<00:19, 40.08it/s]
Loading safetensors checkpoint shards:  24% Completed | 241/1024 [00:05<00:18, 41.63it/s]
Loading safetensors checkpoint shards:  24% Completed | 246/1024 [00:05<00:18, 41.90it/s]
Loading safetensors checkpoint shards:  25% Completed | 252/1024 [00:06<00:17, 44.79it/s]
Loading safetensors checkpoint shards:  25% Completed | 258/1024 [00:06<00:16, 47.49it/s]
Loading safetensors checkpoint shards:  26% Completed | 266/1024 [00:06<00:13, 55.08it/s]
Loading safetensors checkpoint shards:  27% Completed | 273/1024 [00:06<00:12, 58.66it/s]
Loading safetensors checkpoint shards:  27% Completed | 279/1024 [00:06<00:13, 54.06it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:06<00:13, 53.50it/s]
Loading safetensors checkpoint shards:  28% Completed | 291/1024 [00:07<00:32, 22.49it/s]
Loading safetensors checkpoint shards:  29% Completed | 297/1024 [00:07<00:27, 26.69it/s]
Loading safetensors checkpoint shards:  29% Completed | 302/1024 [00:07<00:24, 29.04it/s]
Loading safetensors checkpoint shards:  30% Completed | 307/1024 [00:07<00:23, 31.11it/s]
Loading safetensors checkpoint shards:  30% Completed | 312/1024 [00:07<00:22, 31.67it/s]
Loading safetensors checkpoint shards:  31% Completed | 316/1024 [00:07<00:21, 32.94it/s]
Loading safetensors checkpoint shards:  31% Completed | 321/1024 [00:08<00:20, 34.82it/s]
Loading safetensors checkpoint shards:  32% Completed | 325/1024 [00:08<00:20, 33.70it/s]
Loading safetensors checkpoint shards:  32% Completed | 330/1024 [00:08<00:18, 37.00it/s]
Loading safetensors checkpoint shards:  33% Completed | 335/1024 [00:08<00:17, 38.99it/s]
Loading safetensors checkpoint shards:  33% Completed | 340/1024 [00:08<00:16, 41.61it/s]
Loading safetensors checkpoint shards:  34% Completed | 345/1024 [00:08<00:18, 36.72it/s]
Loading safetensors checkpoint shards:  34% Completed | 350/1024 [00:08<00:17, 37.53it/s]
Loading safetensors checkpoint shards:  35% Completed | 355/1024 [00:08<00:16, 40.03it/s]
Loading safetensors checkpoint shards:  35% Completed | 360/1024 [00:09<00:16, 40.42it/s]
Loading safetensors checkpoint shards:  36% Completed | 365/1024 [00:09<00:17, 37.64it/s]
Loading safetensors checkpoint shards:  36% Completed | 369/1024 [00:09<00:18, 36.03it/s]
Loading safetensors checkpoint shards:  36% Completed | 373/1024 [00:09<00:18, 35.93it/s]
Loading safetensors checkpoint shards:  37% Completed | 377/1024 [00:09<00:19, 33.15it/s]
Loading safetensors checkpoint shards:  37% Completed | 382/1024 [00:09<00:17, 37.23it/s]
Loading safetensors checkpoint shards:  38% Completed | 387/1024 [00:09<00:16, 38.84it/s]
Loading safetensors checkpoint shards:  38% Completed | 391/1024 [00:09<00:17, 37.06it/s]
Loading safetensors checkpoint shards:  39% Completed | 396/1024 [00:10<00:16, 38.59it/s]
Loading safetensors checkpoint shards:  39% Completed | 400/1024 [00:10<00:16, 37.97it/s]
Loading safetensors checkpoint shards:  40% Completed | 405/1024 [00:10<00:15, 40.41it/s]
Loading safetensors checkpoint shards:  40% Completed | 410/1024 [00:10<00:15, 40.81it/s]
Loading safetensors checkpoint shards:  41% Completed | 415/1024 [00:10<00:14, 42.82it/s]
Loading safetensors checkpoint shards:  41% Completed | 420/1024 [00:10<00:14, 40.64it/s]
Loading safetensors checkpoint shards:  42% Completed | 425/1024 [00:10<00:14, 40.45it/s]
Loading safetensors checkpoint shards:  42% Completed | 430/1024 [00:10<00:14, 41.95it/s]
Loading safetensors checkpoint shards:  42% Completed | 435/1024 [00:10<00:14, 40.32it/s]
Loading safetensors checkpoint shards:  43% Completed | 440/1024 [00:11<00:13, 41.98it/s]
Loading safetensors checkpoint shards:  43% Completed | 445/1024 [00:11<00:14, 41.14it/s]
Loading safetensors checkpoint shards:  44% Completed | 450/1024 [00:11<00:13, 41.30it/s]
Loading safetensors checkpoint shards:  44% Completed | 455/1024 [00:11<00:14, 40.04it/s]
Loading safetensors checkpoint shards:  45% Completed | 460/1024 [00:11<00:13, 41.66it/s]
Loading safetensors checkpoint shards:  45% Completed | 465/1024 [00:11<00:13, 40.49it/s]
Loading safetensors checkpoint shards:  46% Completed | 470/1024 [00:11<00:13, 42.01it/s]
Loading safetensors checkpoint shards:  46% Completed | 475/1024 [00:11<00:12, 43.47it/s]
Loading safetensors checkpoint shards:  47% Completed | 480/1024 [00:12<00:12, 43.06it/s]
Loading safetensors checkpoint shards:  47% Completed | 485/1024 [00:12<00:12, 44.43it/s]
Loading safetensors checkpoint shards:  48% Completed | 490/1024 [00:12<00:12, 42.59it/s]
Loading safetensors checkpoint shards:  48% Completed | 495/1024 [00:12<00:11, 44.28it/s]
Loading safetensors checkpoint shards:  49% Completed | 500/1024 [00:12<00:25, 20.37it/s]
Loading safetensors checkpoint shards:  49% Completed | 505/1024 [00:13<00:21, 23.91it/s]
Loading safetensors checkpoint shards:  50% Completed | 509/1024 [00:13<00:19, 26.19it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:13<00:17, 28.47it/s]
Loading safetensors checkpoint shards:  51% Completed | 518/1024 [00:13<00:15, 32.26it/s]
Loading safetensors checkpoint shards:  51% Completed | 522/1024 [00:13<00:15, 33.35it/s]
Loading safetensors checkpoint shards:  51% Completed | 527/1024 [00:13<00:13, 36.60it/s]
Loading safetensors checkpoint shards:  52% Completed | 532/1024 [00:13<00:13, 37.33it/s]
Loading safetensors checkpoint shards:  52% Completed | 537/1024 [00:13<00:12, 38.00it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:13<00:12, 38.03it/s]
Loading safetensors checkpoint shards:  53% Completed | 545/1024 [00:14<00:12, 38.14it/s]
Loading safetensors checkpoint shards:  54% Completed | 550/1024 [00:14<00:11, 40.74it/s]
Loading safetensors checkpoint shards:  54% Completed | 555/1024 [00:14<00:11, 40.49it/s]
Loading safetensors checkpoint shards:  55% Completed | 561/1024 [00:14<00:10, 44.94it/s]
Loading safetensors checkpoint shards:  55% Completed | 566/1024 [00:14<00:10, 43.12it/s]
Loading safetensors checkpoint shards:  56% Completed | 571/1024 [00:14<00:10, 43.20it/s]
Loading safetensors checkpoint shards:  56% Completed | 576/1024 [00:14<00:11, 39.97it/s]
Loading safetensors checkpoint shards:  57% Completed | 581/1024 [00:14<00:10, 40.98it/s]
Loading safetensors checkpoint shards:  57% Completed | 586/1024 [00:15<00:10, 41.35it/s]
Loading safetensors checkpoint shards:  58% Completed | 591/1024 [00:15<00:10, 39.53it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:15<00:10, 41.46it/s]
Loading safetensors checkpoint shards:  59% Completed | 601/1024 [00:15<00:10, 40.63it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:15<00:10, 40.45it/s]
Loading safetensors checkpoint shards:  60% Completed | 611/1024 [00:15<00:10, 39.99it/s]
Loading safetensors checkpoint shards:  60% Completed | 616/1024 [00:15<00:09, 41.34it/s]
Loading safetensors checkpoint shards:  61% Completed | 621/1024 [00:15<00:09, 41.44it/s]
Loading safetensors checkpoint shards:  61% Completed | 626/1024 [00:16<00:09, 40.79it/s]
Loading safetensors checkpoint shards:  62% Completed | 631/1024 [00:16<00:09, 39.40it/s]
Loading safetensors checkpoint shards:  62% Completed | 635/1024 [00:16<00:10, 38.24it/s]
Loading safetensors checkpoint shards:  62% Completed | 640/1024 [00:16<00:09, 38.99it/s]
Loading safetensors checkpoint shards:  63% Completed | 645/1024 [00:16<00:09, 38.24it/s]
Loading safetensors checkpoint shards:  63% Completed | 649/1024 [00:16<00:09, 38.31it/s]
Loading safetensors checkpoint shards:  64% Completed | 653/1024 [00:16<00:09, 38.36it/s]
Loading safetensors checkpoint shards:  64% Completed | 657/1024 [00:16<00:09, 37.50it/s]
Loading safetensors checkpoint shards:  65% Completed | 661/1024 [00:16<00:10, 35.23it/s]
Loading safetensors checkpoint shards:  65% Completed | 665/1024 [00:17<00:10, 35.68it/s]
Loading safetensors checkpoint shards:  65% Completed | 670/1024 [00:17<00:09, 37.70it/s]
Loading safetensors checkpoint shards:  66% Completed | 675/1024 [00:17<00:08, 39.19it/s]
Loading safetensors checkpoint shards:  66% Completed | 679/1024 [00:17<00:08, 38.82it/s]
Loading safetensors checkpoint shards:  67% Completed | 684/1024 [00:17<00:08, 39.68it/s]
Loading safetensors checkpoint shards:  67% Completed | 689/1024 [00:17<00:08, 40.81it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:17<00:07, 43.04it/s]
Loading safetensors checkpoint shards:  68% Completed | 699/1024 [00:17<00:07, 42.86it/s]
Loading safetensors checkpoint shards:  69% Completed | 704/1024 [00:18<00:07, 41.02it/s]
Loading safetensors checkpoint shards:  69% Completed | 709/1024 [00:18<00:07, 41.29it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:18<00:07, 41.80it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:18<00:07, 41.07it/s]
Loading safetensors checkpoint shards:  71% Completed | 724/1024 [00:18<00:07, 41.84it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:18<00:06, 42.60it/s]
Loading safetensors checkpoint shards:  72% Completed | 734/1024 [00:18<00:06, 41.98it/s]
Loading safetensors checkpoint shards:  72% Completed | 739/1024 [00:18<00:06, 42.37it/s]
Loading safetensors checkpoint shards:  73% Completed | 744/1024 [00:18<00:06, 42.78it/s]
Loading safetensors checkpoint shards:  73% Completed | 749/1024 [00:19<00:06, 42.14it/s]
Loading safetensors checkpoint shards:  74% Completed | 754/1024 [00:19<00:06, 42.92it/s]
Loading safetensors checkpoint shards:  74% Completed | 759/1024 [00:19<00:06, 43.26it/s]
Loading safetensors checkpoint shards:  75% Completed | 764/1024 [00:19<00:05, 43.98it/s]
Loading safetensors checkpoint shards:  75% Completed | 769/1024 [00:19<00:05, 44.32it/s]
Loading safetensors checkpoint shards:  76% Completed | 774/1024 [00:19<00:05, 43.24it/s]
Loading safetensors checkpoint shards:  76% Completed | 779/1024 [00:19<00:05, 43.67it/s]
Loading safetensors checkpoint shards:  77% Completed | 784/1024 [00:20<00:13, 18.16it/s]
Loading safetensors checkpoint shards:  77% Completed | 788/1024 [00:20<00:11, 20.98it/s]
Loading safetensors checkpoint shards:  77% Completed | 793/1024 [00:20<00:09, 25.06it/s]
Loading safetensors checkpoint shards:  78% Completed | 798/1024 [00:20<00:07, 28.69it/s]
Loading safetensors checkpoint shards:  78% Completed | 802/1024 [00:20<00:07, 30.79it/s]
Loading safetensors checkpoint shards:  79% Completed | 807/1024 [00:20<00:06, 35.07it/s]
Loading safetensors checkpoint shards:  79% Completed | 812/1024 [00:21<00:05, 37.40it/s]
Loading safetensors checkpoint shards:  80% Completed | 817/1024 [00:21<00:05, 38.50it/s]
Loading safetensors checkpoint shards:  80% Completed | 822/1024 [00:21<00:05, 39.25it/s]
Loading safetensors checkpoint shards:  81% Completed | 827/1024 [00:21<00:04, 40.42it/s]
Loading safetensors checkpoint shards:  81% Completed | 832/1024 [00:21<00:04, 41.49it/s]
Loading safetensors checkpoint shards:  82% Completed | 837/1024 [00:21<00:04, 41.85it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:21<00:04, 42.19it/s]
Loading safetensors checkpoint shards:  83% Completed | 847/1024 [00:21<00:04, 41.62it/s]
Loading safetensors checkpoint shards:  83% Completed | 852/1024 [00:22<00:04, 41.48it/s]
Loading safetensors checkpoint shards:  84% Completed | 857/1024 [00:22<00:03, 42.18it/s]
Loading safetensors checkpoint shards:  84% Completed | 862/1024 [00:22<00:03, 41.45it/s]
Loading safetensors checkpoint shards:  85% Completed | 867/1024 [00:22<00:03, 42.09it/s]
Loading safetensors checkpoint shards:  85% Completed | 872/1024 [00:22<00:03, 42.60it/s]
Loading safetensors checkpoint shards:  86% Completed | 877/1024 [00:22<00:03, 41.82it/s]
Loading safetensors checkpoint shards:  86% Completed | 882/1024 [00:22<00:03, 42.56it/s]
Loading safetensors checkpoint shards:  87% Completed | 887/1024 [00:22<00:03, 43.45it/s]
Loading safetensors checkpoint shards:  87% Completed | 892/1024 [00:22<00:03, 42.80it/s]
Loading safetensors checkpoint shards:  88% Completed | 897/1024 [00:23<00:02, 43.42it/s]
Loading safetensors checkpoint shards:  88% Completed | 902/1024 [00:23<00:02, 44.20it/s]
Loading safetensors checkpoint shards:  89% Completed | 907/1024 [00:23<00:02, 44.11it/s]
Loading safetensors checkpoint shards:  89% Completed | 912/1024 [00:23<00:02, 43.88it/s]
Loading safetensors checkpoint shards:  90% Completed | 917/1024 [00:23<00:02, 44.18it/s]
Loading safetensors checkpoint shards:  90% Completed | 922/1024 [00:23<00:02, 43.88it/s]
Loading safetensors checkpoint shards:  91% Completed | 927/1024 [00:23<00:02, 43.80it/s]
Loading safetensors checkpoint shards:  91% Completed | 932/1024 [00:23<00:02, 41.13it/s]
Loading safetensors checkpoint shards:  92% Completed | 937/1024 [00:24<00:02, 41.12it/s]
Loading safetensors checkpoint shards:  92% Completed | 942/1024 [00:24<00:01, 41.55it/s]
Loading safetensors checkpoint shards:  92% Completed | 947/1024 [00:24<00:01, 41.33it/s]
Loading safetensors checkpoint shards:  93% Completed | 952/1024 [00:24<00:01, 42.26it/s]
Loading safetensors checkpoint shards:  93% Completed | 957/1024 [00:24<00:01, 42.72it/s]
Loading safetensors checkpoint shards:  94% Completed | 962/1024 [00:24<00:01, 42.33it/s]
Loading safetensors checkpoint shards:  94% Completed | 967/1024 [00:24<00:01, 42.79it/s]
Loading safetensors checkpoint shards:  95% Completed | 972/1024 [00:24<00:01, 42.33it/s]
Loading safetensors checkpoint shards:  95% Completed | 977/1024 [00:24<00:01, 43.07it/s]
Loading safetensors checkpoint shards:  96% Completed | 985/1024 [00:25<00:00, 52.79it/s]
Loading safetensors checkpoint shards:  98% Completed | 1003/1024 [00:25<00:00, 86.59it/s]
Loading safetensors checkpoint shards:  99% Completed | 1012/1024 [00:25<00:00, 85.16it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 40.43it/s]

[2025-09-13 07:24:32 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:24:34 TP3] KV Cache is allocated. #tokens: 620209, KV size: 40.59 GB
[2025-09-13 07:24:34 TP2] KV Cache is allocated. #tokens: 620209, KV size: 40.59 GB
[2025-09-13 07:24:34 TP1] KV Cache is allocated. #tokens: 620209, KV size: 40.59 GB
[2025-09-13 07:24:34 TP6] KV Cache is allocated. #tokens: 620209, KV size: 40.59 GB
[2025-09-13 07:24:34 TP0] KV Cache is allocated. #tokens: 620209, KV size: 40.59 GB
[2025-09-13 07:24:34 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:24:34 TP5] KV Cache is allocated. #tokens: 620209, KV size: 40.59 GB
[2025-09-13 07:24:34 TP4] KV Cache is allocated. #tokens: 620209, KV size: 40.59 GB
[2025-09-13 07:24:34 TP7] KV Cache is allocated. #tokens: 620209, KV size: 40.59 GB
[2025-09-13 07:24:34 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:24:35 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.53 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:24:36 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:24:36 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:24:36 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:24:36 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:24:36 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:24:36 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:24:36 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:24:36 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:24:36 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26210.44it/s]
[2025-09-13 07:24:36 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:24:36 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27014.57it/s]
[2025-09-13 07:24:37 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:24:37 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28718.31it/s]
[2025-09-13 07:24:38 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:24:38 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27705.99it/s]
[2025-09-13 07:24:38 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:24:38 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28490.78it/s]
[2025-09-13 07:24:39 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.22 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.15it/s]
[2025-09-13 07:24:42 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:24:42 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:24:42 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:24:42 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:24:42 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:24:42 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:24:42 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:24:42 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:24:42 TP0] Capture cuda graph end. Time elapsed: 7.76 s. mem usage=0.36 GB. avail mem=17.20 GB.
[2025-09-13 07:24:42 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:24:42 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:24:42 TP0] Init torch distributed begin.
[2025-09-13 07:24:42 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:24:42 TP0] Load weight begin. avail mem=17.20 GB
[2025-09-13 07:24:42 TP0] Detected fp8 checkpoint.
[2025-09-13 07:24:42 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 19/1024 [00:00<00:05, 181.29it/s]
Loading safetensors checkpoint shards:   5% Completed | 47/1024 [00:00<00:04, 236.23it/s]
Loading safetensors checkpoint shards:  11% Completed | 110/1024 [00:00<00:02, 410.21it/s]
Loading safetensors checkpoint shards:  17% Completed | 170/1024 [00:00<00:01, 482.78it/s]
Loading safetensors checkpoint shards:  22% Completed | 229/1024 [00:00<00:01, 520.85it/s]
Loading safetensors checkpoint shards:  28% Completed | 288/1024 [00:00<00:01, 544.10it/s]
Loading safetensors checkpoint shards:  34% Completed | 347/1024 [00:00<00:01, 556.78it/s]
Loading safetensors checkpoint shards:  40% Completed | 408/1024 [00:00<00:01, 570.79it/s]
Loading safetensors checkpoint shards:  46% Completed | 467/1024 [00:00<00:00, 576.00it/s]
Loading safetensors checkpoint shards:  52% Completed | 529/1024 [00:01<00:00, 586.31it/s]
Loading safetensors checkpoint shards:  58% Completed | 590/1024 [00:01<00:00, 590.44it/s]
Loading safetensors checkpoint shards:  63% Completed | 650/1024 [00:01<00:00, 586.01it/s]
Loading safetensors checkpoint shards:  69% Completed | 709/1024 [00:01<00:00, 576.94it/s]
Loading safetensors checkpoint shards:  75% Completed | 767/1024 [00:01<00:00, 569.23it/s]
Loading safetensors checkpoint shards:  80% Completed | 824/1024 [00:01<00:00, 564.58it/s]
Loading safetensors checkpoint shards:  86% Completed | 881/1024 [00:01<00:00, 560.88it/s]
Loading safetensors checkpoint shards:  92% Completed | 939/1024 [00:01<00:00, 564.31it/s]
Loading safetensors checkpoint shards:  97% Completed | 996/1024 [00:01<00:00, 464.37it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 497.16it/s]

[2025-09-13 07:24:45 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.21 GB, mem usage=1.99 GB.
[2025-09-13 07:24:45 TP0] KV Cache is allocated. #tokens: 620209, KV size: 0.67 GB
[2025-09-13 07:24:45 TP6] KV Cache is allocated. #tokens: 620209, KV size: 0.67 GB
[2025-09-13 07:24:45 TP0] Memory pool end. avail mem=14.54 GB
[2025-09-13 07:24:45 TP4] KV Cache is allocated. #tokens: 620209, KV size: 0.67 GB
[2025-09-13 07:24:45 TP5] KV Cache is allocated. #tokens: 620209, KV size: 0.67 GB
[2025-09-13 07:24:45 TP3] KV Cache is allocated. #tokens: 620209, KV size: 0.67 GB
[2025-09-13 07:24:45 TP7] KV Cache is allocated. #tokens: 620209, KV size: 0.67 GB
[2025-09-13 07:24:45 TP1] KV Cache is allocated. #tokens: 620209, KV size: 0.67 GB
[2025-09-13 07:24:45 TP2] KV Cache is allocated. #tokens: 620209, KV size: 0.67 GB
[2025-09-13 07:24:45 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:24:45 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.17 GB
[2025-09-13 07:24:45 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:24:45 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:24:45 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:24:45 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:24:45 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:24:45 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
Capturing batches (bs=1 avail_mem=14.57 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  2.83it/s][2025-09-13 07:24:52 TP5] Registering 96 cuda graph addresses
[2025-09-13 07:24:52 TP1] Registering 96 cuda graph addresses
[2025-09-13 07:24:52 TP3] Registering 96 cuda graph addresses
[2025-09-13 07:24:52 TP6] Registering 96 cuda graph addresses
[2025-09-13 07:24:52 TP4] Registering 96 cuda graph addresses
[2025-09-13 07:24:52 TP7] Registering 96 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.57 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.36it/s]
[2025-09-13 07:24:52 TP0] Registering 96 cuda graph addresses
[2025-09-13 07:24:52 TP2] Registering 96 cuda graph addresses
[2025-09-13 07:24:52 TP5] Capture draft cuda graph end. Time elapsed: 6.60 s. mem usage=0.41 GB. avail mem=14.52 GB.
[2025-09-13 07:24:52 TP0] Capture draft cuda graph end. Time elapsed: 6.60 s. mem usage=0.42 GB. avail mem=14.56 GB.
[2025-09-13 07:24:52 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:24:52 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.56 GB
[2025-09-13 07:24:52 TP6] Capture draft cuda graph end. Time elapsed: 6.60 s. mem usage=0.41 GB. avail mem=14.52 GB.
[2025-09-13 07:24:52 TP1] Capture draft cuda graph end. Time elapsed: 6.60 s. mem usage=0.41 GB. avail mem=14.52 GB.
[2025-09-13 07:24:52 TP7] Capture draft cuda graph end. Time elapsed: 6.60 s. mem usage=0.41 GB. avail mem=14.75 GB.
[2025-09-13 07:24:52 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.75 GB
[2025-09-13 07:24:52 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:24:52 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:24:52 TP2] Capture draft cuda graph end. Time elapsed: 6.60 s. mem usage=0.41 GB. avail mem=14.52 GB.
[2025-09-13 07:24:52 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:24:52 TP3] Capture draft cuda graph end. Time elapsed: 6.60 s. mem usage=0.41 GB. avail mem=14.52 GB.
[2025-09-13 07:24:52 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:24:52 TP4] Capture draft cuda graph end. Time elapsed: 6.60 s. mem usage=0.41 GB. avail mem=14.52 GB.
[2025-09-13 07:24:52 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
Capturing batches (bs=1 avail_mem=14.38 GB):  38%|████████████████████████████████▎                                                     | 3/8 [00:00<00:00, 23.73it/s][2025-09-13 07:24:53 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:24:53 TP1] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.38 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 36.97it/s][2025-09-13 07:24:53 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:24:53 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:24:53 TP5] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.38 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 34.76it/s]
[2025-09-13 07:24:53 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:24:53 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:24:53 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:24:53 TP6] Capture draft extend cuda graph end. Time elapsed: 1.26 s. mem usage=0.19 GB. avail mem=14.33 GB.
[2025-09-13 07:24:53 TP1] Capture draft extend cuda graph end. Time elapsed: 1.26 s. mem usage=0.19 GB. avail mem=14.33 GB.
[2025-09-13 07:24:53 TP4] Capture draft extend cuda graph end. Time elapsed: 1.26 s. mem usage=0.19 GB. avail mem=14.33 GB.
[2025-09-13 07:24:53 TP2] Capture draft extend cuda graph end. Time elapsed: 1.26 s. mem usage=0.19 GB. avail mem=14.33 GB.
[2025-09-13 07:24:53 TP5] Capture draft extend cuda graph end. Time elapsed: 1.26 s. mem usage=0.19 GB. avail mem=14.33 GB.
[2025-09-13 07:24:53 TP3] Capture draft extend cuda graph end. Time elapsed: 1.26 s. mem usage=0.19 GB. avail mem=14.33 GB.
[2025-09-13 07:24:53 TP7] Capture draft extend cuda graph end. Time elapsed: 1.26 s. mem usage=0.19 GB. avail mem=14.57 GB.
[2025-09-13 07:24:53 TP0] Capture draft extend cuda graph end. Time elapsed: 1.26 s. mem usage=0.19 GB. avail mem=14.37 GB.
[2025-09-13 07:24:53 TP0] max_total_num_tokens=620209, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.37 GB
[2025-09-13 07:24:53] INFO:     Started server process [277948]
[2025-09-13 07:24:53] INFO:     Waiting for application startup.
[2025-09-13 07:24:53] INFO:     Application startup complete.
[2025-09-13 07:24:53] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:24:54] INFO:     127.0.0.1:46864 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:24:54] INFO:     127.0.0.1:46874 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:24:54 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:24:54 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:24:55 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27777.66it/s]
[2025-09-13 07:24:56] INFO:     127.0.0.1:46884 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:24:56] The server is fired up and ready to roll!
[2025-09-13 07:25:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:25:05] INFO:     127.0.0.1:45910 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:25:05] INFO:     127.0.0.1:45920 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:06 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:25:07] INFO:     127.0.0.1:45924 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:07] INFO:     127.0.0.1:45930 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:25:07] INFO:     127.0.0.1:45932 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:07] INFO:     127.0.0.1:45948 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:07] INFO:     127.0.0.1:45958 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:07] INFO:     127.0.0.1:45960 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:07] INFO:     127.0.0.1:45968 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:07] INFO:     127.0.0.1:45980 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:07 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:25:08 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:25:08 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:25:08 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:25:08 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:25:08 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:25:08 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:25:08 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:25:08 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:25:08 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:25:09 TP0] Decode batch. #running-req: 8, #token: 14458, token usage: 0.02, accept len: 2.58, cuda graph: True, gen throughput (token/s): 36.39, #queue-req: 0, 
[2025-09-13 07:25:10 TP0] Decode batch. #running-req: 8, #token: 15377, token usage: 0.02, accept len: 2.87, cuda graph: True, gen throughput (token/s): 754.10, #queue-req: 0, 
[2025-09-13 07:25:11 TP0] Decode batch. #running-req: 8, #token: 16363, token usage: 0.03, accept len: 3.08, cuda graph: True, gen throughput (token/s): 799.95, #queue-req: 0, 
[2025-09-13 07:25:12 TP0] Decode batch. #running-req: 8, #token: 17341, token usage: 0.03, accept len: 3.06, cuda graph: True, gen throughput (token/s): 792.52, #queue-req: 0, 
 75%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 6/8 [00:06<00:00,  2.00it/s][2025-09-13 07:25:13 TP0] Decode batch. #running-req: 1, #token: 1447, token usage: 0.00, accept len: 3.05, cuda graph: True, gen throughput (token/s): 517.28, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.16it/s]
[2025-09-13 07:25:14] INFO:     127.0.0.1:57192 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.92      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4068      
Request throughput (req/s):              1.16      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         591.72    
Total token throughput (tok/s):          591.72    
Concurrency:                             7.06      
Accept length:                           2.94      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   6104.81   
Median E2E Latency (ms):                 6094.11   
---------------Time to First Token----------------
Mean TTFT (ms):                          664.01    
Median TTFT (ms):                        776.76    
P99 TTFT (ms):                           777.23    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.65     
Median ITL (ms):                         7.72      
P95 ITL (ms):                            28.95     
P99 ITL (ms):                            31.22     
Max ITL (ms):                            752.25    
==================================================
[2025-09-13 07:25:14] INFO:     127.0.0.1:57208 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:25:14] INFO:     127.0.0.1:57216 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:14 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:25:15] INFO:     127.0.0.1:57228 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:15] INFO:     127.0.0.1:57240 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:25:15] INFO:     127.0.0.1:57250 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:15] INFO:     127.0.0.1:57262 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:15] INFO:     127.0.0.1:57264 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:15] INFO:     127.0.0.1:57276 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:15] INFO:     127.0.0.1:57288 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:15] INFO:     127.0.0.1:57292 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:15 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:25:16 TP0] Decode batch. #running-req: 8, #token: 13985, token usage: 0.02, accept len: 2.46, cuda graph: True, gen throughput (token/s): 74.70, #queue-req: 0, 
[2025-09-13 07:25:17 TP0] Decode batch. #running-req: 8, #token: 14857, token usage: 0.02, accept len: 2.73, cuda graph: True, gen throughput (token/s): 735.12, #queue-req: 0, 
[2025-09-13 07:25:18 TP0] Decode batch. #running-req: 8, #token: 15833, token usage: 0.03, accept len: 3.05, cuda graph: True, gen throughput (token/s): 790.68, #queue-req: 0, 
[2025-09-13 07:25:19 TP0] Decode batch. #running-req: 8, #token: 16804, token usage: 0.03, accept len: 3.03, cuda graph: True, gen throughput (token/s): 787.55, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:12,  4.85s/it][2025-09-13 07:25:20] INFO:     127.0.0.1:57922 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:20 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:05<00:31,  2.26s/it][2025-09-13 07:25:21] INFO:     127.0.0.1:57938 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:21 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:17,  1.36s/it][2025-09-13 07:25:21] INFO:     127.0.0.1:57954 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:21 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:25:21 TP0] Decode batch. #running-req: 8, #token: 12328, token usage: 0.02, accept len: 3.05, cuda graph: True, gen throughput (token/s): 555.28, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:11,  1.05it/s][2025-09-13 07:25:21] INFO:     127.0.0.1:57970 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:21 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:06<00:08,  1.36it/s][2025-09-13 07:25:22] INFO:     127.0.0.1:57972 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:22 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:06<00:06,  1.62it/s][2025-09-13 07:25:22] INFO:     127.0.0.1:57982 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:22] INFO:     127.0.0.1:57984 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:22 TP0] Prefill batch. #new-seq: 2, #new-token: 2369, #cached-token: 1751, token usage: 0.01, #running-req: 6, #queue-req: 0, 
[2025-09-13 07:25:23 TP0] Decode batch. #running-req: 8, #token: 10585, token usage: 0.02, accept len: 2.77, cuda graph: True, gen throughput (token/s): 528.52, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:07<00:04,  1.72it/s][2025-09-13 07:25:23] INFO:     127.0.0.1:58000 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:25:23 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:25:24 TP0] Decode batch. #running-req: 8, #token: 15012, token usage: 0.02, accept len: 2.84, cuda graph: True, gen throughput (token/s): 625.35, #queue-req: 0, 
[2025-09-13 07:25:25 TP0] Decode batch. #running-req: 8, #token: 16049, token usage: 0.03, accept len: 3.24, cuda graph: True, gen throughput (token/s): 840.83, #queue-req: 0, 
 62%|████████████████████████████████████████████████████████████████████████████████▋                                                | 10/16 [00:10<00:05,  1.05it/s][2025-09-13 07:25:27 TP0] Decode batch. #running-req: 6, #token: 15059, token usage: 0.02, accept len: 3.23, cuda graph: True, gen throughput (token/s): 782.29, #queue-req: 0, 
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 13/16 [00:11<00:01,  1.84it/s][2025-09-13 07:25:28 TP0] Decode batch. #running-req: 3, #token: 8853, token usage: 0.01, accept len: 2.99, cuda graph: True, gen throughput (token/s): 487.65, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:12<00:00,  1.25it/s]
[2025-09-13 07:25:28] INFO:     127.0.0.1:38330 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  12.78     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8076      
Request throughput (req/s):              1.25      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         640.97    
Total token throughput (tok/s):          640.97    
Concurrency:                             7.36      
Accept length:                           2.96      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5881.53   
Median E2E Latency (ms):                 5827.25   
---------------Time to First Token----------------
Mean TTFT (ms):                          224.65    
Median TTFT (ms):                        233.54    
P99 TTFT (ms):                           283.83    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           11.07     
Median ITL (ms):                         7.72      
P95 ITL (ms):                            30.31     
P99 ITL (ms):                            66.68     
Max ITL (ms):                            266.73    
==================================================
[2025-09-13 07:25:28] INFO:     127.0.0.1:38346 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=27: batch_size=8, steps=5, topk=3, num_draft_tokens=4, speed=96.17 token/s, step_time=30.82 ms
Start i=28: batch_size=8, steps=5, topk=3, num_draft_tokens=6
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 5 --speculative-eagle-topk 3 --speculative-num-draft-tokens 6 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:25:39.242000 283568 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:25:39.242000 283568 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:25:39] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=568896401, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=5, speculative_eagle_topk=3, speculative_num_draft_tokens=6, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:25:40] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:25:48.405000 283776 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:25:48.405000 283776 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:25:48.456000 283784 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:25:48.456000 283784 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:25:48.512000 283783 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:25:48.512000 283783 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:25:48.668000 283780 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:25:48.668000 283780 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:25:48.673000 283777 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:25:48.673000 283777 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:25:48.731000 283781 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:25:48.731000 283781 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:25:48.732000 283782 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:25:48.732000 283782 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:25:48.745000 283778 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:25:48.745000 283778 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:25:48.798000 283779 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:25:48.798000 283779 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:25:48 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:25:48 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:25:48 TP0] Init torch distributed begin.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:25:50 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:25:53 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:25:55 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:25:55 TP0] Detected fp8 checkpoint.
[2025-09-13 07:25:55 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:03, 259.14it/s]
Loading safetensors checkpoint shards:   5% Completed | 52/1024 [00:00<00:11, 85.70it/s]
Loading safetensors checkpoint shards:   7% Completed | 67/1024 [00:00<00:15, 60.87it/s]
Loading safetensors checkpoint shards:   8% Completed | 77/1024 [00:01<00:18, 51.78it/s]
Loading safetensors checkpoint shards:   8% Completed | 85/1024 [00:01<00:19, 48.32it/s]
Loading safetensors checkpoint shards:   9% Completed | 91/1024 [00:01<00:20, 46.30it/s]
Loading safetensors checkpoint shards:   9% Completed | 97/1024 [00:01<00:21, 43.46it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:01<00:21, 42.85it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:02<00:35, 25.78it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:33, 27.57it/s]
Loading safetensors checkpoint shards:  11% Completed | 117/1024 [00:02<00:28, 31.69it/s]
Loading safetensors checkpoint shards:  12% Completed | 122/1024 [00:02<00:26, 33.74it/s]
Loading safetensors checkpoint shards:  12% Completed | 127/1024 [00:02<00:24, 36.86it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:02<00:23, 37.74it/s]
Loading safetensors checkpoint shards:  13% Completed | 138/1024 [00:03<00:20, 42.88it/s]
Loading safetensors checkpoint shards:  14% Completed | 143/1024 [00:03<00:19, 44.53it/s]
Loading safetensors checkpoint shards:  14% Completed | 148/1024 [00:03<00:21, 40.59it/s]
Loading safetensors checkpoint shards:  15% Completed | 154/1024 [00:03<00:19, 43.59it/s]
Loading safetensors checkpoint shards:  16% Completed | 159/1024 [00:03<00:19, 44.87it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:03<00:18, 45.66it/s]
Loading safetensors checkpoint shards:  17% Completed | 169/1024 [00:03<00:19, 43.13it/s]
Loading safetensors checkpoint shards:  17% Completed | 174/1024 [00:03<00:19, 44.59it/s]
Loading safetensors checkpoint shards:  17% Completed | 179/1024 [00:03<00:20, 41.19it/s]
Loading safetensors checkpoint shards:  18% Completed | 184/1024 [00:04<00:20, 41.79it/s]
Loading safetensors checkpoint shards:  18% Completed | 189/1024 [00:04<00:21, 39.76it/s]
Loading safetensors checkpoint shards:  19% Completed | 194/1024 [00:04<00:20, 41.20it/s]
Loading safetensors checkpoint shards:  19% Completed | 199/1024 [00:04<00:20, 39.92it/s]
Loading safetensors checkpoint shards:  20% Completed | 204/1024 [00:04<00:20, 40.29it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:04<00:20, 39.64it/s]
Loading safetensors checkpoint shards:  21% Completed | 213/1024 [00:04<00:20, 39.06it/s]
Loading safetensors checkpoint shards:  21% Completed | 218/1024 [00:04<00:19, 40.42it/s]
Loading safetensors checkpoint shards:  22% Completed | 223/1024 [00:05<00:21, 37.85it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:05<00:20, 38.17it/s]
Loading safetensors checkpoint shards:  23% Completed | 231/1024 [00:05<00:20, 37.97it/s]
Loading safetensors checkpoint shards:  23% Completed | 235/1024 [00:05<00:21, 37.21it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:05<00:20, 39.06it/s]
Loading safetensors checkpoint shards:  24% Completed | 244/1024 [00:05<00:20, 37.96it/s]
Loading safetensors checkpoint shards:  24% Completed | 250/1024 [00:05<00:18, 40.88it/s]
Loading safetensors checkpoint shards:  25% Completed | 255/1024 [00:05<00:19, 38.67it/s]
Loading safetensors checkpoint shards:  25% Completed | 259/1024 [00:06<00:20, 38.17it/s]
Loading safetensors checkpoint shards:  26% Completed | 264/1024 [00:06<00:18, 40.31it/s]
Loading safetensors checkpoint shards:  26% Completed | 269/1024 [00:06<00:18, 40.26it/s]
Loading safetensors checkpoint shards:  27% Completed | 274/1024 [00:06<00:17, 42.21it/s]
Loading safetensors checkpoint shards:  27% Completed | 279/1024 [00:06<00:19, 38.06it/s]
Loading safetensors checkpoint shards:  28% Completed | 284/1024 [00:06<00:18, 38.98it/s]
Loading safetensors checkpoint shards:  28% Completed | 288/1024 [00:06<00:18, 39.06it/s]
Loading safetensors checkpoint shards:  29% Completed | 292/1024 [00:06<00:19, 38.44it/s]
Loading safetensors checkpoint shards:  29% Completed | 297/1024 [00:07<00:43, 16.83it/s]
Loading safetensors checkpoint shards:  29% Completed | 302/1024 [00:07<00:34, 20.98it/s]
Loading safetensors checkpoint shards:  30% Completed | 308/1024 [00:07<00:26, 27.10it/s]
Loading safetensors checkpoint shards:  31% Completed | 314/1024 [00:07<00:21, 32.79it/s]
Loading safetensors checkpoint shards:  31% Completed | 321/1024 [00:07<00:18, 37.02it/s]
Loading safetensors checkpoint shards:  32% Completed | 327/1024 [00:08<00:16, 41.40it/s]
Loading safetensors checkpoint shards:  33% Completed | 334/1024 [00:08<00:14, 47.15it/s]
Loading safetensors checkpoint shards:  33% Completed | 341/1024 [00:08<00:13, 51.18it/s]
Loading safetensors checkpoint shards:  34% Completed | 347/1024 [00:08<00:13, 51.61it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:08<00:12, 54.75it/s]
Loading safetensors checkpoint shards:  35% Completed | 360/1024 [00:08<00:11, 55.38it/s]
Loading safetensors checkpoint shards:  36% Completed | 366/1024 [00:08<00:12, 54.29it/s]
Loading safetensors checkpoint shards:  37% Completed | 375/1024 [00:08<00:10, 62.22it/s]
Loading safetensors checkpoint shards:  37% Completed | 383/1024 [00:08<00:09, 66.86it/s]
Loading safetensors checkpoint shards:  38% Completed | 390/1024 [00:09<00:10, 63.17it/s]
Loading safetensors checkpoint shards:  39% Completed | 397/1024 [00:09<00:10, 60.29it/s]
Loading safetensors checkpoint shards:  40% Completed | 405/1024 [00:09<00:09, 64.10it/s]
Loading safetensors checkpoint shards:  40% Completed | 413/1024 [00:09<00:09, 67.82it/s]
Loading safetensors checkpoint shards:  41% Completed | 420/1024 [00:09<00:09, 65.90it/s]
Loading safetensors checkpoint shards:  42% Completed | 428/1024 [00:09<00:08, 67.30it/s]
Loading safetensors checkpoint shards:  42% Completed | 435/1024 [00:09<00:09, 60.70it/s]
Loading safetensors checkpoint shards:  43% Completed | 442/1024 [00:09<00:09, 62.59it/s]
Loading safetensors checkpoint shards:  44% Completed | 449/1024 [00:10<00:09, 58.98it/s]
Loading safetensors checkpoint shards:  45% Completed | 456/1024 [00:10<00:09, 59.79it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:10<00:09, 60.43it/s]
Loading safetensors checkpoint shards:  46% Completed | 470/1024 [00:10<00:23, 23.38it/s]
Loading safetensors checkpoint shards:  46% Completed | 476/1024 [00:11<00:19, 27.57it/s]
Loading safetensors checkpoint shards:  47% Completed | 481/1024 [00:11<00:18, 28.95it/s]
Loading safetensors checkpoint shards:  47% Completed | 486/1024 [00:11<00:17, 30.34it/s]
Loading safetensors checkpoint shards:  48% Completed | 491/1024 [00:11<00:17, 30.61it/s]
Loading safetensors checkpoint shards:  48% Completed | 495/1024 [00:11<00:17, 30.72it/s]
Loading safetensors checkpoint shards:  49% Completed | 499/1024 [00:11<00:16, 30.99it/s]
Loading safetensors checkpoint shards:  49% Completed | 503/1024 [00:11<00:17, 29.62it/s]
Loading safetensors checkpoint shards:  50% Completed | 507/1024 [00:12<00:17, 29.60it/s]
Loading safetensors checkpoint shards:  50% Completed | 512/1024 [00:12<00:15, 33.37it/s]
Loading safetensors checkpoint shards:  50% Completed | 517/1024 [00:12<00:13, 36.67it/s]
Loading safetensors checkpoint shards:  51% Completed | 521/1024 [00:12<00:14, 35.13it/s]
Loading safetensors checkpoint shards:  51% Completed | 525/1024 [00:12<00:14, 35.20it/s]
Loading safetensors checkpoint shards:  52% Completed | 529/1024 [00:12<00:13, 35.62it/s]
Loading safetensors checkpoint shards:  52% Completed | 533/1024 [00:12<00:14, 33.27it/s]
Loading safetensors checkpoint shards:  52% Completed | 537/1024 [00:12<00:13, 34.83it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:13<00:13, 35.92it/s]
Loading safetensors checkpoint shards:  53% Completed | 545/1024 [00:13<00:13, 36.83it/s]
Loading safetensors checkpoint shards:  54% Completed | 550/1024 [00:13<00:12, 38.06it/s]
Loading safetensors checkpoint shards:  54% Completed | 554/1024 [00:13<00:13, 34.95it/s]
Loading safetensors checkpoint shards:  54% Completed | 558/1024 [00:13<00:14, 32.75it/s]
Loading safetensors checkpoint shards:  55% Completed | 562/1024 [00:13<00:14, 31.91it/s]
Loading safetensors checkpoint shards:  55% Completed | 566/1024 [00:13<00:14, 31.40it/s]
Loading safetensors checkpoint shards:  56% Completed | 571/1024 [00:13<00:13, 34.82it/s]
Loading safetensors checkpoint shards:  56% Completed | 575/1024 [00:14<00:13, 34.06it/s]
Loading safetensors checkpoint shards:  57% Completed | 580/1024 [00:14<00:12, 36.38it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:14<00:11, 39.58it/s]
Loading safetensors checkpoint shards:  58% Completed | 590/1024 [00:14<00:12, 35.25it/s]
Loading safetensors checkpoint shards:  58% Completed | 594/1024 [00:14<00:13, 33.05it/s]
Loading safetensors checkpoint shards:  58% Completed | 599/1024 [00:14<00:11, 35.60it/s]
Loading safetensors checkpoint shards:  59% Completed | 603/1024 [00:14<00:11, 36.43it/s]
Loading safetensors checkpoint shards:  59% Completed | 607/1024 [00:14<00:11, 36.75it/s]
Loading safetensors checkpoint shards:  60% Completed | 611/1024 [00:14<00:11, 36.16it/s]
Loading safetensors checkpoint shards:  60% Completed | 617/1024 [00:15<00:10, 39.09it/s]
Loading safetensors checkpoint shards:  61% Completed | 623/1024 [00:15<00:09, 43.44it/s]
Loading safetensors checkpoint shards:  61% Completed | 628/1024 [00:15<00:09, 42.24it/s]
Loading safetensors checkpoint shards:  62% Completed | 633/1024 [00:15<00:09, 39.43it/s]
Loading safetensors checkpoint shards:  62% Completed | 638/1024 [00:15<00:10, 35.95it/s]
Loading safetensors checkpoint shards:  63% Completed | 642/1024 [00:15<00:10, 34.82it/s]
Loading safetensors checkpoint shards:  63% Completed | 646/1024 [00:15<00:11, 33.51it/s]
Loading safetensors checkpoint shards:  63% Completed | 650/1024 [00:16<00:11, 33.15it/s]
Loading safetensors checkpoint shards:  64% Completed | 654/1024 [00:16<00:11, 31.03it/s]
Loading safetensors checkpoint shards:  64% Completed | 658/1024 [00:16<00:11, 31.48it/s]
Loading safetensors checkpoint shards:  65% Completed | 662/1024 [00:16<00:12, 28.65it/s]
Loading safetensors checkpoint shards:  65% Completed | 665/1024 [00:16<00:12, 27.98it/s]
Loading safetensors checkpoint shards:  65% Completed | 668/1024 [00:16<00:12, 27.81it/s]
Loading safetensors checkpoint shards:  66% Completed | 672/1024 [00:17<00:27, 12.95it/s]
Loading safetensors checkpoint shards:  66% Completed | 676/1024 [00:17<00:22, 15.80it/s]
Loading safetensors checkpoint shards:  66% Completed | 679/1024 [00:17<00:19, 17.88it/s]
Loading safetensors checkpoint shards:  67% Completed | 682/1024 [00:17<00:18, 18.99it/s]
Loading safetensors checkpoint shards:  67% Completed | 685/1024 [00:17<00:16, 20.18it/s]
Loading safetensors checkpoint shards:  67% Completed | 688/1024 [00:17<00:15, 21.18it/s]
Loading safetensors checkpoint shards:  67% Completed | 691/1024 [00:18<00:15, 21.22it/s]
Loading safetensors checkpoint shards:  68% Completed | 695/1024 [00:18<00:13, 24.48it/s]
Loading safetensors checkpoint shards:  68% Completed | 699/1024 [00:18<00:12, 26.75it/s]
Loading safetensors checkpoint shards:  69% Completed | 703/1024 [00:18<00:11, 28.27it/s]
Loading safetensors checkpoint shards:  69% Completed | 707/1024 [00:18<00:10, 29.83it/s]
Loading safetensors checkpoint shards:  69% Completed | 711/1024 [00:18<00:10, 30.87it/s]
Loading safetensors checkpoint shards:  70% Completed | 715/1024 [00:18<00:09, 32.36it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:18<00:09, 33.38it/s]
Loading safetensors checkpoint shards:  71% Completed | 723/1024 [00:19<00:08, 35.07it/s]
Loading safetensors checkpoint shards:  71% Completed | 727/1024 [00:19<00:08, 36.34it/s]
Loading safetensors checkpoint shards:  71% Completed | 731/1024 [00:19<00:08, 34.90it/s]
Loading safetensors checkpoint shards:  72% Completed | 735/1024 [00:19<00:08, 35.37it/s]
Loading safetensors checkpoint shards:  72% Completed | 740/1024 [00:19<00:07, 36.86it/s]
Loading safetensors checkpoint shards:  73% Completed | 745/1024 [00:19<00:07, 37.84it/s]
Loading safetensors checkpoint shards:  73% Completed | 749/1024 [00:19<00:07, 35.99it/s]
Loading safetensors checkpoint shards:  74% Completed | 753/1024 [00:19<00:07, 36.89it/s]
Loading safetensors checkpoint shards:  74% Completed | 758/1024 [00:19<00:06, 38.46it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:20<00:06, 39.78it/s]
Loading safetensors checkpoint shards:  75% Completed | 768/1024 [00:20<00:06, 40.13it/s]
Loading safetensors checkpoint shards:  75% Completed | 773/1024 [00:20<00:06, 39.63it/s]
Loading safetensors checkpoint shards:  76% Completed | 778/1024 [00:20<00:06, 40.27it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:20<00:05, 40.71it/s]
Loading safetensors checkpoint shards:  77% Completed | 788/1024 [00:20<00:05, 39.98it/s]
Loading safetensors checkpoint shards:  77% Completed | 793/1024 [00:20<00:05, 40.80it/s]
Loading safetensors checkpoint shards:  78% Completed | 798/1024 [00:20<00:05, 41.50it/s]
Loading safetensors checkpoint shards:  78% Completed | 803/1024 [00:21<00:05, 43.04it/s]
Loading safetensors checkpoint shards:  79% Completed | 808/1024 [00:21<00:05, 42.39it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:21<00:04, 42.87it/s]
Loading safetensors checkpoint shards:  80% Completed | 818/1024 [00:21<00:04, 41.79it/s]
Loading safetensors checkpoint shards:  80% Completed | 823/1024 [00:21<00:04, 40.96it/s]
Loading safetensors checkpoint shards:  81% Completed | 828/1024 [00:21<00:04, 41.98it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:21<00:04, 42.42it/s]
Loading safetensors checkpoint shards:  82% Completed | 838/1024 [00:21<00:04, 42.80it/s]
Loading safetensors checkpoint shards:  82% Completed | 843/1024 [00:22<00:04, 42.38it/s]
Loading safetensors checkpoint shards:  83% Completed | 848/1024 [00:22<00:04, 42.46it/s]
Loading safetensors checkpoint shards:  83% Completed | 853/1024 [00:22<00:03, 42.99it/s]
Loading safetensors checkpoint shards:  84% Completed | 858/1024 [00:22<00:03, 42.78it/s]
Loading safetensors checkpoint shards:  84% Completed | 863/1024 [00:22<00:03, 43.13it/s]
Loading safetensors checkpoint shards:  85% Completed | 868/1024 [00:22<00:03, 43.83it/s]
Loading safetensors checkpoint shards:  85% Completed | 873/1024 [00:22<00:03, 43.71it/s]
Loading safetensors checkpoint shards:  86% Completed | 878/1024 [00:22<00:03, 41.52it/s]
Loading safetensors checkpoint shards:  86% Completed | 883/1024 [00:22<00:03, 41.88it/s]
Loading safetensors checkpoint shards:  87% Completed | 888/1024 [00:23<00:03, 42.08it/s]
Loading safetensors checkpoint shards:  87% Completed | 893/1024 [00:23<00:03, 41.97it/s]
Loading safetensors checkpoint shards:  88% Completed | 898/1024 [00:23<00:02, 42.61it/s]
Loading safetensors checkpoint shards:  88% Completed | 903/1024 [00:23<00:02, 43.31it/s]
Loading safetensors checkpoint shards:  89% Completed | 908/1024 [00:23<00:02, 43.87it/s]
Loading safetensors checkpoint shards:  89% Completed | 913/1024 [00:23<00:02, 43.12it/s]
Loading safetensors checkpoint shards:  90% Completed | 919/1024 [00:23<00:02, 45.22it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:23<00:02, 44.73it/s]
Loading safetensors checkpoint shards:  91% Completed | 929/1024 [00:23<00:02, 44.81it/s]
Loading safetensors checkpoint shards:  91% Completed | 934/1024 [00:24<00:02, 43.30it/s]
Loading safetensors checkpoint shards:  92% Completed | 939/1024 [00:24<00:01, 43.15it/s]
Loading safetensors checkpoint shards:  92% Completed | 944/1024 [00:24<00:01, 43.42it/s]
Loading safetensors checkpoint shards:  93% Completed | 949/1024 [00:24<00:01, 42.40it/s]
Loading safetensors checkpoint shards:  93% Completed | 954/1024 [00:24<00:01, 43.12it/s]
Loading safetensors checkpoint shards:  94% Completed | 959/1024 [00:24<00:01, 43.49it/s]
Loading safetensors checkpoint shards:  94% Completed | 964/1024 [00:24<00:01, 42.61it/s]
Loading safetensors checkpoint shards:  95% Completed | 969/1024 [00:24<00:01, 42.89it/s]
Loading safetensors checkpoint shards:  95% Completed | 974/1024 [00:25<00:01, 42.24it/s]
Loading safetensors checkpoint shards:  96% Completed | 979/1024 [00:25<00:01, 42.88it/s]
Loading safetensors checkpoint shards:  97% Completed | 993/1024 [00:25<00:01, 27.17it/s]
Loading safetensors checkpoint shards:  98% Completed | 1003/1024 [00:25<00:00, 35.99it/s]
Loading safetensors checkpoint shards:  99% Completed | 1016/1024 [00:26<00:00, 50.17it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:26<00:00, 39.25it/s]

[2025-09-13 07:26:22 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:26:23 TP2] KV Cache is allocated. #tokens: 620225, KV size: 40.59 GB
[2025-09-13 07:26:23 TP6] KV Cache is allocated. #tokens: 620225, KV size: 40.59 GB
[2025-09-13 07:26:23 TP1] KV Cache is allocated. #tokens: 620225, KV size: 40.59 GB
[2025-09-13 07:26:23 TP4] KV Cache is allocated. #tokens: 620225, KV size: 40.59 GB
[2025-09-13 07:26:23 TP7] KV Cache is allocated. #tokens: 620225, KV size: 40.59 GB
[2025-09-13 07:26:23 TP5] KV Cache is allocated. #tokens: 620225, KV size: 40.59 GB
[2025-09-13 07:26:23 TP3] KV Cache is allocated. #tokens: 620225, KV size: 40.59 GB
[2025-09-13 07:26:23 TP0] KV Cache is allocated. #tokens: 620225, KV size: 40.59 GB
[2025-09-13 07:26:23 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:26:24 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:26:24 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.52 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:26:25 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:26:25 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:26:25 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:26:25 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:26:25 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:26:25 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:26:25 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:26:25 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:26:25 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25893.28it/s]
[2025-09-13 07:26:25 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:26:25 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27104.60it/s]
[2025-09-13 07:26:26 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:26:26 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28378.34it/s]
[2025-09-13 07:26:27 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:26:27 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27716.12it/s]
[2025-09-13 07:26:27 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:26:27 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28392.91it/s]
[2025-09-13 07:26:28 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.23 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.15it/s]
[2025-09-13 07:26:31 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:26:31 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:26:31 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:26:31 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:26:31 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:26:31 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:26:31 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:26:31 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:26:31 TP0] Capture cuda graph end. Time elapsed: 7.58 s. mem usage=0.35 GB. avail mem=17.21 GB.
[2025-09-13 07:26:32 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:26:32 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:26:32 TP0] Init torch distributed begin.
[2025-09-13 07:26:32 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:26:32 TP0] Load weight begin. avail mem=17.21 GB
[2025-09-13 07:26:32 TP0] Detected fp8 checkpoint.
[2025-09-13 07:26:32 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 170.19it/s]
Loading safetensors checkpoint shards:   4% Completed | 44/1024 [00:00<00:04, 221.60it/s]
Loading safetensors checkpoint shards:  10% Completed | 103/1024 [00:00<00:02, 386.00it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:00<00:01, 471.49it/s]
Loading safetensors checkpoint shards:  22% Completed | 224/1024 [00:00<00:01, 516.50it/s]
Loading safetensors checkpoint shards:  28% Completed | 286/1024 [00:00<00:01, 549.78it/s]
Loading safetensors checkpoint shards:  34% Completed | 347/1024 [00:00<00:01, 566.80it/s]
Loading safetensors checkpoint shards:  40% Completed | 409/1024 [00:00<00:01, 583.10it/s]
Loading safetensors checkpoint shards:  46% Completed | 470/1024 [00:00<00:00, 590.70it/s]
Loading safetensors checkpoint shards:  52% Completed | 532/1024 [00:01<00:00, 597.28it/s]
Loading safetensors checkpoint shards:  58% Completed | 594/1024 [00:01<00:00, 604.17it/s]
Loading safetensors checkpoint shards:  64% Completed | 655/1024 [00:01<00:00, 596.40it/s]
Loading safetensors checkpoint shards:  70% Completed | 715/1024 [00:01<00:00, 589.16it/s]
Loading safetensors checkpoint shards:  76% Completed | 774/1024 [00:01<00:00, 581.99it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:01<00:00, 580.06it/s]
Loading safetensors checkpoint shards:  87% Completed | 892/1024 [00:01<00:00, 574.28it/s]
Loading safetensors checkpoint shards:  93% Completed | 950/1024 [00:01<00:00, 574.56it/s]
Loading safetensors checkpoint shards:  98% Completed | 1008/1024 [00:01<00:00, 417.56it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 504.49it/s]

[2025-09-13 07:26:34 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.22 GB, mem usage=1.99 GB.
[2025-09-13 07:26:34 TP0] KV Cache is allocated. #tokens: 620225, KV size: 0.67 GB
[2025-09-13 07:26:34 TP5] KV Cache is allocated. #tokens: 620225, KV size: 0.67 GB
[2025-09-13 07:26:34 TP7] KV Cache is allocated. #tokens: 620225, KV size: 0.67 GB
[2025-09-13 07:26:34 TP4] KV Cache is allocated. #tokens: 620225, KV size: 0.67 GB
[2025-09-13 07:26:34 TP0] Memory pool end. avail mem=14.55 GB
[2025-09-13 07:26:34 TP1] KV Cache is allocated. #tokens: 620225, KV size: 0.67 GB
[2025-09-13 07:26:34 TP2] KV Cache is allocated. #tokens: 620225, KV size: 0.67 GB
[2025-09-13 07:26:34 TP3] KV Cache is allocated. #tokens: 620225, KV size: 0.67 GB
[2025-09-13 07:26:34 TP6] KV Cache is allocated. #tokens: 620225, KV size: 0.67 GB
[2025-09-13 07:26:34 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:26:34 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:26:34 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:26:34 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:26:34 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:26:34 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.99 GB
[2025-09-13 07:26:34 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.18 GB
[2025-09-13 07:26:34 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
Capturing batches (bs=1 avail_mem=14.58 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.41it/s]
[2025-09-13 07:26:40 TP4] Registering 96 cuda graph addresses
[2025-09-13 07:26:40 TP2] Registering 96 cuda graph addresses
[2025-09-13 07:26:40 TP0] Registering 96 cuda graph addresses
[2025-09-13 07:26:40 TP7] Registering 96 cuda graph addresses
[2025-09-13 07:26:40 TP1] Registering 96 cuda graph addresses
[2025-09-13 07:26:40 TP6] Registering 96 cuda graph addresses
[2025-09-13 07:26:40 TP3] Registering 96 cuda graph addresses
[2025-09-13 07:26:40 TP5] Registering 96 cuda graph addresses
[2025-09-13 07:26:40 TP2] Capture draft cuda graph end. Time elapsed: 6.36 s. mem usage=0.41 GB. avail mem=14.53 GB.
[2025-09-13 07:26:40 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.53 GB
[2025-09-13 07:26:40 TP1] Capture draft cuda graph end. Time elapsed: 6.37 s. mem usage=0.41 GB. avail mem=14.53 GB.
[2025-09-13 07:26:40 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.53 GB
[2025-09-13 07:26:40 TP4] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.41 GB. avail mem=14.53 GB.
[2025-09-13 07:26:40 TP0] Capture draft cuda graph end. Time elapsed: 6.37 s. mem usage=0.41 GB. avail mem=14.57 GB.
[2025-09-13 07:26:40 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.53 GB
[2025-09-13 07:26:40 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.57 GB
[2025-09-13 07:26:40 TP5] Capture draft cuda graph end. Time elapsed: 6.37 s. mem usage=0.41 GB. avail mem=14.53 GB.
[2025-09-13 07:26:40 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.53 GB
[2025-09-13 07:26:40 TP7] Capture draft cuda graph end. Time elapsed: 6.37 s. mem usage=0.41 GB. avail mem=14.77 GB.
[2025-09-13 07:26:40 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.77 GB
[2025-09-13 07:26:40 TP3] Capture draft cuda graph end. Time elapsed: 6.37 s. mem usage=0.41 GB. avail mem=14.53 GB.
[2025-09-13 07:26:40 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.53 GB
[2025-09-13 07:26:40 TP6] Capture draft cuda graph end. Time elapsed: 6.37 s. mem usage=0.41 GB. avail mem=14.53 GB.
[2025-09-13 07:26:40 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.53 GB
Capturing batches (bs=1 avail_mem=14.39 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 23.99it/s]
[2025-09-13 07:26:42 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:26:42 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:26:42 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:26:42 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:26:42 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:26:42 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:26:42 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:26:42 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:26:42 TP7] Capture draft extend cuda graph end. Time elapsed: 1.08 s. mem usage=0.19 GB. avail mem=14.58 GB.
[2025-09-13 07:26:42 TP1] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.19 GB. avail mem=14.34 GB.
[2025-09-13 07:26:42 TP0] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.19 GB. avail mem=14.38 GB.
[2025-09-13 07:26:42 TP2] Capture draft extend cuda graph end. Time elapsed: 1.10 s. mem usage=0.19 GB. avail mem=14.34 GB.
[2025-09-13 07:26:42 TP5] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.19 GB. avail mem=14.34 GB.
[2025-09-13 07:26:42 TP0] max_total_num_tokens=620225, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.38 GB
[2025-09-13 07:26:42 TP6] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.19 GB. avail mem=14.34 GB.
[2025-09-13 07:26:42 TP4] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.19 GB. avail mem=14.34 GB.
[2025-09-13 07:26:42 TP3] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.19 GB. avail mem=14.34 GB.
[2025-09-13 07:26:42] INFO:     Started server process [283568]
[2025-09-13 07:26:42] INFO:     Waiting for application startup.
[2025-09-13 07:26:42] INFO:     Application startup complete.
[2025-09-13 07:26:42] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:26:43] INFO:     127.0.0.1:48972 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:26:43 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:26:43 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:26:43 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup:   0%|                                                                                                                      | 0/16384 [00:00<?, ?it/s][2025-09-13 07:26:43] INFO:     127.0.0.1:48980 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28379.40it/s]
[2025-09-13 07:26:44] INFO:     127.0.0.1:48978 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:26:44] The server is fired up and ready to roll!
[2025-09-13 07:26:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:26:54] INFO:     127.0.0.1:40996 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:26:55] INFO:     127.0.0.1:41012 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:26:55 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:26:56] INFO:     127.0.0.1:41024 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:26:56] INFO:     127.0.0.1:41036 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:26:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:26:56] INFO:     127.0.0.1:41038 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:26:56] INFO:     127.0.0.1:41044 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:26:56] INFO:     127.0.0.1:41054 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:26:56] INFO:     127.0.0.1:41062 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:26:56] INFO:     127.0.0.1:41070 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:26:56] INFO:     127.0.0.1:41078 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:26:56 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:26:57 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:26:57 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:26:57 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:26:57 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:26:57 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:26:57 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:26:57 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:26:57 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:26:57 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:26:58 TP0] Decode batch. #running-req: 8, #token: 14521, token usage: 0.02, accept len: 2.85, cuda graph: True, gen throughput (token/s): 39.32, #queue-req: 0, 
[2025-09-13 07:26:59 TP0] Decode batch. #running-req: 8, #token: 15652, token usage: 0.03, accept len: 3.53, cuda graph: True, gen throughput (token/s): 896.95, #queue-req: 0, 
[2025-09-13 07:27:00 TP0] Decode batch. #running-req: 8, #token: 16846, token usage: 0.03, accept len: 3.73, cuda graph: True, gen throughput (token/s): 917.08, #queue-req: 0, 
 38%|█████████████████████████████████████████████████▏                                                                                 | 3/8 [00:05<00:06,  1.23s/it][2025-09-13 07:27:02 TP0] Decode batch. #running-req: 5, #token: 11814, token usage: 0.02, accept len: 3.40, cuda graph: True, gen throughput (token/s): 722.87, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.27it/s]
[2025-09-13 07:27:02] INFO:     127.0.0.1:42458 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.30      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4086      
Request throughput (req/s):              1.27      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         649.82    
Total token throughput (tok/s):          649.82    
Concurrency:                             7.00      
Accept length:                           3.42      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5512.92   
Median E2E Latency (ms):                 5542.03   
---------------Time to First Token----------------
Mean TTFT (ms):                          631.35    
Median TTFT (ms):                        742.33    
P99 TTFT (ms):                           742.88    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.55      
Median ITL (ms):                         7.31      
P95 ITL (ms):                            17.96     
P99 ITL (ms):                            32.48     
Max ITL (ms):                            727.79    
==================================================
[2025-09-13 07:27:02] INFO:     127.0.0.1:42472 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:27:02] INFO:     127.0.0.1:42480 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:27:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:27:03 TP0] Decode batch. #running-req: 1, #token: 4692, token usage: 0.01, accept len: 3.30, cuda graph: True, gen throughput (token/s): 225.98, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:27:04] INFO:     127.0.0.1:42484 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:27:04] INFO:     127.0.0.1:42500 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:27:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:27:04] INFO:     127.0.0.1:42512 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:27:04] INFO:     127.0.0.1:42524 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:27:04] INFO:     127.0.0.1:42536 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:27:04] INFO:     127.0.0.1:42546 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:27:04] INFO:     127.0.0.1:42556 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:27:04] INFO:     127.0.0.1:42560 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:27:04 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:27:05 TP0] Decode batch. #running-req: 8, #token: 14903, token usage: 0.02, accept len: 3.16, cuda graph: True, gen throughput (token/s): 399.60, #queue-req: 0, 
[2025-09-13 07:27:07 TP0] Decode batch. #running-req: 8, #token: 16092, token usage: 0.03, accept len: 3.72, cuda graph: True, gen throughput (token/s): 924.24, #queue-req: 0, 
[2025-09-13 07:27:08 TP0] Decode batch. #running-req: 8, #token: 17354, token usage: 0.03, accept len: 3.94, cuda graph: True, gen throughput (token/s): 973.57, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:02,  4.18s/it][2025-09-13 07:27:08] INFO:     127.0.0.1:55016 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:27:08 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:27:08] INFO:     127.0.0.1:55018 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:27:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:04<00:16,  1.27s/it][2025-09-13 07:27:08] INFO:     127.0.0.1:55022 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:27:09 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:11,  1.04it/s][2025-09-13 07:27:09] INFO:     127.0.0.1:55030 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:27:09 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:07,  1.38it/s][2025-09-13 07:27:09] INFO:     127.0.0.1:55038 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:27:09 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:06,  1.56it/s][2025-09-13 07:27:10] INFO:     127.0.0.1:55050 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:27:10 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:04,  1.81it/s][2025-09-13 07:27:10] INFO:     127.0.0.1:55064 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:27:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:27:10 TP0] Decode batch. #running-req: 8, #token: 10347, token usage: 0.02, accept len: 3.36, cuda graph: True, gen throughput (token/s): 456.22, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:07<00:05,  1.52it/s][2025-09-13 07:27:11] INFO:     127.0.0.1:55070 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:27:11 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:27:12 TP0] Decode batch. #running-req: 8, #token: 14885, token usage: 0.02, accept len: 3.19, cuda graph: True, gen throughput (token/s): 677.65, #queue-req: 0, 
[2025-09-13 07:27:13 TP0] Decode batch. #running-req: 8, #token: 16041, token usage: 0.03, accept len: 3.61, cuda graph: True, gen throughput (token/s): 891.03, #queue-req: 0, 
 69%|████████████████████████████████████████████████████████████████████████████████████████▋                                        | 11/16 [00:10<00:03,  1.34it/s][2025-09-13 07:27:14 TP0] Decode batch. #running-req: 5, #token: 12023, token usage: 0.02, accept len: 3.89, cuda graph: True, gen throughput (token/s): 891.57, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.43it/s]
[2025-09-13 07:27:15] INFO:     127.0.0.1:55076 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.23     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8097      
Request throughput (req/s):              1.42      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         729.48    
Total token throughput (tok/s):          729.48    
Concurrency:                             7.55      
Accept length:                           3.50      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5295.92   
Median E2E Latency (ms):                 5217.74   
---------------Time to First Token----------------
Mean TTFT (ms):                          234.69    
Median TTFT (ms):                        270.91    
P99 TTFT (ms):                           385.92    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.90      
Median ITL (ms):                         6.46      
P95 ITL (ms):                            30.89     
P99 ITL (ms):                            53.92     
Max ITL (ms):                            268.62    
==================================================
[2025-09-13 07:27:15] INFO:     127.0.0.1:55090 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=28: batch_size=8, steps=5, topk=3, num_draft_tokens=6, speed=108.37 token/s, step_time=32.31 ms
Start i=29: batch_size=8, steps=5, topk=3, num_draft_tokens=8
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 5 --speculative-eagle-topk 3 --speculative-num-draft-tokens 8 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:27:26.279000 289186 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:27:26.279000 289186 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:27:26] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=407638452, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=5, speculative_eagle_topk=3, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:27:27] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:27:35.418000 289441 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:27:35.418000 289441 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:27:35.614000 289439 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:27:35.614000 289439 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:27:35.614000 289443 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:27:35.614000 289443 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:27:35.707000 289446 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:27:35.707000 289446 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:27:35.784000 289445 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:27:35.784000 289445 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:27:35.844000 289438 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:27:35.844000 289438 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:27:35.845000 289444 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:27:35.845000 289444 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:27:35.875000 289440 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:27:35.875000 289440 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:27:35.913000 289442 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:27:35.913000 289442 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:27:36 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:27:36 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:27:36 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:27:38 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:27:40 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:27:42 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:27:42 TP0] Detected fp8 checkpoint.
[2025-09-13 07:27:42 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 35/1024 [00:00<00:02, 338.00it/s]
Loading safetensors checkpoint shards:   7% Completed | 69/1024 [00:01<00:18, 52.11it/s]
Loading safetensors checkpoint shards:   8% Completed | 85/1024 [00:01<00:18, 49.56it/s]
Loading safetensors checkpoint shards:   9% Completed | 96/1024 [00:01<00:19, 47.98it/s]
Loading safetensors checkpoint shards:  10% Completed | 105/1024 [00:01<00:18, 48.45it/s]
Loading safetensors checkpoint shards:  11% Completed | 113/1024 [00:02<00:28, 31.84it/s]
Loading safetensors checkpoint shards:  12% Completed | 119/1024 [00:02<00:26, 33.63it/s]
Loading safetensors checkpoint shards:  12% Completed | 124/1024 [00:02<00:26, 34.55it/s]
Loading safetensors checkpoint shards:  13% Completed | 129/1024 [00:02<00:24, 36.79it/s]
Loading safetensors checkpoint shards:  13% Completed | 134/1024 [00:03<00:23, 37.23it/s]
Loading safetensors checkpoint shards:  14% Completed | 140/1024 [00:03<00:22, 39.94it/s]
Loading safetensors checkpoint shards:  14% Completed | 145/1024 [00:03<00:22, 39.20it/s]
Loading safetensors checkpoint shards:  15% Completed | 150/1024 [00:03<00:21, 39.93it/s]
Loading safetensors checkpoint shards:  15% Completed | 155/1024 [00:03<00:21, 39.60it/s]
Loading safetensors checkpoint shards:  16% Completed | 160/1024 [00:03<00:20, 41.24it/s]
Loading safetensors checkpoint shards:  16% Completed | 165/1024 [00:03<00:21, 40.46it/s]
Loading safetensors checkpoint shards:  17% Completed | 170/1024 [00:03<00:20, 41.30it/s]
Loading safetensors checkpoint shards:  17% Completed | 176/1024 [00:04<00:19, 43.60it/s]
Loading safetensors checkpoint shards:  18% Completed | 181/1024 [00:04<00:20, 41.91it/s]
Loading safetensors checkpoint shards:  18% Completed | 186/1024 [00:04<00:19, 42.57it/s]
Loading safetensors checkpoint shards:  19% Completed | 191/1024 [00:04<00:20, 41.00it/s]
Loading safetensors checkpoint shards:  19% Completed | 196/1024 [00:04<00:19, 41.72it/s]
Loading safetensors checkpoint shards:  20% Completed | 201/1024 [00:04<00:20, 40.08it/s]
Loading safetensors checkpoint shards:  20% Completed | 206/1024 [00:04<00:20, 40.63it/s]
Loading safetensors checkpoint shards:  21% Completed | 211/1024 [00:04<00:19, 41.57it/s]
Loading safetensors checkpoint shards:  21% Completed | 217/1024 [00:04<00:18, 44.23it/s]
Loading safetensors checkpoint shards:  22% Completed | 222/1024 [00:05<00:18, 43.41it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:05<00:18, 43.89it/s]
Loading safetensors checkpoint shards:  23% Completed | 232/1024 [00:05<00:17, 44.14it/s]
Loading safetensors checkpoint shards:  23% Completed | 237/1024 [00:05<00:17, 45.05it/s]
Loading safetensors checkpoint shards:  24% Completed | 242/1024 [00:05<00:18, 42.63it/s]
Loading safetensors checkpoint shards:  24% Completed | 247/1024 [00:05<00:18, 41.69it/s]
Loading safetensors checkpoint shards:  25% Completed | 253/1024 [00:05<00:17, 44.45it/s]
Loading safetensors checkpoint shards:  25% Completed | 258/1024 [00:05<00:17, 44.13it/s]
Loading safetensors checkpoint shards:  26% Completed | 264/1024 [00:06<00:16, 45.61it/s]
Loading safetensors checkpoint shards:  26% Completed | 269/1024 [00:06<00:17, 43.99it/s]
Loading safetensors checkpoint shards:  27% Completed | 274/1024 [00:06<00:16, 44.32it/s]
Loading safetensors checkpoint shards:  27% Completed | 279/1024 [00:06<00:16, 44.63it/s]
Loading safetensors checkpoint shards:  28% Completed | 284/1024 [00:06<00:16, 45.59it/s]
Loading safetensors checkpoint shards:  28% Completed | 289/1024 [00:06<00:18, 40.04it/s]
Loading safetensors checkpoint shards:  29% Completed | 294/1024 [00:06<00:18, 39.84it/s]
Loading safetensors checkpoint shards:  29% Completed | 299/1024 [00:06<00:18, 38.63it/s]
Loading safetensors checkpoint shards:  30% Completed | 305/1024 [00:07<00:17, 41.40it/s]
Loading safetensors checkpoint shards:  30% Completed | 310/1024 [00:07<00:17, 40.58it/s]
Loading safetensors checkpoint shards:  31% Completed | 315/1024 [00:07<00:36, 19.60it/s]
Loading safetensors checkpoint shards:  31% Completed | 319/1024 [00:07<00:31, 22.19it/s]
Loading safetensors checkpoint shards:  32% Completed | 323/1024 [00:07<00:28, 24.35it/s]
Loading safetensors checkpoint shards:  32% Completed | 328/1024 [00:08<00:24, 28.31it/s]
Loading safetensors checkpoint shards:  32% Completed | 332/1024 [00:08<00:22, 30.50it/s]
Loading safetensors checkpoint shards:  33% Completed | 336/1024 [00:08<00:21, 32.28it/s]
Loading safetensors checkpoint shards:  33% Completed | 341/1024 [00:08<00:19, 34.88it/s]
Loading safetensors checkpoint shards:  34% Completed | 345/1024 [00:08<00:20, 32.89it/s]
Loading safetensors checkpoint shards:  34% Completed | 350/1024 [00:08<00:19, 35.12it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:08<00:19, 35.23it/s]
Loading safetensors checkpoint shards:  35% Completed | 358/1024 [00:08<00:18, 35.79it/s]
Loading safetensors checkpoint shards:  35% Completed | 363/1024 [00:09<00:17, 38.60it/s]
Loading safetensors checkpoint shards:  36% Completed | 367/1024 [00:09<00:17, 37.82it/s]
Loading safetensors checkpoint shards:  36% Completed | 372/1024 [00:09<00:16, 39.84it/s]
Loading safetensors checkpoint shards:  37% Completed | 377/1024 [00:09<00:16, 39.28it/s]
Loading safetensors checkpoint shards:  37% Completed | 381/1024 [00:09<00:16, 38.82it/s]
Loading safetensors checkpoint shards:  38% Completed | 386/1024 [00:09<00:15, 39.90it/s]
Loading safetensors checkpoint shards:  38% Completed | 391/1024 [00:09<00:16, 39.36it/s]
Loading safetensors checkpoint shards:  39% Completed | 396/1024 [00:09<00:15, 40.57it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:09<00:15, 39.83it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:10<00:15, 40.67it/s]
Loading safetensors checkpoint shards:  40% Completed | 411/1024 [00:10<00:15, 40.16it/s]
Loading safetensors checkpoint shards:  41% Completed | 417/1024 [00:10<00:14, 42.30it/s]
Loading safetensors checkpoint shards:  41% Completed | 424/1024 [00:10<00:12, 48.65it/s]
Loading safetensors checkpoint shards:  42% Completed | 431/1024 [00:10<00:11, 51.50it/s]
Loading safetensors checkpoint shards:  43% Completed | 437/1024 [00:10<00:12, 48.54it/s]
Loading safetensors checkpoint shards:  43% Completed | 442/1024 [00:10<00:12, 48.14it/s]
Loading safetensors checkpoint shards:  44% Completed | 448/1024 [00:10<00:11, 50.66it/s]
Loading safetensors checkpoint shards:  44% Completed | 454/1024 [00:11<00:11, 49.20it/s]
Loading safetensors checkpoint shards:  45% Completed | 461/1024 [00:11<00:10, 51.85it/s]
Loading safetensors checkpoint shards:  46% Completed | 467/1024 [00:11<00:11, 49.67it/s]
Loading safetensors checkpoint shards:  46% Completed | 475/1024 [00:11<00:09, 54.96it/s]
Loading safetensors checkpoint shards:  47% Completed | 481/1024 [00:11<00:10, 51.74it/s]
Loading safetensors checkpoint shards:  48% Completed | 487/1024 [00:11<00:10, 53.28it/s]
Loading safetensors checkpoint shards:  48% Completed | 493/1024 [00:11<00:09, 53.86it/s]
Loading safetensors checkpoint shards:  49% Completed | 500/1024 [00:11<00:09, 55.97it/s]
Loading safetensors checkpoint shards:  49% Completed | 506/1024 [00:11<00:09, 55.71it/s]
Loading safetensors checkpoint shards:  50% Completed | 512/1024 [00:12<00:09, 54.51it/s]
Loading safetensors checkpoint shards:  51% Completed | 519/1024 [00:12<00:08, 56.19it/s]
Loading safetensors checkpoint shards:  51% Completed | 525/1024 [00:12<00:20, 24.85it/s]
Loading safetensors checkpoint shards:  52% Completed | 530/1024 [00:12<00:17, 27.88it/s]
Loading safetensors checkpoint shards:  52% Completed | 535/1024 [00:13<00:17, 28.72it/s]
Loading safetensors checkpoint shards:  53% Completed | 540/1024 [00:13<00:14, 32.31it/s]
Loading safetensors checkpoint shards:  53% Completed | 545/1024 [00:13<00:13, 34.77it/s]
Loading safetensors checkpoint shards:  54% Completed | 551/1024 [00:13<00:12, 39.22it/s]
Loading safetensors checkpoint shards:  54% Completed | 556/1024 [00:13<00:12, 36.10it/s]
Loading safetensors checkpoint shards:  55% Completed | 561/1024 [00:13<00:12, 35.79it/s]
Loading safetensors checkpoint shards:  55% Completed | 565/1024 [00:13<00:15, 29.19it/s]
Loading safetensors checkpoint shards:  56% Completed | 569/1024 [00:14<00:17, 26.64it/s]
Loading safetensors checkpoint shards:  56% Completed | 572/1024 [00:14<00:17, 25.61it/s]
Loading safetensors checkpoint shards:  56% Completed | 575/1024 [00:14<00:19, 23.43it/s]
Loading safetensors checkpoint shards:  56% Completed | 578/1024 [00:14<00:20, 21.24it/s]
Loading safetensors checkpoint shards:  57% Completed | 581/1024 [00:14<00:20, 21.46it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:14<00:18, 23.20it/s]
Loading safetensors checkpoint shards:  57% Completed | 588/1024 [00:14<00:18, 24.01it/s]
Loading safetensors checkpoint shards:  58% Completed | 592/1024 [00:15<00:16, 26.44it/s]
Loading safetensors checkpoint shards:  58% Completed | 597/1024 [00:15<00:13, 30.72it/s]
Loading safetensors checkpoint shards:  59% Completed | 601/1024 [00:15<00:13, 32.33it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:15<00:12, 34.48it/s]
Loading safetensors checkpoint shards:  60% Completed | 611/1024 [00:15<00:11, 35.28it/s]
Loading safetensors checkpoint shards:  60% Completed | 616/1024 [00:15<00:11, 37.05it/s]
Loading safetensors checkpoint shards:  61% Completed | 620/1024 [00:15<00:10, 37.22it/s]
Loading safetensors checkpoint shards:  61% Completed | 625/1024 [00:15<00:10, 38.16it/s]
Loading safetensors checkpoint shards:  61% Completed | 629/1024 [00:16<00:10, 38.40it/s]
Loading safetensors checkpoint shards:  62% Completed | 633/1024 [00:16<00:10, 37.48it/s]
Loading safetensors checkpoint shards:  62% Completed | 637/1024 [00:16<00:10, 36.82it/s]
Loading safetensors checkpoint shards:  63% Completed | 641/1024 [00:16<00:10, 36.45it/s]
Loading safetensors checkpoint shards:  63% Completed | 645/1024 [00:16<00:10, 34.90it/s]
Loading safetensors checkpoint shards:  63% Completed | 649/1024 [00:16<00:10, 34.97it/s]
Loading safetensors checkpoint shards:  64% Completed | 653/1024 [00:16<00:10, 35.08it/s]
Loading safetensors checkpoint shards:  64% Completed | 657/1024 [00:16<00:10, 35.08it/s]
Loading safetensors checkpoint shards:  65% Completed | 661/1024 [00:17<00:10, 33.20it/s]
Loading safetensors checkpoint shards:  65% Completed | 665/1024 [00:17<00:10, 33.65it/s]
Loading safetensors checkpoint shards:  65% Completed | 669/1024 [00:17<00:10, 34.34it/s]
Loading safetensors checkpoint shards:  66% Completed | 673/1024 [00:17<00:10, 34.65it/s]
Loading safetensors checkpoint shards:  66% Completed | 677/1024 [00:17<00:10, 33.31it/s]
Loading safetensors checkpoint shards:  67% Completed | 681/1024 [00:17<00:10, 34.23it/s]
Loading safetensors checkpoint shards:  67% Completed | 685/1024 [00:17<00:09, 34.50it/s]
Loading safetensors checkpoint shards:  67% Completed | 689/1024 [00:17<00:09, 35.20it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:17<00:08, 37.42it/s]
Loading safetensors checkpoint shards:  68% Completed | 698/1024 [00:18<00:08, 37.46it/s]
Loading safetensors checkpoint shards:  69% Completed | 702/1024 [00:18<00:09, 35.46it/s]
Loading safetensors checkpoint shards:  69% Completed | 706/1024 [00:18<00:09, 35.14it/s]
Loading safetensors checkpoint shards:  69% Completed | 710/1024 [00:18<00:09, 34.36it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:18<00:09, 34.36it/s]
Loading safetensors checkpoint shards:  70% Completed | 718/1024 [00:18<00:08, 34.43it/s]
Loading safetensors checkpoint shards:  71% Completed | 722/1024 [00:18<00:08, 34.66it/s]
Loading safetensors checkpoint shards:  71% Completed | 726/1024 [00:18<00:08, 34.84it/s]
Loading safetensors checkpoint shards:  71% Completed | 730/1024 [00:18<00:08, 35.39it/s]
Loading safetensors checkpoint shards:  72% Completed | 734/1024 [00:19<00:08, 34.34it/s]
Loading safetensors checkpoint shards:  72% Completed | 738/1024 [00:19<00:08, 34.99it/s]
Loading safetensors checkpoint shards:  73% Completed | 743/1024 [00:19<00:07, 38.51it/s]
Loading safetensors checkpoint shards:  73% Completed | 747/1024 [00:19<00:07, 37.90it/s]
Loading safetensors checkpoint shards:  73% Completed | 752/1024 [00:19<00:06, 40.59it/s]
Loading safetensors checkpoint shards:  74% Completed | 757/1024 [00:19<00:06, 42.62it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:19<00:05, 46.36it/s]
Loading safetensors checkpoint shards:  75% Completed | 768/1024 [00:19<00:05, 46.16it/s]
Loading safetensors checkpoint shards:  75% Completed | 773/1024 [00:19<00:05, 43.65it/s]
Loading safetensors checkpoint shards:  76% Completed | 780/1024 [00:20<00:13, 17.74it/s]
Loading safetensors checkpoint shards:  77% Completed | 786/1024 [00:20<00:10, 22.74it/s]
Loading safetensors checkpoint shards:  77% Completed | 791/1024 [00:20<00:08, 26.41it/s]
Loading safetensors checkpoint shards:  78% Completed | 798/1024 [00:21<00:06, 32.96it/s]
Loading safetensors checkpoint shards:  79% Completed | 804/1024 [00:21<00:05, 38.04it/s]
Loading safetensors checkpoint shards:  79% Completed | 811/1024 [00:21<00:04, 43.84it/s]
Loading safetensors checkpoint shards:  80% Completed | 818/1024 [00:21<00:04, 49.18it/s]
Loading safetensors checkpoint shards:  80% Completed | 824/1024 [00:21<00:03, 51.10it/s]
Loading safetensors checkpoint shards:  81% Completed | 830/1024 [00:21<00:03, 53.20it/s]
Loading safetensors checkpoint shards:  82% Completed | 836/1024 [00:21<00:03, 54.60it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:21<00:03, 55.62it/s]
Loading safetensors checkpoint shards:  83% Completed | 848/1024 [00:21<00:03, 55.53it/s]
Loading safetensors checkpoint shards:  83% Completed | 855/1024 [00:22<00:02, 59.59it/s]
Loading safetensors checkpoint shards:  84% Completed | 862/1024 [00:22<00:02, 60.16it/s]
Loading safetensors checkpoint shards:  85% Completed | 870/1024 [00:22<00:02, 63.25it/s]
Loading safetensors checkpoint shards:  86% Completed | 877/1024 [00:22<00:02, 59.32it/s]
Loading safetensors checkpoint shards:  86% Completed | 884/1024 [00:22<00:02, 57.29it/s]
Loading safetensors checkpoint shards:  87% Completed | 890/1024 [00:22<00:02, 53.52it/s]
Loading safetensors checkpoint shards:  88% Completed | 896/1024 [00:22<00:02, 53.82it/s]
Loading safetensors checkpoint shards:  88% Completed | 903/1024 [00:22<00:02, 57.31it/s]
Loading safetensors checkpoint shards:  89% Completed | 911/1024 [00:22<00:01, 62.94it/s]
Loading safetensors checkpoint shards:  90% Completed | 921/1024 [00:23<00:01, 71.65it/s]
Loading safetensors checkpoint shards:  91% Completed | 931/1024 [00:23<00:01, 76.89it/s]
Loading safetensors checkpoint shards:  92% Completed | 940/1024 [00:23<00:01, 79.86it/s]
Loading safetensors checkpoint shards:  93% Completed | 949/1024 [00:23<00:00, 78.49it/s]
Loading safetensors checkpoint shards:  94% Completed | 958/1024 [00:23<00:00, 81.49it/s]
Loading safetensors checkpoint shards:  94% Completed | 967/1024 [00:23<00:00, 75.46it/s]
Loading safetensors checkpoint shards:  95% Completed | 975/1024 [00:23<00:00, 74.76it/s]
Loading safetensors checkpoint shards:  96% Completed | 986/1024 [00:23<00:00, 80.24it/s]
Loading safetensors checkpoint shards:  98% Completed | 1003/1024 [00:23<00:00, 103.70it/s]
Loading safetensors checkpoint shards: 100% Completed | 1021/1024 [00:24<00:00, 124.37it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:24<00:00, 42.50it/s]
 
[2025-09-13 07:28:10 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:28:10 TP6] KV Cache is allocated. #tokens: 620241, KV size: 40.59 GB
[2025-09-13 07:28:10 TP7] KV Cache is allocated. #tokens: 620241, KV size: 40.59 GB
[2025-09-13 07:28:10 TP1] KV Cache is allocated. #tokens: 620241, KV size: 40.59 GB
[2025-09-13 07:28:10 TP0] KV Cache is allocated. #tokens: 620241, KV size: 40.59 GB
[2025-09-13 07:28:10 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:28:10 TP5] KV Cache is allocated. #tokens: 620241, KV size: 40.59 GB
[2025-09-13 07:28:10 TP3] KV Cache is allocated. #tokens: 620241, KV size: 40.59 GB
[2025-09-13 07:28:10 TP2] KV Cache is allocated. #tokens: 620241, KV size: 40.59 GB
[2025-09-13 07:28:10 TP4] KV Cache is allocated. #tokens: 620241, KV size: 40.59 GB
[2025-09-13 07:28:10 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:28:11 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.51 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s][2025-09-13 07:28:12 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:28:12 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:28:12 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:28:12 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:28:12 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:28:12 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:28:12 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:28:12 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:28:12 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25279.35it/s]
[2025-09-13 07:28:12 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:28:12 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26242.67it/s]
[2025-09-13 07:28:13 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:28:13 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27956.75it/s]
[2025-09-13 07:28:14 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:28:14 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26976.48it/s]
[2025-09-13 07:28:14 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:28:14 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28192.72it/s]
[2025-09-13 07:28:15 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.20 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.75it/s][2025-09-13 07:28:18 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:28:18 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:28:18 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:28:18 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:28:18 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:28:18 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:28:18 TP6] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.20 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.11it/s]
[2025-09-13 07:28:18 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:28:18 TP0] Capture cuda graph end. Time elapsed: 7.99 s. mem usage=0.39 GB. avail mem=17.17 GB.
[2025-09-13 07:28:19 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:28:19 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:28:19 TP0] Init torch distributed begin.
[2025-09-13 07:28:19 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:28:19 TP0] Load weight begin. avail mem=17.17 GB
[2025-09-13 07:28:19 TP0] Detected fp8 checkpoint.
[2025-09-13 07:28:19 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 179.90it/s]
Loading safetensors checkpoint shards:   4% Completed | 41/1024 [00:00<00:04, 208.22it/s]
Loading safetensors checkpoint shards:  10% Completed | 100/1024 [00:00<00:02, 380.90it/s]
Loading safetensors checkpoint shards:  16% Completed | 162/1024 [00:00<00:01, 474.16it/s]
Loading safetensors checkpoint shards:  22% Completed | 223/1024 [00:00<00:01, 520.77it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:00<00:01, 553.55it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:00<00:01, 569.95it/s]
Loading safetensors checkpoint shards:  40% Completed | 408/1024 [00:00<00:01, 585.13it/s]
Loading safetensors checkpoint shards:  46% Completed | 469/1024 [00:00<00:00, 590.14it/s]
Loading safetensors checkpoint shards:  52% Completed | 531/1024 [00:01<00:00, 599.05it/s]
Loading safetensors checkpoint shards:  58% Completed | 593/1024 [00:01<00:00, 605.00it/s]
Loading safetensors checkpoint shards:  64% Completed | 654/1024 [00:01<00:00, 598.19it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:01<00:00, 591.03it/s]
Loading safetensors checkpoint shards:  76% Completed | 774/1024 [00:01<00:00, 582.24it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:01<00:00, 577.80it/s]
Loading safetensors checkpoint shards:  87% Completed | 891/1024 [00:01<00:00, 573.88it/s]
Loading safetensors checkpoint shards:  93% Completed | 949/1024 [00:01<00:00, 573.55it/s]
Loading safetensors checkpoint shards:  98% Completed | 1007/1024 [00:01<00:00, 427.78it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 507.78it/s]

[2025-09-13 07:28:21 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.18 GB, mem usage=1.99 GB.
[2025-09-13 07:28:21 TP1] KV Cache is allocated. #tokens: 620241, KV size: 0.67 GB
[2025-09-13 07:28:21 TP6] KV Cache is allocated. #tokens: 620241, KV size: 0.67 GB
[2025-09-13 07:28:21 TP2] KV Cache is allocated. #tokens: 620241, KV size: 0.67 GB
[2025-09-13 07:28:21 TP3] KV Cache is allocated. #tokens: 620241, KV size: 0.67 GB
[2025-09-13 07:28:21 TP5] KV Cache is allocated. #tokens: 620241, KV size: 0.67 GB
[2025-09-13 07:28:21 TP0] KV Cache is allocated. #tokens: 620241, KV size: 0.67 GB
[2025-09-13 07:28:21 TP7] KV Cache is allocated. #tokens: 620241, KV size: 0.67 GB
[2025-09-13 07:28:21 TP4] KV Cache is allocated. #tokens: 620241, KV size: 0.67 GB
[2025-09-13 07:28:21 TP0] Memory pool end. avail mem=14.52 GB
[2025-09-13 07:28:21 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:28:21 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:28:21 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.14 GB
[2025-09-13 07:28:21 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:28:21 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:28:21 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:28:21 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:28:21 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.95 GB
Capturing batches (bs=1 avail_mem=14.54 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  3.13it/s][2025-09-13 07:28:28 TP7] Registering 96 cuda graph addresses
[2025-09-13 07:28:28 TP1] Registering 96 cuda graph addresses
[2025-09-13 07:28:28 TP3] Registering 96 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.54 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.46it/s]
[2025-09-13 07:28:28 TP5] Registering 96 cuda graph addresses
[2025-09-13 07:28:28 TP0] Registering 96 cuda graph addresses
[2025-09-13 07:28:28 TP6] Registering 96 cuda graph addresses
[2025-09-13 07:28:28 TP4] Registering 96 cuda graph addresses
[2025-09-13 07:28:28 TP2] Registering 96 cuda graph addresses
[2025-09-13 07:28:28 TP5] Capture draft cuda graph end. Time elapsed: 6.27 s. mem usage=0.41 GB. avail mem=14.49 GB.
[2025-09-13 07:28:28 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.49 GB
[2025-09-13 07:28:28 TP1] Capture draft cuda graph end. Time elapsed: 6.27 s. mem usage=0.41 GB. avail mem=14.49 GB.
[2025-09-13 07:28:28 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.49 GB
[2025-09-13 07:28:28 TP3] Capture draft cuda graph end. Time elapsed: 6.27 s. mem usage=0.41 GB. avail mem=14.49 GB.
[2025-09-13 07:28:28 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.49 GB
[2025-09-13 07:28:28 TP0] Capture draft cuda graph end. Time elapsed: 6.27 s. mem usage=0.41 GB. avail mem=14.54 GB.
[2025-09-13 07:28:28 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 07:28:28 TP2] Capture draft cuda graph end. Time elapsed: 6.27 s. mem usage=0.41 GB. avail mem=14.49 GB.
[2025-09-13 07:28:28 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.49 GB
[2025-09-13 07:28:28 TP7] Capture draft cuda graph end. Time elapsed: 6.27 s. mem usage=0.41 GB. avail mem=14.73 GB.
[2025-09-13 07:28:28 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.73 GB
[2025-09-13 07:28:28 TP4] Capture draft cuda graph end. Time elapsed: 6.27 s. mem usage=0.41 GB. avail mem=14.49 GB.
[2025-09-13 07:28:28 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.49 GB
[2025-09-13 07:28:28 TP6] Capture draft cuda graph end. Time elapsed: 6.27 s. mem usage=0.41 GB. avail mem=14.49 GB.
[2025-09-13 07:28:28 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.49 GB
Capturing batches (bs=1 avail_mem=14.35 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 35.65it/s]
[2025-09-13 07:28:29 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:28:29 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:28:29 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:28:29 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:28:29 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:28:29 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:28:29 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:28:29 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:28:29 TP1] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.31 GB.
[2025-09-13 07:28:29 TP6] Capture draft extend cuda graph end. Time elapsed: 1.10 s. mem usage=0.19 GB. avail mem=14.31 GB.
[2025-09-13 07:28:29 TP4] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.31 GB.
[2025-09-13 07:28:29 TP3] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.31 GB.
[2025-09-13 07:28:29 TP0] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.35 GB.
[2025-09-13 07:28:29 TP0] max_total_num_tokens=620241, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.35 GB
[2025-09-13 07:28:29 TP2] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.31 GB.
[2025-09-13 07:28:29 TP7] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.54 GB.
[2025-09-13 07:28:29 TP5] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.31 GB.
[2025-09-13 07:28:29] INFO:     Started server process [289186]
[2025-09-13 07:28:29] INFO:     Waiting for application startup.
[2025-09-13 07:28:29] INFO:     Application startup complete.
[2025-09-13 07:28:29] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:28:30] INFO:     127.0.0.1:40418 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:28:30] INFO:     127.0.0.1:40422 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:28:30 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:28:30 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:28:30 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26127.03it/s]
[2025-09-13 07:28:32] INFO:     127.0.0.1:40424 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:32] The server is fired up and ready to roll!
[2025-09-13 07:28:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:28:41] INFO:     127.0.0.1:59720 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:28:42] INFO:     127.0.0.1:59722 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:42 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:28:43] INFO:     127.0.0.1:59732 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:43] INFO:     127.0.0.1:59736 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:28:43] INFO:     127.0.0.1:59748 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:43] INFO:     127.0.0.1:59760 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:43] INFO:     127.0.0.1:59766 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:43] INFO:     127.0.0.1:59778 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:43] INFO:     127.0.0.1:59792 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:43] INFO:     127.0.0.1:59798 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:43 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:28:44 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:28:44 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:28:44 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:28:44 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:28:44 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:28:44 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:28:44 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:28:44 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:28:44 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:28:45 TP0] Decode batch. #running-req: 8, #token: 14615, token usage: 0.02, accept len: 3.17, cuda graph: True, gen throughput (token/s): 45.79, #queue-req: 0, 
[2025-09-13 07:28:46 TP0] Decode batch. #running-req: 8, #token: 15869, token usage: 0.03, accept len: 3.92, cuda graph: True, gen throughput (token/s): 869.71, #queue-req: 0, 
[2025-09-13 07:28:48 TP0] Decode batch. #running-req: 8, #token: 17245, token usage: 0.03, accept len: 4.30, cuda graph: True, gen throughput (token/s): 1006.00, #queue-req: 0, 
 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 7/8 [00:05<00:00,  2.86it/s][2025-09-13 07:28:49 TP0] Decode batch. #running-req: 1, #token: 1450, token usage: 0.00, accept len: 3.99, cuda graph: True, gen throughput (token/s): 515.56, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.30it/s]
[2025-09-13 07:28:49] INFO:     127.0.0.1:58140 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.16      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4088      
Request throughput (req/s):              1.30      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         664.70    
Total token throughput (tok/s):          664.70    
Concurrency:                             6.90      
Accept length:                           3.88      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5317.73   
Median E2E Latency (ms):                 5377.87   
---------------Time to First Token----------------
Mean TTFT (ms):                          625.72    
Median TTFT (ms):                        742.28    
P99 TTFT (ms):                           742.88    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.18      
Median ITL (ms):                         6.68      
P95 ITL (ms):                            17.57     
P99 ITL (ms):                            33.98     
Max ITL (ms):                            748.99    
==================================================
[2025-09-13 07:28:49] INFO:     127.0.0.1:58148 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:28:49] INFO:     127.0.0.1:58154 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:28:51] INFO:     127.0.0.1:58158 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:51] INFO:     127.0.0.1:58160 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:28:51] INFO:     127.0.0.1:58166 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:51] INFO:     127.0.0.1:58182 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:51] INFO:     127.0.0.1:58186 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:51] INFO:     127.0.0.1:58200 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:51] INFO:     127.0.0.1:58206 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:51] INFO:     127.0.0.1:58208 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:51 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:28:51 TP0] Decode batch. #running-req: 8, #token: 14262, token usage: 0.02, accept len: 3.19, cuda graph: True, gen throughput (token/s): 186.90, #queue-req: 0, 
[2025-09-13 07:28:53 TP0] Decode batch. #running-req: 8, #token: 15430, token usage: 0.02, accept len: 3.65, cuda graph: True, gen throughput (token/s): 879.48, #queue-req: 0, 
[2025-09-13 07:28:54 TP0] Decode batch. #running-req: 8, #token: 16768, token usage: 0.03, accept len: 4.18, cuda graph: True, gen throughput (token/s): 983.55, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:03<00:58,  3.93s/it][2025-09-13 07:28:54] INFO:     127.0.0.1:58212 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:54 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:26,  1.89s/it][2025-09-13 07:28:55] INFO:     127.0.0.1:58228 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:55 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:04<00:15,  1.16s/it][2025-09-13 07:28:55] INFO:     127.0.0.1:58242 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:55 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:11,  1.09it/s][2025-09-13 07:28:56] INFO:     127.0.0.1:58252 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:56 TP0] Decode batch. #running-req: 7, #token: 7279, token usage: 0.01, accept len: 4.09, cuda graph: True, gen throughput (token/s): 692.13, #queue-req: 0, 
[2025-09-13 07:28:56 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:28:56] INFO:     127.0.0.1:58266 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:56 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:04,  2.07it/s][2025-09-13 07:28:56] INFO:     127.0.0.1:58268 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:56 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:05<00:04,  2.21it/s][2025-09-13 07:28:56] INFO:     127.0.0.1:58276 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:04,  1.63it/s][2025-09-13 07:28:57] INFO:     127.0.0.1:58282 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:28:57 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:28:58 TP0] Decode batch. #running-req: 8, #token: 14633, token usage: 0.02, accept len: 3.50, cuda graph: True, gen throughput (token/s): 526.25, #queue-req: 0, 
[2025-09-13 07:28:59 TP0] Decode batch. #running-req: 8, #token: 15928, token usage: 0.03, accept len: 4.05, cuda graph: True, gen throughput (token/s): 973.47, #queue-req: 0, 
 69%|████████████████████████████████████████████████████████████████████████████████████████▋                                        | 11/16 [00:09<00:03,  1.35it/s][2025-09-13 07:29:01 TP0] Decode batch. #running-req: 4, #token: 11386, token usage: 0.02, accept len: 4.55, cuda graph: True, gen throughput (token/s): 957.85, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.47it/s]
[2025-09-13 07:29:01] INFO:     127.0.0.1:36088 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  10.91     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8092      
Request throughput (req/s):              1.47      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         750.94    
Total token throughput (tok/s):          750.94    
Concurrency:                             7.38      
Accept length:                           3.92      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5034.03   
Median E2E Latency (ms):                 5016.99   
---------------Time to First Token----------------
Mean TTFT (ms):                          244.92    
Median TTFT (ms):                        285.43    
P99 TTFT (ms):                           339.33    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.37      
Median ITL (ms):                         5.78      
P95 ITL (ms):                            27.03     
P99 ITL (ms):                            49.62     
Max ITL (ms):                            210.07    
==================================================
[2025-09-13 07:29:01] INFO:     127.0.0.1:36096 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=29: batch_size=8, steps=5, topk=3, num_draft_tokens=8, speed=116.67 token/s, step_time=33.56 ms
Start i=30: batch_size=8, steps=5, topk=3, num_draft_tokens=12
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 5 --speculative-eagle-topk 3 --speculative-num-draft-tokens 12 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:29:12.667000 295455 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:29:12.667000 295455 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:29:12] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=505826762, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=5, speculative_eagle_topk=3, speculative_num_draft_tokens=12, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:29:13] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:29:21.539000 295662 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:29:21.539000 295662 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 07:29:21.848000 295666 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:29:21.848000 295666 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
[2025-09-13 07:29:22 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:29:22 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:29:22 TP0] Init torch distributed begin.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:29:22.210000 295668 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:29:22.210000 295668 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:29:22.237000 295669 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:29:22.237000 295669 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:29:22.237000 295667 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:29:22.237000 295667 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:29:22.263000 295670 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:29:22.263000 295670 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:29:22.264000 295665 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:29:22.264000 295665 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:29:22.285000 295663 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:29:22.285000 295663 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:29:22.326000 295664 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:29:22.326000 295664 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:29:23 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:29:27 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:29:29 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:29:29 TP0] Detected fp8 checkpoint.
[2025-09-13 07:29:29 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:03, 253.72it/s]
Loading safetensors checkpoint shards:   5% Completed | 52/1024 [00:00<00:13, 73.69it/s]
Loading safetensors checkpoint shards:   6% Completed | 66/1024 [00:00<00:15, 61.24it/s]
Loading safetensors checkpoint shards:   7% Completed | 76/1024 [00:01<00:16, 59.06it/s]
Loading safetensors checkpoint shards:   8% Completed | 84/1024 [00:01<00:15, 60.67it/s]
Loading safetensors checkpoint shards:   9% Completed | 92/1024 [00:01<00:18, 51.17it/s]
Loading safetensors checkpoint shards:  10% Completed | 99/1024 [00:01<00:20, 45.72it/s]
Loading safetensors checkpoint shards:  10% Completed | 105/1024 [00:02<00:32, 28.34it/s]
Loading safetensors checkpoint shards:  11% Completed | 109/1024 [00:02<00:32, 28.36it/s]
Loading safetensors checkpoint shards:  11% Completed | 113/1024 [00:02<00:30, 29.71it/s]
Loading safetensors checkpoint shards:  12% Completed | 118/1024 [00:02<00:27, 33.22it/s]
Loading safetensors checkpoint shards:  12% Completed | 124/1024 [00:02<00:24, 37.37it/s]
Loading safetensors checkpoint shards:  13% Completed | 130/1024 [00:02<00:21, 41.11it/s]
Loading safetensors checkpoint shards:  13% Completed | 135/1024 [00:02<00:21, 40.67it/s]
Loading safetensors checkpoint shards:  14% Completed | 141/1024 [00:03<00:19, 44.82it/s]
Loading safetensors checkpoint shards:  14% Completed | 146/1024 [00:03<00:19, 44.52it/s]
Loading safetensors checkpoint shards:  15% Completed | 151/1024 [00:03<00:19, 44.70it/s]
Loading safetensors checkpoint shards:  15% Completed | 156/1024 [00:03<00:19, 43.89it/s]
Loading safetensors checkpoint shards:  16% Completed | 162/1024 [00:03<00:18, 45.68it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:03<00:19, 43.88it/s]
Loading safetensors checkpoint shards:  17% Completed | 172/1024 [00:03<00:18, 45.43it/s]
Loading safetensors checkpoint shards:  17% Completed | 177/1024 [00:03<00:18, 45.02it/s]
Loading safetensors checkpoint shards:  18% Completed | 182/1024 [00:03<00:18, 45.64it/s]
Loading safetensors checkpoint shards:  18% Completed | 187/1024 [00:04<00:18, 45.19it/s]
Loading safetensors checkpoint shards:  19% Completed | 192/1024 [00:04<00:18, 45.35it/s]
Loading safetensors checkpoint shards:  19% Completed | 198/1024 [00:04<00:17, 46.42it/s]
Loading safetensors checkpoint shards:  20% Completed | 203/1024 [00:04<00:18, 44.91it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:04<00:17, 46.68it/s]
Loading safetensors checkpoint shards:  21% Completed | 214/1024 [00:04<00:17, 46.20it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:04<00:17, 46.44it/s]
Loading safetensors checkpoint shards:  22% Completed | 224/1024 [00:04<00:17, 46.23it/s]
Loading safetensors checkpoint shards:  22% Completed | 229/1024 [00:04<00:17, 46.37it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:05<00:17, 45.80it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:05<00:16, 47.72it/s]
Loading safetensors checkpoint shards:  24% Completed | 245/1024 [00:05<00:16, 47.42it/s]
Loading safetensors checkpoint shards:  25% Completed | 251/1024 [00:05<00:15, 49.35it/s]
Loading safetensors checkpoint shards:  25% Completed | 256/1024 [00:05<00:16, 47.37it/s]
Loading safetensors checkpoint shards:  26% Completed | 262/1024 [00:05<00:15, 48.32it/s]
Loading safetensors checkpoint shards:  26% Completed | 267/1024 [00:05<00:16, 46.87it/s]
Loading safetensors checkpoint shards:  27% Completed | 273/1024 [00:05<00:15, 48.40it/s]
Loading safetensors checkpoint shards:  27% Completed | 278/1024 [00:05<00:16, 46.21it/s]
Loading safetensors checkpoint shards:  28% Completed | 284/1024 [00:06<00:15, 47.44it/s]
Loading safetensors checkpoint shards:  28% Completed | 289/1024 [00:06<00:15, 45.97it/s]
Loading safetensors checkpoint shards:  29% Completed | 294/1024 [00:06<00:15, 46.54it/s]
Loading safetensors checkpoint shards:  29% Completed | 299/1024 [00:06<00:31, 23.22it/s]
Loading safetensors checkpoint shards:  30% Completed | 304/1024 [00:06<00:26, 27.19it/s]
Loading safetensors checkpoint shards:  30% Completed | 308/1024 [00:07<00:24, 28.66it/s]
Loading safetensors checkpoint shards:  31% Completed | 313/1024 [00:07<00:22, 31.59it/s]
Loading safetensors checkpoint shards:  31% Completed | 318/1024 [00:07<00:19, 35.58it/s]
Loading safetensors checkpoint shards:  32% Completed | 323/1024 [00:07<00:18, 37.32it/s]
Loading safetensors checkpoint shards:  32% Completed | 329/1024 [00:07<00:17, 40.68it/s]
Loading safetensors checkpoint shards:  33% Completed | 334/1024 [00:07<00:16, 41.40it/s]
Loading safetensors checkpoint shards:  33% Completed | 340/1024 [00:07<00:15, 43.94it/s]
Loading safetensors checkpoint shards:  34% Completed | 345/1024 [00:07<00:15, 42.53it/s]
Loading safetensors checkpoint shards:  34% Completed | 351/1024 [00:07<00:14, 45.01it/s]
Loading safetensors checkpoint shards:  35% Completed | 356/1024 [00:08<00:14, 45.34it/s]
Loading safetensors checkpoint shards:  35% Completed | 362/1024 [00:08<00:14, 46.78it/s]
Loading safetensors checkpoint shards:  36% Completed | 367/1024 [00:08<00:14, 46.52it/s]
Loading safetensors checkpoint shards:  36% Completed | 373/1024 [00:08<00:13, 47.91it/s]
Loading safetensors checkpoint shards:  37% Completed | 378/1024 [00:08<00:14, 45.91it/s]
Loading safetensors checkpoint shards:  37% Completed | 383/1024 [00:08<00:13, 46.75it/s]
Loading safetensors checkpoint shards:  38% Completed | 388/1024 [00:08<00:13, 45.72it/s]
Loading safetensors checkpoint shards:  38% Completed | 393/1024 [00:08<00:13, 46.42it/s]
Loading safetensors checkpoint shards:  39% Completed | 398/1024 [00:08<00:13, 45.66it/s]
Loading safetensors checkpoint shards:  39% Completed | 403/1024 [00:09<00:13, 45.25it/s]
Loading safetensors checkpoint shards:  40% Completed | 409/1024 [00:09<00:13, 47.13it/s]
Loading safetensors checkpoint shards:  40% Completed | 414/1024 [00:09<00:13, 46.63it/s]
Loading safetensors checkpoint shards:  41% Completed | 419/1024 [00:09<00:12, 46.77it/s]
Loading safetensors checkpoint shards:  41% Completed | 424/1024 [00:09<00:13, 45.71it/s]
Loading safetensors checkpoint shards:  42% Completed | 430/1024 [00:09<00:12, 47.53it/s]
Loading safetensors checkpoint shards:  42% Completed | 435/1024 [00:09<00:12, 45.83it/s]
Loading safetensors checkpoint shards:  43% Completed | 441/1024 [00:09<00:12, 47.13it/s]
Loading safetensors checkpoint shards:  44% Completed | 446/1024 [00:09<00:12, 46.16it/s]
Loading safetensors checkpoint shards:  44% Completed | 451/1024 [00:10<00:12, 45.99it/s]
Loading safetensors checkpoint shards:  45% Completed | 456/1024 [00:10<00:12, 44.81it/s]
Loading safetensors checkpoint shards:  45% Completed | 462/1024 [00:10<00:12, 46.75it/s]
Loading safetensors checkpoint shards:  46% Completed | 467/1024 [00:10<00:12, 45.19it/s]
Loading safetensors checkpoint shards:  46% Completed | 474/1024 [00:10<00:11, 48.77it/s]
Loading safetensors checkpoint shards:  47% Completed | 479/1024 [00:10<00:11, 48.04it/s]
Loading safetensors checkpoint shards:  47% Completed | 485/1024 [00:10<00:11, 49.00it/s]
Loading safetensors checkpoint shards:  48% Completed | 490/1024 [00:10<00:11, 46.47it/s]
Loading safetensors checkpoint shards:  48% Completed | 496/1024 [00:11<00:11, 47.37it/s]
Loading safetensors checkpoint shards:  49% Completed | 501/1024 [00:11<00:11, 46.23it/s]
Loading safetensors checkpoint shards:  49% Completed | 506/1024 [00:11<00:11, 46.21it/s]
Loading safetensors checkpoint shards:  50% Completed | 511/1024 [00:11<00:11, 45.07it/s]
Loading safetensors checkpoint shards:  50% Completed | 516/1024 [00:11<00:11, 46.11it/s]
Loading safetensors checkpoint shards:  51% Completed | 521/1024 [00:11<00:11, 43.68it/s]
Loading safetensors checkpoint shards:  51% Completed | 526/1024 [00:11<00:11, 45.14it/s]
Loading safetensors checkpoint shards:  52% Completed | 531/1024 [00:11<00:11, 43.65it/s]
Loading safetensors checkpoint shards:  52% Completed | 536/1024 [00:11<00:11, 41.75it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:12<00:11, 43.59it/s]
Loading safetensors checkpoint shards:  53% Completed | 546/1024 [00:12<00:22, 20.99it/s]
Loading safetensors checkpoint shards:  54% Completed | 551/1024 [00:12<00:18, 24.98it/s]
Loading safetensors checkpoint shards:  54% Completed | 555/1024 [00:12<00:17, 27.27it/s]
Loading safetensors checkpoint shards:  55% Completed | 560/1024 [00:12<00:15, 30.23it/s]
Loading safetensors checkpoint shards:  55% Completed | 564/1024 [00:13<00:14, 31.60it/s]
Loading safetensors checkpoint shards:  55% Completed | 568/1024 [00:13<00:13, 33.00it/s]
Loading safetensors checkpoint shards:  56% Completed | 573/1024 [00:13<00:12, 36.03it/s]
Loading safetensors checkpoint shards:  56% Completed | 577/1024 [00:13<00:12, 35.83it/s]
Loading safetensors checkpoint shards:  57% Completed | 583/1024 [00:13<00:10, 40.36it/s]
Loading safetensors checkpoint shards:  57% Completed | 588/1024 [00:13<00:10, 40.06it/s]
Loading safetensors checkpoint shards:  58% Completed | 593/1024 [00:13<00:10, 41.23it/s]
Loading safetensors checkpoint shards:  58% Completed | 598/1024 [00:13<00:10, 42.57it/s]
Loading safetensors checkpoint shards:  59% Completed | 603/1024 [00:13<00:10, 41.00it/s]
Loading safetensors checkpoint shards:  59% Completed | 608/1024 [00:14<00:10, 39.85it/s]
Loading safetensors checkpoint shards:  60% Completed | 613/1024 [00:14<00:10, 38.73it/s]
Loading safetensors checkpoint shards:  60% Completed | 618/1024 [00:14<00:09, 40.84it/s]
Loading safetensors checkpoint shards:  61% Completed | 623/1024 [00:14<00:09, 40.25it/s]
Loading safetensors checkpoint shards:  61% Completed | 628/1024 [00:14<00:10, 38.82it/s]
Loading safetensors checkpoint shards:  62% Completed | 632/1024 [00:14<00:10, 37.48it/s]
Loading safetensors checkpoint shards:  62% Completed | 636/1024 [00:14<00:10, 36.78it/s]
Loading safetensors checkpoint shards:  62% Completed | 640/1024 [00:14<00:10, 36.37it/s]
Loading safetensors checkpoint shards:  63% Completed | 644/1024 [00:15<00:10, 36.29it/s]
Loading safetensors checkpoint shards:  63% Completed | 648/1024 [00:15<00:10, 36.87it/s]
Loading safetensors checkpoint shards:  64% Completed | 654/1024 [00:15<00:08, 41.64it/s]
Loading safetensors checkpoint shards:  64% Completed | 659/1024 [00:15<00:09, 37.22it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:15<00:10, 35.73it/s]
Loading safetensors checkpoint shards:  65% Completed | 669/1024 [00:15<00:09, 39.32it/s]
Loading safetensors checkpoint shards:  66% Completed | 675/1024 [00:15<00:08, 41.88it/s]
Loading safetensors checkpoint shards:  66% Completed | 680/1024 [00:16<00:08, 39.02it/s]
Loading safetensors checkpoint shards:  67% Completed | 684/1024 [00:16<00:09, 36.75it/s]
Loading safetensors checkpoint shards:  67% Completed | 689/1024 [00:16<00:08, 38.90it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:16<00:08, 39.54it/s]
Loading safetensors checkpoint shards:  68% Completed | 700/1024 [00:16<00:07, 42.81it/s]
Loading safetensors checkpoint shards:  69% Completed | 705/1024 [00:16<00:07, 40.31it/s]
Loading safetensors checkpoint shards:  69% Completed | 710/1024 [00:16<00:08, 36.01it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:16<00:08, 35.23it/s]
Loading safetensors checkpoint shards:  70% Completed | 718/1024 [00:17<00:08, 35.81it/s]
Loading safetensors checkpoint shards:  71% Completed | 724/1024 [00:17<00:07, 41.10it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:17<00:06, 42.79it/s]
Loading safetensors checkpoint shards:  72% Completed | 734/1024 [00:17<00:06, 44.45it/s]
Loading safetensors checkpoint shards:  72% Completed | 739/1024 [00:17<00:06, 45.46it/s]
Loading safetensors checkpoint shards:  73% Completed | 745/1024 [00:17<00:05, 46.62it/s]
Loading safetensors checkpoint shards:  73% Completed | 750/1024 [00:17<00:07, 38.52it/s]
Loading safetensors checkpoint shards:  74% Completed | 755/1024 [00:17<00:07, 35.78it/s]
Loading safetensors checkpoint shards:  74% Completed | 759/1024 [00:18<00:07, 34.75it/s]
Loading safetensors checkpoint shards:  75% Completed | 764/1024 [00:18<00:06, 37.41it/s]
Loading safetensors checkpoint shards:  75% Completed | 769/1024 [00:18<00:06, 39.75it/s]
Loading safetensors checkpoint shards:  76% Completed | 774/1024 [00:18<00:06, 39.81it/s]
Loading safetensors checkpoint shards:  76% Completed | 779/1024 [00:18<00:05, 41.76it/s]
Loading safetensors checkpoint shards:  77% Completed | 784/1024 [00:18<00:05, 42.38it/s]
Loading safetensors checkpoint shards:  77% Completed | 789/1024 [00:18<00:05, 42.40it/s]
Loading safetensors checkpoint shards:  78% Completed | 794/1024 [00:18<00:05, 43.46it/s]
Loading safetensors checkpoint shards:  78% Completed | 799/1024 [00:18<00:05, 44.30it/s]
Loading safetensors checkpoint shards:  79% Completed | 804/1024 [00:19<00:04, 45.08it/s]
Loading safetensors checkpoint shards:  79% Completed | 809/1024 [00:19<00:12, 16.86it/s]
Loading safetensors checkpoint shards:  79% Completed | 814/1024 [00:19<00:10, 20.67it/s]
Loading safetensors checkpoint shards:  80% Completed | 819/1024 [00:20<00:08, 24.02it/s]
Loading safetensors checkpoint shards:  80% Completed | 824/1024 [00:20<00:07, 27.67it/s]
Loading safetensors checkpoint shards:  81% Completed | 829/1024 [00:20<00:06, 30.96it/s]
Loading safetensors checkpoint shards:  81% Completed | 834/1024 [00:20<00:05, 34.23it/s]
Loading safetensors checkpoint shards:  82% Completed | 839/1024 [00:20<00:05, 36.63it/s]
Loading safetensors checkpoint shards:  82% Completed | 844/1024 [00:20<00:04, 37.73it/s]
Loading safetensors checkpoint shards:  83% Completed | 849/1024 [00:20<00:04, 38.72it/s]
Loading safetensors checkpoint shards:  83% Completed | 854/1024 [00:20<00:04, 39.74it/s]
Loading safetensors checkpoint shards:  84% Completed | 859/1024 [00:20<00:04, 39.15it/s]
Loading safetensors checkpoint shards:  84% Completed | 864/1024 [00:21<00:04, 39.93it/s]
Loading safetensors checkpoint shards:  85% Completed | 869/1024 [00:21<00:03, 41.05it/s]
Loading safetensors checkpoint shards:  85% Completed | 874/1024 [00:21<00:03, 40.54it/s]
Loading safetensors checkpoint shards:  86% Completed | 879/1024 [00:21<00:03, 41.58it/s]
Loading safetensors checkpoint shards:  86% Completed | 884/1024 [00:21<00:03, 42.21it/s]
Loading safetensors checkpoint shards:  87% Completed | 889/1024 [00:21<00:03, 41.38it/s]
Loading safetensors checkpoint shards:  87% Completed | 894/1024 [00:21<00:03, 41.85it/s]
Loading safetensors checkpoint shards:  88% Completed | 899/1024 [00:21<00:02, 42.26it/s]
Loading safetensors checkpoint shards:  88% Completed | 904/1024 [00:22<00:02, 42.71it/s]
Loading safetensors checkpoint shards:  89% Completed | 909/1024 [00:22<00:02, 43.31it/s]
Loading safetensors checkpoint shards:  89% Completed | 914/1024 [00:22<00:02, 43.94it/s]
Loading safetensors checkpoint shards:  90% Completed | 919/1024 [00:22<00:02, 43.29it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:22<00:02, 43.29it/s]
Loading safetensors checkpoint shards:  91% Completed | 929/1024 [00:22<00:02, 43.28it/s]
Loading safetensors checkpoint shards:  91% Completed | 934/1024 [00:22<00:02, 42.17it/s]
Loading safetensors checkpoint shards:  92% Completed | 939/1024 [00:22<00:01, 42.53it/s]
Loading safetensors checkpoint shards:  92% Completed | 944/1024 [00:22<00:01, 43.39it/s]
Loading safetensors checkpoint shards:  93% Completed | 949/1024 [00:23<00:01, 42.81it/s]
Loading safetensors checkpoint shards:  93% Completed | 954/1024 [00:23<00:01, 42.85it/s]
Loading safetensors checkpoint shards:  94% Completed | 959/1024 [00:23<00:01, 43.77it/s]
Loading safetensors checkpoint shards:  94% Completed | 964/1024 [00:23<00:01, 42.60it/s]
Loading safetensors checkpoint shards:  95% Completed | 969/1024 [00:23<00:01, 41.46it/s]
Loading safetensors checkpoint shards:  95% Completed | 974/1024 [00:23<00:01, 39.20it/s]
Loading safetensors checkpoint shards:  96% Completed | 978/1024 [00:23<00:01, 38.74it/s]
Loading safetensors checkpoint shards:  96% Completed | 985/1024 [00:23<00:00, 46.88it/s]
Loading safetensors checkpoint shards: 100% Completed | 1019/1024 [00:24<00:00, 122.51it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:24<00:00, 42.48it/s]
 
[2025-09-13 07:29:54 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:29:57 TP6] KV Cache is allocated. #tokens: 620273, KV size: 40.59 GB
[2025-09-13 07:29:57 TP0] KV Cache is allocated. #tokens: 620273, KV size: 40.59 GB
[2025-09-13 07:29:57 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:29:57 TP1] KV Cache is allocated. #tokens: 620273, KV size: 40.59 GB
[2025-09-13 07:29:57 TP2] KV Cache is allocated. #tokens: 620273, KV size: 40.59 GB
[2025-09-13 07:29:57 TP4] KV Cache is allocated. #tokens: 620273, KV size: 40.59 GB
[2025-09-13 07:29:57 TP7] KV Cache is allocated. #tokens: 620273, KV size: 40.59 GB
[2025-09-13 07:29:57 TP3] KV Cache is allocated. #tokens: 620273, KV size: 40.59 GB
[2025-09-13 07:29:57 TP5] KV Cache is allocated. #tokens: 620273, KV size: 40.59 GB
[2025-09-13 07:29:57 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:29:57 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.50 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:29:58 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:29:58 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 

Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                                             Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:29:58 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:29:58 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:29:58 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:29:58 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:29:58 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:29:59 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:29:59 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25400.59it/s]
[2025-09-13 07:29:59 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:29:59 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26234.79it/s]
[2025-09-13 07:30:00 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:30:00 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27583.88it/s]
[2025-09-13 07:30:00 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:30:00 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26270.18it/s]
[2025-09-13 07:30:01 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:30:01 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28255.40it/s]
[2025-09-13 07:30:02 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.16 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.12it/s]
[2025-09-13 07:30:05 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:30:05 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:30:05 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:30:05 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:30:05 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:30:05 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:30:05 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:30:05 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:30:05 TP0] Capture cuda graph end. Time elapsed: 7.89 s. mem usage=0.43 GB. avail mem=17.14 GB.
[2025-09-13 07:30:05 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:30:05 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:30:05 TP0] Init torch distributed begin.
[2025-09-13 07:30:05 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:30:05 TP0] Load weight begin. avail mem=17.14 GB
[2025-09-13 07:30:05 TP0] Detected fp8 checkpoint.
[2025-09-13 07:30:05 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 172.73it/s]
Loading safetensors checkpoint shards:   4% Completed | 42/1024 [00:00<00:04, 211.32it/s]
Loading safetensors checkpoint shards:  10% Completed | 101/1024 [00:00<00:02, 379.96it/s]
Loading safetensors checkpoint shards:  16% Completed | 161/1024 [00:00<00:01, 465.35it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:00<00:01, 506.06it/s]
Loading safetensors checkpoint shards:  27% Completed | 278/1024 [00:00<00:01, 532.24it/s]
Loading safetensors checkpoint shards:  33% Completed | 338/1024 [00:00<00:01, 553.87it/s]
Loading safetensors checkpoint shards:  39% Completed | 399/1024 [00:00<00:01, 568.60it/s]
Loading safetensors checkpoint shards:  45% Completed | 460/1024 [00:00<00:00, 581.34it/s]
Loading safetensors checkpoint shards:  51% Completed | 521/1024 [00:01<00:00, 588.59it/s]
Loading safetensors checkpoint shards:  57% Completed | 582/1024 [00:01<00:00, 594.27it/s]
Loading safetensors checkpoint shards:  63% Completed | 642/1024 [00:01<00:00, 590.75it/s]
Loading safetensors checkpoint shards:  69% Completed | 702/1024 [00:01<00:00, 584.73it/s]
Loading safetensors checkpoint shards:  74% Completed | 761/1024 [00:01<00:00, 579.14it/s]
Loading safetensors checkpoint shards:  80% Completed | 819/1024 [00:01<00:00, 576.61it/s]
Loading safetensors checkpoint shards:  86% Completed | 877/1024 [00:01<00:00, 571.57it/s]
Loading safetensors checkpoint shards:  91% Completed | 936/1024 [00:01<00:00, 574.34it/s]
Loading safetensors checkpoint shards:  97% Completed | 994/1024 [00:01<00:00, 486.62it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 498.59it/s]

[2025-09-13 07:30:08 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.15 GB, mem usage=1.99 GB.
[2025-09-13 07:30:08 TP6] KV Cache is allocated. #tokens: 620273, KV size: 0.67 GB
[2025-09-13 07:30:08 TP0] KV Cache is allocated. #tokens: 620273, KV size: 0.67 GB
[2025-09-13 07:30:08 TP3] KV Cache is allocated. #tokens: 620273, KV size: 0.67 GB
[2025-09-13 07:30:08 TP2] KV Cache is allocated. #tokens: 620273, KV size: 0.67 GB
[2025-09-13 07:30:08 TP7] KV Cache is allocated. #tokens: 620273, KV size: 0.67 GB
[2025-09-13 07:30:08 TP1] KV Cache is allocated. #tokens: 620273, KV size: 0.67 GB
[2025-09-13 07:30:08 TP0] Memory pool end. avail mem=14.48 GB
[2025-09-13 07:30:08 TP4] KV Cache is allocated. #tokens: 620273, KV size: 0.67 GB
[2025-09-13 07:30:08 TP5] KV Cache is allocated. #tokens: 620273, KV size: 0.67 GB
[2025-09-13 07:30:08 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:30:08 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:30:08 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:30:08 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.11 GB
[2025-09-13 07:30:08 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:30:08 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:30:08 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:30:08 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
Capturing batches (bs=1 avail_mem=14.50 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  3.06it/s][2025-09-13 07:30:14 TP4] Registering 96 cuda graph addresses
[2025-09-13 07:30:14 TP7] Registering 96 cuda graph addresses
[2025-09-13 07:30:14 TP3] Registering 96 cuda graph addresses
[2025-09-13 07:30:14 TP1] Registering 96 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.50 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.42it/s]
[2025-09-13 07:30:14 TP0] Registering 96 cuda graph addresses
[2025-09-13 07:30:14 TP5] Registering 96 cuda graph addresses
[2025-09-13 07:30:14 TP2] Registering 96 cuda graph addresses
[2025-09-13 07:30:14 TP6] Registering 96 cuda graph addresses
[2025-09-13 07:30:14 TP2] Capture draft cuda graph end. Time elapsed: 6.36 s. mem usage=0.41 GB. avail mem=14.46 GB.
[2025-09-13 07:30:14 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
[2025-09-13 07:30:14 TP4] Capture draft cuda graph end. Time elapsed: 6.46 s. mem usage=0.41 GB. avail mem=14.46 GB.
[2025-09-13 07:30:14 TP0] Capture draft cuda graph end. Time elapsed: 6.37 s. mem usage=0.41 GB. avail mem=14.50 GB.
[2025-09-13 07:30:14 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
[2025-09-13 07:30:14 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 07:30:14 TP5] Capture draft cuda graph end. Time elapsed: 6.40 s. mem usage=0.41 GB. avail mem=14.46 GB.
[2025-09-13 07:30:14 TP1] Capture draft cuda graph end. Time elapsed: 6.40 s. mem usage=0.41 GB. avail mem=14.46 GB.
[2025-09-13 07:30:14 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
[2025-09-13 07:30:14 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
[2025-09-13 07:30:14 TP7] Capture draft cuda graph end. Time elapsed: 6.40 s. mem usage=0.41 GB. avail mem=14.69 GB.
[2025-09-13 07:30:14 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.69 GB
[2025-09-13 07:30:14 TP6] Capture draft cuda graph end. Time elapsed: 6.37 s. mem usage=0.41 GB. avail mem=14.46 GB.
[2025-09-13 07:30:14 TP3] Capture draft cuda graph end. Time elapsed: 6.40 s. mem usage=0.41 GB. avail mem=14.46 GB.
[2025-09-13 07:30:14 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
[2025-09-13 07:30:14 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
Capturing batches (bs=1 avail_mem=14.31 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:00<00:00, 24.99it/s][2025-09-13 07:30:15 TP3] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.31 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 24.65it/s]
[2025-09-13 07:30:15 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:30:15 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:30:15 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:30:15 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:30:15 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:30:15 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:30:15 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:30:15 TP0] Capture draft extend cuda graph end. Time elapsed: 1.06 s. mem usage=0.19 GB. avail mem=14.31 GB.
[2025-09-13 07:30:15 TP6] Capture draft extend cuda graph end. Time elapsed: 1.06 s. mem usage=0.19 GB. avail mem=14.27 GB.
[2025-09-13 07:30:15 TP5] Capture draft extend cuda graph end. Time elapsed: 1.06 s. mem usage=0.19 GB. avail mem=14.27 GB.
[2025-09-13 07:30:15 TP0] max_total_num_tokens=620273, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.31 GB
[2025-09-13 07:30:15 TP4] Capture draft extend cuda graph end. Time elapsed: 1.06 s. mem usage=0.19 GB. avail mem=14.27 GB.
[2025-09-13 07:30:15 TP2] Capture draft extend cuda graph end. Time elapsed: 1.06 s. mem usage=0.19 GB. avail mem=14.27 GB.
[2025-09-13 07:30:15 TP7] Capture draft extend cuda graph end. Time elapsed: 1.06 s. mem usage=0.19 GB. avail mem=14.50 GB.
[2025-09-13 07:30:15 TP3] Capture draft extend cuda graph end. Time elapsed: 1.06 s. mem usage=0.19 GB. avail mem=14.27 GB.
[2025-09-13 07:30:15 TP1] Capture draft extend cuda graph end. Time elapsed: 1.06 s. mem usage=0.19 GB. avail mem=14.27 GB.
[2025-09-13 07:30:16] INFO:     Started server process [295455]
[2025-09-13 07:30:16] INFO:     Waiting for application startup.
[2025-09-13 07:30:16] INFO:     Application startup complete.
[2025-09-13 07:30:16] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:30:17] INFO:     127.0.0.1:33580 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:30:17] INFO:     127.0.0.1:33586 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:30:17 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:30:17 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:30:17 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28354.13it/s]
[2025-09-13 07:30:18] INFO:     127.0.0.1:33588 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:18] The server is fired up and ready to roll!
[2025-09-13 07:30:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:30:28] INFO:     127.0.0.1:48988 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:30:28] INFO:     127.0.0.1:37310 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:28 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:30:29] INFO:     127.0.0.1:37314 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:29] INFO:     127.0.0.1:37328 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:30 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:30:30] INFO:     127.0.0.1:37332 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:30] INFO:     127.0.0.1:37340 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:30] INFO:     127.0.0.1:37342 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:30] INFO:     127.0.0.1:37348 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:30] INFO:     127.0.0.1:37364 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:30] INFO:     127.0.0.1:37380 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:30 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:30:30 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:30:30 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:30:30 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:30:30 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:30:30 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:30:30 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:30:30 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:30:30 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:30:30 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:30:31 TP0] Decode batch. #running-req: 8, #token: 14653, token usage: 0.02, accept len: 3.33, cuda graph: True, gen throughput (token/s): 48.47, #queue-req: 0, 
[2025-09-13 07:30:33 TP0] Decode batch. #running-req: 8, #token: 15912, token usage: 0.03, accept len: 3.93, cuda graph: True, gen throughput (token/s): 878.53, #queue-req: 0, 
[2025-09-13 07:30:34 TP0] Decode batch. #running-req: 8, #token: 17333, token usage: 0.03, accept len: 4.44, cuda graph: True, gen throughput (token/s): 980.84, #queue-req: 0, 
 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 7/8 [00:05<00:00,  2.03it/s][2025-09-13 07:30:36 TP0] Decode batch. #running-req: 1, #token: 1474, token usage: 0.00, accept len: 3.90, cuda graph: True, gen throughput (token/s): 464.95, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.26it/s]
[2025-09-13 07:30:36] INFO:     127.0.0.1:37392 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.37      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4085      
Request throughput (req/s):              1.26      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         643.49    
Total token throughput (tok/s):          643.49    
Concurrency:                             6.95      
Accept length:                           3.95      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5526.03   
Median E2E Latency (ms):                 5478.71   
---------------Time to First Token----------------
Mean TTFT (ms):                          684.29    
Median TTFT (ms):                        827.39    
P99 TTFT (ms):                           827.91    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.48      
Median ITL (ms):                         7.00      
P95 ITL (ms):                            18.11     
P99 ITL (ms):                            35.95     
Max ITL (ms):                            849.44    
==================================================
[2025-09-13 07:30:36] INFO:     127.0.0.1:37404 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:30:36] INFO:     127.0.0.1:37406 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:30:37] INFO:     127.0.0.1:37414 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:37] INFO:     127.0.0.1:37428 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:30:37] INFO:     127.0.0.1:37438 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:37] INFO:     127.0.0.1:37448 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:37] INFO:     127.0.0.1:37464 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:37] INFO:     127.0.0.1:37480 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:37] INFO:     127.0.0.1:37482 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:37] INFO:     127.0.0.1:37484 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:37 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:30:38 TP0] Decode batch. #running-req: 8, #token: 14345, token usage: 0.02, accept len: 3.14, cuda graph: True, gen throughput (token/s): 198.55, #queue-req: 0, 
[2025-09-13 07:30:40 TP0] Decode batch. #running-req: 8, #token: 15570, token usage: 0.03, accept len: 3.83, cuda graph: True, gen throughput (token/s): 855.66, #queue-req: 0, 
[2025-09-13 07:30:41 TP0] Decode batch. #running-req: 8, #token: 16937, token usage: 0.03, accept len: 4.27, cuda graph: True, gen throughput (token/s): 942.58, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:04,  4.33s/it][2025-09-13 07:30:42] INFO:     127.0.0.1:46684 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:42 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:27,  2.00s/it][2025-09-13 07:30:42] INFO:     127.0.0.1:46688 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:42 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:16,  1.30s/it][2025-09-13 07:30:42] INFO:     127.0.0.1:46700 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:42 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:30:42] INFO:     127.0.0.1:46708 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:43 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:06,  1.60it/s][2025-09-13 07:30:43] INFO:     127.0.0.1:46722 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:43 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.76it/s][2025-09-13 07:30:43] INFO:     127.0.0.1:46738 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:43 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:04,  2.15it/s][2025-09-13 07:30:43] INFO:     127.0.0.1:46752 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:30:44 TP0] Decode batch. #running-req: 8, #token: 10168, token usage: 0.02, accept len: 4.10, cuda graph: True, gen throughput (token/s): 511.60, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:07<00:05,  1.56it/s][2025-09-13 07:30:44] INFO:     127.0.0.1:46756 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:30:44 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:30:45 TP0] Decode batch. #running-req: 8, #token: 14868, token usage: 0.02, accept len: 3.69, cuda graph: True, gen throughput (token/s): 709.91, #queue-req: 0, 
[2025-09-13 07:30:47 TP0] Decode batch. #running-req: 8, #token: 16314, token usage: 0.03, accept len: 4.52, cuda graph: True, gen throughput (token/s): 1007.80, #queue-req: 0, 
 75%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                | 12/16 [00:10<00:02,  1.78it/s][2025-09-13 07:30:48 TP0] Decode batch. #running-req: 3, #token: 8787, token usage: 0.01, accept len: 4.41, cuda graph: True, gen throughput (token/s): 775.83, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.40it/s]
[2025-09-13 07:30:49] INFO:     127.0.0.1:36728 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.39     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8117      
Request throughput (req/s):              1.40      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         718.94    
Total token throughput (tok/s):          718.94    
Concurrency:                             7.41      
Accept length:                           4.01      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5278.47   
Median E2E Latency (ms):                 5179.90   
---------------Time to First Token----------------
Mean TTFT (ms):                          251.77    
Median TTFT (ms):                        295.87    
P99 TTFT (ms):                           321.42    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.84      
Median ITL (ms):                         6.12      
P95 ITL (ms):                            29.08     
P99 ITL (ms):                            48.27     
Max ITL (ms):                            289.63    
==================================================
[2025-09-13 07:30:49] INFO:     127.0.0.1:36734 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=30: batch_size=8, steps=5, topk=3, num_draft_tokens=12, speed=111.92 token/s, step_time=35.85 ms
Start i=31: batch_size=8, steps=5, topk=4, num_draft_tokens=4
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 5 --speculative-eagle-topk 4 --speculative-num-draft-tokens 4 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:30:59.938000 301134 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:30:59.938000 301134 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:31:00] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=734640130, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=4, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:31:00] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:31:09.166000 301344 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:31:09.166000 301344 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:31:09.369000 301348 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:31:09.369000 301348 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:31:09.460000 301347 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:31:09.460000 301347 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:31:09.463000 301350 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:31:09.463000 301350 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:31:09.485000 301342 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:31:09.485000 301342 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:31:09.517000 301343 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:31:09.517000 301343 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:31:09.563000 301349 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:31:09.563000 301349 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:31:09.563000 301346 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:31:09.563000 301346 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:31:09.633000 301345 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:31:09.633000 301345 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:31:10 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:31:10 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:31:10 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:31:12 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:31:14 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:31:16 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:31:16 TP0] Detected fp8 checkpoint.
[2025-09-13 07:31:16 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:04, 241.25it/s]
Loading safetensors checkpoint shards:   5% Completed | 51/1024 [00:00<00:16, 58.04it/s]
Loading safetensors checkpoint shards:   6% Completed | 64/1024 [00:01<00:20, 46.49it/s]
Loading safetensors checkpoint shards:   7% Completed | 73/1024 [00:01<00:21, 45.16it/s]
Loading safetensors checkpoint shards:   8% Completed | 80/1024 [00:01<00:20, 45.96it/s]
Loading safetensors checkpoint shards:   8% Completed | 87/1024 [00:01<00:18, 49.48it/s]
Loading safetensors checkpoint shards:   9% Completed | 94/1024 [00:01<00:18, 50.78it/s]
Loading safetensors checkpoint shards:  10% Completed | 100/1024 [00:01<00:19, 47.66it/s]
Loading safetensors checkpoint shards:  10% Completed | 106/1024 [00:02<00:20, 44.77it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:37, 24.25it/s]
Loading safetensors checkpoint shards:  11% Completed | 115/1024 [00:02<00:34, 26.39it/s]
Loading safetensors checkpoint shards:  12% Completed | 119/1024 [00:02<00:33, 27.38it/s]
Loading safetensors checkpoint shards:  12% Completed | 123/1024 [00:02<00:31, 28.46it/s]
Loading safetensors checkpoint shards:  13% Completed | 129/1024 [00:03<00:26, 33.24it/s]
Loading safetensors checkpoint shards:  13% Completed | 134/1024 [00:03<00:24, 36.07it/s]
Loading safetensors checkpoint shards:  14% Completed | 141/1024 [00:03<00:20, 42.91it/s]
Loading safetensors checkpoint shards:  14% Completed | 147/1024 [00:03<00:18, 46.79it/s]
Loading safetensors checkpoint shards:  15% Completed | 153/1024 [00:03<00:18, 47.33it/s]
Loading safetensors checkpoint shards:  16% Completed | 159/1024 [00:03<00:17, 49.50it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:03<00:15, 55.14it/s]
Loading safetensors checkpoint shards:  17% Completed | 174/1024 [00:03<00:14, 58.96it/s]
Loading safetensors checkpoint shards:  18% Completed | 181/1024 [00:04<00:15, 54.00it/s]
Loading safetensors checkpoint shards:  18% Completed | 189/1024 [00:04<00:14, 58.50it/s]
Loading safetensors checkpoint shards:  19% Completed | 197/1024 [00:04<00:13, 63.40it/s]
Loading safetensors checkpoint shards:  20% Completed | 205/1024 [00:04<00:12, 65.59it/s]
Loading safetensors checkpoint shards:  21% Completed | 212/1024 [00:04<00:12, 64.08it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:04<00:12, 62.22it/s]
Loading safetensors checkpoint shards:  22% Completed | 226/1024 [00:04<00:12, 63.49it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:04<00:12, 63.84it/s]
Loading safetensors checkpoint shards:  24% Completed | 243/1024 [00:04<00:11, 67.94it/s]
Loading safetensors checkpoint shards:  25% Completed | 251/1024 [00:05<00:11, 66.70it/s]
Loading safetensors checkpoint shards:  25% Completed | 258/1024 [00:05<00:28, 26.67it/s]
Loading safetensors checkpoint shards:  26% Completed | 266/1024 [00:05<00:22, 33.30it/s]
Loading safetensors checkpoint shards:  27% Completed | 274/1024 [00:05<00:18, 39.94it/s]
Loading safetensors checkpoint shards:  27% Completed | 281/1024 [00:06<00:17, 43.59it/s]
Loading safetensors checkpoint shards:  28% Completed | 289/1024 [00:06<00:15, 48.88it/s]
Loading safetensors checkpoint shards:  29% Completed | 296/1024 [00:06<00:14, 49.79it/s]
Loading safetensors checkpoint shards:  29% Completed | 302/1024 [00:06<00:14, 51.53it/s]
Loading safetensors checkpoint shards:  30% Completed | 309/1024 [00:06<00:13, 53.73it/s]
Loading safetensors checkpoint shards:  31% Completed | 317/1024 [00:06<00:11, 59.88it/s]
Loading safetensors checkpoint shards:  32% Completed | 324/1024 [00:06<00:11, 59.59it/s]
Loading safetensors checkpoint shards:  32% Completed | 332/1024 [00:06<00:10, 64.77it/s]
Loading safetensors checkpoint shards:  33% Completed | 340/1024 [00:06<00:10, 67.63it/s]
Loading safetensors checkpoint shards:  34% Completed | 347/1024 [00:07<00:10, 62.61it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:07<00:10, 62.31it/s]
Loading safetensors checkpoint shards:  35% Completed | 361/1024 [00:07<00:12, 53.22it/s]
Loading safetensors checkpoint shards:  36% Completed | 367/1024 [00:07<00:14, 44.96it/s]
Loading safetensors checkpoint shards:  36% Completed | 372/1024 [00:07<00:14, 45.52it/s]
Loading safetensors checkpoint shards:  37% Completed | 377/1024 [00:07<00:15, 42.44it/s]
Loading safetensors checkpoint shards:  37% Completed | 383/1024 [00:07<00:14, 44.98it/s]
Loading safetensors checkpoint shards:  38% Completed | 389/1024 [00:08<00:13, 46.91it/s]
Loading safetensors checkpoint shards:  39% Completed | 395/1024 [00:08<00:12, 48.86it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:08<00:12, 49.40it/s]
Loading safetensors checkpoint shards:  40% Completed | 408/1024 [00:08<00:11, 54.35it/s]
Loading safetensors checkpoint shards:  41% Completed | 415/1024 [00:08<00:10, 57.82it/s]
Loading safetensors checkpoint shards:  41% Completed | 421/1024 [00:08<00:11, 54.12it/s]
Loading safetensors checkpoint shards:  42% Completed | 427/1024 [00:09<00:25, 23.35it/s]
Loading safetensors checkpoint shards:  42% Completed | 432/1024 [00:09<00:22, 25.97it/s]
Loading safetensors checkpoint shards:  43% Completed | 438/1024 [00:09<00:19, 30.32it/s]
Loading safetensors checkpoint shards:  43% Completed | 443/1024 [00:09<00:18, 31.92it/s]
Loading safetensors checkpoint shards:  44% Completed | 448/1024 [00:09<00:16, 34.67it/s]
Loading safetensors checkpoint shards:  44% Completed | 453/1024 [00:09<00:16, 34.12it/s]
Loading safetensors checkpoint shards:  45% Completed | 457/1024 [00:10<00:17, 33.20it/s]
Loading safetensors checkpoint shards:  45% Completed | 462/1024 [00:10<00:15, 35.77it/s]
Loading safetensors checkpoint shards:  46% Completed | 466/1024 [00:10<00:15, 36.24it/s]
Loading safetensors checkpoint shards:  46% Completed | 471/1024 [00:10<00:14, 39.44it/s]
Loading safetensors checkpoint shards:  46% Completed | 476/1024 [00:10<00:14, 38.09it/s]
Loading safetensors checkpoint shards:  47% Completed | 480/1024 [00:10<00:14, 37.55it/s]
Loading safetensors checkpoint shards:  47% Completed | 484/1024 [00:10<00:14, 37.36it/s]
Loading safetensors checkpoint shards:  48% Completed | 488/1024 [00:10<00:14, 37.02it/s]
Loading safetensors checkpoint shards:  48% Completed | 492/1024 [00:10<00:14, 36.78it/s]
Loading safetensors checkpoint shards:  49% Completed | 497/1024 [00:11<00:14, 37.59it/s]
Loading safetensors checkpoint shards:  49% Completed | 501/1024 [00:11<00:14, 36.97it/s]
Loading safetensors checkpoint shards:  49% Completed | 505/1024 [00:11<00:14, 36.46it/s]
Loading safetensors checkpoint shards:  50% Completed | 509/1024 [00:11<00:14, 35.01it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:11<00:15, 33.66it/s]
Loading safetensors checkpoint shards:  50% Completed | 517/1024 [00:11<00:14, 34.23it/s]
Loading safetensors checkpoint shards:  51% Completed | 521/1024 [00:11<00:15, 32.04it/s]
Loading safetensors checkpoint shards:  51% Completed | 525/1024 [00:11<00:16, 29.96it/s]
Loading safetensors checkpoint shards:  52% Completed | 529/1024 [00:12<00:16, 30.67it/s]
Loading safetensors checkpoint shards:  52% Completed | 533/1024 [00:12<00:16, 30.63it/s]
Loading safetensors checkpoint shards:  52% Completed | 537/1024 [00:12<00:15, 30.85it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:12<00:16, 30.05it/s]
Loading safetensors checkpoint shards:  53% Completed | 545/1024 [00:12<00:15, 31.23it/s]
Loading safetensors checkpoint shards:  54% Completed | 549/1024 [00:12<00:14, 32.25it/s]
Loading safetensors checkpoint shards:  54% Completed | 553/1024 [00:12<00:15, 31.15it/s]
Loading safetensors checkpoint shards:  54% Completed | 557/1024 [00:12<00:15, 30.10it/s]
Loading safetensors checkpoint shards:  55% Completed | 561/1024 [00:13<00:14, 31.11it/s]
Loading safetensors checkpoint shards:  55% Completed | 565/1024 [00:13<00:14, 31.91it/s]
Loading safetensors checkpoint shards:  56% Completed | 569/1024 [00:13<00:15, 30.03it/s]
Loading safetensors checkpoint shards:  56% Completed | 573/1024 [00:13<00:14, 30.42it/s]
Loading safetensors checkpoint shards:  56% Completed | 577/1024 [00:13<00:15, 28.17it/s]
Loading safetensors checkpoint shards:  57% Completed | 583/1024 [00:13<00:12, 33.97it/s]
Loading safetensors checkpoint shards:  57% Completed | 587/1024 [00:13<00:13, 33.36it/s]
Loading safetensors checkpoint shards:  58% Completed | 591/1024 [00:14<00:13, 33.20it/s]
Loading safetensors checkpoint shards:  58% Completed | 595/1024 [00:14<00:13, 32.94it/s]
Loading safetensors checkpoint shards:  58% Completed | 599/1024 [00:14<00:12, 32.88it/s]
Loading safetensors checkpoint shards:  59% Completed | 603/1024 [00:14<00:13, 31.87it/s]
Loading safetensors checkpoint shards:  59% Completed | 607/1024 [00:14<00:13, 31.64it/s]
Loading safetensors checkpoint shards:  60% Completed | 611/1024 [00:14<00:13, 29.92it/s]
Loading safetensors checkpoint shards:  60% Completed | 615/1024 [00:14<00:13, 30.54it/s]
Loading safetensors checkpoint shards:  60% Completed | 619/1024 [00:14<00:14, 28.68it/s]
Loading safetensors checkpoint shards:  61% Completed | 622/1024 [00:15<00:13, 28.91it/s]
Loading safetensors checkpoint shards:  61% Completed | 626/1024 [00:15<00:13, 30.40it/s]
Loading safetensors checkpoint shards:  62% Completed | 630/1024 [00:15<00:13, 30.14it/s]
Loading safetensors checkpoint shards:  62% Completed | 634/1024 [00:15<00:27, 14.17it/s]
Loading safetensors checkpoint shards:  62% Completed | 638/1024 [00:16<00:22, 17.00it/s]
Loading safetensors checkpoint shards:  63% Completed | 643/1024 [00:16<00:17, 21.55it/s]
Loading safetensors checkpoint shards:  63% Completed | 647/1024 [00:16<00:15, 24.36it/s]
Loading safetensors checkpoint shards:  64% Completed | 652/1024 [00:16<00:13, 28.49it/s]
Loading safetensors checkpoint shards:  64% Completed | 657/1024 [00:16<00:11, 31.68it/s]
Loading safetensors checkpoint shards:  65% Completed | 661/1024 [00:16<00:11, 32.37it/s]
Loading safetensors checkpoint shards:  65% Completed | 666/1024 [00:16<00:10, 34.85it/s]
Loading safetensors checkpoint shards:  66% Completed | 671/1024 [00:16<00:09, 36.52it/s]
Loading safetensors checkpoint shards:  66% Completed | 675/1024 [00:17<00:09, 37.28it/s]
Loading safetensors checkpoint shards:  66% Completed | 679/1024 [00:17<00:09, 36.50it/s]
Loading safetensors checkpoint shards:  67% Completed | 683/1024 [00:17<00:09, 37.11it/s]
Loading safetensors checkpoint shards:  67% Completed | 688/1024 [00:17<00:08, 38.29it/s]
Loading safetensors checkpoint shards:  68% Completed | 693/1024 [00:17<00:08, 41.17it/s]
Loading safetensors checkpoint shards:  68% Completed | 698/1024 [00:17<00:07, 41.22it/s]
Loading safetensors checkpoint shards:  69% Completed | 703/1024 [00:17<00:08, 39.46it/s]
Loading safetensors checkpoint shards:  69% Completed | 708/1024 [00:17<00:07, 39.62it/s]
Loading safetensors checkpoint shards:  70% Completed | 713/1024 [00:17<00:07, 40.67it/s]
Loading safetensors checkpoint shards:  70% Completed | 718/1024 [00:18<00:07, 40.28it/s]
Loading safetensors checkpoint shards:  71% Completed | 723/1024 [00:18<00:07, 40.93it/s]
Loading safetensors checkpoint shards:  71% Completed | 728/1024 [00:18<00:07, 41.53it/s]
Loading safetensors checkpoint shards:  72% Completed | 733/1024 [00:18<00:07, 40.52it/s]
Loading safetensors checkpoint shards:  72% Completed | 738/1024 [00:18<00:06, 40.99it/s]
Loading safetensors checkpoint shards:  73% Completed | 743/1024 [00:18<00:06, 41.87it/s]
Loading safetensors checkpoint shards:  73% Completed | 748/1024 [00:18<00:06, 41.00it/s]
Loading safetensors checkpoint shards:  74% Completed | 753/1024 [00:18<00:06, 41.47it/s]
Loading safetensors checkpoint shards:  74% Completed | 758/1024 [00:19<00:06, 42.13it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:19<00:06, 42.37it/s]
Loading safetensors checkpoint shards:  75% Completed | 768/1024 [00:19<00:06, 42.51it/s]
Loading safetensors checkpoint shards:  75% Completed | 773/1024 [00:19<00:06, 40.41it/s]
Loading safetensors checkpoint shards:  76% Completed | 778/1024 [00:19<00:06, 40.62it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:19<00:05, 40.37it/s]
Loading safetensors checkpoint shards:  77% Completed | 788/1024 [00:19<00:06, 38.96it/s]
Loading safetensors checkpoint shards:  77% Completed | 793/1024 [00:19<00:05, 40.00it/s]
Loading safetensors checkpoint shards:  78% Completed | 798/1024 [00:20<00:05, 40.93it/s]
Loading safetensors checkpoint shards:  78% Completed | 803/1024 [00:20<00:05, 42.40it/s]
Loading safetensors checkpoint shards:  79% Completed | 808/1024 [00:20<00:05, 42.39it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:20<00:04, 42.38it/s]
Loading safetensors checkpoint shards:  80% Completed | 818/1024 [00:20<00:04, 41.56it/s]
Loading safetensors checkpoint shards:  80% Completed | 823/1024 [00:20<00:04, 41.25it/s]
Loading safetensors checkpoint shards:  81% Completed | 828/1024 [00:20<00:04, 41.30it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:20<00:04, 42.71it/s]
Loading safetensors checkpoint shards:  82% Completed | 838/1024 [00:20<00:04, 44.06it/s]
Loading safetensors checkpoint shards:  82% Completed | 843/1024 [00:21<00:04, 42.90it/s]
Loading safetensors checkpoint shards:  83% Completed | 848/1024 [00:21<00:04, 43.47it/s]
Loading safetensors checkpoint shards:  83% Completed | 853/1024 [00:21<00:03, 43.98it/s]
Loading safetensors checkpoint shards:  84% Completed | 858/1024 [00:21<00:03, 42.78it/s]
Loading safetensors checkpoint shards:  84% Completed | 863/1024 [00:21<00:03, 43.18it/s]
Loading safetensors checkpoint shards:  85% Completed | 868/1024 [00:21<00:03, 43.36it/s]
Loading safetensors checkpoint shards:  85% Completed | 873/1024 [00:21<00:03, 43.33it/s]
Loading safetensors checkpoint shards:  86% Completed | 878/1024 [00:21<00:03, 42.49it/s]
Loading safetensors checkpoint shards:  86% Completed | 883/1024 [00:22<00:03, 43.03it/s]
Loading safetensors checkpoint shards:  87% Completed | 888/1024 [00:22<00:03, 43.49it/s]
Loading safetensors checkpoint shards:  87% Completed | 893/1024 [00:22<00:03, 42.83it/s]
Loading safetensors checkpoint shards:  88% Completed | 898/1024 [00:22<00:02, 43.20it/s]
Loading safetensors checkpoint shards:  88% Completed | 903/1024 [00:22<00:02, 43.67it/s]
Loading safetensors checkpoint shards:  89% Completed | 908/1024 [00:22<00:02, 43.87it/s]
Loading safetensors checkpoint shards:  89% Completed | 913/1024 [00:22<00:02, 42.14it/s]
Loading safetensors checkpoint shards:  90% Completed | 919/1024 [00:22<00:02, 44.46it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:22<00:02, 44.42it/s]
Loading safetensors checkpoint shards:  91% Completed | 929/1024 [00:23<00:02, 44.23it/s]
Loading safetensors checkpoint shards:  91% Completed | 934/1024 [00:23<00:02, 43.04it/s]
Loading safetensors checkpoint shards:  92% Completed | 939/1024 [00:23<00:01, 43.62it/s]
Loading safetensors checkpoint shards:  92% Completed | 944/1024 [00:24<00:04, 16.56it/s]
Loading safetensors checkpoint shards:  93% Completed | 948/1024 [00:24<00:03, 19.43it/s]
Loading safetensors checkpoint shards:  93% Completed | 953/1024 [00:24<00:03, 23.45it/s]
Loading safetensors checkpoint shards:  94% Completed | 958/1024 [00:24<00:02, 27.63it/s]
Loading safetensors checkpoint shards:  94% Completed | 963/1024 [00:24<00:01, 30.93it/s]
Loading safetensors checkpoint shards:  95% Completed | 968/1024 [00:24<00:01, 34.07it/s]
Loading safetensors checkpoint shards:  95% Completed | 973/1024 [00:24<00:01, 35.93it/s]
Loading safetensors checkpoint shards:  96% Completed | 978/1024 [00:24<00:01, 38.23it/s]
Loading safetensors checkpoint shards:  97% Completed | 989/1024 [00:24<00:00, 56.00it/s]
Loading safetensors checkpoint shards:  98% Completed | 1004/1024 [00:25<00:00, 79.39it/s]
Loading safetensors checkpoint shards:  99% Completed | 1014/1024 [00:25<00:00, 81.47it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 40.67it/s]

[2025-09-13 07:31:42 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:31:44 TP7] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:31:44 TP6] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:31:44 TP2] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:31:44 TP1] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:31:44 TP0] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:31:44 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:31:44 TP3] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:31:44 TP4] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:31:44 TP5] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:31:45 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:31:45 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.53 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s][2025-09-13 07:31:46 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:31:46 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:31:46 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:31:46 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:31:46 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:31:46 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:31:46 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:31:46 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:31:46 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26104.01it/s]
[2025-09-13 07:31:46 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:31:46 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27256.17it/s]
[2025-09-13 07:31:47 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:31:47 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28986.18it/s]
[2025-09-13 07:31:48 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:31:48 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27785.00it/s]
[2025-09-13 07:31:48 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:31:48 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28875.77it/s]
[2025-09-13 07:31:49 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.22 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.15it/s]
[2025-09-13 07:31:52 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:31:52 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:31:52 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:31:52 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:31:52 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:31:52 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:31:52 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:31:52 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:31:52 TP0] Capture cuda graph end. Time elapsed: 7.60 s. mem usage=0.36 GB. avail mem=17.20 GB.
[2025-09-13 07:31:53 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:31:53 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:31:53 TP0] Init torch distributed begin.
[2025-09-13 07:31:53 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:31:53 TP0] Load weight begin. avail mem=17.20 GB
[2025-09-13 07:31:53 TP0] Detected fp8 checkpoint.
[2025-09-13 07:31:53 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 171.18it/s]
Loading safetensors checkpoint shards:   4% Completed | 37/1024 [00:00<00:05, 180.34it/s]
Loading safetensors checkpoint shards:   7% Completed | 69/1024 [00:00<00:03, 240.98it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:00<00:03, 293.44it/s]
Loading safetensors checkpoint shards:  17% Completed | 172/1024 [00:00<00:02, 419.74it/s]
Loading safetensors checkpoint shards:  23% Completed | 236/1024 [00:00<00:01, 493.07it/s]
Loading safetensors checkpoint shards:  29% Completed | 302/1024 [00:00<00:01, 544.78it/s]
Loading safetensors checkpoint shards:  36% Completed | 368/1024 [00:00<00:01, 578.74it/s]
Loading safetensors checkpoint shards:  42% Completed | 433/1024 [00:00<00:00, 599.38it/s]
Loading safetensors checkpoint shards:  49% Completed | 499/1024 [00:01<00:00, 614.95it/s]
Loading safetensors checkpoint shards:  55% Completed | 565/1024 [00:01<00:00, 626.62it/s]
Loading safetensors checkpoint shards:  62% Completed | 631/1024 [00:01<00:00, 634.91it/s]
Loading safetensors checkpoint shards:  68% Completed | 695/1024 [00:01<00:00, 630.17it/s]
Loading safetensors checkpoint shards:  74% Completed | 759/1024 [00:01<00:00, 624.47it/s]
Loading safetensors checkpoint shards:  80% Completed | 822/1024 [00:01<00:00, 622.82it/s]
Loading safetensors checkpoint shards:  86% Completed | 885/1024 [00:01<00:00, 619.94it/s]
Loading safetensors checkpoint shards:  93% Completed | 948/1024 [00:01<00:00, 620.03it/s]
Loading safetensors checkpoint shards:  99% Completed | 1011/1024 [00:01<00:00, 421.85it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 503.10it/s]

[2025-09-13 07:31:55 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.21 GB, mem usage=1.99 GB.
[2025-09-13 07:31:55 TP7] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:31:55 TP3] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:31:55 TP0] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:31:55 TP1] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:31:55 TP6] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:31:55 TP5] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:31:55 TP4] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:31:55 TP0] Memory pool end. avail mem=14.54 GB
[2025-09-13 07:31:55 TP2] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:31:55 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:31:55 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:31:55 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:31:55 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:31:55 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:31:55 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:31:55 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:31:55 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.17 GB
Capturing batches (bs=1 avail_mem=14.51 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  3.07it/s][2025-09-13 07:32:01 TP3] Registering 96 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.51 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.44it/s]
[2025-09-13 07:32:01 TP0] Registering 96 cuda graph addresses
[2025-09-13 07:32:01 TP1] Registering 96 cuda graph addresses
[2025-09-13 07:32:01 TP6] Registering 96 cuda graph addresses
[2025-09-13 07:32:01 TP4] Registering 96 cuda graph addresses
[2025-09-13 07:32:01 TP5] Registering 96 cuda graph addresses
[2025-09-13 07:32:01 TP7] Registering 96 cuda graph addresses
[2025-09-13 07:32:01 TP2] Registering 96 cuda graph addresses
[2025-09-13 07:32:01 TP7] Capture draft cuda graph end. Time elapsed: 6.30 s. mem usage=0.47 GB. avail mem=14.70 GB.
[2025-09-13 07:32:01 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.70 GB
[2025-09-13 07:32:01 TP6] Capture draft cuda graph end. Time elapsed: 6.30 s. mem usage=0.47 GB. avail mem=14.46 GB.
[2025-09-13 07:32:01 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
[2025-09-13 07:32:01 TP3] Capture draft cuda graph end. Time elapsed: 6.30 s. mem usage=0.47 GB. avail mem=14.46 GB.
[2025-09-13 07:32:01 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
[2025-09-13 07:32:01 TP1] Capture draft cuda graph end. Time elapsed: 6.30 s. mem usage=0.47 GB. avail mem=14.46 GB.
[2025-09-13 07:32:01 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
[2025-09-13 07:32:01 TP5] Capture draft cuda graph end. Time elapsed: 6.31 s. mem usage=0.47 GB. avail mem=14.46 GB.
[2025-09-13 07:32:01 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
[2025-09-13 07:32:01 TP0] Capture draft cuda graph end. Time elapsed: 6.31 s. mem usage=0.47 GB. avail mem=14.50 GB.
[2025-09-13 07:32:01 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 07:32:01 TP4] Capture draft cuda graph end. Time elapsed: 6.31 s. mem usage=0.47 GB. avail mem=14.46 GB.
[2025-09-13 07:32:01 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
[2025-09-13 07:32:01 TP2] Capture draft cuda graph end. Time elapsed: 6.31 s. mem usage=0.47 GB. avail mem=14.46 GB.
[2025-09-13 07:32:01 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
Capturing batches (bs=1 avail_mem=14.32 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:00<00:00, 22.23it/s][2025-09-13 07:32:02 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:32:02 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:32:02 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:32:02 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:32:02 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:32:02 TP2] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.32 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 21.08it/s][2025-09-13 07:32:02 TP7] Registering 24 cuda graph addresses

[2025-09-13 07:32:03 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:32:03 TP7] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.19 GB. avail mem=14.51 GB.
[2025-09-13 07:32:03 TP2] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.19 GB. avail mem=14.28 GB.
[2025-09-13 07:32:03 TP4] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.19 GB. avail mem=14.28 GB.
[2025-09-13 07:32:03 TP0] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.19 GB. avail mem=14.32 GB.
[2025-09-13 07:32:03 TP1] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.19 GB. avail mem=14.28 GB.
[2025-09-13 07:32:03 TP0] max_total_num_tokens=620249, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.32 GB
[2025-09-13 07:32:03 TP6] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.19 GB. avail mem=14.28 GB.
[2025-09-13 07:32:03 TP5] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.19 GB. avail mem=14.28 GB.
[2025-09-13 07:32:03 TP3] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.19 GB. avail mem=14.28 GB.
[2025-09-13 07:32:03] INFO:     Started server process [301134]
[2025-09-13 07:32:03] INFO:     Waiting for application startup.
[2025-09-13 07:32:03] INFO:     Application startup complete.
[2025-09-13 07:32:03] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:32:04] INFO:     127.0.0.1:56504 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:32:04] INFO:     127.0.0.1:56510 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:32:04 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:32:04 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:32:04 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27127.97it/s]
[2025-09-13 07:32:05] INFO:     127.0.0.1:56518 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:05] The server is fired up and ready to roll!
[2025-09-13 07:32:14 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:32:15] INFO:     127.0.0.1:60234 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:32:15] INFO:     127.0.0.1:60244 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:15 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:32:17] INFO:     127.0.0.1:60252 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:17] INFO:     127.0.0.1:60256 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:32:17] INFO:     127.0.0.1:60264 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:17] INFO:     127.0.0.1:60272 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:17] INFO:     127.0.0.1:60282 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:17] INFO:     127.0.0.1:60292 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:17] INFO:     127.0.0.1:60298 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:17] INFO:     127.0.0.1:60300 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:17 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:32:17 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:32:17 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:32:17 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:32:17 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:32:17 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:32:17 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:32:17 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:32:17 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:32:17 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:32:18 TP0] Decode batch. #running-req: 8, #token: 14466, token usage: 0.02, accept len: 2.61, cuda graph: True, gen throughput (token/s): 37.11, #queue-req: 0, 
[2025-09-13 07:32:19 TP0] Decode batch. #running-req: 8, #token: 15409, token usage: 0.02, accept len: 2.95, cuda graph: True, gen throughput (token/s): 769.61, #queue-req: 0, 
[2025-09-13 07:32:21 TP0] Decode batch. #running-req: 8, #token: 16354, token usage: 0.03, accept len: 2.95, cuda graph: True, gen throughput (token/s): 764.88, #queue-req: 0, 
[2025-09-13 07:32:22 TP0] Decode batch. #running-req: 8, #token: 17321, token usage: 0.03, accept len: 3.02, cuda graph: True, gen throughput (token/s): 786.95, #queue-req: 0, 
 62%|█████████████████████████████████████████████████████████████████████████████████▉                                                 | 5/8 [00:06<00:02,  1.35it/s][2025-09-13 07:32:23 TP0] Decode batch. #running-req: 3, #token: 6503, token usage: 0.01, accept len: 3.19, cuda graph: True, gen throughput (token/s): 564.02, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.19it/s]
[2025-09-13 07:32:23] INFO:     127.0.0.1:45462 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.75      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4068      
Request throughput (req/s):              1.19      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         607.13    
Total token throughput (tok/s):          607.13    
Concurrency:                             7.21      
Accept length:                           2.95      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   6080.96   
Median E2E Latency (ms):                 6021.27   
---------------Time to First Token----------------
Mean TTFT (ms):                          607.81    
Median TTFT (ms):                        719.62    
P99 TTFT (ms):                           720.11    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.71     
Median ITL (ms):                         7.74      
P95 ITL (ms):                            29.58     
P99 ITL (ms):                            32.49     
Max ITL (ms):                            728.10    
==================================================
[2025-09-13 07:32:23] INFO:     127.0.0.1:45470 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:32:23] INFO:     127.0.0.1:45472 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:32:25] INFO:     127.0.0.1:45474 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:25] INFO:     127.0.0.1:45478 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:32:25] INFO:     127.0.0.1:45484 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:25] INFO:     127.0.0.1:45488 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:25] INFO:     127.0.0.1:45496 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:25] INFO:     127.0.0.1:45504 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:25] INFO:     127.0.0.1:45508 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:25] INFO:     127.0.0.1:45518 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:25 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:32:25 TP0] Decode batch. #running-req: 8, #token: 14255, token usage: 0.02, accept len: 2.45, cuda graph: True, gen throughput (token/s): 162.87, #queue-req: 0, 
[2025-09-13 07:32:27 TP0] Decode batch. #running-req: 8, #token: 15188, token usage: 0.02, accept len: 2.92, cuda graph: True, gen throughput (token/s): 767.04, #queue-req: 0, 
[2025-09-13 07:32:28 TP0] Decode batch. #running-req: 8, #token: 16129, token usage: 0.03, accept len: 2.94, cuda graph: True, gen throughput (token/s): 763.32, #queue-req: 0, 
[2025-09-13 07:32:29 TP0] Decode batch. #running-req: 8, #token: 17119, token usage: 0.03, accept len: 3.09, cuda graph: True, gen throughput (token/s): 803.97, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:13,  4.92s/it][2025-09-13 07:32:30] INFO:     127.0.0.1:52276 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:30 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:05<00:31,  2.28s/it][2025-09-13 07:32:30] INFO:     127.0.0.1:52290 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:30 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:17,  1.34s/it][2025-09-13 07:32:30] INFO:     127.0.0.1:52298 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:30 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:11,  1.07it/s][2025-09-13 07:32:31] INFO:     127.0.0.1:52306 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:31 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:06<00:07,  1.43it/s][2025-09-13 07:32:31] INFO:     127.0.0.1:52314 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:31 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:32:31 TP0] Decode batch. #running-req: 8, #token: 12636, token usage: 0.02, accept len: 3.05, cuda graph: True, gen throughput (token/s): 476.31, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:06<00:06,  1.52it/s][2025-09-13 07:32:31] INFO:     127.0.0.1:52320 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:31 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:32:31] INFO:     127.0.0.1:52336 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:07<00:03,  2.37it/s][2025-09-13 07:32:32] INFO:     127.0.0.1:52346 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:32:32 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:32:33 TP0] Decode batch. #running-req: 8, #token: 14437, token usage: 0.02, accept len: 2.83, cuda graph: True, gen throughput (token/s): 523.07, #queue-req: 0, 
[2025-09-13 07:32:34 TP0] Decode batch. #running-req: 8, #token: 15366, token usage: 0.02, accept len: 2.90, cuda graph: True, gen throughput (token/s): 760.98, #queue-req: 0, 
[2025-09-13 07:32:35 TP0] Decode batch. #running-req: 8, #token: 16384, token usage: 0.03, accept len: 3.18, cuda graph: True, gen throughput (token/s): 825.08, #queue-req: 0, 
 69%|████████████████████████████████████████████████████████████████████████████████████████▋                                        | 11/16 [00:11<00:04,  1.18it/s][2025-09-13 07:32:37 TP0] Decode batch. #running-req: 5, #token: 12541, token usage: 0.02, accept len: 3.23, cuda graph: True, gen throughput (token/s): 770.25, #queue-req: 0, 
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 15/16 [00:12<00:00,  2.75it/s][2025-09-13 07:32:37 TP0] Decode batch. #running-req: 1, #token: 3218, token usage: 0.01, accept len: 2.89, cuda graph: True, gen throughput (token/s): 309.91, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:12<00:00,  1.25it/s]
[2025-09-13 07:32:38] INFO:     127.0.0.1:57972 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  12.79     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8087      
Request throughput (req/s):              1.25      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         640.73    
Total token throughput (tok/s):          640.73    
Concurrency:                             7.45      
Accept length:                           2.97      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5951.19   
Median E2E Latency (ms):                 5980.05   
---------------Time to First Token----------------
Mean TTFT (ms):                          232.64    
Median TTFT (ms):                        274.28    
P99 TTFT (ms):                           296.41    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           11.19     
Median ITL (ms):                         7.72      
P95 ITL (ms):                            30.49     
P99 ITL (ms):                            52.29     
Max ITL (ms):                            264.44    
==================================================
[2025-09-13 07:32:38] INFO:     127.0.0.1:57984 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-09-13 07:32:38 TP6] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2612, in run_scheduler_process
    scheduler.event_loop_normal()
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 811, in event_loop_normal
    recv_reqs = self.recv_requests()
                ^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 1095, in recv_requests
    recv_reqs = broadcast_pyobj(
                ^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/utils.py", line 1059, in broadcast_pyobj
    dist.broadcast(tensor_size, src=src, group=dist_group)
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
    work.wait()
RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:535] Read error [172.17.0.8]:15255: Connection reset by peer

[2025-09-13 07:32:38] Received sigquit from a child process. It usually means the child failed.
Finish i=31: batch_size=8, steps=5, topk=4, num_draft_tokens=4, speed=96.80 token/s, step_time=30.65 ms
Start i=32: batch_size=8, steps=5, topk=4, num_draft_tokens=6
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 5 --speculative-eagle-topk 4 --speculative-num-draft-tokens 6 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:32:48.830000 307407 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:32:48.830000 307407 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:32:49] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=715893717, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=6, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:32:49] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:32:58.189000 307856 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:32:58.189000 307856 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:32:58.195000 307855 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:32:58.195000 307855 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:32:58.216000 307851 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:32:58.216000 307851 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:32:58.418000 307850 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:32:58.418000 307850 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 07:32:58.447000 307848 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:32:58.447000 307848 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:32:58.462000 307849 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:32:58.462000 307849 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:32:58.484000 307853 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:32:58.484000 307853 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:32:58.506000 307854 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:32:58.506000 307854 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:32:58.508000 307852 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:32:58.508000 307852 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:32:59 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:32:59 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:32:59 TP0] Init torch distributed begin.
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:33:01 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:33:03 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:33:05 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:33:05 TP0] Detected fp8 checkpoint.
[2025-09-13 07:33:05 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:04, 208.84it/s]
Loading safetensors checkpoint shards:   5% Completed | 47/1024 [00:00<00:14, 67.28it/s]
Loading safetensors checkpoint shards:   6% Completed | 59/1024 [00:00<00:17, 55.72it/s]
Loading safetensors checkpoint shards:   7% Completed | 67/1024 [00:01<00:19, 48.70it/s]
Loading safetensors checkpoint shards:   7% Completed | 74/1024 [00:01<00:20, 46.75it/s]
Loading safetensors checkpoint shards:   8% Completed | 80/1024 [00:01<00:21, 43.42it/s]
Loading safetensors checkpoint shards:   8% Completed | 85/1024 [00:01<00:21, 43.77it/s]
Loading safetensors checkpoint shards:   9% Completed | 90/1024 [00:01<00:21, 42.87it/s]
Loading safetensors checkpoint shards:   9% Completed | 95/1024 [00:01<00:22, 40.62it/s]
Loading safetensors checkpoint shards:  10% Completed | 100/1024 [00:02<00:23, 39.37it/s]
Loading safetensors checkpoint shards:  10% Completed | 105/1024 [00:02<00:23, 39.35it/s]
Loading safetensors checkpoint shards:  11% Completed | 109/1024 [00:02<00:23, 38.49it/s]
Loading safetensors checkpoint shards:  11% Completed | 113/1024 [00:02<00:23, 38.16it/s]
Loading safetensors checkpoint shards:  12% Completed | 118/1024 [00:02<00:22, 40.38it/s]
Loading safetensors checkpoint shards:  12% Completed | 123/1024 [00:02<00:40, 22.35it/s]
Loading safetensors checkpoint shards:  12% Completed | 128/1024 [00:03<00:33, 26.39it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:03<00:31, 28.05it/s]
Loading safetensors checkpoint shards:  13% Completed | 136/1024 [00:03<00:29, 29.95it/s]
Loading safetensors checkpoint shards:  14% Completed | 142/1024 [00:03<00:25, 34.84it/s]
Loading safetensors checkpoint shards:  14% Completed | 146/1024 [00:03<00:24, 35.37it/s]
Loading safetensors checkpoint shards:  15% Completed | 151/1024 [00:03<00:23, 36.55it/s]
Loading safetensors checkpoint shards:  15% Completed | 155/1024 [00:03<00:23, 37.22it/s]
Loading safetensors checkpoint shards:  16% Completed | 160/1024 [00:03<00:21, 40.32it/s]
Loading safetensors checkpoint shards:  16% Completed | 165/1024 [00:03<00:22, 38.56it/s]
Loading safetensors checkpoint shards:  17% Completed | 169/1024 [00:04<00:22, 38.24it/s]
Loading safetensors checkpoint shards:  17% Completed | 174/1024 [00:04<00:21, 40.08it/s]
Loading safetensors checkpoint shards:  17% Completed | 179/1024 [00:04<00:21, 38.86it/s]
Loading safetensors checkpoint shards:  18% Completed | 184/1024 [00:04<00:20, 40.39it/s]
Loading safetensors checkpoint shards:  18% Completed | 189/1024 [00:04<00:20, 40.23it/s]
Loading safetensors checkpoint shards:  19% Completed | 194/1024 [00:04<00:19, 41.73it/s]
Loading safetensors checkpoint shards:  19% Completed | 199/1024 [00:04<00:20, 40.78it/s]
Loading safetensors checkpoint shards:  20% Completed | 204/1024 [00:04<00:20, 40.70it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:05<00:20, 39.58it/s]
Loading safetensors checkpoint shards:  21% Completed | 213/1024 [00:05<00:20, 39.41it/s]
Loading safetensors checkpoint shards:  21% Completed | 218/1024 [00:05<00:20, 40.30it/s]
Loading safetensors checkpoint shards:  22% Completed | 223/1024 [00:05<00:20, 38.14it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:05<00:20, 38.29it/s]
Loading safetensors checkpoint shards:  23% Completed | 231/1024 [00:05<00:20, 37.97it/s]
Loading safetensors checkpoint shards:  23% Completed | 235/1024 [00:05<00:21, 37.38it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:05<00:20, 38.99it/s]
Loading safetensors checkpoint shards:  24% Completed | 244/1024 [00:05<00:20, 37.94it/s]
Loading safetensors checkpoint shards:  24% Completed | 250/1024 [00:06<00:18, 41.59it/s]
Loading safetensors checkpoint shards:  25% Completed | 255/1024 [00:06<00:19, 39.00it/s]
Loading safetensors checkpoint shards:  25% Completed | 259/1024 [00:06<00:19, 38.39it/s]
Loading safetensors checkpoint shards:  26% Completed | 264/1024 [00:06<00:18, 40.02it/s]
Loading safetensors checkpoint shards:  26% Completed | 269/1024 [00:06<00:19, 39.20it/s]
Loading safetensors checkpoint shards:  27% Completed | 274/1024 [00:06<00:18, 40.35it/s]
Loading safetensors checkpoint shards:  27% Completed | 279/1024 [00:06<00:19, 38.31it/s]
Loading safetensors checkpoint shards:  28% Completed | 284/1024 [00:06<00:18, 39.80it/s]
Loading safetensors checkpoint shards:  28% Completed | 289/1024 [00:07<00:18, 38.76it/s]
Loading safetensors checkpoint shards:  29% Completed | 294/1024 [00:07<00:18, 39.57it/s]
Loading safetensors checkpoint shards:  29% Completed | 298/1024 [00:07<00:18, 39.48it/s]
Loading safetensors checkpoint shards:  30% Completed | 303/1024 [00:07<00:18, 39.64it/s]
Loading safetensors checkpoint shards:  30% Completed | 308/1024 [00:07<00:17, 40.53it/s]
Loading safetensors checkpoint shards:  31% Completed | 313/1024 [00:07<00:17, 40.49it/s]
Loading safetensors checkpoint shards:  31% Completed | 318/1024 [00:07<00:16, 42.51it/s]
Loading safetensors checkpoint shards:  32% Completed | 323/1024 [00:07<00:17, 41.22it/s]
Loading safetensors checkpoint shards:  32% Completed | 328/1024 [00:08<00:32, 21.17it/s]
Loading safetensors checkpoint shards:  33% Completed | 334/1024 [00:08<00:25, 26.80it/s]
Loading safetensors checkpoint shards:  33% Completed | 341/1024 [00:08<00:20, 33.65it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:08<00:19, 35.67it/s]
Loading safetensors checkpoint shards:  34% Completed | 353/1024 [00:08<00:15, 42.50it/s]
Loading safetensors checkpoint shards:  35% Completed | 360/1024 [00:08<00:14, 47.38it/s]
Loading safetensors checkpoint shards:  36% Completed | 366/1024 [00:09<00:13, 48.27it/s]
Loading safetensors checkpoint shards:  37% Completed | 374/1024 [00:09<00:11, 56.13it/s]
Loading safetensors checkpoint shards:  37% Completed | 381/1024 [00:09<00:11, 56.96it/s]
Loading safetensors checkpoint shards:  38% Completed | 389/1024 [00:09<00:10, 62.78it/s]
Loading safetensors checkpoint shards:  39% Completed | 396/1024 [00:09<00:09, 62.82it/s]
Loading safetensors checkpoint shards:  39% Completed | 403/1024 [00:09<00:09, 63.82it/s]
Loading safetensors checkpoint shards:  40% Completed | 411/1024 [00:09<00:09, 66.41it/s]
Loading safetensors checkpoint shards:  41% Completed | 418/1024 [00:09<00:09, 67.08it/s]
Loading safetensors checkpoint shards:  42% Completed | 425/1024 [00:09<00:09, 63.47it/s]
Loading safetensors checkpoint shards:  42% Completed | 432/1024 [00:10<00:09, 61.40it/s]
Loading safetensors checkpoint shards:  43% Completed | 440/1024 [00:10<00:08, 65.40it/s]
Loading safetensors checkpoint shards:  44% Completed | 447/1024 [00:10<00:08, 64.82it/s]
Loading safetensors checkpoint shards:  44% Completed | 455/1024 [00:10<00:08, 67.12it/s]
Loading safetensors checkpoint shards:  45% Completed | 462/1024 [00:10<00:08, 67.38it/s]
Loading safetensors checkpoint shards:  46% Completed | 469/1024 [00:10<00:08, 62.92it/s]
Loading safetensors checkpoint shards:  47% Completed | 477/1024 [00:10<00:08, 66.17it/s]
Loading safetensors checkpoint shards:  47% Completed | 484/1024 [00:10<00:08, 61.44it/s]
Loading safetensors checkpoint shards:  48% Completed | 491/1024 [00:11<00:10, 52.53it/s]
Loading safetensors checkpoint shards:  49% Completed | 497/1024 [00:11<00:10, 49.33it/s]
Loading safetensors checkpoint shards:  49% Completed | 503/1024 [00:11<00:20, 25.23it/s]
Loading safetensors checkpoint shards:  50% Completed | 509/1024 [00:11<00:17, 29.10it/s]
Loading safetensors checkpoint shards:  50% Completed | 514/1024 [00:12<00:16, 31.47it/s]
Loading safetensors checkpoint shards:  51% Completed | 519/1024 [00:12<00:14, 34.21it/s]
Loading safetensors checkpoint shards:  51% Completed | 524/1024 [00:12<00:14, 34.02it/s]
Loading safetensors checkpoint shards:  52% Completed | 529/1024 [00:12<00:13, 36.12it/s]
Loading safetensors checkpoint shards:  52% Completed | 534/1024 [00:12<00:13, 37.41it/s]
Loading safetensors checkpoint shards:  53% Completed | 539/1024 [00:12<00:12, 38.53it/s]
Loading safetensors checkpoint shards:  53% Completed | 544/1024 [00:12<00:12, 38.53it/s]
Loading safetensors checkpoint shards:  54% Completed | 551/1024 [00:12<00:10, 44.67it/s]
Loading safetensors checkpoint shards:  54% Completed | 556/1024 [00:13<00:10, 43.35it/s]
Loading safetensors checkpoint shards:  55% Completed | 561/1024 [00:13<00:11, 41.22it/s]
Loading safetensors checkpoint shards:  55% Completed | 566/1024 [00:13<00:12, 37.78it/s]
Loading safetensors checkpoint shards:  56% Completed | 570/1024 [00:13<00:11, 38.08it/s]
Loading safetensors checkpoint shards:  56% Completed | 574/1024 [00:13<00:12, 34.97it/s]
Loading safetensors checkpoint shards:  56% Completed | 578/1024 [00:13<00:13, 33.85it/s]
Loading safetensors checkpoint shards:  57% Completed | 583/1024 [00:13<00:11, 37.23it/s]
Loading safetensors checkpoint shards:  57% Completed | 587/1024 [00:13<00:12, 35.50it/s]
Loading safetensors checkpoint shards:  58% Completed | 591/1024 [00:14<00:12, 34.70it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:14<00:11, 35.87it/s]
Loading safetensors checkpoint shards:  59% Completed | 600/1024 [00:14<00:12, 34.19it/s]
Loading safetensors checkpoint shards:  59% Completed | 604/1024 [00:14<00:11, 35.27it/s]
Loading safetensors checkpoint shards:  59% Completed | 608/1024 [00:14<00:12, 33.64it/s]
Loading safetensors checkpoint shards:  60% Completed | 612/1024 [00:14<00:12, 31.90it/s]
Loading safetensors checkpoint shards:  60% Completed | 617/1024 [00:14<00:11, 36.00it/s]
Loading safetensors checkpoint shards:  61% Completed | 621/1024 [00:14<00:11, 36.53it/s]
Loading safetensors checkpoint shards:  61% Completed | 626/1024 [00:15<00:10, 37.36it/s]
Loading safetensors checkpoint shards:  62% Completed | 630/1024 [00:15<00:11, 33.14it/s]
Loading safetensors checkpoint shards:  62% Completed | 635/1024 [00:15<00:11, 34.66it/s]
Loading safetensors checkpoint shards:  62% Completed | 639/1024 [00:15<00:10, 35.37it/s]
Loading safetensors checkpoint shards:  63% Completed | 643/1024 [00:15<00:10, 35.63it/s]
Loading safetensors checkpoint shards:  63% Completed | 647/1024 [00:15<00:10, 35.23it/s]
Loading safetensors checkpoint shards:  64% Completed | 651/1024 [00:15<00:10, 34.34it/s]
Loading safetensors checkpoint shards:  64% Completed | 656/1024 [00:15<00:10, 36.73it/s]
Loading safetensors checkpoint shards:  64% Completed | 660/1024 [00:15<00:10, 35.88it/s]
Loading safetensors checkpoint shards:  65% Completed | 664/1024 [00:16<00:09, 36.90it/s]
Loading safetensors checkpoint shards:  65% Completed | 669/1024 [00:16<00:08, 40.02it/s]
Loading safetensors checkpoint shards:  66% Completed | 674/1024 [00:16<00:08, 39.90it/s]
Loading safetensors checkpoint shards:  66% Completed | 679/1024 [00:16<00:08, 41.15it/s]
Loading safetensors checkpoint shards:  67% Completed | 685/1024 [00:16<00:07, 46.12it/s]
Loading safetensors checkpoint shards:  67% Completed | 691/1024 [00:16<00:06, 48.37it/s]
Loading safetensors checkpoint shards:  68% Completed | 699/1024 [00:16<00:05, 56.77it/s]
Loading safetensors checkpoint shards:  69% Completed | 706/1024 [00:16<00:05, 58.31it/s]
Loading safetensors checkpoint shards:  70% Completed | 712/1024 [00:17<00:18, 17.31it/s]
Loading safetensors checkpoint shards:  70% Completed | 717/1024 [00:18<00:16, 18.82it/s]
Loading safetensors checkpoint shards:  70% Completed | 721/1024 [00:18<00:14, 20.94it/s]
Loading safetensors checkpoint shards:  71% Completed | 725/1024 [00:18<00:12, 23.03it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:18<00:12, 24.34it/s]
Loading safetensors checkpoint shards:  72% Completed | 733/1024 [00:18<00:11, 24.95it/s]
Loading safetensors checkpoint shards:  72% Completed | 737/1024 [00:18<00:11, 24.66it/s]
Loading safetensors checkpoint shards:  72% Completed | 740/1024 [00:18<00:11, 24.40it/s]
Loading safetensors checkpoint shards:  73% Completed | 744/1024 [00:18<00:10, 26.20it/s]
Loading safetensors checkpoint shards:  73% Completed | 748/1024 [00:19<00:10, 27.45it/s]
Loading safetensors checkpoint shards:  73% Completed | 752/1024 [00:19<00:09, 29.37it/s]
Loading safetensors checkpoint shards:  74% Completed | 756/1024 [00:19<00:08, 30.32it/s]
Loading safetensors checkpoint shards:  74% Completed | 760/1024 [00:19<00:08, 32.12it/s]
Loading safetensors checkpoint shards:  75% Completed | 764/1024 [00:19<00:08, 31.99it/s]
Loading safetensors checkpoint shards:  75% Completed | 768/1024 [00:19<00:07, 33.22it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:19<00:07, 32.89it/s]
Loading safetensors checkpoint shards:  76% Completed | 776/1024 [00:19<00:07, 32.90it/s]
Loading safetensors checkpoint shards:  76% Completed | 780/1024 [00:20<00:07, 31.92it/s]
Loading safetensors checkpoint shards:  77% Completed | 784/1024 [00:20<00:07, 32.27it/s]
Loading safetensors checkpoint shards:  77% Completed | 788/1024 [00:20<00:07, 30.81it/s]
Loading safetensors checkpoint shards:  77% Completed | 792/1024 [00:20<00:07, 30.58it/s]
Loading safetensors checkpoint shards:  78% Completed | 796/1024 [00:20<00:07, 31.10it/s]
Loading safetensors checkpoint shards:  78% Completed | 800/1024 [00:20<00:07, 30.88it/s]
Loading safetensors checkpoint shards:  79% Completed | 804/1024 [00:20<00:06, 31.97it/s]
Loading safetensors checkpoint shards:  79% Completed | 808/1024 [00:20<00:06, 30.90it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:21<00:06, 33.73it/s]
Loading safetensors checkpoint shards:  80% Completed | 817/1024 [00:21<00:06, 32.09it/s]
Loading safetensors checkpoint shards:  80% Completed | 821/1024 [00:21<00:06, 32.54it/s]
Loading safetensors checkpoint shards:  81% Completed | 825/1024 [00:21<00:06, 32.75it/s]
Loading safetensors checkpoint shards:  81% Completed | 830/1024 [00:21<00:05, 35.94it/s]
Loading safetensors checkpoint shards:  82% Completed | 835/1024 [00:21<00:04, 38.44it/s]
Loading safetensors checkpoint shards:  82% Completed | 840/1024 [00:21<00:04, 40.31it/s]
Loading safetensors checkpoint shards:  83% Completed | 845/1024 [00:21<00:04, 39.97it/s]
Loading safetensors checkpoint shards:  83% Completed | 850/1024 [00:22<00:04, 39.94it/s]
Loading safetensors checkpoint shards:  83% Completed | 855/1024 [00:22<00:04, 39.04it/s]
Loading safetensors checkpoint shards:  84% Completed | 859/1024 [00:22<00:04, 37.23it/s]
Loading safetensors checkpoint shards:  84% Completed | 863/1024 [00:22<00:04, 36.99it/s]
Loading safetensors checkpoint shards:  85% Completed | 868/1024 [00:22<00:04, 37.80it/s]
Loading safetensors checkpoint shards:  85% Completed | 872/1024 [00:22<00:03, 38.25it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:22<00:04, 36.80it/s]
Loading safetensors checkpoint shards:  86% Completed | 880/1024 [00:22<00:03, 36.84it/s]
Loading safetensors checkpoint shards:  86% Completed | 884/1024 [00:22<00:03, 36.68it/s]
Loading safetensors checkpoint shards:  87% Completed | 888/1024 [00:23<00:03, 36.47it/s]
Loading safetensors checkpoint shards:  87% Completed | 892/1024 [00:23<00:03, 35.68it/s]
Loading safetensors checkpoint shards:  88% Completed | 896/1024 [00:23<00:03, 36.56it/s]
Loading safetensors checkpoint shards:  88% Completed | 900/1024 [00:23<00:03, 36.94it/s]
Loading safetensors checkpoint shards:  88% Completed | 904/1024 [00:23<00:03, 37.18it/s]
Loading safetensors checkpoint shards:  89% Completed | 908/1024 [00:23<00:03, 37.43it/s]
Loading safetensors checkpoint shards:  89% Completed | 912/1024 [00:23<00:03, 37.10it/s]
Loading safetensors checkpoint shards:  89% Completed | 916/1024 [00:23<00:02, 37.78it/s]
Loading safetensors checkpoint shards:  90% Completed | 920/1024 [00:23<00:02, 37.81it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:24<00:02, 38.10it/s]
Loading safetensors checkpoint shards:  91% Completed | 928/1024 [00:24<00:02, 37.86it/s]
Loading safetensors checkpoint shards:  91% Completed | 932/1024 [00:24<00:02, 36.56it/s]
Loading safetensors checkpoint shards:  91% Completed | 936/1024 [00:24<00:02, 37.26it/s]
Loading safetensors checkpoint shards:  92% Completed | 940/1024 [00:24<00:02, 37.63it/s]
Loading safetensors checkpoint shards:  92% Completed | 944/1024 [00:24<00:02, 38.17it/s]
Loading safetensors checkpoint shards:  93% Completed | 948/1024 [00:24<00:02, 37.77it/s]
Loading safetensors checkpoint shards:  93% Completed | 952/1024 [00:24<00:01, 37.80it/s]
Loading safetensors checkpoint shards:  93% Completed | 956/1024 [00:24<00:01, 38.43it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:25<00:01, 38.94it/s]
Loading safetensors checkpoint shards:  94% Completed | 966/1024 [00:25<00:01, 39.92it/s]
Loading safetensors checkpoint shards:  95% Completed | 970/1024 [00:25<00:01, 39.13it/s]
Loading safetensors checkpoint shards:  95% Completed | 974/1024 [00:25<00:01, 39.27it/s]
Loading safetensors checkpoint shards:  96% Completed | 979/1024 [00:25<00:01, 40.28it/s]
Loading safetensors checkpoint shards:  97% Completed | 995/1024 [00:25<00:00, 71.61it/s]
Loading safetensors checkpoint shards:  98% Completed | 1003/1024 [00:25<00:00, 71.01it/s]
Loading safetensors checkpoint shards:  99% Completed | 1011/1024 [00:26<00:00, 25.26it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:26<00:00, 38.56it/s]

[2025-09-13 07:33:32 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:33:34 TP5] KV Cache is allocated. #tokens: 620265, KV size: 40.59 GB
[2025-09-13 07:33:35 TP4] KV Cache is allocated. #tokens: 620265, KV size: 40.59 GB
[2025-09-13 07:33:35 TP6] KV Cache is allocated. #tokens: 620265, KV size: 40.59 GB
[2025-09-13 07:33:35 TP0] KV Cache is allocated. #tokens: 620265, KV size: 40.59 GB
[2025-09-13 07:33:35 TP3] KV Cache is allocated. #tokens: 620265, KV size: 40.59 GB
[2025-09-13 07:33:35 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:33:35 TP2] KV Cache is allocated. #tokens: 620265, KV size: 40.59 GB
[2025-09-13 07:33:35 TP1] KV Cache is allocated. #tokens: 620265, KV size: 40.59 GB
[2025-09-13 07:33:35 TP7] KV Cache is allocated. #tokens: 620265, KV size: 40.59 GB
[2025-09-13 07:33:35 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:33:35 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.52 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:33:36 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:33:36 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:33:36 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:33:36 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:33:36 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:33:36 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:33:36 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:33:36 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:33:36 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25231.72it/s]
[2025-09-13 07:33:37 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:33:37 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26297.58it/s]
[2025-09-13 07:33:37 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:33:37 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27803.18it/s]
[2025-09-13 07:33:38 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:33:38 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27074.57it/s]
[2025-09-13 07:33:39 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:33:39 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28055.50it/s]
[2025-09-13 07:33:39 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.23 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.15it/s]
[2025-09-13 07:33:42 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:33:42 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:33:42 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:33:42 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:33:42 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:33:42 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:33:42 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:33:42 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:33:42 TP0] Capture cuda graph end. Time elapsed: 7.73 s. mem usage=0.35 GB. avail mem=17.21 GB.
[2025-09-13 07:33:43 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:33:43 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:33:43 TP0] Init torch distributed begin.
[2025-09-13 07:33:43 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:33:43 TP0] Load weight begin. avail mem=17.21 GB
[2025-09-13 07:33:43 TP0] Detected fp8 checkpoint.
[2025-09-13 07:33:43 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 19/1024 [00:00<00:05, 180.46it/s]
Loading safetensors checkpoint shards:   5% Completed | 47/1024 [00:00<00:04, 235.93it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:00<00:02, 398.10it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:00<00:01, 476.75it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:00<00:01, 519.71it/s]
Loading safetensors checkpoint shards:  28% Completed | 287/1024 [00:00<00:01, 545.96it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:00<00:01, 559.91it/s]
Loading safetensors checkpoint shards:  40% Completed | 407/1024 [00:00<00:01, 573.14it/s]
Loading safetensors checkpoint shards:  46% Completed | 466/1024 [00:00<00:00, 578.07it/s]
Loading safetensors checkpoint shards:  51% Completed | 527/1024 [00:01<00:00, 586.80it/s]
Loading safetensors checkpoint shards:  57% Completed | 588/1024 [00:01<00:00, 591.40it/s]
Loading safetensors checkpoint shards:  63% Completed | 648/1024 [00:01<00:00, 587.04it/s]
Loading safetensors checkpoint shards:  69% Completed | 707/1024 [00:01<00:00, 578.86it/s]
Loading safetensors checkpoint shards:  75% Completed | 765/1024 [00:01<00:00, 571.00it/s]
Loading safetensors checkpoint shards:  80% Completed | 823/1024 [00:01<00:00, 568.44it/s]
Loading safetensors checkpoint shards:  86% Completed | 880/1024 [00:01<00:00, 565.28it/s]
Loading safetensors checkpoint shards:  92% Completed | 937/1024 [00:01<00:00, 565.94it/s]
Loading safetensors checkpoint shards:  97% Completed | 994/1024 [00:01<00:00, 485.37it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 503.16it/s]

[2025-09-13 07:33:45 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.22 GB, mem usage=1.99 GB.
[2025-09-13 07:33:45 TP1] KV Cache is allocated. #tokens: 620265, KV size: 0.67 GB
[2025-09-13 07:33:45 TP0] KV Cache is allocated. #tokens: 620265, KV size: 0.67 GB
[2025-09-13 07:33:45 TP6] KV Cache is allocated. #tokens: 620265, KV size: 0.67 GB
[2025-09-13 07:33:45 TP3] KV Cache is allocated. #tokens: 620265, KV size: 0.67 GB
[2025-09-13 07:33:45 TP7] KV Cache is allocated. #tokens: 620265, KV size: 0.67 GB
[2025-09-13 07:33:45 TP0] Memory pool end. avail mem=14.55 GB
[2025-09-13 07:33:45 TP5] KV Cache is allocated. #tokens: 620265, KV size: 0.67 GB
[2025-09-13 07:33:45 TP4] KV Cache is allocated. #tokens: 620265, KV size: 0.67 GB
[2025-09-13 07:33:45 TP2] KV Cache is allocated. #tokens: 620265, KV size: 0.67 GB
[2025-09-13 07:33:45 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:33:45 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:33:45 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.99 GB
[2025-09-13 07:33:45 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:33:45 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:33:45 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.18 GB
[2025-09-13 07:33:45 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:33:45 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
Capturing batches (bs=1 avail_mem=14.52 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  3.16it/s][2025-09-13 07:33:52 TP7] Registering 96 cuda graph addresses
[2025-09-13 07:33:52 TP3] Registering 96 cuda graph addresses
[2025-09-13 07:33:52 TP4] Registering 96 cuda graph addresses
[2025-09-13 07:33:52 TP6] Registering 96 cuda graph addresses
[2025-09-13 07:33:52 TP5] Registering 96 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.52 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.46it/s]
[2025-09-13 07:33:52 TP1] Registering 96 cuda graph addresses
[2025-09-13 07:33:52 TP0] Registering 96 cuda graph addresses
[2025-09-13 07:33:52 TP2] Registering 96 cuda graph addresses
[2025-09-13 07:33:52 TP0] Capture draft cuda graph end. Time elapsed: 6.37 s. mem usage=0.47 GB. avail mem=14.52 GB.
[2025-09-13 07:33:52 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:33:52 TP7] Capture draft cuda graph end. Time elapsed: 6.37 s. mem usage=0.47 GB. avail mem=14.71 GB.
[2025-09-13 07:33:52 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.71 GB
[2025-09-13 07:33:52 TP3] Capture draft cuda graph end. Time elapsed: 6.37 s. mem usage=0.47 GB. avail mem=14.47 GB.
[2025-09-13 07:33:52 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.47 GB
[2025-09-13 07:33:52 TP4] Capture draft cuda graph end. Time elapsed: 6.37 s. mem usage=0.47 GB. avail mem=14.47 GB.
[2025-09-13 07:33:52 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.47 GB
[2025-09-13 07:33:52 TP2] Capture draft cuda graph end. Time elapsed: 6.37 s. mem usage=0.47 GB. avail mem=14.47 GB.
[2025-09-13 07:33:52 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.47 GB
[2025-09-13 07:33:52 TP6] Capture draft cuda graph end. Time elapsed: 6.38 s. mem usage=0.47 GB. avail mem=14.47 GB.
[2025-09-13 07:33:52 TP1] Capture draft cuda graph end. Time elapsed: 6.38 s. mem usage=0.47 GB. avail mem=14.47 GB.
[2025-09-13 07:33:52 TP5] Capture draft cuda graph end. Time elapsed: 6.38 s. mem usage=0.47 GB. avail mem=14.47 GB.
[2025-09-13 07:33:52 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.47 GB
[2025-09-13 07:33:52 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.47 GB
[2025-09-13 07:33:52 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.47 GB
Capturing batches (bs=1 avail_mem=14.33 GB):  50%|███████████████████████████████████████████                                           | 4/8 [00:00<00:00, 19.42it/s][2025-09-13 07:33:53 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:33:53 TP3] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.33 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 26.69it/s]
[2025-09-13 07:33:53 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:33:53 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:33:53 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:33:53 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:33:53 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:33:53 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:33:53 TP2] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.29 GB.
[2025-09-13 07:33:53 TP1] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.29 GB.
[2025-09-13 07:33:53 TP4] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.19 GB. avail mem=14.29 GB.
[2025-09-13 07:33:53 TP0] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.19 GB. avail mem=14.33 GB.
[2025-09-13 07:33:53 TP5] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.29 GB.
[2025-09-13 07:33:53 TP3] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.19 GB. avail mem=14.29 GB.
[2025-09-13 07:33:53 TP7] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.19 GB. avail mem=14.52 GB.
[2025-09-13 07:33:53 TP6] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.19 GB. avail mem=14.29 GB.
[2025-09-13 07:33:53 TP0] max_total_num_tokens=620265, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.33 GB
[2025-09-13 07:33:53] INFO:     Started server process [307407]
[2025-09-13 07:33:53] INFO:     Waiting for application startup.
[2025-09-13 07:33:53] INFO:     Application startup complete.
[2025-09-13 07:33:53] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:33:54] INFO:     127.0.0.1:51512 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:33:54 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:33:54 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:33:54 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28659.37it/s]
[2025-09-13 07:33:56] INFO:     127.0.0.1:51528 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:33:56] The server is fired up and ready to roll!
[2025-09-13 07:34:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:34:04] INFO:     127.0.0.1:55136 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:34:04] INFO:     127.0.0.1:55150 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:04 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:34:06] INFO:     127.0.0.1:55162 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:06] INFO:     127.0.0.1:55170 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:34:06] INFO:     127.0.0.1:55180 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:06] INFO:     127.0.0.1:55194 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:06] INFO:     127.0.0.1:55208 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:06] INFO:     127.0.0.1:55210 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:06] INFO:     127.0.0.1:55224 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:06] INFO:     127.0.0.1:55228 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:06 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:34:06 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:34:06 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:34:06 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:34:06 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:34:06 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:34:06 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:34:06 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:34:06 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:34:06 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:34:07 TP0] Decode batch. #running-req: 8, #token: 14540, token usage: 0.02, accept len: 2.94, cuda graph: True, gen throughput (token/s): 45.69, #queue-req: 0, 
[2025-09-13 07:34:09 TP0] Decode batch. #running-req: 8, #token: 15650, token usage: 0.03, accept len: 3.47, cuda graph: True, gen throughput (token/s): 868.20, #queue-req: 0, 
[2025-09-13 07:34:10 TP0] Decode batch. #running-req: 8, #token: 16880, token usage: 0.03, accept len: 3.84, cuda graph: True, gen throughput (token/s): 948.71, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████▌                                                                 | 4/8 [00:05<00:04,  1.08s/it][2025-09-13 07:34:11 TP0] Decode batch. #running-req: 4, #token: 7049, token usage: 0.01, accept len: 3.73, cuda graph: True, gen throughput (token/s): 696.81, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.24it/s]
[2025-09-13 07:34:12] INFO:     127.0.0.1:35738 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.43      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4082      
Request throughput (req/s):              1.24      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         636.95    
Total token throughput (tok/s):          636.95    
Concurrency:                             6.82      
Accept length:                           3.53      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5485.62   
Median E2E Latency (ms):                 5559.95   
---------------Time to First Token----------------
Mean TTFT (ms):                          714.61    
Median TTFT (ms):                        830.28    
P99 TTFT (ms):                           830.69    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.34      
Median ITL (ms):                         6.47      
P95 ITL (ms):                            17.73     
P99 ITL (ms):                            32.70     
Max ITL (ms):                            765.15    
==================================================
[2025-09-13 07:34:12] INFO:     127.0.0.1:35742 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:34:12] INFO:     127.0.0.1:35744 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:12 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:34:12 TP0] Decode batch. #running-req: 1, #token: 4681, token usage: 0.01, accept len: 3.61, cuda graph: True, gen throughput (token/s): 187.92, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:34:13] INFO:     127.0.0.1:35760 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:13] INFO:     127.0.0.1:35770 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:34:13] INFO:     127.0.0.1:35780 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:13] INFO:     127.0.0.1:35790 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:13] INFO:     127.0.0.1:35792 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:13] INFO:     127.0.0.1:35808 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:13] INFO:     127.0.0.1:35810 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:13] INFO:     127.0.0.1:35818 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:13 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:34:15 TP0] Decode batch. #running-req: 8, #token: 14762, token usage: 0.02, accept len: 3.09, cuda graph: True, gen throughput (token/s): 354.31, #queue-req: 0, 
[2025-09-13 07:34:16 TP0] Decode batch. #running-req: 8, #token: 15906, token usage: 0.03, accept len: 3.58, cuda graph: True, gen throughput (token/s): 887.28, #queue-req: 0, 
[2025-09-13 07:34:17 TP0] Decode batch. #running-req: 8, #token: 17098, token usage: 0.03, accept len: 3.73, cuda graph: True, gen throughput (token/s): 921.59, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:02,  4.20s/it][2025-09-13 07:34:18] INFO:     127.0.0.1:56374 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:18 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:34:18] INFO:     127.0.0.1:56388 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:18] INFO:     127.0.0.1:56398 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:18 TP0] Prefill batch. #new-seq: 2, #new-token: 2409, #cached-token: 1752, token usage: 0.02, #running-req: 6, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:12,  1.06s/it][2025-09-13 07:34:19] INFO:     127.0.0.1:56412 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:19 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:09,  1.17it/s][2025-09-13 07:34:19] INFO:     127.0.0.1:56414 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:19 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:06,  1.45it/s][2025-09-13 07:34:19] INFO:     127.0.0.1:56416 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:19 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:34:19 TP0] Decode batch. #running-req: 8, #token: 8991, token usage: 0.01, accept len: 3.55, cuda graph: True, gen throughput (token/s): 527.43, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:05,  1.58it/s][2025-09-13 07:34:20] INFO:     127.0.0.1:56426 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:20 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:04,  1.67it/s][2025-09-13 07:34:20] INFO:     127.0.0.1:56432 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:34:20 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:34:21 TP0] Decode batch. #running-req: 8, #token: 14682, token usage: 0.02, accept len: 3.17, cuda graph: True, gen throughput (token/s): 614.00, #queue-req: 0, 
[2025-09-13 07:34:22 TP0] Decode batch. #running-req: 8, #token: 15788, token usage: 0.03, accept len: 3.46, cuda graph: True, gen throughput (token/s): 850.51, #queue-req: 0, 
 62%|████████████████████████████████████████████████████████████████████████████████▋                                                | 10/16 [00:10<00:06,  1.01s/it][2025-09-13 07:34:24 TP0] Decode batch. #running-req: 6, #token: 12482, token usage: 0.02, accept len: 4.10, cuda graph: True, gen throughput (token/s): 964.81, #queue-req: 0, 
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 15/16 [00:11<00:00,  3.03it/s][2025-09-13 07:34:25 TP0] Decode batch. #running-req: 1, #token: 1856, token usage: 0.00, accept len: 3.86, cuda graph: True, gen throughput (token/s): 474.60, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.40it/s]
[2025-09-13 07:34:25] INFO:     127.0.0.1:56446 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.41     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8111      
Request throughput (req/s):              1.40      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         717.89    
Total token throughput (tok/s):          717.89    
Concurrency:                             7.43      
Accept length:                           3.54      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5301.26   
Median E2E Latency (ms):                 5565.73   
---------------Time to First Token----------------
Mean TTFT (ms):                          256.22    
Median TTFT (ms):                        279.94    
P99 TTFT (ms):                           433.72    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.87      
Median ITL (ms):                         6.51      
P95 ITL (ms):                            30.18     
P99 ITL (ms):                            43.47     
Max ITL (ms):                            281.91    
==================================================
[2025-09-13 07:34:25] INFO:     127.0.0.1:56450 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=32: batch_size=8, steps=5, topk=4, num_draft_tokens=6, speed=109.64 token/s, step_time=32.29 ms
Start i=33: batch_size=8, steps=5, topk=4, num_draft_tokens=8
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 5 --speculative-eagle-topk 4 --speculative-num-draft-tokens 8 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:34:36.117000 313430 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:34:36.117000 313430 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:34:36] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=89811955, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:34:36] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:34:45.218000 313648 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:34:45.218000 313648 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:34:45.565000 313649 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:34:45.565000 313649 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:34:45.605000 313650 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:34:45.605000 313650 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:34:45.614000 313655 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:34:45.614000 313655 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:34:45.647000 313653 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:34:45.647000 313653 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:34:45.709000 313647 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:34:45.709000 313647 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:34:45.719000 313652 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:34:45.719000 313652 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:34:45.800000 313651 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:34:45.800000 313651 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:34:45.812000 313654 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:34:45.812000 313654 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:34:46 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:34:46 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:34:46 TP0] Init torch distributed begin.
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:34:48 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:34:50 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:34:52 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:34:52 TP0] Detected fp8 checkpoint.
[2025-09-13 07:34:52 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 28/1024 [00:00<00:04, 241.36it/s]
Loading safetensors checkpoint shards:   5% Completed | 53/1024 [00:00<00:15, 62.56it/s]
Loading safetensors checkpoint shards:   6% Completed | 66/1024 [00:01<00:17, 55.68it/s]
Loading safetensors checkpoint shards:   7% Completed | 75/1024 [00:01<00:16, 59.23it/s]
Loading safetensors checkpoint shards:   8% Completed | 84/1024 [00:01<00:17, 53.86it/s]
Loading safetensors checkpoint shards:   9% Completed | 91/1024 [00:01<00:19, 47.58it/s]
Loading safetensors checkpoint shards:   9% Completed | 97/1024 [00:01<00:20, 45.92it/s]
Loading safetensors checkpoint shards:  10% Completed | 105/1024 [00:01<00:18, 50.38it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:20, 44.72it/s]
Loading safetensors checkpoint shards:  11% Completed | 116/1024 [00:02<00:32, 27.91it/s]
Loading safetensors checkpoint shards:  12% Completed | 121/1024 [00:02<00:29, 30.83it/s]
Loading safetensors checkpoint shards:  12% Completed | 127/1024 [00:02<00:25, 35.01it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:02<00:24, 36.28it/s]
Loading safetensors checkpoint shards:  13% Completed | 138/1024 [00:02<00:21, 40.85it/s]
Loading safetensors checkpoint shards:  14% Completed | 143/1024 [00:03<00:21, 41.59it/s]
Loading safetensors checkpoint shards:  14% Completed | 148/1024 [00:03<00:21, 41.09it/s]
Loading safetensors checkpoint shards:  15% Completed | 154/1024 [00:03<00:19, 43.67it/s]
Loading safetensors checkpoint shards:  16% Completed | 159/1024 [00:03<00:19, 43.29it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:03<00:19, 43.59it/s]
Loading safetensors checkpoint shards:  17% Completed | 169/1024 [00:03<00:19, 43.48it/s]
Loading safetensors checkpoint shards:  17% Completed | 175/1024 [00:03<00:18, 45.36it/s]
Loading safetensors checkpoint shards:  18% Completed | 180/1024 [00:03<00:19, 43.51it/s]
Loading safetensors checkpoint shards:  18% Completed | 185/1024 [00:03<00:18, 45.09it/s]
Loading safetensors checkpoint shards:  19% Completed | 190/1024 [00:04<00:18, 44.81it/s]
Loading safetensors checkpoint shards:  19% Completed | 196/1024 [00:04<00:17, 47.04it/s]
Loading safetensors checkpoint shards:  20% Completed | 201/1024 [00:04<00:18, 45.39it/s]
Loading safetensors checkpoint shards:  20% Completed | 206/1024 [00:04<00:18, 44.27it/s]
Loading safetensors checkpoint shards:  21% Completed | 211/1024 [00:04<00:19, 42.07it/s]
Loading safetensors checkpoint shards:  21% Completed | 216/1024 [00:04<00:18, 42.77it/s]
Loading safetensors checkpoint shards:  22% Completed | 221/1024 [00:04<00:20, 40.00it/s]
Loading safetensors checkpoint shards:  22% Completed | 226/1024 [00:04<00:20, 38.86it/s]
Loading safetensors checkpoint shards:  22% Completed | 230/1024 [00:05<00:21, 37.62it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:05<00:21, 36.89it/s]
Loading safetensors checkpoint shards:  23% Completed | 239/1024 [00:05<00:20, 39.02it/s]
Loading safetensors checkpoint shards:  24% Completed | 243/1024 [00:05<00:20, 38.93it/s]
Loading safetensors checkpoint shards:  24% Completed | 247/1024 [00:05<00:20, 38.62it/s]
Loading safetensors checkpoint shards:  25% Completed | 252/1024 [00:05<00:18, 41.30it/s]
Loading safetensors checkpoint shards:  25% Completed | 257/1024 [00:05<00:18, 41.18it/s]
Loading safetensors checkpoint shards:  26% Completed | 262/1024 [00:05<00:18, 42.08it/s]
Loading safetensors checkpoint shards:  26% Completed | 267/1024 [00:05<00:19, 39.23it/s]
Loading safetensors checkpoint shards:  27% Completed | 272/1024 [00:06<00:18, 40.50it/s]
Loading safetensors checkpoint shards:  27% Completed | 277/1024 [00:06<00:19, 38.84it/s]
Loading safetensors checkpoint shards:  27% Completed | 281/1024 [00:06<00:19, 38.89it/s]
Loading safetensors checkpoint shards:  28% Completed | 286/1024 [00:06<00:17, 41.45it/s]
Loading safetensors checkpoint shards:  28% Completed | 291/1024 [00:06<00:17, 41.47it/s]
Loading safetensors checkpoint shards:  29% Completed | 297/1024 [00:06<00:16, 44.83it/s]
Loading safetensors checkpoint shards:  29% Completed | 302/1024 [00:06<00:17, 42.09it/s]
Loading safetensors checkpoint shards:  30% Completed | 307/1024 [00:06<00:17, 40.42it/s]
Loading safetensors checkpoint shards:  30% Completed | 312/1024 [00:07<00:17, 39.97it/s]
Loading safetensors checkpoint shards:  31% Completed | 317/1024 [00:07<00:32, 21.70it/s]
Loading safetensors checkpoint shards:  31% Completed | 321/1024 [00:07<00:29, 23.59it/s]
Loading safetensors checkpoint shards:  32% Completed | 325/1024 [00:07<00:27, 25.88it/s]
Loading safetensors checkpoint shards:  32% Completed | 329/1024 [00:07<00:24, 28.04it/s]
Loading safetensors checkpoint shards:  33% Completed | 333/1024 [00:08<00:23, 29.37it/s]
Loading safetensors checkpoint shards:  33% Completed | 338/1024 [00:08<00:21, 31.80it/s]
Loading safetensors checkpoint shards:  33% Completed | 342/1024 [00:08<00:20, 32.73it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:08<00:19, 34.19it/s]
Loading safetensors checkpoint shards:  34% Completed | 351/1024 [00:08<00:17, 38.11it/s]
Loading safetensors checkpoint shards:  35% Completed | 356/1024 [00:08<00:16, 39.43it/s]
Loading safetensors checkpoint shards:  35% Completed | 361/1024 [00:08<00:16, 41.33it/s]
Loading safetensors checkpoint shards:  36% Completed | 366/1024 [00:08<00:15, 41.14it/s]
Loading safetensors checkpoint shards:  36% Completed | 371/1024 [00:08<00:15, 42.19it/s]
Loading safetensors checkpoint shards:  37% Completed | 376/1024 [00:09<00:15, 40.80it/s]
Loading safetensors checkpoint shards:  37% Completed | 381/1024 [00:09<00:16, 39.04it/s]
Loading safetensors checkpoint shards:  38% Completed | 386/1024 [00:09<00:15, 40.37it/s]
Loading safetensors checkpoint shards:  38% Completed | 391/1024 [00:09<00:15, 40.03it/s]
Loading safetensors checkpoint shards:  39% Completed | 396/1024 [00:09<00:15, 40.20it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:09<00:15, 39.49it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:09<00:15, 40.79it/s]
Loading safetensors checkpoint shards:  40% Completed | 411/1024 [00:09<00:15, 39.42it/s]
Loading safetensors checkpoint shards:  41% Completed | 417/1024 [00:10<00:13, 43.68it/s]
Loading safetensors checkpoint shards:  41% Completed | 424/1024 [00:10<00:12, 49.28it/s]
Loading safetensors checkpoint shards:  42% Completed | 430/1024 [00:10<00:11, 51.77it/s]
Loading safetensors checkpoint shards:  43% Completed | 436/1024 [00:10<00:12, 45.68it/s]
Loading safetensors checkpoint shards:  43% Completed | 442/1024 [00:10<00:12, 47.29it/s]
Loading safetensors checkpoint shards:  44% Completed | 447/1024 [00:10<00:13, 42.86it/s]
Loading safetensors checkpoint shards:  44% Completed | 452/1024 [00:10<00:13, 42.63it/s]
Loading safetensors checkpoint shards:  45% Completed | 457/1024 [00:10<00:13, 43.50it/s]
Loading safetensors checkpoint shards:  45% Completed | 462/1024 [00:11<00:12, 45.03it/s]
Loading safetensors checkpoint shards:  46% Completed | 467/1024 [00:11<00:13, 42.13it/s]
Loading safetensors checkpoint shards:  46% Completed | 473/1024 [00:11<00:12, 44.38it/s]
Loading safetensors checkpoint shards:  47% Completed | 478/1024 [00:11<00:12, 43.67it/s]
Loading safetensors checkpoint shards:  47% Completed | 483/1024 [00:11<00:12, 43.72it/s]
Loading safetensors checkpoint shards:  48% Completed | 488/1024 [00:11<00:13, 40.81it/s]
Loading safetensors checkpoint shards:  48% Completed | 495/1024 [00:11<00:11, 46.26it/s]
Loading safetensors checkpoint shards:  49% Completed | 501/1024 [00:11<00:10, 49.76it/s]
Loading safetensors checkpoint shards:  50% Completed | 507/1024 [00:12<00:09, 52.11it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:12<00:10, 48.12it/s]
Loading safetensors checkpoint shards:  51% Completed | 518/1024 [00:12<00:11, 42.92it/s]
Loading safetensors checkpoint shards:  51% Completed | 523/1024 [00:12<00:12, 41.16it/s]
Loading safetensors checkpoint shards:  52% Completed | 528/1024 [00:13<00:25, 19.31it/s]
Loading safetensors checkpoint shards:  52% Completed | 532/1024 [00:13<00:22, 21.70it/s]
Loading safetensors checkpoint shards:  52% Completed | 536/1024 [00:13<00:19, 24.53it/s]
Loading safetensors checkpoint shards:  53% Completed | 542/1024 [00:13<00:15, 30.51it/s]
Loading safetensors checkpoint shards:  53% Completed | 547/1024 [00:13<00:14, 33.77it/s]
Loading safetensors checkpoint shards:  54% Completed | 553/1024 [00:13<00:12, 39.20it/s]
Loading safetensors checkpoint shards:  54% Completed | 558/1024 [00:13<00:11, 40.75it/s]
Loading safetensors checkpoint shards:  55% Completed | 564/1024 [00:13<00:10, 44.57it/s]
Loading safetensors checkpoint shards:  56% Completed | 570/1024 [00:13<00:09, 48.22it/s]
Loading safetensors checkpoint shards:  56% Completed | 576/1024 [00:14<00:10, 43.15it/s]
Loading safetensors checkpoint shards:  57% Completed | 581/1024 [00:14<00:10, 43.76it/s]
Loading safetensors checkpoint shards:  57% Completed | 586/1024 [00:14<00:09, 43.86it/s]
Loading safetensors checkpoint shards:  58% Completed | 591/1024 [00:14<00:10, 41.46it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:14<00:09, 43.02it/s]
Loading safetensors checkpoint shards:  59% Completed | 601/1024 [00:14<00:10, 41.69it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:14<00:10, 41.52it/s]
Loading safetensors checkpoint shards:  60% Completed | 611/1024 [00:14<00:10, 40.35it/s]
Loading safetensors checkpoint shards:  60% Completed | 618/1024 [00:15<00:08, 47.58it/s]
Loading safetensors checkpoint shards:  61% Completed | 623/1024 [00:15<00:08, 46.03it/s]
Loading safetensors checkpoint shards:  61% Completed | 628/1024 [00:15<00:09, 42.53it/s]
Loading safetensors checkpoint shards:  62% Completed | 633/1024 [00:15<00:10, 36.82it/s]
Loading safetensors checkpoint shards:  62% Completed | 637/1024 [00:15<00:11, 34.68it/s]
Loading safetensors checkpoint shards:  63% Completed | 641/1024 [00:15<00:12, 29.67it/s]
Loading safetensors checkpoint shards:  63% Completed | 645/1024 [00:15<00:12, 30.28it/s]
Loading safetensors checkpoint shards:  63% Completed | 650/1024 [00:16<00:11, 33.69it/s]
Loading safetensors checkpoint shards:  64% Completed | 658/1024 [00:16<00:08, 43.26it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:16<00:08, 44.54it/s]
Loading safetensors checkpoint shards:  65% Completed | 668/1024 [00:16<00:07, 44.99it/s]
Loading safetensors checkpoint shards:  66% Completed | 674/1024 [00:16<00:07, 48.13it/s]
Loading safetensors checkpoint shards:  66% Completed | 680/1024 [00:16<00:06, 50.10it/s]
Loading safetensors checkpoint shards:  67% Completed | 688/1024 [00:16<00:05, 57.95it/s]
Loading safetensors checkpoint shards:  68% Completed | 695/1024 [00:16<00:05, 60.36it/s]
Loading safetensors checkpoint shards:  69% Completed | 702/1024 [00:16<00:05, 58.08it/s]
Loading safetensors checkpoint shards:  69% Completed | 708/1024 [00:17<00:05, 55.99it/s]
Loading safetensors checkpoint shards:  70% Completed | 716/1024 [00:17<00:05, 60.35it/s]
Loading safetensors checkpoint shards:  71% Completed | 724/1024 [00:17<00:04, 64.32it/s]
Loading safetensors checkpoint shards:  71% Completed | 731/1024 [00:17<00:11, 26.00it/s]
Loading safetensors checkpoint shards:  72% Completed | 737/1024 [00:18<00:09, 30.30it/s]
Loading safetensors checkpoint shards:  73% Completed | 745/1024 [00:18<00:07, 37.43it/s]
Loading safetensors checkpoint shards:  73% Completed | 751/1024 [00:18<00:06, 40.87it/s]
Loading safetensors checkpoint shards:  74% Completed | 758/1024 [00:18<00:05, 45.97it/s]
Loading safetensors checkpoint shards:  75% Completed | 765/1024 [00:18<00:05, 50.92it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:18<00:04, 51.46it/s]
Loading safetensors checkpoint shards:  76% Completed | 778/1024 [00:18<00:04, 49.41it/s]
Loading safetensors checkpoint shards:  77% Completed | 784/1024 [00:18<00:04, 49.42it/s]
Loading safetensors checkpoint shards:  77% Completed | 790/1024 [00:18<00:04, 50.36it/s]
Loading safetensors checkpoint shards:  78% Completed | 796/1024 [00:19<00:04, 51.49it/s]
Loading safetensors checkpoint shards:  78% Completed | 802/1024 [00:19<00:04, 50.36it/s]
Loading safetensors checkpoint shards:  79% Completed | 808/1024 [00:19<00:04, 51.51it/s]
Loading safetensors checkpoint shards:  80% Completed | 815/1024 [00:19<00:03, 53.86it/s]
Loading safetensors checkpoint shards:  80% Completed | 821/1024 [00:19<00:03, 54.13it/s]
Loading safetensors checkpoint shards:  81% Completed | 827/1024 [00:19<00:03, 54.61it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:19<00:03, 55.54it/s]
Loading safetensors checkpoint shards:  82% Completed | 839/1024 [00:19<00:03, 54.78it/s]
Loading safetensors checkpoint shards:  83% Completed | 845/1024 [00:19<00:03, 53.55it/s]
Loading safetensors checkpoint shards:  83% Completed | 851/1024 [00:20<00:03, 51.60it/s]
Loading safetensors checkpoint shards:  84% Completed | 857/1024 [00:20<00:03, 47.95it/s]
Loading safetensors checkpoint shards:  84% Completed | 862/1024 [00:20<00:03, 45.98it/s]
Loading safetensors checkpoint shards:  85% Completed | 867/1024 [00:20<00:03, 45.37it/s]
Loading safetensors checkpoint shards:  85% Completed | 872/1024 [00:20<00:03, 44.18it/s]
Loading safetensors checkpoint shards:  86% Completed | 877/1024 [00:20<00:03, 44.12it/s]
Loading safetensors checkpoint shards:  86% Completed | 882/1024 [00:20<00:03, 44.96it/s]
Loading safetensors checkpoint shards:  87% Completed | 887/1024 [00:20<00:03, 45.48it/s]
Loading safetensors checkpoint shards:  87% Completed | 892/1024 [00:21<00:02, 45.06it/s]
Loading safetensors checkpoint shards:  88% Completed | 897/1024 [00:21<00:02, 46.01it/s]
Loading safetensors checkpoint shards:  88% Completed | 903/1024 [00:21<00:02, 46.74it/s]
Loading safetensors checkpoint shards:  89% Completed | 909/1024 [00:21<00:02, 47.61it/s]
Loading safetensors checkpoint shards:  89% Completed | 915/1024 [00:21<00:02, 50.87it/s]
Loading safetensors checkpoint shards:  90% Completed | 921/1024 [00:21<00:02, 48.87it/s]
Loading safetensors checkpoint shards:  90% Completed | 926/1024 [00:21<00:02, 47.89it/s]
Loading safetensors checkpoint shards:  91% Completed | 931/1024 [00:21<00:01, 48.39it/s]
Loading safetensors checkpoint shards:  91% Completed | 936/1024 [00:21<00:01, 45.84it/s]
Loading safetensors checkpoint shards:  92% Completed | 941/1024 [00:22<00:01, 45.01it/s]
Loading safetensors checkpoint shards:  92% Completed | 946/1024 [00:22<00:01, 46.22it/s]
Loading safetensors checkpoint shards:  93% Completed | 951/1024 [00:22<00:01, 39.95it/s]
Loading safetensors checkpoint shards:  93% Completed | 956/1024 [00:22<00:01, 38.94it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:22<00:01, 36.89it/s]
Loading safetensors checkpoint shards:  94% Completed | 965/1024 [00:23<00:03, 15.84it/s]
Loading safetensors checkpoint shards:  95% Completed | 969/1024 [00:23<00:02, 18.72it/s]
Loading safetensors checkpoint shards:  95% Completed | 974/1024 [00:23<00:02, 22.83it/s]
Loading safetensors checkpoint shards:  96% Completed | 980/1024 [00:23<00:01, 28.12it/s]
Loading safetensors checkpoint shards:  97% Completed | 990/1024 [00:23<00:00, 41.50it/s]
Loading safetensors checkpoint shards:  98% Completed | 1001/1024 [00:23<00:00, 55.40it/s]
Loading safetensors checkpoint shards:  99% Completed | 1013/1024 [00:23<00:00, 69.77it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:24<00:00, 42.57it/s]

[2025-09-13 07:35:20 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:35:20 TP1] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:35:20 TP3] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:35:20 TP4] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:35:20 TP2] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:35:20 TP6] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:35:20 TP7] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:35:20 TP0] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:35:20 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:35:20 TP5] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:35:20 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:35:21 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.51 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:35:22 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:35:22 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:35:22 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:35:22 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:35:22 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:35:22 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:35:22 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:35:22 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:35:22 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25913.93it/s]
[2025-09-13 07:35:22 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:35:22 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26381.35it/s]
[2025-09-13 07:35:23 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:35:23 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27649.73it/s]
[2025-09-13 07:35:24 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:35:24 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26783.93it/s]
[2025-09-13 07:35:24 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:35:24 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27935.81it/s]
[2025-09-13 07:35:25 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.20 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.76it/s][2025-09-13 07:35:28 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:35:28 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:35:28 TP4] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.20 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.14it/s]
[2025-09-13 07:35:28 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:35:28 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:35:28 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:35:28 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:35:28 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:35:28 TP0] Capture cuda graph end. Time elapsed: 7.85 s. mem usage=0.39 GB. avail mem=17.17 GB.
[2025-09-13 07:35:28 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:35:28 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:35:28 TP0] Init torch distributed begin.
[2025-09-13 07:35:28 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:35:28 TP0] Load weight begin. avail mem=17.17 GB
[2025-09-13 07:35:28 TP0] Detected fp8 checkpoint.
[2025-09-13 07:35:28 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 169.32it/s]
Loading safetensors checkpoint shards:   4% Completed | 44/1024 [00:00<00:04, 220.00it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:00<00:02, 403.31it/s]
Loading safetensors checkpoint shards:  17% Completed | 170/1024 [00:00<00:01, 491.61it/s]
Loading safetensors checkpoint shards:  23% Completed | 232/1024 [00:00<00:01, 534.73it/s]
Loading safetensors checkpoint shards:  29% Completed | 294/1024 [00:00<00:01, 562.52it/s]
Loading safetensors checkpoint shards:  35% Completed | 356/1024 [00:00<00:01, 578.04it/s]
Loading safetensors checkpoint shards:  41% Completed | 419/1024 [00:00<00:01, 591.87it/s]
Loading safetensors checkpoint shards:  47% Completed | 481/1024 [00:00<00:00, 598.13it/s]
Loading safetensors checkpoint shards:  53% Completed | 543/1024 [00:01<00:00, 602.56it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:01<00:00, 608.13it/s]
Loading safetensors checkpoint shards:  65% Completed | 667/1024 [00:01<00:00, 598.50it/s]
Loading safetensors checkpoint shards:  71% Completed | 727/1024 [00:01<00:00, 592.45it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:01<00:00, 585.11it/s]
Loading safetensors checkpoint shards:  83% Completed | 846/1024 [00:01<00:00, 584.05it/s]
Loading safetensors checkpoint shards:  88% Completed | 905/1024 [00:01<00:00, 581.11it/s]
Loading safetensors checkpoint shards:  94% Completed | 964/1024 [00:01<00:00, 581.81it/s]
Loading safetensors checkpoint shards: 100% Completed | 1023/1024 [00:02<00:00, 390.61it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 510.29it/s]

[2025-09-13 07:35:31 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.18 GB, mem usage=1.99 GB.
[2025-09-13 07:35:31 TP0] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:35:31 TP5] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:35:31 TP0] Memory pool end. avail mem=14.52 GB
[2025-09-13 07:35:31 TP3] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:35:31 TP1] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:35:31 TP4] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:35:31 TP6] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:35:31 TP7] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:35:31 TP2] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:35:31 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:35:31 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:35:31 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.95 GB
[2025-09-13 07:35:31 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:35:31 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:35:31 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:35:31 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:35:31 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.14 GB
Capturing batches (bs=1 avail_mem=14.48 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  3.05it/s][2025-09-13 07:35:37 TP5] Registering 96 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.48 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.40it/s]
[2025-09-13 07:35:37 TP3] Registering 96 cuda graph addresses
[2025-09-13 07:35:37 TP0] Registering 96 cuda graph addresses
[2025-09-13 07:35:37 TP4] Registering 96 cuda graph addresses
[2025-09-13 07:35:37 TP1] Registering 96 cuda graph addresses
[2025-09-13 07:35:37 TP6] Registering 96 cuda graph addresses
[2025-09-13 07:35:37 TP2] Registering 96 cuda graph addresses
[2025-09-13 07:35:37 TP7] Registering 96 cuda graph addresses
[2025-09-13 07:35:37 TP4] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.47 GB. avail mem=14.44 GB.
[2025-09-13 07:35:37 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
[2025-09-13 07:35:37 TP1] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.47 GB. avail mem=14.44 GB.
[2025-09-13 07:35:37 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
[2025-09-13 07:35:37 TP0] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.47 GB. avail mem=14.48 GB.
[2025-09-13 07:35:37 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.48 GB
[2025-09-13 07:35:37 TP3] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.47 GB. avail mem=14.44 GB.
[2025-09-13 07:35:37 TP6] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.47 GB. avail mem=14.44 GB.
[2025-09-13 07:35:37 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
[2025-09-13 07:35:37 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
[2025-09-13 07:35:37 TP2] Capture draft cuda graph end. Time elapsed: 6.42 s. mem usage=0.47 GB. avail mem=14.44 GB.
[2025-09-13 07:35:37 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
[2025-09-13 07:35:37 TP5] Capture draft cuda graph end. Time elapsed: 6.42 s. mem usage=0.47 GB. avail mem=14.44 GB.
[2025-09-13 07:35:37 TP7] Capture draft cuda graph end. Time elapsed: 6.42 s. mem usage=0.47 GB. avail mem=14.67 GB.
[2025-09-13 07:35:37 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
[2025-09-13 07:35:37 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.67 GB
Capturing batches (bs=1 avail_mem=14.29 GB):  62%|█████████████████████████████████████████████████████▊                                | 5/8 [00:00<00:00, 16.26it/s][2025-09-13 07:35:39 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:35:39 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:35:39 TP1] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.29 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 17.92it/s]
[2025-09-13 07:35:39 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:35:39 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:35:39 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:35:39 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:35:39 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:35:39 TP4] Capture draft extend cuda graph end. Time elapsed: 1.24 s. mem usage=0.19 GB. avail mem=14.25 GB.
[2025-09-13 07:35:39 TP7] Capture draft extend cuda graph end. Time elapsed: 1.23 s. mem usage=0.19 GB. avail mem=14.48 GB.
[2025-09-13 07:35:39 TP3] Capture draft extend cuda graph end. Time elapsed: 1.24 s. mem usage=0.19 GB. avail mem=14.25 GB.
[2025-09-13 07:35:39 TP1] Capture draft extend cuda graph end. Time elapsed: 1.24 s. mem usage=0.19 GB. avail mem=14.25 GB.
[2025-09-13 07:35:39 TP5] Capture draft extend cuda graph end. Time elapsed: 1.24 s. mem usage=0.19 GB. avail mem=14.25 GB.
[2025-09-13 07:35:39 TP0] Capture draft extend cuda graph end. Time elapsed: 1.24 s. mem usage=0.19 GB. avail mem=14.29 GB.
[2025-09-13 07:35:39 TP2] Capture draft extend cuda graph end. Time elapsed: 1.24 s. mem usage=0.19 GB. avail mem=14.25 GB.
[2025-09-13 07:35:39 TP6] Capture draft extend cuda graph end. Time elapsed: 1.24 s. mem usage=0.19 GB. avail mem=14.25 GB.
[2025-09-13 07:35:39 TP0] max_total_num_tokens=620281, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.29 GB
[2025-09-13 07:35:39] INFO:     Started server process [313430]
[2025-09-13 07:35:39] INFO:     Waiting for application startup.
[2025-09-13 07:35:39] INFO:     Application startup complete.
[2025-09-13 07:35:39] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:35:40] INFO:     127.0.0.1:39822 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:35:40] INFO:     127.0.0.1:39832 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:35:40 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:35:40 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:35:40 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28432.12it/s]
[2025-09-13 07:35:41] INFO:     127.0.0.1:39848 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:35:41] The server is fired up and ready to roll!
[2025-09-13 07:35:50 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:35:51] INFO:     127.0.0.1:53052 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:35:51] INFO:     127.0.0.1:53058 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:35:51 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:35:53] INFO:     127.0.0.1:53060 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:35:53] INFO:     127.0.0.1:53072 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:35:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:35:53] INFO:     127.0.0.1:53074 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:35:53] INFO:     127.0.0.1:53080 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:35:53] INFO:     127.0.0.1:53094 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:35:53] INFO:     127.0.0.1:53106 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:35:53] INFO:     127.0.0.1:53116 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:35:53] INFO:     127.0.0.1:53130 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:35:53 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:35:53 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:35:53 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:35:53 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:35:53 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:35:53 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:35:53 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:35:53 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:35:53 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:35:53 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:35:54 TP0] Decode batch. #running-req: 8, #token: 14588, token usage: 0.02, accept len: 3.06, cuda graph: True, gen throughput (token/s): 44.62, #queue-req: 0, 
[2025-09-13 07:35:56 TP0] Decode batch. #running-req: 8, #token: 15710, token usage: 0.03, accept len: 3.51, cuda graph: True, gen throughput (token/s): 832.87, #queue-req: 0, 
[2025-09-13 07:35:57 TP0] Decode batch. #running-req: 8, #token: 16961, token usage: 0.03, accept len: 3.91, cuda graph: True, gen throughput (token/s): 917.77, #queue-req: 0, 
 75%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 6/8 [00:05<00:00,  2.10it/s][2025-09-13 07:35:58 TP0] Decode batch. #running-req: 1, #token: 1433, token usage: 0.00, accept len: 4.06, cuda graph: True, gen throughput (token/s): 747.68, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.34it/s]
[2025-09-13 07:35:59] INFO:     127.0.0.1:35962 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  5.96      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4054      
Request throughput (req/s):              1.34      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         687.44    
Total token throughput (tok/s):          687.44    
Concurrency:                             7.23      
Accept length:                           3.65      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5388.09   
Median E2E Latency (ms):                 5454.50   
---------------Time to First Token----------------
Mean TTFT (ms):                          655.79    
Median TTFT (ms):                        792.78    
P99 TTFT (ms):                           793.28    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.26      
Median ITL (ms):                         6.77      
P95 ITL (ms):                            17.05     
P99 ITL (ms):                            34.07     
Max ITL (ms):                            703.37    
==================================================
[2025-09-13 07:35:59] INFO:     127.0.0.1:35968 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:35:59] INFO:     127.0.0.1:35972 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:35:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:36:00] INFO:     127.0.0.1:35974 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:36:00] INFO:     127.0.0.1:35986 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:36:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:36:00] INFO:     127.0.0.1:35992 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:36:00] INFO:     127.0.0.1:35994 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:36:00] INFO:     127.0.0.1:36000 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:36:00] INFO:     127.0.0.1:36008 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:36:00] INFO:     127.0.0.1:36010 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:36:00] INFO:     127.0.0.1:36016 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:36:00 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:36:01 TP0] Decode batch. #running-req: 8, #token: 14257, token usage: 0.02, accept len: 3.27, cuda graph: True, gen throughput (token/s): 190.01, #queue-req: 0, 
[2025-09-13 07:36:02 TP0] Decode batch. #running-req: 8, #token: 15283, token usage: 0.02, accept len: 3.21, cuda graph: True, gen throughput (token/s): 767.64, #queue-req: 0, 
[2025-09-13 07:36:03 TP0] Decode batch. #running-req: 8, #token: 16570, token usage: 0.03, accept len: 4.02, cuda graph: True, gen throughput (token/s): 942.63, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:03<00:59,  3.95s/it][2025-09-13 07:36:04] INFO:     127.0.0.1:36020 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:36:04 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:36:05 TP0] Decode batch. #running-req: 8, #token: 13594, token usage: 0.02, accept len: 3.91, cuda graph: True, gen throughput (token/s): 829.17, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:30,  2.19s/it][2025-09-13 07:36:05] INFO:     127.0.0.1:36030 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:36:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:17,  1.31s/it][2025-09-13 07:36:05] INFO:     127.0.0.1:36046 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:36:05 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.14it/s][2025-09-13 07:36:05] INFO:     127.0.0.1:36056 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:36:05 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:07,  1.56it/s][2025-09-13 07:36:06] INFO:     127.0.0.1:36070 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:36:06] INFO:     127.0.0.1:36074 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:36:06] INFO:     127.0.0.1:36088 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:36:06 TP0] Prefill batch. #new-seq: 3, #new-token: 5108, #cached-token: 2599, token usage: 0.01, #running-req: 5, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:03,  2.17it/s][2025-09-13 07:36:07] INFO:     127.0.0.1:36094 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:36:07 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:36:07 TP0] Decode batch. #running-req: 8, #token: 14352, token usage: 0.02, accept len: 3.42, cuda graph: True, gen throughput (token/s): 487.66, #queue-req: 0, 
[2025-09-13 07:36:09 TP0] Decode batch. #running-req: 8, #token: 15520, token usage: 0.03, accept len: 3.65, cuda graph: True, gen throughput (token/s): 863.69, #queue-req: 0, 
 56%|█████████████████████████████████████████████████████████████████████████▏                                                        | 9/16 [00:09<00:07,  1.05s/it][2025-09-13 07:36:10 TP0] Decode batch. #running-req: 7, #token: 15481, token usage: 0.02, accept len: 4.00, cuda graph: True, gen throughput (token/s): 938.78, #queue-req: 0, 
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 15/16 [00:10<00:00,  2.86it/s][2025-09-13 07:36:11 TP0] Decode batch. #running-req: 1, #token: 3203, token usage: 0.01, accept len: 4.35, cuda graph: True, gen throughput (token/s): 639.57, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.43it/s]
[2025-09-13 07:36:11] INFO:     127.0.0.1:50366 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.19     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8063      
Request throughput (req/s):              1.43      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         732.19    
Total token throughput (tok/s):          732.19    
Concurrency:                             7.50      
Accept length:                           3.70      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5242.91   
Median E2E Latency (ms):                 5282.48   
---------------Time to First Token----------------
Mean TTFT (ms):                          247.95    
Median TTFT (ms):                        289.51    
P99 TTFT (ms):                           291.33    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.77      
Median ITL (ms):                         6.72      
P95 ITL (ms):                            28.08     
P99 ITL (ms):                            34.41     
Max ITL (ms):                            294.05    
==================================================
[2025-09-13 07:36:11] INFO:     127.0.0.1:50372 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=33: batch_size=8, steps=5, topk=4, num_draft_tokens=8, speed=109.52 token/s, step_time=33.76 ms
Start i=34: batch_size=8, steps=5, topk=4, num_draft_tokens=12
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 5 --speculative-eagle-topk 4 --speculative-num-draft-tokens 12 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:36:22.375000 318533 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:36:22.375000 318533 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:36:22] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=918398916, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=5, speculative_eagle_topk=4, speculative_num_draft_tokens=12, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:36:23] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:36:31.445000 318791 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:36:31.445000 318791 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:36:31.813000 318798 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:36:31.813000 318798 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:36:31.820000 318795 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:36:31.820000 318795 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:36:31.820000 318796 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:36:31.820000 318796 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:36:31.927000 318797 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:36:31.927000 318797 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:36:31.999000 318793 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:36:31.999000 318793 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:36:32.047000 318794 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:36:32.047000 318794 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[2025-09-13 07:36:32 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:36:32 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:36:32 TP0] Init torch distributed begin.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:36:32.100000 318799 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:36:32.100000 318799 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:36:32.101000 318792 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:36:32.101000 318792 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:36:33 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:36:37 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:36:38 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:36:38 TP0] Detected fp8 checkpoint.
[2025-09-13 07:36:39 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 28/1024 [00:00<00:03, 270.43it/s]
Loading safetensors checkpoint shards:   5% Completed | 56/1024 [00:00<00:08, 108.01it/s]
Loading safetensors checkpoint shards:   7% Completed | 72/1024 [00:00<00:12, 76.17it/s]
Loading safetensors checkpoint shards:   8% Completed | 83/1024 [00:01<00:13, 68.51it/s]
Loading safetensors checkpoint shards:   9% Completed | 92/1024 [00:01<00:15, 60.25it/s]
Loading safetensors checkpoint shards:  10% Completed | 99/1024 [00:01<00:30, 30.75it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:02<00:25, 36.15it/s]
Loading safetensors checkpoint shards:  11% Completed | 117/1024 [00:02<00:21, 42.86it/s]
Loading safetensors checkpoint shards:  12% Completed | 125/1024 [00:02<00:18, 48.54it/s]
Loading safetensors checkpoint shards:  13% Completed | 133/1024 [00:02<00:16, 53.95it/s]
Loading safetensors checkpoint shards:  14% Completed | 141/1024 [00:02<00:14, 58.94it/s]
Loading safetensors checkpoint shards:  15% Completed | 149/1024 [00:02<00:14, 62.22it/s]
Loading safetensors checkpoint shards:  15% Completed | 157/1024 [00:02<00:14, 60.30it/s]
Loading safetensors checkpoint shards:  16% Completed | 165/1024 [00:02<00:13, 63.04it/s]
Loading safetensors checkpoint shards:  17% Completed | 175/1024 [00:02<00:11, 70.97it/s]
Loading safetensors checkpoint shards:  18% Completed | 184/1024 [00:03<00:11, 75.39it/s]
Loading safetensors checkpoint shards:  19% Completed | 194/1024 [00:03<00:10, 81.14it/s]
Loading safetensors checkpoint shards:  20% Completed | 203/1024 [00:03<00:10, 77.70it/s]
Loading safetensors checkpoint shards:  21% Completed | 212/1024 [00:03<00:10, 80.38it/s]
Loading safetensors checkpoint shards:  22% Completed | 221/1024 [00:03<00:10, 74.47it/s]
Loading safetensors checkpoint shards:  22% Completed | 229/1024 [00:03<00:10, 74.75it/s]
Loading safetensors checkpoint shards:  23% Completed | 237/1024 [00:04<00:21, 36.44it/s]
Loading safetensors checkpoint shards:  24% Completed | 245/1024 [00:04<00:18, 42.88it/s]
Loading safetensors checkpoint shards:  25% Completed | 253/1024 [00:04<00:15, 49.52it/s]
Loading safetensors checkpoint shards:  25% Completed | 260/1024 [00:04<00:14, 53.42it/s]
Loading safetensors checkpoint shards:  26% Completed | 267/1024 [00:04<00:13, 54.28it/s]
Loading safetensors checkpoint shards:  27% Completed | 274/1024 [00:04<00:13, 57.14it/s]
Loading safetensors checkpoint shards:  27% Completed | 281/1024 [00:04<00:13, 57.03it/s]
Loading safetensors checkpoint shards:  28% Completed | 289/1024 [00:04<00:11, 62.03it/s]
Loading safetensors checkpoint shards:  29% Completed | 296/1024 [00:05<00:11, 60.87it/s]
Loading safetensors checkpoint shards:  30% Completed | 303/1024 [00:05<00:12, 57.29it/s]
Loading safetensors checkpoint shards:  30% Completed | 309/1024 [00:05<00:12, 56.60it/s]
Loading safetensors checkpoint shards:  31% Completed | 315/1024 [00:05<00:12, 56.37it/s]
Loading safetensors checkpoint shards:  31% Completed | 321/1024 [00:05<00:13, 53.14it/s]
Loading safetensors checkpoint shards:  32% Completed | 327/1024 [00:05<00:13, 52.52it/s]
Loading safetensors checkpoint shards:  33% Completed | 333/1024 [00:05<00:13, 51.40it/s]
Loading safetensors checkpoint shards:  33% Completed | 339/1024 [00:05<00:13, 52.28it/s]
Loading safetensors checkpoint shards:  34% Completed | 345/1024 [00:06<00:14, 46.10it/s]
Loading safetensors checkpoint shards:  34% Completed | 350/1024 [00:06<00:14, 46.07it/s]
Loading safetensors checkpoint shards:  35% Completed | 355/1024 [00:06<00:14, 44.80it/s]
Loading safetensors checkpoint shards:  35% Completed | 361/1024 [00:06<00:14, 47.10it/s]
Loading safetensors checkpoint shards:  36% Completed | 366/1024 [00:06<00:14, 45.54it/s]
Loading safetensors checkpoint shards:  36% Completed | 371/1024 [00:06<00:14, 43.79it/s]
Loading safetensors checkpoint shards:  37% Completed | 376/1024 [00:06<00:16, 39.45it/s]
Loading safetensors checkpoint shards:  37% Completed | 381/1024 [00:06<00:17, 35.99it/s]
Loading safetensors checkpoint shards:  38% Completed | 385/1024 [00:07<00:17, 36.88it/s]
Loading safetensors checkpoint shards:  38% Completed | 389/1024 [00:07<00:17, 36.96it/s]
Loading safetensors checkpoint shards:  38% Completed | 394/1024 [00:07<00:16, 38.75it/s]
Loading safetensors checkpoint shards:  39% Completed | 399/1024 [00:07<00:15, 39.64it/s]
Loading safetensors checkpoint shards:  39% Completed | 404/1024 [00:07<00:31, 19.98it/s]
Loading safetensors checkpoint shards:  40% Completed | 408/1024 [00:08<00:27, 22.63it/s]
Loading safetensors checkpoint shards:  40% Completed | 413/1024 [00:08<00:22, 26.67it/s]
Loading safetensors checkpoint shards:  41% Completed | 417/1024 [00:08<00:21, 28.63it/s]
Loading safetensors checkpoint shards:  41% Completed | 421/1024 [00:08<00:19, 30.32it/s]
Loading safetensors checkpoint shards:  42% Completed | 427/1024 [00:08<00:16, 35.43it/s]
Loading safetensors checkpoint shards:  42% Completed | 431/1024 [00:08<00:17, 34.07it/s]
Loading safetensors checkpoint shards:  42% Completed | 435/1024 [00:08<00:18, 31.02it/s]
Loading safetensors checkpoint shards:  43% Completed | 439/1024 [00:08<00:18, 31.68it/s]
Loading safetensors checkpoint shards:  43% Completed | 443/1024 [00:09<00:20, 28.14it/s]
Loading safetensors checkpoint shards:  44% Completed | 447/1024 [00:09<00:22, 25.78it/s]
Loading safetensors checkpoint shards:  44% Completed | 450/1024 [00:09<00:21, 26.58it/s]
Loading safetensors checkpoint shards:  44% Completed | 453/1024 [00:09<00:23, 24.23it/s]
Loading safetensors checkpoint shards:  45% Completed | 456/1024 [00:09<00:24, 22.76it/s]
Loading safetensors checkpoint shards:  45% Completed | 459/1024 [00:09<00:24, 23.53it/s]
Loading safetensors checkpoint shards:  45% Completed | 462/1024 [00:09<00:26, 21.56it/s]
Loading safetensors checkpoint shards:  45% Completed | 465/1024 [00:10<00:27, 20.52it/s]
Loading safetensors checkpoint shards:  46% Completed | 468/1024 [00:10<00:27, 19.96it/s]
Loading safetensors checkpoint shards:  46% Completed | 472/1024 [00:10<00:23, 23.94it/s]
Loading safetensors checkpoint shards:  46% Completed | 476/1024 [00:10<00:20, 26.88it/s]
Loading safetensors checkpoint shards:  47% Completed | 479/1024 [00:10<00:20, 26.12it/s]
Loading safetensors checkpoint shards:  47% Completed | 483/1024 [00:10<00:19, 28.35it/s]
Loading safetensors checkpoint shards:  48% Completed | 487/1024 [00:10<00:17, 30.13it/s]
Loading safetensors checkpoint shards:  48% Completed | 491/1024 [00:11<00:18, 28.52it/s]
Loading safetensors checkpoint shards:  48% Completed | 495/1024 [00:11<00:16, 31.17it/s]
Loading safetensors checkpoint shards:  49% Completed | 499/1024 [00:11<00:16, 32.67it/s]
Loading safetensors checkpoint shards:  49% Completed | 503/1024 [00:11<00:15, 33.52it/s]
Loading safetensors checkpoint shards:  50% Completed | 508/1024 [00:11<00:13, 37.45it/s]
Loading safetensors checkpoint shards:  50% Completed | 512/1024 [00:11<00:14, 35.90it/s]
Loading safetensors checkpoint shards:  51% Completed | 518/1024 [00:11<00:12, 41.74it/s]
Loading safetensors checkpoint shards:  51% Completed | 523/1024 [00:11<00:12, 41.30it/s]
Loading safetensors checkpoint shards:  52% Completed | 528/1024 [00:11<00:12, 40.74it/s]
Loading safetensors checkpoint shards:  52% Completed | 533/1024 [00:12<00:12, 39.96it/s]
Loading safetensors checkpoint shards:  53% Completed | 538/1024 [00:12<00:12, 39.87it/s]
Loading safetensors checkpoint shards:  53% Completed | 543/1024 [00:12<00:12, 39.91it/s]
Loading safetensors checkpoint shards:  54% Completed | 550/1024 [00:12<00:10, 46.54it/s]
Loading safetensors checkpoint shards:  54% Completed | 555/1024 [00:12<00:10, 46.43it/s]
Loading safetensors checkpoint shards:  55% Completed | 560/1024 [00:12<00:10, 44.10it/s]
Loading safetensors checkpoint shards:  55% Completed | 565/1024 [00:12<00:11, 40.18it/s]
Loading safetensors checkpoint shards:  56% Completed | 571/1024 [00:12<00:10, 43.77it/s]
Loading safetensors checkpoint shards:  56% Completed | 577/1024 [00:13<00:09, 47.03it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:13<00:07, 55.39it/s]
Loading safetensors checkpoint shards:  58% Completed | 592/1024 [00:13<00:07, 57.98it/s]
Loading safetensors checkpoint shards:  58% Completed | 598/1024 [00:13<00:08, 48.85it/s]
Loading safetensors checkpoint shards:  59% Completed | 604/1024 [00:13<00:10, 41.55it/s]
Loading safetensors checkpoint shards:  59% Completed | 609/1024 [00:13<00:11, 35.16it/s]
Loading safetensors checkpoint shards:  60% Completed | 613/1024 [00:14<00:30, 13.49it/s]
Loading safetensors checkpoint shards:  60% Completed | 617/1024 [00:14<00:26, 15.44it/s]
Loading safetensors checkpoint shards:  61% Completed | 621/1024 [00:14<00:21, 18.35it/s]
Loading safetensors checkpoint shards:  61% Completed | 625/1024 [00:15<00:19, 20.81it/s]
Loading safetensors checkpoint shards:  62% Completed | 630/1024 [00:15<00:16, 24.39it/s]
Loading safetensors checkpoint shards:  62% Completed | 634/1024 [00:15<00:14, 26.04it/s]
Loading safetensors checkpoint shards:  62% Completed | 639/1024 [00:15<00:12, 30.52it/s]
Loading safetensors checkpoint shards:  63% Completed | 643/1024 [00:15<00:11, 32.21it/s]
Loading safetensors checkpoint shards:  63% Completed | 647/1024 [00:15<00:11, 31.63it/s]
Loading safetensors checkpoint shards:  64% Completed | 651/1024 [00:15<00:11, 32.62it/s]
Loading safetensors checkpoint shards:  64% Completed | 655/1024 [00:15<00:11, 31.97it/s]
Loading safetensors checkpoint shards:  64% Completed | 659/1024 [00:16<00:11, 30.78it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:16<00:11, 30.28it/s]
Loading safetensors checkpoint shards:  65% Completed | 667/1024 [00:16<00:11, 30.46it/s]
Loading safetensors checkpoint shards:  66% Completed | 671/1024 [00:16<00:11, 30.27it/s]
Loading safetensors checkpoint shards:  66% Completed | 675/1024 [00:16<00:12, 28.08it/s]
Loading safetensors checkpoint shards:  66% Completed | 678/1024 [00:16<00:12, 27.90it/s]
Loading safetensors checkpoint shards:  67% Completed | 682/1024 [00:16<00:11, 29.50it/s]
Loading safetensors checkpoint shards:  67% Completed | 685/1024 [00:16<00:11, 29.14it/s]
Loading safetensors checkpoint shards:  67% Completed | 689/1024 [00:17<00:10, 30.92it/s]
Loading safetensors checkpoint shards:  68% Completed | 693/1024 [00:17<00:10, 32.70it/s]
Loading safetensors checkpoint shards:  68% Completed | 697/1024 [00:17<00:09, 33.58it/s]
Loading safetensors checkpoint shards:  68% Completed | 701/1024 [00:17<00:09, 33.48it/s]
Loading safetensors checkpoint shards:  69% Completed | 705/1024 [00:17<00:09, 33.19it/s]
Loading safetensors checkpoint shards:  69% Completed | 709/1024 [00:17<00:10, 30.77it/s]
Loading safetensors checkpoint shards:  70% Completed | 713/1024 [00:17<00:09, 32.57it/s]
Loading safetensors checkpoint shards:  70% Completed | 717/1024 [00:17<00:09, 33.42it/s]
Loading safetensors checkpoint shards:  70% Completed | 721/1024 [00:18<00:09, 32.73it/s]
Loading safetensors checkpoint shards:  71% Completed | 725/1024 [00:18<00:08, 33.86it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:18<00:08, 34.93it/s]
Loading safetensors checkpoint shards:  72% Completed | 733/1024 [00:18<00:08, 33.64it/s]
Loading safetensors checkpoint shards:  72% Completed | 737/1024 [00:18<00:08, 32.59it/s]
Loading safetensors checkpoint shards:  72% Completed | 741/1024 [00:18<00:09, 31.09it/s]
Loading safetensors checkpoint shards:  73% Completed | 746/1024 [00:18<00:08, 33.98it/s]
Loading safetensors checkpoint shards:  73% Completed | 750/1024 [00:18<00:08, 34.12it/s]
Loading safetensors checkpoint shards:  74% Completed | 754/1024 [00:19<00:07, 35.36it/s]
Loading safetensors checkpoint shards:  74% Completed | 759/1024 [00:19<00:07, 37.08it/s]
Loading safetensors checkpoint shards:  75% Completed | 764/1024 [00:19<00:06, 38.15it/s]
Loading safetensors checkpoint shards:  75% Completed | 768/1024 [00:19<00:06, 37.57it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:19<00:06, 36.15it/s]
Loading safetensors checkpoint shards:  76% Completed | 776/1024 [00:19<00:06, 36.88it/s]
Loading safetensors checkpoint shards:  76% Completed | 781/1024 [00:19<00:06, 38.19it/s]
Loading safetensors checkpoint shards:  77% Completed | 786/1024 [00:19<00:06, 38.78it/s]
Loading safetensors checkpoint shards:  77% Completed | 790/1024 [00:19<00:06, 38.00it/s]
Loading safetensors checkpoint shards:  78% Completed | 794/1024 [00:20<00:06, 38.31it/s]
Loading safetensors checkpoint shards:  78% Completed | 798/1024 [00:20<00:05, 38.51it/s]
Loading safetensors checkpoint shards:  78% Completed | 802/1024 [00:20<00:05, 37.68it/s]
Loading safetensors checkpoint shards:  79% Completed | 807/1024 [00:20<00:05, 39.89it/s]
Loading safetensors checkpoint shards:  79% Completed | 811/1024 [00:20<00:05, 39.57it/s]
Loading safetensors checkpoint shards:  80% Completed | 815/1024 [00:20<00:05, 38.10it/s]
Loading safetensors checkpoint shards:  80% Completed | 819/1024 [00:20<00:05, 36.92it/s]
Loading safetensors checkpoint shards:  80% Completed | 824/1024 [00:20<00:05, 37.77it/s]
Loading safetensors checkpoint shards:  81% Completed | 828/1024 [00:20<00:05, 38.23it/s]
Loading safetensors checkpoint shards:  81% Completed | 832/1024 [00:21<00:05, 38.20it/s]
Loading safetensors checkpoint shards:  82% Completed | 836/1024 [00:21<00:04, 38.49it/s]
Loading safetensors checkpoint shards:  82% Completed | 840/1024 [00:21<00:04, 38.52it/s]
Loading safetensors checkpoint shards:  82% Completed | 844/1024 [00:21<00:04, 36.13it/s]
Loading safetensors checkpoint shards:  83% Completed | 848/1024 [00:21<00:04, 35.91it/s]
Loading safetensors checkpoint shards:  83% Completed | 852/1024 [00:21<00:04, 36.75it/s]
Loading safetensors checkpoint shards:  84% Completed | 856/1024 [00:21<00:04, 37.48it/s]
Loading safetensors checkpoint shards:  84% Completed | 860/1024 [00:21<00:04, 36.21it/s]
Loading safetensors checkpoint shards:  84% Completed | 864/1024 [00:21<00:04, 36.76it/s]
Loading safetensors checkpoint shards:  85% Completed | 868/1024 [00:22<00:04, 37.31it/s]
Loading safetensors checkpoint shards:  85% Completed | 872/1024 [00:22<00:04, 37.67it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:22<00:10, 13.70it/s]
Loading safetensors checkpoint shards:  86% Completed | 880/1024 [00:22<00:08, 16.80it/s]
Loading safetensors checkpoint shards:  86% Completed | 884/1024 [00:23<00:06, 20.13it/s]
Loading safetensors checkpoint shards:  87% Completed | 888/1024 [00:23<00:05, 23.61it/s]
Loading safetensors checkpoint shards:  87% Completed | 892/1024 [00:23<00:05, 26.27it/s]
Loading safetensors checkpoint shards:  88% Completed | 897/1024 [00:23<00:04, 29.81it/s]
Loading safetensors checkpoint shards:  88% Completed | 902/1024 [00:23<00:03, 32.90it/s]
Loading safetensors checkpoint shards:  89% Completed | 907/1024 [00:23<00:03, 34.85it/s]
Loading safetensors checkpoint shards:  89% Completed | 912/1024 [00:23<00:03, 36.32it/s]
Loading safetensors checkpoint shards:  90% Completed | 917/1024 [00:23<00:02, 37.76it/s]
Loading safetensors checkpoint shards:  90% Completed | 921/1024 [00:23<00:02, 38.24it/s]
Loading safetensors checkpoint shards:  90% Completed | 925/1024 [00:24<00:02, 37.79it/s]
Loading safetensors checkpoint shards:  91% Completed | 929/1024 [00:24<00:02, 37.82it/s]
Loading safetensors checkpoint shards:  91% Completed | 933/1024 [00:24<00:02, 36.79it/s]
Loading safetensors checkpoint shards:  92% Completed | 937/1024 [00:24<00:02, 37.30it/s]
Loading safetensors checkpoint shards:  92% Completed | 942/1024 [00:24<00:02, 38.73it/s]
Loading safetensors checkpoint shards:  92% Completed | 946/1024 [00:24<00:02, 38.84it/s]
Loading safetensors checkpoint shards:  93% Completed | 950/1024 [00:24<00:01, 39.03it/s]
Loading safetensors checkpoint shards:  93% Completed | 954/1024 [00:24<00:01, 39.22it/s]
Loading safetensors checkpoint shards:  94% Completed | 959/1024 [00:24<00:01, 40.77it/s]
Loading safetensors checkpoint shards:  94% Completed | 964/1024 [00:25<00:01, 40.14it/s]
Loading safetensors checkpoint shards:  95% Completed | 969/1024 [00:25<00:01, 41.14it/s]
Loading safetensors checkpoint shards:  95% Completed | 974/1024 [00:25<00:01, 40.88it/s]
Loading safetensors checkpoint shards:  96% Completed | 979/1024 [00:25<00:01, 41.87it/s]
Loading safetensors checkpoint shards:  97% Completed | 994/1024 [00:25<00:00, 70.95it/s]
Loading safetensors checkpoint shards:  98% Completed | 1005/1024 [00:25<00:00, 79.38it/s]
Loading safetensors checkpoint shards:  99% Completed | 1014/1024 [00:25<00:00, 81.89it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 39.68it/s]

[2025-09-13 07:37:05 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:37:07 TP7] KV Cache is allocated. #tokens: 620313, KV size: 40.60 GB
[2025-09-13 07:37:07 TP3] KV Cache is allocated. #tokens: 620313, KV size: 40.60 GB
[2025-09-13 07:37:07 TP6] KV Cache is allocated. #tokens: 620313, KV size: 40.60 GB
[2025-09-13 07:37:07 TP1] KV Cache is allocated. #tokens: 620313, KV size: 40.60 GB
[2025-09-13 07:37:07 TP5] KV Cache is allocated. #tokens: 620313, KV size: 40.60 GB
[2025-09-13 07:37:07 TP2] KV Cache is allocated. #tokens: 620313, KV size: 40.60 GB
[2025-09-13 07:37:07 TP0] KV Cache is allocated. #tokens: 620313, KV size: 40.60 GB
[2025-09-13 07:37:07 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:37:07 TP4] KV Cache is allocated. #tokens: 620313, KV size: 40.60 GB
[2025-09-13 07:37:07 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:37:08 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.50 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:37:09 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:37:09 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:37:09 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:37:09 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:37:09 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:37:09 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:37:09 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:37:09 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:37:09 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26214.35it/s]
[2025-09-13 07:37:09 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:37:09 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26522.59it/s]
[2025-09-13 07:37:10 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:37:10 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28845.89it/s]
[2025-09-13 07:37:10 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:37:10 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27579.62it/s]
[2025-09-13 07:37:11 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:37:11 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28439.28it/s]
[2025-09-13 07:37:12 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.16 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.12it/s]
[2025-09-13 07:37:15 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:37:15 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:37:15 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:37:15 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:37:15 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:37:15 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:37:15 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:37:15 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:37:15 TP0] Capture cuda graph end. Time elapsed: 7.84 s. mem usage=0.43 GB. avail mem=17.14 GB.
[2025-09-13 07:37:15 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:37:15 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:37:15 TP0] Init torch distributed begin.
[2025-09-13 07:37:15 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:37:15 TP0] Load weight begin. avail mem=17.14 GB
[2025-09-13 07:37:15 TP0] Detected fp8 checkpoint.
[2025-09-13 07:37:15 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 178.58it/s]
Loading safetensors checkpoint shards:   4% Completed | 44/1024 [00:00<00:04, 224.53it/s]
Loading safetensors checkpoint shards:  10% Completed | 104/1024 [00:00<00:02, 394.19it/s]
Loading safetensors checkpoint shards:  16% Completed | 165/1024 [00:00<00:01, 475.72it/s]
Loading safetensors checkpoint shards:  22% Completed | 225/1024 [00:00<00:01, 516.99it/s]
Loading safetensors checkpoint shards:  28% Completed | 286/1024 [00:00<00:01, 546.00it/s]
Loading safetensors checkpoint shards:  34% Completed | 345/1024 [00:00<00:01, 558.64it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:00<00:01, 571.74it/s]
Loading safetensors checkpoint shards:  45% Completed | 465/1024 [00:00<00:00, 575.27it/s]
Loading safetensors checkpoint shards:  51% Completed | 525/1024 [00:01<00:00, 582.08it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:01<00:00, 586.42it/s]
Loading safetensors checkpoint shards:  63% Completed | 644/1024 [00:01<00:00, 579.42it/s]
Loading safetensors checkpoint shards:  69% Completed | 702/1024 [00:01<00:00, 576.80it/s]
Loading safetensors checkpoint shards:  74% Completed | 760/1024 [00:01<00:00, 567.55it/s]
Loading safetensors checkpoint shards:  80% Completed | 817/1024 [00:01<00:00, 565.22it/s]
Loading safetensors checkpoint shards:  85% Completed | 874/1024 [00:01<00:00, 561.44it/s]
Loading safetensors checkpoint shards:  91% Completed | 931/1024 [00:01<00:00, 559.58it/s]
Loading safetensors checkpoint shards:  96% Completed | 987/1024 [00:01<00:00, 514.22it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 495.36it/s]

[2025-09-13 07:37:18 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.15 GB, mem usage=1.99 GB.
[2025-09-13 07:37:18 TP2] KV Cache is allocated. #tokens: 620313, KV size: 0.67 GB
[2025-09-13 07:37:18 TP4] KV Cache is allocated. #tokens: 620313, KV size: 0.67 GB
[2025-09-13 07:37:18 TP5] KV Cache is allocated. #tokens: 620313, KV size: 0.67 GB
[2025-09-13 07:37:18 TP0] KV Cache is allocated. #tokens: 620313, KV size: 0.67 GB
[2025-09-13 07:37:18 TP3] KV Cache is allocated. #tokens: 620313, KV size: 0.67 GB
[2025-09-13 07:37:18 TP0] Memory pool end. avail mem=14.48 GB
[2025-09-13 07:37:18 TP7] KV Cache is allocated. #tokens: 620313, KV size: 0.67 GB
[2025-09-13 07:37:18 TP1] KV Cache is allocated. #tokens: 620313, KV size: 0.67 GB
[2025-09-13 07:37:18 TP6] KV Cache is allocated. #tokens: 620313, KV size: 0.67 GB
[2025-09-13 07:37:18 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:37:18 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:37:18 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:37:18 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:37:18 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.11 GB
[2025-09-13 07:37:18 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:37:18 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:37:18 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
Capturing batches (bs=1 avail_mem=14.45 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.43it/s]
[2025-09-13 07:37:24 TP2] Registering 96 cuda graph addresses
[2025-09-13 07:37:24 TP0] Registering 96 cuda graph addresses
[2025-09-13 07:37:24 TP3] Registering 96 cuda graph addresses
[2025-09-13 07:37:24 TP5] Registering 96 cuda graph addresses
[2025-09-13 07:37:24 TP1] Registering 96 cuda graph addresses
[2025-09-13 07:37:24 TP6] Registering 96 cuda graph addresses
[2025-09-13 07:37:24 TP4] Registering 96 cuda graph addresses
[2025-09-13 07:37:24 TP7] Registering 96 cuda graph addresses
[2025-09-13 07:37:24 TP1] Capture draft cuda graph end. Time elapsed: 6.29 s. mem usage=0.47 GB. avail mem=14.40 GB.
[2025-09-13 07:37:24 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.40 GB
[2025-09-13 07:37:24 TP0] Capture draft cuda graph end. Time elapsed: 6.29 s. mem usage=0.47 GB. avail mem=14.44 GB.
[2025-09-13 07:37:24 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
[2025-09-13 07:37:24 TP3] Capture draft cuda graph end. Time elapsed: 6.29 s. mem usage=0.47 GB. avail mem=14.40 GB.
[2025-09-13 07:37:24 TP2] Capture draft cuda graph end. Time elapsed: 6.29 s. mem usage=0.47 GB. avail mem=14.40 GB.
[2025-09-13 07:37:24 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.40 GB
[2025-09-13 07:37:24 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.40 GB
[2025-09-13 07:37:24 TP7] Capture draft cuda graph end. Time elapsed: 6.29 s. mem usage=0.47 GB. avail mem=14.64 GB.
[2025-09-13 07:37:24 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.64 GB
[2025-09-13 07:37:24 TP6] Capture draft cuda graph end. Time elapsed: 6.29 s. mem usage=0.47 GB. avail mem=14.40 GB.
[2025-09-13 07:37:24 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.40 GB
[2025-09-13 07:37:24 TP5] Capture draft cuda graph end. Time elapsed: 6.29 s. mem usage=0.47 GB. avail mem=14.40 GB.
[2025-09-13 07:37:24 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.40 GB
[2025-09-13 07:37:24 TP4] Capture draft cuda graph end. Time elapsed: 6.29 s. mem usage=0.47 GB. avail mem=14.40 GB.
[2025-09-13 07:37:24 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.40 GB
Capturing batches (bs=1 avail_mem=14.26 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 19.95it/s]
[2025-09-13 07:37:25 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:37:25 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:37:25 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:37:25 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:37:25 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:37:25 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:37:25 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:37:25 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:37:26 TP2] Capture draft extend cuda graph end. Time elapsed: 1.16 s. mem usage=0.19 GB. avail mem=14.21 GB.
[2025-09-13 07:37:26 TP5] Capture draft extend cuda graph end. Time elapsed: 1.16 s. mem usage=0.19 GB. avail mem=14.21 GB.
[2025-09-13 07:37:26 TP3] Capture draft extend cuda graph end. Time elapsed: 1.16 s. mem usage=0.19 GB. avail mem=14.21 GB.
[2025-09-13 07:37:26 TP1] Capture draft extend cuda graph end. Time elapsed: 1.17 s. mem usage=0.19 GB. avail mem=14.21 GB.
[2025-09-13 07:37:26 TP6] Capture draft extend cuda graph end. Time elapsed: 1.16 s. mem usage=0.19 GB. avail mem=14.21 GB.
[2025-09-13 07:37:26 TP0] Capture draft extend cuda graph end. Time elapsed: 1.16 s. mem usage=0.19 GB. avail mem=14.25 GB.
[2025-09-13 07:37:26 TP0] max_total_num_tokens=620313, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.25 GB
[2025-09-13 07:37:26 TP4] Capture draft extend cuda graph end. Time elapsed: 1.16 s. mem usage=0.19 GB. avail mem=14.21 GB.
[2025-09-13 07:37:26 TP7] Capture draft extend cuda graph end. Time elapsed: 1.16 s. mem usage=0.19 GB. avail mem=14.45 GB.
[2025-09-13 07:37:26] INFO:     Started server process [318533]
[2025-09-13 07:37:26] INFO:     Waiting for application startup.
[2025-09-13 07:37:26] INFO:     Application startup complete.
[2025-09-13 07:37:26] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:37:26] INFO:     127.0.0.1:40796 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:37:27] INFO:     127.0.0.1:40802 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:37:27 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:37:27 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:37:27 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 29014.45it/s]
[2025-09-13 07:37:28] INFO:     127.0.0.1:40814 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:28] The server is fired up and ready to roll!
[2025-09-13 07:37:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:37:37] INFO:     127.0.0.1:38432 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:37:38] INFO:     127.0.0.1:59912 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:38 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:37:39] INFO:     127.0.0.1:59914 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:39] INFO:     127.0.0.1:59916 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:37:39] INFO:     127.0.0.1:59922 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:39] INFO:     127.0.0.1:59936 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:39] INFO:     127.0.0.1:59948 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:39] INFO:     127.0.0.1:59954 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:39] INFO:     127.0.0.1:59966 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:39] INFO:     127.0.0.1:59982 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:39 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:37:40 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:37:40 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:37:40 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:37:40 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:37:40 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:37:40 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:37:40 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:37:40 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:37:40 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:37:41 TP0] Decode batch. #running-req: 8, #token: 14658, token usage: 0.02, accept len: 3.35, cuda graph: True, gen throughput (token/s): 49.95, #queue-req: 0, 
[2025-09-13 07:37:42 TP0] Decode batch. #running-req: 8, #token: 15938, token usage: 0.03, accept len: 4.00, cuda graph: True, gen throughput (token/s): 885.79, #queue-req: 0, 
[2025-09-13 07:37:44 TP0] Decode batch. #running-req: 8, #token: 17281, token usage: 0.03, accept len: 4.20, cuda graph: True, gen throughput (token/s): 927.26, #queue-req: 0, 
 62%|█████████████████████████████████████████████████████████████████████████████████▉                                                 | 5/8 [00:05<00:01,  1.65it/s][2025-09-13 07:37:45 TP0] Decode batch. #running-req: 2, #token: 5796, token usage: 0.01, accept len: 4.02, cuda graph: True, gen throughput (token/s): 477.63, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.27it/s]
[2025-09-13 07:37:46] INFO:     127.0.0.1:59988 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.30      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4071      
Request throughput (req/s):              1.27      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         650.16    
Total token throughput (tok/s):          650.16    
Concurrency:                             6.93      
Accept length:                           3.92      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5461.11   
Median E2E Latency (ms):                 5393.62   
---------------Time to First Token----------------
Mean TTFT (ms):                          610.04    
Median TTFT (ms):                        721.55    
P99 TTFT (ms):                           722.05    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.49      
Median ITL (ms):                         7.10      
P95 ITL (ms):                            18.14     
P99 ITL (ms):                            36.21     
Max ITL (ms):                            736.47    
==================================================
[2025-09-13 07:37:46] INFO:     127.0.0.1:59994 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:37:46] INFO:     127.0.0.1:60004 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:37:47] INFO:     127.0.0.1:60010 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:47] INFO:     127.0.0.1:60018 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:37:47] INFO:     127.0.0.1:60030 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:47] INFO:     127.0.0.1:60044 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:47] INFO:     127.0.0.1:60058 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:47] INFO:     127.0.0.1:60062 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:47] INFO:     127.0.0.1:60076 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:47] INFO:     127.0.0.1:60090 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:47 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:37:48 TP0] Decode batch. #running-req: 8, #token: 14418, token usage: 0.02, accept len: 3.29, cuda graph: True, gen throughput (token/s): 229.34, #queue-req: 0, 
[2025-09-13 07:37:49 TP0] Decode batch. #running-req: 8, #token: 15650, token usage: 0.03, accept len: 3.85, cuda graph: True, gen throughput (token/s): 855.25, #queue-req: 0, 
[2025-09-13 07:37:51 TP0] Decode batch. #running-req: 8, #token: 17019, token usage: 0.03, accept len: 4.28, cuda graph: True, gen throughput (token/s): 937.06, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:03,  4.26s/it][2025-09-13 07:37:51] INFO:     127.0.0.1:34958 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:51 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:27,  1.99s/it][2025-09-13 07:37:52] INFO:     127.0.0.1:34970 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:16,  1.30s/it][2025-09-13 07:37:52] INFO:     127.0.0.1:34976 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:52 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.15it/s][2025-09-13 07:37:52] INFO:     127.0.0.1:34982 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:52 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:37:52] INFO:     127.0.0.1:34988 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:52 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:04,  2.17it/s][2025-09-13 07:37:52] INFO:     127.0.0.1:35004 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:53 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:37:53 TP0] Decode batch. #running-req: 8, #token: 12677, token usage: 0.02, accept len: 4.02, cuda graph: True, gen throughput (token/s): 524.88, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:05,  1.64it/s][2025-09-13 07:37:53] INFO:     127.0.0.1:35012 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:04,  1.87it/s][2025-09-13 07:37:54] INFO:     127.0.0.1:35014 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:37:54 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:37:55 TP0] Decode batch. #running-req: 8, #token: 14820, token usage: 0.02, accept len: 3.37, cuda graph: True, gen throughput (token/s): 594.52, #queue-req: 0, 
[2025-09-13 07:37:56 TP0] Decode batch. #running-req: 8, #token: 16033, token usage: 0.03, accept len: 3.79, cuda graph: True, gen throughput (token/s): 832.01, #queue-req: 0, 
 75%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                | 12/16 [00:10<00:02,  1.45it/s][2025-09-13 07:37:58 TP0] Decode batch. #running-req: 3, #token: 8731, token usage: 0.01, accept len: 4.55, cuda graph: True, gen throughput (token/s): 906.25, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.39it/s]
[2025-09-13 07:37:58] INFO:     127.0.0.1:44150 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.53     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8098      
Request throughput (req/s):              1.39      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         710.19    
Total token throughput (tok/s):          710.19    
Concurrency:                             7.60      
Accept length:                           3.91      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5476.47   
Median E2E Latency (ms):                 5409.25   
---------------Time to First Token----------------
Mean TTFT (ms):                          248.23    
Median TTFT (ms):                        288.15    
P99 TTFT (ms):                           348.41    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.23     
Median ITL (ms):                         7.23      
P95 ITL (ms):                            27.76     
P99 ITL (ms):                            45.27     
Max ITL (ms):                            292.42    
==================================================
[2025-09-13 07:37:58] INFO:     127.0.0.1:44166 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=34: batch_size=8, steps=5, topk=4, num_draft_tokens=12, speed=108.09 token/s, step_time=36.18 ms
Start i=35: batch_size=8, steps=6, topk=1, num_draft_tokens=4
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 6 --speculative-eagle-topk 1 --speculative-num-draft-tokens 4 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:38:09.614000 324256 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:38:09.614000 324256 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
WARNING:sglang.srt.server_args:speculative_num_draft_tokens is adjusted to speculative_num_steps + 1 when speculative_eagle_topk == 1
[2025-09-13 07:38:09] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=320397239, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=6, speculative_eagle_topk=1, speculative_num_draft_tokens=7, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:38:10] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:38:18.872000 324631 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:38:18.872000 324631 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:38:18.983000 324628 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:38:18.983000 324628 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:38:19.127000 324629 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:38:19.127000 324629 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:38:19.156000 324630 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:38:19.156000 324630 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:38:19.157000 324632 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:38:19.157000 324632 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:38:19.159000 324634 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:38:19.159000 324634 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:38:19.220000 324627 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:38:19.220000 324627 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:38:19.235000 324633 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:38:19.235000 324633 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:38:19.291000 324626 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:38:19.291000 324626 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:38:19 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:38:19 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:38:19 TP0] Init torch distributed begin.
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:38:21 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:38:24 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:38:26 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:38:26 TP0] Detected fp8 checkpoint.
[2025-09-13 07:38:26 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:03, 249.59it/s]
Loading safetensors checkpoint shards:   5% Completed | 51/1024 [00:00<00:13, 72.99it/s]
Loading safetensors checkpoint shards:   6% Completed | 65/1024 [00:00<00:15, 62.23it/s]
Loading safetensors checkpoint shards:   7% Completed | 75/1024 [00:01<00:15, 60.41it/s]
Loading safetensors checkpoint shards:   8% Completed | 83/1024 [00:01<00:15, 59.71it/s]
Loading safetensors checkpoint shards:   9% Completed | 91/1024 [00:01<00:17, 52.48it/s]
Loading safetensors checkpoint shards:   9% Completed | 97/1024 [00:01<00:20, 45.55it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:02<00:35, 26.09it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:02<00:32, 28.64it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:31, 29.30it/s]
Loading safetensors checkpoint shards:  11% Completed | 116/1024 [00:02<00:28, 32.25it/s]
Loading safetensors checkpoint shards:  12% Completed | 121/1024 [00:02<00:25, 35.25it/s]
Loading safetensors checkpoint shards:  12% Completed | 127/1024 [00:02<00:23, 38.78it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:02<00:23, 38.23it/s]
Loading safetensors checkpoint shards:  13% Completed | 137/1024 [00:02<00:21, 40.82it/s]
Loading safetensors checkpoint shards:  14% Completed | 142/1024 [00:03<00:20, 42.55it/s]
Loading safetensors checkpoint shards:  14% Completed | 147/1024 [00:03<00:20, 42.36it/s]
Loading safetensors checkpoint shards:  15% Completed | 152/1024 [00:03<00:20, 42.75it/s]
Loading safetensors checkpoint shards:  15% Completed | 157/1024 [00:03<00:20, 42.34it/s]
Loading safetensors checkpoint shards:  16% Completed | 162/1024 [00:03<00:19, 44.18it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:03<00:20, 42.84it/s]
Loading safetensors checkpoint shards:  17% Completed | 172/1024 [00:03<00:19, 44.46it/s]
Loading safetensors checkpoint shards:  17% Completed | 177/1024 [00:03<00:19, 43.93it/s]
Loading safetensors checkpoint shards:  18% Completed | 182/1024 [00:04<00:18, 44.58it/s]
Loading safetensors checkpoint shards:  18% Completed | 187/1024 [00:04<00:19, 43.85it/s]
Loading safetensors checkpoint shards:  19% Completed | 192/1024 [00:04<00:18, 43.93it/s]
Loading safetensors checkpoint shards:  19% Completed | 198/1024 [00:04<00:17, 46.17it/s]
Loading safetensors checkpoint shards:  20% Completed | 203/1024 [00:04<00:18, 44.70it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:04<00:17, 46.43it/s]
Loading safetensors checkpoint shards:  21% Completed | 214/1024 [00:04<00:17, 45.86it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:04<00:17, 46.60it/s]
Loading safetensors checkpoint shards:  22% Completed | 224/1024 [00:04<00:17, 46.07it/s]
Loading safetensors checkpoint shards:  22% Completed | 229/1024 [00:05<00:17, 46.12it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:05<00:17, 44.79it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:05<00:16, 46.59it/s]
Loading safetensors checkpoint shards:  24% Completed | 245/1024 [00:05<00:17, 45.70it/s]
Loading safetensors checkpoint shards:  25% Completed | 251/1024 [00:05<00:16, 47.26it/s]
Loading safetensors checkpoint shards:  25% Completed | 256/1024 [00:05<00:16, 46.71it/s]
Loading safetensors checkpoint shards:  25% Completed | 261/1024 [00:05<00:16, 47.18it/s]
Loading safetensors checkpoint shards:  26% Completed | 266/1024 [00:05<00:16, 45.53it/s]
Loading safetensors checkpoint shards:  27% Completed | 272/1024 [00:05<00:16, 46.30it/s]
Loading safetensors checkpoint shards:  27% Completed | 277/1024 [00:06<00:17, 43.22it/s]
Loading safetensors checkpoint shards:  28% Completed | 282/1024 [00:06<00:16, 44.73it/s]
Loading safetensors checkpoint shards:  28% Completed | 287/1024 [00:06<00:17, 43.33it/s]
Loading safetensors checkpoint shards:  29% Completed | 292/1024 [00:06<00:17, 41.00it/s]
Loading safetensors checkpoint shards:  29% Completed | 297/1024 [00:06<00:34, 20.84it/s]
Loading safetensors checkpoint shards:  29% Completed | 302/1024 [00:07<00:29, 24.47it/s]
Loading safetensors checkpoint shards:  30% Completed | 307/1024 [00:07<00:25, 28.03it/s]
Loading safetensors checkpoint shards:  30% Completed | 312/1024 [00:07<00:22, 31.13it/s]
Loading safetensors checkpoint shards:  31% Completed | 317/1024 [00:07<00:20, 34.88it/s]
Loading safetensors checkpoint shards:  31% Completed | 322/1024 [00:07<00:19, 35.85it/s]
Loading safetensors checkpoint shards:  32% Completed | 327/1024 [00:07<00:18, 38.00it/s]
Loading safetensors checkpoint shards:  32% Completed | 332/1024 [00:07<00:18, 38.08it/s]
Loading safetensors checkpoint shards:  33% Completed | 337/1024 [00:07<00:17, 40.28it/s]
Loading safetensors checkpoint shards:  33% Completed | 342/1024 [00:08<00:17, 39.39it/s]
Loading safetensors checkpoint shards:  34% Completed | 347/1024 [00:08<00:18, 36.97it/s]
Loading safetensors checkpoint shards:  34% Completed | 352/1024 [00:08<00:17, 38.51it/s]
Loading safetensors checkpoint shards:  35% Completed | 356/1024 [00:08<00:17, 38.64it/s]
Loading safetensors checkpoint shards:  35% Completed | 361/1024 [00:08<00:16, 40.71it/s]
Loading safetensors checkpoint shards:  36% Completed | 366/1024 [00:08<00:16, 39.67it/s]
Loading safetensors checkpoint shards:  36% Completed | 371/1024 [00:08<00:15, 41.95it/s]
Loading safetensors checkpoint shards:  37% Completed | 376/1024 [00:08<00:15, 42.01it/s]
Loading safetensors checkpoint shards:  37% Completed | 381/1024 [00:09<00:15, 40.86it/s]
Loading safetensors checkpoint shards:  38% Completed | 386/1024 [00:09<00:14, 43.03it/s]
Loading safetensors checkpoint shards:  38% Completed | 391/1024 [00:09<00:14, 43.14it/s]
Loading safetensors checkpoint shards:  39% Completed | 396/1024 [00:09<00:14, 43.80it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:09<00:15, 41.07it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:09<00:14, 41.99it/s]
Loading safetensors checkpoint shards:  40% Completed | 411/1024 [00:09<00:14, 41.00it/s]
Loading safetensors checkpoint shards:  41% Completed | 416/1024 [00:09<00:14, 42.04it/s]
Loading safetensors checkpoint shards:  41% Completed | 421/1024 [00:09<00:15, 39.64it/s]
Loading safetensors checkpoint shards:  42% Completed | 426/1024 [00:10<00:14, 40.29it/s]
Loading safetensors checkpoint shards:  42% Completed | 431/1024 [00:10<00:15, 38.84it/s]
Loading safetensors checkpoint shards:  42% Completed | 435/1024 [00:10<00:15, 37.73it/s]
Loading safetensors checkpoint shards:  43% Completed | 440/1024 [00:10<00:14, 39.61it/s]
Loading safetensors checkpoint shards:  43% Completed | 445/1024 [00:10<00:14, 39.68it/s]
Loading safetensors checkpoint shards:  44% Completed | 449/1024 [00:10<00:14, 39.68it/s]
Loading safetensors checkpoint shards:  44% Completed | 453/1024 [00:10<00:14, 38.30it/s]
Loading safetensors checkpoint shards:  45% Completed | 458/1024 [00:10<00:14, 39.35it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:11<00:13, 41.35it/s]
Loading safetensors checkpoint shards:  46% Completed | 468/1024 [00:11<00:13, 42.02it/s]
Loading safetensors checkpoint shards:  46% Completed | 474/1024 [00:11<00:11, 46.53it/s]
Loading safetensors checkpoint shards:  47% Completed | 479/1024 [00:11<00:11, 46.24it/s]
Loading safetensors checkpoint shards:  47% Completed | 485/1024 [00:11<00:11, 46.98it/s]
Loading safetensors checkpoint shards:  48% Completed | 490/1024 [00:11<00:11, 44.80it/s]
Loading safetensors checkpoint shards:  48% Completed | 495/1024 [00:11<00:11, 45.84it/s]
Loading safetensors checkpoint shards:  49% Completed | 500/1024 [00:11<00:12, 43.55it/s]
Loading safetensors checkpoint shards:  49% Completed | 505/1024 [00:11<00:11, 43.81it/s]
Loading safetensors checkpoint shards:  50% Completed | 510/1024 [00:12<00:12, 42.05it/s]
Loading safetensors checkpoint shards:  50% Completed | 516/1024 [00:12<00:11, 44.14it/s]
Loading safetensors checkpoint shards:  51% Completed | 521/1024 [00:12<00:11, 42.47it/s]
Loading safetensors checkpoint shards:  51% Completed | 526/1024 [00:12<00:11, 44.27it/s]
Loading safetensors checkpoint shards:  52% Completed | 531/1024 [00:12<00:11, 43.65it/s]
Loading safetensors checkpoint shards:  52% Completed | 536/1024 [00:12<00:11, 42.20it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:12<00:11, 43.76it/s]
Loading safetensors checkpoint shards:  53% Completed | 546/1024 [00:13<00:26, 17.74it/s]
Loading safetensors checkpoint shards:  54% Completed | 551/1024 [00:13<00:21, 21.75it/s]
Loading safetensors checkpoint shards:  54% Completed | 555/1024 [00:13<00:19, 24.57it/s]
Loading safetensors checkpoint shards:  55% Completed | 560/1024 [00:13<00:16, 28.28it/s]
Loading safetensors checkpoint shards:  55% Completed | 564/1024 [00:13<00:15, 30.55it/s]
Loading safetensors checkpoint shards:  55% Completed | 568/1024 [00:14<00:13, 32.57it/s]
Loading safetensors checkpoint shards:  56% Completed | 573/1024 [00:14<00:12, 35.97it/s]
Loading safetensors checkpoint shards:  56% Completed | 578/1024 [00:14<00:12, 36.02it/s]
Loading safetensors checkpoint shards:  57% Completed | 584/1024 [00:14<00:11, 39.93it/s]
Loading safetensors checkpoint shards:  58% Completed | 589/1024 [00:14<00:10, 40.16it/s]
Loading safetensors checkpoint shards:  58% Completed | 594/1024 [00:14<00:10, 40.18it/s]
Loading safetensors checkpoint shards:  58% Completed | 599/1024 [00:14<00:10, 38.69it/s]
Loading safetensors checkpoint shards:  59% Completed | 603/1024 [00:14<00:10, 38.33it/s]
Loading safetensors checkpoint shards:  59% Completed | 607/1024 [00:14<00:10, 38.60it/s]
Loading safetensors checkpoint shards:  60% Completed | 611/1024 [00:15<00:10, 38.55it/s]
Loading safetensors checkpoint shards:  60% Completed | 616/1024 [00:15<00:09, 41.33it/s]
Loading safetensors checkpoint shards:  61% Completed | 621/1024 [00:15<00:09, 41.60it/s]
Loading safetensors checkpoint shards:  61% Completed | 626/1024 [00:15<00:09, 42.05it/s]
Loading safetensors checkpoint shards:  62% Completed | 631/1024 [00:15<00:09, 39.70it/s]
Loading safetensors checkpoint shards:  62% Completed | 636/1024 [00:15<00:10, 38.64it/s]
Loading safetensors checkpoint shards:  62% Completed | 640/1024 [00:15<00:10, 37.99it/s]
Loading safetensors checkpoint shards:  63% Completed | 644/1024 [00:15<00:10, 37.02it/s]
Loading safetensors checkpoint shards:  63% Completed | 649/1024 [00:16<00:09, 39.41it/s]
Loading safetensors checkpoint shards:  64% Completed | 654/1024 [00:16<00:08, 41.24it/s]
Loading safetensors checkpoint shards:  64% Completed | 659/1024 [00:16<00:09, 40.24it/s]
Loading safetensors checkpoint shards:  65% Completed | 664/1024 [00:16<00:08, 41.73it/s]
Loading safetensors checkpoint shards:  66% Completed | 671/1024 [00:16<00:07, 47.87it/s]
Loading safetensors checkpoint shards:  66% Completed | 676/1024 [00:16<00:07, 47.72it/s]
Loading safetensors checkpoint shards:  67% Completed | 681/1024 [00:16<00:07, 47.25it/s]
Loading safetensors checkpoint shards:  67% Completed | 686/1024 [00:16<00:07, 46.01it/s]
Loading safetensors checkpoint shards:  67% Completed | 691/1024 [00:16<00:07, 42.84it/s]
Loading safetensors checkpoint shards:  68% Completed | 696/1024 [00:17<00:07, 43.34it/s]
Loading safetensors checkpoint shards:  68% Completed | 701/1024 [00:17<00:08, 37.26it/s]
Loading safetensors checkpoint shards:  69% Completed | 705/1024 [00:17<00:08, 37.17it/s]
Loading safetensors checkpoint shards:  69% Completed | 709/1024 [00:17<00:08, 36.11it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:17<00:08, 38.16it/s]
Loading safetensors checkpoint shards:  70% Completed | 718/1024 [00:17<00:08, 37.26it/s]
Loading safetensors checkpoint shards:  71% Completed | 722/1024 [00:17<00:08, 37.25it/s]
Loading safetensors checkpoint shards:  71% Completed | 728/1024 [00:17<00:06, 42.83it/s]
Loading safetensors checkpoint shards:  72% Completed | 733/1024 [00:18<00:06, 44.13it/s]
Loading safetensors checkpoint shards:  72% Completed | 739/1024 [00:18<00:06, 47.19it/s]
Loading safetensors checkpoint shards:  73% Completed | 744/1024 [00:18<00:06, 44.52it/s]
Loading safetensors checkpoint shards:  73% Completed | 749/1024 [00:18<00:06, 42.66it/s]
Loading safetensors checkpoint shards:  74% Completed | 754/1024 [00:18<00:06, 41.11it/s]
Loading safetensors checkpoint shards:  74% Completed | 759/1024 [00:18<00:06, 40.18it/s]
Loading safetensors checkpoint shards:  75% Completed | 764/1024 [00:18<00:06, 38.77it/s]
Loading safetensors checkpoint shards:  75% Completed | 768/1024 [00:18<00:07, 35.69it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:19<00:07, 33.94it/s]
Loading safetensors checkpoint shards:  76% Completed | 776/1024 [00:19<00:07, 33.70it/s]
Loading safetensors checkpoint shards:  76% Completed | 780/1024 [00:19<00:17, 13.78it/s]
Loading safetensors checkpoint shards:  77% Completed | 784/1024 [00:20<00:14, 16.89it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:20<00:12, 18.61it/s]
Loading safetensors checkpoint shards:  77% Completed | 792/1024 [00:20<00:09, 23.57it/s]
Loading safetensors checkpoint shards:  78% Completed | 796/1024 [00:20<00:08, 26.23it/s]
Loading safetensors checkpoint shards:  78% Completed | 801/1024 [00:20<00:07, 30.58it/s]
Loading safetensors checkpoint shards:  79% Completed | 806/1024 [00:20<00:06, 34.25it/s]
Loading safetensors checkpoint shards:  79% Completed | 811/1024 [00:20<00:05, 36.78it/s]
Loading safetensors checkpoint shards:  80% Completed | 816/1024 [00:20<00:05, 37.75it/s]
Loading safetensors checkpoint shards:  80% Completed | 821/1024 [00:20<00:05, 38.62it/s]
Loading safetensors checkpoint shards:  81% Completed | 826/1024 [00:21<00:04, 40.35it/s]
Loading safetensors checkpoint shards:  81% Completed | 831/1024 [00:21<00:04, 41.92it/s]
Loading safetensors checkpoint shards:  82% Completed | 836/1024 [00:21<00:04, 43.33it/s]
Loading safetensors checkpoint shards:  82% Completed | 841/1024 [00:21<00:04, 44.16it/s]
Loading safetensors checkpoint shards:  83% Completed | 846/1024 [00:21<00:04, 43.36it/s]
Loading safetensors checkpoint shards:  83% Completed | 851/1024 [00:21<00:03, 43.26it/s]
Loading safetensors checkpoint shards:  84% Completed | 856/1024 [00:21<00:03, 43.31it/s]
Loading safetensors checkpoint shards:  84% Completed | 861/1024 [00:21<00:03, 42.53it/s]
Loading safetensors checkpoint shards:  85% Completed | 866/1024 [00:21<00:03, 42.88it/s]
Loading safetensors checkpoint shards:  85% Completed | 871/1024 [00:22<00:03, 43.60it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:22<00:03, 42.33it/s]
Loading safetensors checkpoint shards:  86% Completed | 881/1024 [00:22<00:03, 42.79it/s]
Loading safetensors checkpoint shards:  87% Completed | 886/1024 [00:22<00:03, 42.16it/s]
Loading safetensors checkpoint shards:  87% Completed | 891/1024 [00:22<00:03, 40.60it/s]
Loading safetensors checkpoint shards:  88% Completed | 896/1024 [00:22<00:03, 40.72it/s]
Loading safetensors checkpoint shards:  88% Completed | 901/1024 [00:22<00:02, 41.56it/s]
Loading safetensors checkpoint shards:  88% Completed | 906/1024 [00:22<00:02, 42.31it/s]
Loading safetensors checkpoint shards:  89% Completed | 911/1024 [00:23<00:02, 42.64it/s]
Loading safetensors checkpoint shards:  89% Completed | 916/1024 [00:23<00:02, 43.57it/s]
Loading safetensors checkpoint shards:  90% Completed | 921/1024 [00:23<00:02, 43.06it/s]
Loading safetensors checkpoint shards:  90% Completed | 926/1024 [00:23<00:02, 42.72it/s]
Loading safetensors checkpoint shards:  91% Completed | 931/1024 [00:23<00:02, 40.99it/s]
Loading safetensors checkpoint shards:  91% Completed | 936/1024 [00:23<00:02, 39.87it/s]
Loading safetensors checkpoint shards:  92% Completed | 941/1024 [00:23<00:02, 39.76it/s]
Loading safetensors checkpoint shards:  92% Completed | 945/1024 [00:23<00:02, 39.39it/s]
Loading safetensors checkpoint shards:  93% Completed | 949/1024 [00:23<00:01, 39.35it/s]
Loading safetensors checkpoint shards:  93% Completed | 953/1024 [00:24<00:01, 39.42it/s]
Loading safetensors checkpoint shards:  93% Completed | 957/1024 [00:24<00:01, 38.72it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:24<00:01, 37.30it/s]
Loading safetensors checkpoint shards:  94% Completed | 966/1024 [00:24<00:01, 38.74it/s]
Loading safetensors checkpoint shards:  95% Completed | 970/1024 [00:24<00:01, 37.98it/s]
Loading safetensors checkpoint shards:  95% Completed | 975/1024 [00:24<00:01, 39.58it/s]
Loading safetensors checkpoint shards:  96% Completed | 980/1024 [00:24<00:01, 40.48it/s]
Loading safetensors checkpoint shards:  98% Completed | 1001/1024 [00:24<00:00, 86.30it/s]
Loading safetensors checkpoint shards:  99% Completed | 1011/1024 [00:24<00:00, 84.56it/s]
Loading safetensors checkpoint shards: 100% Completed | 1023/1024 [00:25<00:00, 93.99it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 40.83it/s]

[2025-09-13 07:38:51 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:38:54 TP5] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 07:38:54 TP1] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 07:38:54 TP4] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 07:38:54 TP3] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 07:38:54 TP6] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 07:38:54 TP2] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 07:38:54 TP0] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 07:38:54 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:38:54 TP7] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 07:38:55 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:38:55 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.52 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:38:56 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:38:56 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:38:56 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:38:56 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:38:56 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:38:56 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:38:56 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:38:56 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:38:56 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26354.32it/s]
[2025-09-13 07:38:56 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:38:56 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27403.98it/s]
[2025-09-13 07:38:57 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:38:57 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28967.51it/s]
[2025-09-13 07:38:58 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:38:58 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28299.17it/s]
[2025-09-13 07:38:58 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:38:58 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 29156.29it/s]
[2025-09-13 07:38:59 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.23 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:07<00:00,  1.56it/s][2025-09-13 07:39:03 TP1] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.23 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.08it/s]
[2025-09-13 07:39:03 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:39:03 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:39:03 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:39:03 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:39:03 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:39:03 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:39:03 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:39:03 TP0] Capture cuda graph end. Time elapsed: 8.08 s. mem usage=0.35 GB. avail mem=17.22 GB.
[2025-09-13 07:39:03 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:39:03 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:39:03 TP0] Init torch distributed begin.
[2025-09-13 07:39:03 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:39:03 TP0] Load weight begin. avail mem=17.22 GB
[2025-09-13 07:39:03 TP0] Detected fp8 checkpoint.
[2025-09-13 07:39:03 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 17/1024 [00:00<00:06, 165.85it/s]
Loading safetensors checkpoint shards:   3% Completed | 35/1024 [00:00<00:05, 172.64it/s]
Loading safetensors checkpoint shards:   9% Completed | 96/1024 [00:00<00:02, 367.88it/s]
Loading safetensors checkpoint shards:  15% Completed | 158/1024 [00:00<00:01, 464.10it/s]
Loading safetensors checkpoint shards:  21% Completed | 220/1024 [00:00<00:01, 519.06it/s]
Loading safetensors checkpoint shards:  28% Completed | 283/1024 [00:00<00:01, 554.53it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:00<00:01, 575.84it/s]
Loading safetensors checkpoint shards:  40% Completed | 411/1024 [00:00<00:01, 596.44it/s]
Loading safetensors checkpoint shards:  46% Completed | 473/1024 [00:00<00:00, 602.00it/s]
Loading safetensors checkpoint shards:  52% Completed | 534/1024 [00:01<00:00, 597.87it/s]
Loading safetensors checkpoint shards:  58% Completed | 594/1024 [00:01<00:00, 597.82it/s]
Loading safetensors checkpoint shards:  64% Completed | 654/1024 [00:01<00:00, 596.60it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:01<00:00, 594.30it/s]
Loading safetensors checkpoint shards:  76% Completed | 774/1024 [00:01<00:00, 591.23it/s]
Loading safetensors checkpoint shards:  81% Completed | 834/1024 [00:01<00:00, 591.20it/s]
Loading safetensors checkpoint shards:  87% Completed | 894/1024 [00:01<00:00, 588.04it/s]
Loading safetensors checkpoint shards:  93% Completed | 953/1024 [00:01<00:00, 586.74it/s]
Loading safetensors checkpoint shards:  99% Completed | 1012/1024 [00:01<00:00, 389.49it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 501.83it/s]

[2025-09-13 07:39:05 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.24 GB, mem usage=1.98 GB.
[2025-09-13 07:39:05 TP7] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 07:39:05 TP6] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 07:39:05 TP2] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 07:39:05 TP3] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 07:39:05 TP4] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 07:39:05 TP5] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 07:39:05 TP0] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 07:39:05 TP1] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 07:39:05 TP0] Memory pool end. avail mem=14.57 GB
[2025-09-13 07:39:06 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.96 GB
[2025-09-13 07:39:06 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.96 GB
[2025-09-13 07:39:06 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.96 GB
[2025-09-13 07:39:06 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.00 GB
[2025-09-13 07:39:06 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.96 GB
[2025-09-13 07:39:06 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.96 GB
[2025-09-13 07:39:06 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.20 GB
[2025-09-13 07:39:06 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.96 GB
Capturing batches (bs=1 avail_mem=14.75 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:01<00:00,  6.24it/s][2025-09-13 07:39:09 TP6] Registering 120 cuda graph addresses
[2025-09-13 07:39:09 TP4] Registering 120 cuda graph addresses
[2025-09-13 07:39:09 TP7] Registering 120 cuda graph addresses
[2025-09-13 07:39:09 TP5] Registering 120 cuda graph addresses
[2025-09-13 07:39:09 TP2] Registering 120 cuda graph addresses
[2025-09-13 07:39:09 TP3] Registering 120 cuda graph addresses
[2025-09-13 07:39:09 TP1] Registering 120 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.75 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:02<00:00,  3.39it/s]
[2025-09-13 07:39:09 TP0] Registering 120 cuda graph addresses
[2025-09-13 07:39:09 TP3] Capture draft cuda graph end. Time elapsed: 3.02 s. mem usage=0.26 GB. avail mem=14.71 GB.
[2025-09-13 07:39:09 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.71 GB
[2025-09-13 07:39:09 TP0] Capture draft cuda graph end. Time elapsed: 3.03 s. mem usage=0.26 GB. avail mem=14.75 GB.
[2025-09-13 07:39:09 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.75 GB
[2025-09-13 07:39:09 TP5] Capture draft cuda graph end. Time elapsed: 3.03 s. mem usage=0.26 GB. avail mem=14.71 GB.
[2025-09-13 07:39:09 TP6] Capture draft cuda graph end. Time elapsed: 3.04 s. mem usage=0.26 GB. avail mem=14.71 GB.
[2025-09-13 07:39:09 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.71 GB
[2025-09-13 07:39:09 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.71 GB
[2025-09-13 07:39:09 TP2] Capture draft cuda graph end. Time elapsed: 3.04 s. mem usage=0.26 GB. avail mem=14.71 GB.
[2025-09-13 07:39:09 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.71 GB
[2025-09-13 07:39:09 TP7] Capture draft cuda graph end. Time elapsed: 3.03 s. mem usage=0.26 GB. avail mem=14.94 GB.
[2025-09-13 07:39:09 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:39:09 TP4] Capture draft cuda graph end. Time elapsed: 3.04 s. mem usage=0.26 GB. avail mem=14.71 GB.
[2025-09-13 07:39:09 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.71 GB
[2025-09-13 07:39:09 TP1] Capture draft cuda graph end. Time elapsed: 3.03 s. mem usage=0.26 GB. avail mem=14.71 GB.
[2025-09-13 07:39:09 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.71 GB
Capturing batches (bs=1 avail_mem=14.55 GB):  25%|█████████████████████▌                                                                | 2/8 [00:00<00:00, 18.51it/s][2025-09-13 07:39:10 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:39:10 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:39:10 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:39:10 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:39:10 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:39:10 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:39:10 TP1] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.55 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 34.78it/s]
[2025-09-13 07:39:10 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:39:10 TP3] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.20 GB. avail mem=14.50 GB.
[2025-09-13 07:39:10 TP6] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.20 GB. avail mem=14.50 GB.
[2025-09-13 07:39:10 TP7] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.20 GB. avail mem=14.74 GB.
[2025-09-13 07:39:10 TP5] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.20 GB. avail mem=14.50 GB.
[2025-09-13 07:39:10 TP2] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.20 GB. avail mem=14.50 GB.
[2025-09-13 07:39:10 TP0] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.20 GB. avail mem=14.55 GB.
[2025-09-13 07:39:10 TP4] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.20 GB. avail mem=14.50 GB.
[2025-09-13 07:39:10 TP1] Capture draft extend cuda graph end. Time elapsed: 1.05 s. mem usage=0.20 GB. avail mem=14.50 GB.
[2025-09-13 07:39:10 TP0] max_total_num_tokens=620161, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.55 GB
[2025-09-13 07:39:10] INFO:     Started server process [324256]
[2025-09-13 07:39:10] INFO:     Waiting for application startup.
[2025-09-13 07:39:10] INFO:     Application startup complete.
[2025-09-13 07:39:10] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:39:11] INFO:     127.0.0.1:60992 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:39:11 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:39:12 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:39:12 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26409.47it/s]
[2025-09-13 07:39:13] INFO:     127.0.0.1:32772 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:13] The server is fired up and ready to roll!
[2025-09-13 07:39:14 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:39:15] INFO:     127.0.0.1:32780 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:39:15] INFO:     127.0.0.1:32790 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:15 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:39:16] INFO:     127.0.0.1:32794 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:16] INFO:     127.0.0.1:32798 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:39:16] INFO:     127.0.0.1:32810 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:16] INFO:     127.0.0.1:32818 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:17] INFO:     127.0.0.1:32832 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:17] INFO:     127.0.0.1:32840 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:17] INFO:     127.0.0.1:32848 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:17] INFO:     127.0.0.1:32850 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:17 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:39:17 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:39:17 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:39:17 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:39:17 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:39:17 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:39:17 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:39:17 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:39:17 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:39:17 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:39:18 TP0] Decode batch. #running-req: 8, #token: 14581, token usage: 0.02, accept len: 3.03, cuda graph: True, gen throughput (token/s): 81.24, #queue-req: 0, 
[2025-09-13 07:39:19 TP0] Decode batch. #running-req: 8, #token: 15770, token usage: 0.03, accept len: 3.72, cuda graph: True, gen throughput (token/s): 930.35, #queue-req: 0, 
[2025-09-13 07:39:21 TP0] Decode batch. #running-req: 8, #token: 17162, token usage: 0.03, accept len: 4.35, cuda graph: True, gen throughput (token/s): 1086.56, #queue-req: 0, 
 62%|█████████████████████████████████████████████████████████████████████████████████▉                                                 | 5/8 [00:05<00:02,  1.36it/s][2025-09-13 07:39:22 TP0] Decode batch. #running-req: 3, #token: 2746, token usage: 0.00, accept len: 3.63, cuda graph: True, gen throughput (token/s): 522.10, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.24it/s]
[2025-09-13 07:39:23] INFO:     127.0.0.1:58154 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.46      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4079      
Request throughput (req/s):              1.24      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         633.85    
Total token throughput (tok/s):          633.85    
Concurrency:                             6.53      
Accept length:                           3.74      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5274.24   
Median E2E Latency (ms):                 5165.16   
---------------Time to First Token----------------
Mean TTFT (ms):                          626.14    
Median TTFT (ms):                        742.26    
P99 TTFT (ms):                           742.79    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.10      
Median ITL (ms):                         6.13      
P95 ITL (ms):                            23.55     
P99 ITL (ms):                            38.77     
Max ITL (ms):                            859.02    
==================================================
[2025-09-13 07:39:23] INFO:     127.0.0.1:58170 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:39:23] INFO:     127.0.0.1:58176 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:39:23 TP0] Decode batch. #running-req: 1, #token: 4688, token usage: 0.01, accept len: 3.37, cuda graph: True, gen throughput (token/s): 162.49, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:39:24] INFO:     127.0.0.1:58186 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:24] INFO:     127.0.0.1:58192 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:39:24] INFO:     127.0.0.1:58198 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:24] INFO:     127.0.0.1:58202 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:24] INFO:     127.0.0.1:58214 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:24] INFO:     127.0.0.1:58226 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:24] INFO:     127.0.0.1:58240 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:24] INFO:     127.0.0.1:58242 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:24 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:39:26 TP0] Decode batch. #running-req: 8, #token: 14874, token usage: 0.02, accept len: 3.23, cuda graph: True, gen throughput (token/s): 371.02, #queue-req: 0, 
[2025-09-13 07:39:27 TP0] Decode batch. #running-req: 8, #token: 16095, token usage: 0.03, accept len: 3.82, cuda graph: True, gen throughput (token/s): 949.73, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:03<00:57,  3.83s/it][2025-09-13 07:39:28] INFO:     127.0.0.1:38368 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:28 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:39:29 TP0] Decode batch. #running-req: 8, #token: 12966, token usage: 0.02, accept len: 4.42, cuda graph: True, gen throughput (token/s): 867.59, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:27,  1.93s/it][2025-09-13 07:39:29] INFO:     127.0.0.1:38372 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:39:29] INFO:     127.0.0.1:38386 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:29 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.09it/s][2025-09-13 07:39:29] INFO:     127.0.0.1:38400 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:29 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:08,  1.35it/s][2025-09-13 07:39:30] INFO:     127.0.0.1:38404 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:30 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:06<00:07,  1.38it/s][2025-09-13 07:39:30] INFO:     127.0.0.1:38408 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:30 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:05,  1.77it/s][2025-09-13 07:39:31] INFO:     127.0.0.1:38410 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:31 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:39:31 TP0] Decode batch. #running-req: 8, #token: 10464, token usage: 0.02, accept len: 3.23, cuda graph: True, gen throughput (token/s): 483.82, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:07<00:05,  1.48it/s][2025-09-13 07:39:31] INFO:     127.0.0.1:38418 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:39:32 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:39:32 TP0] Decode batch. #running-req: 8, #token: 15048, token usage: 0.02, accept len: 3.33, cuda graph: True, gen throughput (token/s): 709.37, #queue-req: 0, 
[2025-09-13 07:39:34 TP0] Decode batch. #running-req: 8, #token: 16377, token usage: 0.03, accept len: 4.15, cuda graph: True, gen throughput (token/s): 1035.45, #queue-req: 0, 
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 13/16 [00:10<00:01,  2.07it/s][2025-09-13 07:39:35 TP0] Decode batch. #running-req: 3, #token: 8632, token usage: 0.01, accept len: 4.33, cuda graph: True, gen throughput (token/s): 743.93, #queue-req: 0, 
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 15/16 [00:11<00:00,  1.94it/s][2025-09-13 07:39:36 TP0] Decode batch. #running-req: 1, #token: 3217, token usage: 0.01, accept len: 3.77, cuda graph: True, gen throughput (token/s): 366.40, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.40it/s]
[2025-09-13 07:39:36] INFO:     127.0.0.1:38434 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.44     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8082      
Request throughput (req/s):              1.40      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         716.28    
Total token throughput (tok/s):          716.28    
Concurrency:                             7.20      
Accept length:                           3.75      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5146.59   
Median E2E Latency (ms):                 5122.77   
---------------Time to First Token----------------
Mean TTFT (ms):                          286.95    
Median TTFT (ms):                        285.96    
P99 TTFT (ms):                           406.62    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.51      
Median ITL (ms):                         6.01      
P95 ITL (ms):                            31.08     
P99 ITL (ms):                            55.89     
Max ITL (ms):                            375.30    
==================================================
[2025-09-13 07:39:36] INFO:     127.0.0.1:38438 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-09-13 07:39:36 TP7] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2612, in run_scheduler_process
    scheduler.event_loop_normal()
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 811, in event_loop_normal
    recv_reqs = self.recv_requests()
                ^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 1095, in recv_requests
    recv_reqs = broadcast_pyobj(
                ^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/utils.py", line 1059, in broadcast_pyobj
    dist.broadcast(tensor_size, src=src, group=dist_group)
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
    work.wait()
RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:535] Read error [172.17.0.8]:52106: Connection reset by peer

[2025-09-13 07:39:36] Received sigquit from a child process. It usually means the child failed.
Finish i=35: batch_size=8, steps=6, topk=1, num_draft_tokens=4, speed=116.88 token/s, step_time=32.06 ms
Start i=36: batch_size=8, steps=6, topk=1, num_draft_tokens=6
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 6 --speculative-eagle-topk 1 --speculative-num-draft-tokens 6 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:39:47.226000 332993 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:39:47.226000 332993 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
WARNING:sglang.srt.server_args:speculative_num_draft_tokens is adjusted to speculative_num_steps + 1 when speculative_eagle_topk == 1
[2025-09-13 07:39:47] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=421294710, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=6, speculative_eagle_topk=1, speculative_num_draft_tokens=7, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:39:47] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:39:56.390000 333244 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:39:56.390000 333244 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:39:56.517000 333251 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:39:56.517000 333251 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:39:56.691000 333252 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:39:56.691000 333252 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 07:39:56.783000 333250 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:39:56.783000 333250 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:39:56.802000 333249 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:39:56.802000 333249 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:39:56.824000 333248 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:39:56.824000 333248 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:39:56.847000 333247 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:39:56.847000 333247 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:39:56.855000 333245 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:39:56.855000 333245 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
[2025-09-13 07:39:56 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:39:56 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:39:56 TP0] Init torch distributed begin.
W0913 07:39:56.997000 333246 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:39:56.997000 333246 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:39:58 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:40:02 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:40:03 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:40:03 TP0] Detected fp8 checkpoint.
[2025-09-13 07:40:04 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:04, 226.55it/s]
Loading safetensors checkpoint shards:   5% Completed | 49/1024 [00:00<00:11, 88.61it/s]
Loading safetensors checkpoint shards:   6% Completed | 62/1024 [00:00<00:12, 74.52it/s]
Loading safetensors checkpoint shards:   7% Completed | 72/1024 [00:00<00:13, 70.90it/s]
Loading safetensors checkpoint shards:   8% Completed | 81/1024 [00:01<00:14, 66.66it/s]
Loading safetensors checkpoint shards:   9% Completed | 89/1024 [00:01<00:14, 63.44it/s]
Loading safetensors checkpoint shards:   9% Completed | 96/1024 [00:01<00:29, 31.20it/s]
Loading safetensors checkpoint shards:  10% Completed | 103/1024 [00:01<00:25, 36.08it/s]
Loading safetensors checkpoint shards:  11% Completed | 110/1024 [00:02<00:22, 40.97it/s]
Loading safetensors checkpoint shards:  12% Completed | 119/1024 [00:02<00:18, 49.05it/s]
Loading safetensors checkpoint shards:  12% Completed | 127/1024 [00:02<00:16, 54.10it/s]
Loading safetensors checkpoint shards:  13% Completed | 134/1024 [00:02<00:16, 55.19it/s]
Loading safetensors checkpoint shards:  14% Completed | 141/1024 [00:02<00:15, 57.62it/s]
Loading safetensors checkpoint shards:  14% Completed | 148/1024 [00:02<00:15, 55.71it/s]
Loading safetensors checkpoint shards:  15% Completed | 156/1024 [00:02<00:14, 60.92it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:02<00:13, 64.85it/s]
Loading safetensors checkpoint shards:  17% Completed | 174/1024 [00:02<00:11, 73.71it/s]
Loading safetensors checkpoint shards:  18% Completed | 183/1024 [00:03<00:11, 75.94it/s]
Loading safetensors checkpoint shards:  19% Completed | 194/1024 [00:03<00:09, 83.09it/s]
Loading safetensors checkpoint shards:  20% Completed | 203/1024 [00:03<00:10, 79.61it/s]
Loading safetensors checkpoint shards:  21% Completed | 212/1024 [00:03<00:10, 78.41it/s]
Loading safetensors checkpoint shards:  21% Completed | 220/1024 [00:03<00:10, 77.36it/s]
Loading safetensors checkpoint shards:  22% Completed | 228/1024 [00:03<00:10, 75.72it/s]
Loading safetensors checkpoint shards:  23% Completed | 236/1024 [00:04<00:23, 33.20it/s]
Loading safetensors checkpoint shards:  24% Completed | 244/1024 [00:04<00:20, 38.87it/s]
Loading safetensors checkpoint shards:  25% Completed | 252/1024 [00:04<00:17, 45.29it/s]
Loading safetensors checkpoint shards:  26% Completed | 262/1024 [00:04<00:13, 55.06it/s]
Loading safetensors checkpoint shards:  26% Completed | 270/1024 [00:04<00:12, 60.14it/s]
Loading safetensors checkpoint shards:  27% Completed | 279/1024 [00:04<00:11, 66.46it/s]
Loading safetensors checkpoint shards:  28% Completed | 289/1024 [00:04<00:10, 73.12it/s]
Loading safetensors checkpoint shards:  29% Completed | 298/1024 [00:04<00:09, 73.46it/s]
Loading safetensors checkpoint shards:  30% Completed | 306/1024 [00:05<00:09, 74.01it/s]
Loading safetensors checkpoint shards:  31% Completed | 316/1024 [00:05<00:08, 79.97it/s]
Loading safetensors checkpoint shards:  32% Completed | 325/1024 [00:05<00:09, 76.85it/s]
Loading safetensors checkpoint shards:  33% Completed | 334/1024 [00:05<00:09, 76.28it/s]
Loading safetensors checkpoint shards:  33% Completed | 342/1024 [00:05<00:09, 75.61it/s]
Loading safetensors checkpoint shards:  34% Completed | 350/1024 [00:05<00:08, 76.20it/s]
Loading safetensors checkpoint shards:  35% Completed | 358/1024 [00:05<00:08, 75.49it/s]
Loading safetensors checkpoint shards:  36% Completed | 366/1024 [00:05<00:09, 68.84it/s]
Loading safetensors checkpoint shards:  37% Completed | 376/1024 [00:05<00:08, 75.99it/s]
Loading safetensors checkpoint shards:  38% Completed | 384/1024 [00:06<00:08, 76.90it/s]
Loading safetensors checkpoint shards:  38% Completed | 392/1024 [00:06<00:08, 77.64it/s]
Loading safetensors checkpoint shards:  39% Completed | 400/1024 [00:06<00:21, 29.22it/s]
Loading safetensors checkpoint shards:  40% Completed | 408/1024 [00:06<00:17, 35.51it/s]
Loading safetensors checkpoint shards:  41% Completed | 416/1024 [00:07<00:14, 42.02it/s]
Loading safetensors checkpoint shards:  41% Completed | 423/1024 [00:07<00:14, 42.68it/s]
Loading safetensors checkpoint shards:  42% Completed | 430/1024 [00:07<00:12, 47.51it/s]
Loading safetensors checkpoint shards:  43% Completed | 438/1024 [00:07<00:11, 52.95it/s]
Loading safetensors checkpoint shards:  44% Completed | 446/1024 [00:07<00:09, 58.95it/s]
Loading safetensors checkpoint shards:  44% Completed | 454/1024 [00:07<00:09, 62.46it/s]
Loading safetensors checkpoint shards:  45% Completed | 462/1024 [00:07<00:08, 65.34it/s]
Loading safetensors checkpoint shards:  46% Completed | 470/1024 [00:07<00:09, 55.42it/s]
Loading safetensors checkpoint shards:  47% Completed | 477/1024 [00:08<00:10, 54.36it/s]
Loading safetensors checkpoint shards:  47% Completed | 485/1024 [00:08<00:09, 59.31it/s]
Loading safetensors checkpoint shards:  48% Completed | 492/1024 [00:08<00:09, 58.68it/s]
Loading safetensors checkpoint shards:  49% Completed | 499/1024 [00:08<00:08, 61.02it/s]
Loading safetensors checkpoint shards:  49% Completed | 506/1024 [00:08<00:08, 62.23it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:08<00:07, 64.07it/s]
Loading safetensors checkpoint shards:  51% Completed | 520/1024 [00:08<00:08, 61.81it/s]
Loading safetensors checkpoint shards:  52% Completed | 528/1024 [00:08<00:07, 64.39it/s]
Loading safetensors checkpoint shards:  52% Completed | 535/1024 [00:08<00:07, 62.92it/s]
Loading safetensors checkpoint shards:  53% Completed | 544/1024 [00:09<00:07, 67.97it/s]
Loading safetensors checkpoint shards:  54% Completed | 553/1024 [00:09<00:06, 71.77it/s]
Loading safetensors checkpoint shards:  55% Completed | 561/1024 [00:09<00:07, 64.39it/s]
Loading safetensors checkpoint shards:  55% Completed | 568/1024 [00:09<00:06, 65.31it/s]
Loading safetensors checkpoint shards:  56% Completed | 575/1024 [00:09<00:06, 64.71it/s]
Loading safetensors checkpoint shards:  57% Completed | 584/1024 [00:09<00:06, 69.55it/s]
Loading safetensors checkpoint shards:  58% Completed | 592/1024 [00:09<00:06, 64.33it/s]
Loading safetensors checkpoint shards:  58% Completed | 599/1024 [00:10<00:17, 24.60it/s]
Loading safetensors checkpoint shards:  59% Completed | 607/1024 [00:10<00:13, 31.24it/s]
Loading safetensors checkpoint shards:  60% Completed | 616/1024 [00:10<00:10, 39.02it/s]
Loading safetensors checkpoint shards:  61% Completed | 624/1024 [00:10<00:08, 45.43it/s]
Loading safetensors checkpoint shards:  62% Completed | 631/1024 [00:11<00:07, 49.58it/s]
Loading safetensors checkpoint shards:  62% Completed | 640/1024 [00:11<00:06, 57.53it/s]
Loading safetensors checkpoint shards:  63% Completed | 648/1024 [00:11<00:06, 58.39it/s]
Loading safetensors checkpoint shards:  64% Completed | 657/1024 [00:11<00:05, 64.47it/s]
Loading safetensors checkpoint shards:  65% Completed | 665/1024 [00:11<00:05, 63.24it/s]
Loading safetensors checkpoint shards:  66% Completed | 672/1024 [00:11<00:05, 61.98it/s]
Loading safetensors checkpoint shards:  66% Completed | 679/1024 [00:11<00:06, 54.80it/s]
Loading safetensors checkpoint shards:  67% Completed | 685/1024 [00:11<00:06, 49.36it/s]
Loading safetensors checkpoint shards:  67% Completed | 691/1024 [00:12<00:06, 48.00it/s]
Loading safetensors checkpoint shards:  68% Completed | 699/1024 [00:12<00:05, 54.71it/s]
Loading safetensors checkpoint shards:  69% Completed | 705/1024 [00:12<00:06, 48.00it/s]
Loading safetensors checkpoint shards:  69% Completed | 711/1024 [00:12<00:06, 46.22it/s]
Loading safetensors checkpoint shards:  70% Completed | 716/1024 [00:12<00:06, 46.65it/s]
Loading safetensors checkpoint shards:  70% Completed | 721/1024 [00:12<00:06, 43.40it/s]
Loading safetensors checkpoint shards:  71% Completed | 726/1024 [00:12<00:06, 43.22it/s]
Loading safetensors checkpoint shards:  71% Completed | 731/1024 [00:12<00:06, 44.51it/s]
Loading safetensors checkpoint shards:  72% Completed | 736/1024 [00:13<00:06, 41.83it/s]
Loading safetensors checkpoint shards:  72% Completed | 741/1024 [00:13<00:07, 39.95it/s]
Loading safetensors checkpoint shards:  73% Completed | 746/1024 [00:13<00:07, 37.09it/s]
Loading safetensors checkpoint shards:  73% Completed | 750/1024 [00:13<00:07, 36.50it/s]
Loading safetensors checkpoint shards:  74% Completed | 754/1024 [00:13<00:07, 36.89it/s]
Loading safetensors checkpoint shards:  74% Completed | 758/1024 [00:13<00:07, 36.07it/s]
Loading safetensors checkpoint shards:  74% Completed | 762/1024 [00:13<00:07, 34.30it/s]
Loading safetensors checkpoint shards:  75% Completed | 766/1024 [00:13<00:07, 35.15it/s]
Loading safetensors checkpoint shards:  75% Completed | 770/1024 [00:14<00:07, 35.32it/s]
Loading safetensors checkpoint shards:  76% Completed | 774/1024 [00:14<00:07, 32.47it/s]
Loading safetensors checkpoint shards:  76% Completed | 779/1024 [00:14<00:06, 35.32it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:14<00:06, 35.87it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:14<00:07, 33.20it/s]
Loading safetensors checkpoint shards:  77% Completed | 791/1024 [00:14<00:06, 33.39it/s]
Loading safetensors checkpoint shards:  78% Completed | 795/1024 [00:14<00:07, 30.86it/s]
Loading safetensors checkpoint shards:  78% Completed | 799/1024 [00:15<00:07, 29.51it/s]
Loading safetensors checkpoint shards:  78% Completed | 803/1024 [00:15<00:07, 29.92it/s]
Loading safetensors checkpoint shards:  79% Completed | 807/1024 [00:15<00:06, 31.48it/s]
Loading safetensors checkpoint shards:  79% Completed | 811/1024 [00:15<00:06, 31.76it/s]
Loading safetensors checkpoint shards:  80% Completed | 815/1024 [00:15<00:06, 30.38it/s]
Loading safetensors checkpoint shards:  80% Completed | 819/1024 [00:15<00:06, 29.96it/s]
Loading safetensors checkpoint shards:  80% Completed | 823/1024 [00:15<00:07, 28.58it/s]
Loading safetensors checkpoint shards:  81% Completed | 826/1024 [00:15<00:06, 28.86it/s]
Loading safetensors checkpoint shards:  81% Completed | 830/1024 [00:16<00:06, 30.33it/s]
Loading safetensors checkpoint shards:  81% Completed | 834/1024 [00:16<00:18, 10.37it/s]
Loading safetensors checkpoint shards:  82% Completed | 838/1024 [00:17<00:14, 13.13it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:17<00:11, 16.51it/s]
Loading safetensors checkpoint shards:  83% Completed | 847/1024 [00:17<00:08, 21.27it/s]
Loading safetensors checkpoint shards:  83% Completed | 853/1024 [00:17<00:06, 26.99it/s]
Loading safetensors checkpoint shards:  84% Completed | 858/1024 [00:17<00:05, 29.90it/s]
Loading safetensors checkpoint shards:  84% Completed | 862/1024 [00:17<00:05, 31.14it/s]
Loading safetensors checkpoint shards:  85% Completed | 868/1024 [00:17<00:04, 35.89it/s]
Loading safetensors checkpoint shards:  85% Completed | 873/1024 [00:17<00:03, 38.14it/s]
Loading safetensors checkpoint shards:  86% Completed | 878/1024 [00:18<00:04, 36.16it/s]
Loading safetensors checkpoint shards:  86% Completed | 883/1024 [00:18<00:03, 38.04it/s]
Loading safetensors checkpoint shards:  87% Completed | 889/1024 [00:18<00:03, 40.54it/s]
Loading safetensors checkpoint shards:  87% Completed | 895/1024 [00:18<00:02, 43.92it/s]
Loading safetensors checkpoint shards:  88% Completed | 901/1024 [00:18<00:02, 47.96it/s]
Loading safetensors checkpoint shards:  89% Completed | 908/1024 [00:18<00:02, 52.06it/s]
Loading safetensors checkpoint shards:  89% Completed | 915/1024 [00:18<00:01, 55.09it/s]
Loading safetensors checkpoint shards:  90% Completed | 922/1024 [00:18<00:01, 57.17it/s]
Loading safetensors checkpoint shards:  91% Completed | 928/1024 [00:18<00:01, 55.39it/s]
Loading safetensors checkpoint shards:  91% Completed | 934/1024 [00:19<00:01, 53.93it/s]
Loading safetensors checkpoint shards:  92% Completed | 942/1024 [00:19<00:01, 60.79it/s]
Loading safetensors checkpoint shards:  93% Completed | 949/1024 [00:19<00:01, 60.30it/s]
Loading safetensors checkpoint shards:  93% Completed | 956/1024 [00:19<00:01, 62.70it/s]
Loading safetensors checkpoint shards:  94% Completed | 963/1024 [00:19<00:00, 61.41it/s]
Loading safetensors checkpoint shards:  95% Completed | 970/1024 [00:19<00:00, 58.45it/s]
Loading safetensors checkpoint shards:  95% Completed | 977/1024 [00:19<00:00, 60.87it/s]
Loading safetensors checkpoint shards:  96% Completed | 986/1024 [00:19<00:00, 66.22it/s]
Loading safetensors checkpoint shards:  98% Completed | 1001/1024 [00:19<00:00, 88.31it/s]
Loading safetensors checkpoint shards:  99% Completed | 1013/1024 [00:20<00:00, 95.91it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:20<00:00, 50.70it/s]

[2025-09-13 07:40:33 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:40:33 TP7] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 07:40:33 TP4] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 07:40:33 TP0] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 07:40:33 TP1] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 07:40:33 TP3] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 07:40:33 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:40:33 TP6] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 07:40:33 TP2] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 07:40:33 TP5] KV Cache is allocated. #tokens: 620161, KV size: 40.59 GB
[2025-09-13 07:40:33 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:40:34 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.52 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:40:34 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:40:34 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:40:35 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:40:35 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:40:35 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:40:35 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:40:35 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:40:35 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:40:35 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25785.99it/s]
[2025-09-13 07:40:35 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:40:35 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26219.46it/s]
[2025-09-13 07:40:36 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:40:36 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27864.43it/s]
[2025-09-13 07:40:36 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:40:36 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27159.70it/s]
[2025-09-13 07:40:37 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:40:37 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27866.08it/s]
[2025-09-13 07:40:38 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.23 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  2.15it/s][2025-09-13 07:40:41 TP6] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.23 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.18it/s]
[2025-09-13 07:40:41 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:40:41 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:40:41 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:40:41 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:40:41 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:40:41 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:40:41 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:40:41 TP0] Capture cuda graph end. Time elapsed: 7.51 s. mem usage=0.35 GB. avail mem=17.22 GB.
[2025-09-13 07:40:41 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:40:41 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:40:41 TP0] Init torch distributed begin.
[2025-09-13 07:40:41 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:40:41 TP0] Load weight begin. avail mem=17.22 GB
[2025-09-13 07:40:41 TP0] Detected fp8 checkpoint.
[2025-09-13 07:40:41 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 19/1024 [00:00<00:05, 183.06it/s]
Loading safetensors checkpoint shards:   5% Completed | 50/1024 [00:00<00:03, 254.11it/s]
Loading safetensors checkpoint shards:  11% Completed | 109/1024 [00:00<00:02, 403.53it/s]
Loading safetensors checkpoint shards:  17% Completed | 170/1024 [00:00<00:01, 483.62it/s]
Loading safetensors checkpoint shards:  23% Completed | 232/1024 [00:00<00:01, 529.83it/s]
Loading safetensors checkpoint shards:  29% Completed | 295/1024 [00:00<00:01, 560.50it/s]
Loading safetensors checkpoint shards:  35% Completed | 356/1024 [00:00<00:01, 575.02it/s]
Loading safetensors checkpoint shards:  41% Completed | 418/1024 [00:00<00:01, 588.82it/s]
Loading safetensors checkpoint shards:  47% Completed | 480/1024 [00:00<00:00, 596.09it/s]
Loading safetensors checkpoint shards:  53% Completed | 542/1024 [00:01<00:00, 601.43it/s]
Loading safetensors checkpoint shards:  59% Completed | 604/1024 [00:01<00:00, 606.39it/s]
Loading safetensors checkpoint shards:  65% Completed | 665/1024 [00:01<00:00, 595.53it/s]
Loading safetensors checkpoint shards:  71% Completed | 725/1024 [00:01<00:00, 588.32it/s]
Loading safetensors checkpoint shards:  77% Completed | 784/1024 [00:01<00:00, 582.15it/s]
Loading safetensors checkpoint shards:  82% Completed | 843/1024 [00:01<00:00, 580.80it/s]
Loading safetensors checkpoint shards:  88% Completed | 902/1024 [00:01<00:00, 576.17it/s]
Loading safetensors checkpoint shards:  94% Completed | 960/1024 [00:01<00:00, 574.78it/s]
Loading safetensors checkpoint shards:  99% Completed | 1018/1024 [00:01<00:00, 399.95it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:01<00:00, 512.59it/s]

[2025-09-13 07:40:43 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.24 GB, mem usage=1.98 GB.
[2025-09-13 07:40:43 TP6] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 07:40:43 TP5] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 07:40:43 TP2] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 07:40:43 TP7] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 07:40:43 TP4] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 07:40:43 TP3] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 07:40:43 TP0] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 07:40:43 TP1] KV Cache is allocated. #tokens: 620161, KV size: 0.67 GB
[2025-09-13 07:40:43 TP0] Memory pool end. avail mem=14.57 GB
[2025-09-13 07:40:44 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.96 GB
[2025-09-13 07:40:44 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.96 GB
[2025-09-13 07:40:44 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.00 GB
[2025-09-13 07:40:44 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.96 GB
[2025-09-13 07:40:44 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.96 GB
[2025-09-13 07:40:44 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.96 GB
[2025-09-13 07:40:44 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.20 GB
[2025-09-13 07:40:44 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.96 GB
Capturing batches (bs=1 avail_mem=14.75 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:01<00:00,  5.57it/s][2025-09-13 07:40:47 TP1] Registering 120 cuda graph addresses
[2025-09-13 07:40:47 TP7] Registering 120 cuda graph addresses
[2025-09-13 07:40:47 TP2] Registering 120 cuda graph addresses
[2025-09-13 07:40:47 TP6] Registering 120 cuda graph addresses
[2025-09-13 07:40:47 TP4] Registering 120 cuda graph addresses
[2025-09-13 07:40:47 TP5] Registering 120 cuda graph addresses
[2025-09-13 07:40:47 TP3] Registering 120 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.75 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:02<00:00,  3.21it/s]
[2025-09-13 07:40:47 TP0] Registering 120 cuda graph addresses
[2025-09-13 07:40:47 TP4] Capture draft cuda graph end. Time elapsed: 3.29 s. mem usage=0.26 GB. avail mem=14.71 GB.
[2025-09-13 07:40:47 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.71 GB
[2025-09-13 07:40:47 TP6] Capture draft cuda graph end. Time elapsed: 3.30 s. mem usage=0.26 GB. avail mem=14.71 GB.
[2025-09-13 07:40:47 TP5] Capture draft cuda graph end. Time elapsed: 3.30 s. mem usage=0.26 GB. avail mem=14.71 GB.
[2025-09-13 07:40:47 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.71 GB
[2025-09-13 07:40:47 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.71 GB
[2025-09-13 07:40:47 TP0] Capture draft cuda graph end. Time elapsed: 3.30 s. mem usage=0.26 GB. avail mem=14.75 GB.
[2025-09-13 07:40:47 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.75 GB
[2025-09-13 07:40:47 TP2] Capture draft cuda graph end. Time elapsed: 3.30 s. mem usage=0.26 GB. avail mem=14.71 GB.
[2025-09-13 07:40:47 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.71 GB
[2025-09-13 07:40:47 TP3] Capture draft cuda graph end. Time elapsed: 3.29 s. mem usage=0.26 GB. avail mem=14.71 GB.
[2025-09-13 07:40:47 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.71 GB
[2025-09-13 07:40:47 TP7] Capture draft cuda graph end. Time elapsed: 3.30 s. mem usage=0.26 GB. avail mem=14.94 GB.
[2025-09-13 07:40:47 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:40:47 TP1] Capture draft cuda graph end. Time elapsed: 3.30 s. mem usage=0.26 GB. avail mem=14.71 GB.
[2025-09-13 07:40:47 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.71 GB
Capturing batches (bs=1 avail_mem=14.55 GB):  38%|████████████████████████████████▎                                                     | 3/8 [00:00<00:00, 28.12it/s][2025-09-13 07:40:48 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:40:48 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:40:48 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:40:48 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:40:48 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:40:48 TP4] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.55 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 39.59it/s]
[2025-09-13 07:40:48 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:40:48 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:40:48 TP5] Capture draft extend cuda graph end. Time elapsed: 0.98 s. mem usage=0.20 GB. avail mem=14.50 GB.
[2025-09-13 07:40:48 TP4] Capture draft extend cuda graph end. Time elapsed: 0.99 s. mem usage=0.20 GB. avail mem=14.50 GB.
[2025-09-13 07:40:48 TP6] Capture draft extend cuda graph end. Time elapsed: 0.99 s. mem usage=0.20 GB. avail mem=14.50 GB.
[2025-09-13 07:40:48 TP2] Capture draft extend cuda graph end. Time elapsed: 0.99 s. mem usage=0.20 GB. avail mem=14.50 GB.
[2025-09-13 07:40:48 TP7] Capture draft extend cuda graph end. Time elapsed: 0.99 s. mem usage=0.20 GB. avail mem=14.74 GB.
[2025-09-13 07:40:48 TP3] Capture draft extend cuda graph end. Time elapsed: 0.99 s. mem usage=0.20 GB. avail mem=14.50 GB.
[2025-09-13 07:40:48 TP1] Capture draft extend cuda graph end. Time elapsed: 0.99 s. mem usage=0.20 GB. avail mem=14.50 GB.
[2025-09-13 07:40:48 TP0] Capture draft extend cuda graph end. Time elapsed: 0.99 s. mem usage=0.20 GB. avail mem=14.55 GB.
[2025-09-13 07:40:48 TP0] max_total_num_tokens=620161, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.55 GB
[2025-09-13 07:40:48] INFO:     Started server process [332993]
[2025-09-13 07:40:48] INFO:     Waiting for application startup.
[2025-09-13 07:40:48] INFO:     Application startup complete.
[2025-09-13 07:40:48] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:40:49] INFO:     127.0.0.1:60348 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:40:49 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:40:49 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:40:49 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28738.62it/s]
[2025-09-13 07:40:51] INFO:     127.0.0.1:60356 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:40:51] The server is fired up and ready to roll!
[2025-09-13 07:40:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:40:52] INFO:     127.0.0.1:60366 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:40:52] INFO:     127.0.0.1:60372 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:40:52 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:40:54] INFO:     127.0.0.1:60378 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:40:54] INFO:     127.0.0.1:60386 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:40:54 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:40:54] INFO:     127.0.0.1:60390 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:40:54] INFO:     127.0.0.1:60400 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:40:54] INFO:     127.0.0.1:60404 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:40:54] INFO:     127.0.0.1:60412 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:40:54] INFO:     127.0.0.1:60422 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:40:54] INFO:     127.0.0.1:60426 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:40:54 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:40:54 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:40:54 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:40:54 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:40:54 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:40:54 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:40:54 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:40:54 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:40:54 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:40:54 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:40:55 TP0] Decode batch. #running-req: 8, #token: 14581, token usage: 0.02, accept len: 3.03, cuda graph: True, gen throughput (token/s): 94.88, #queue-req: 0, 
[2025-09-13 07:40:56 TP0] Decode batch. #running-req: 8, #token: 15770, token usage: 0.03, accept len: 3.72, cuda graph: True, gen throughput (token/s): 934.53, #queue-req: 0, 
[2025-09-13 07:40:58 TP0] Decode batch. #running-req: 8, #token: 17162, token usage: 0.03, accept len: 4.35, cuda graph: True, gen throughput (token/s): 1089.57, #queue-req: 0, 
 62%|█████████████████████████████████████████████████████████████████████████████████▉                                                 | 5/8 [00:04<00:01,  1.55it/s][2025-09-13 07:40:59 TP0] Decode batch. #running-req: 3, #token: 2746, token usage: 0.00, accept len: 3.63, cuda graph: True, gen throughput (token/s): 620.21, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.38it/s]
[2025-09-13 07:40:59] INFO:     127.0.0.1:47754 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  5.82      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4079      
Request throughput (req/s):              1.38      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         704.20    
Total token throughput (tok/s):          704.20    
Concurrency:                             6.70      
Accept length:                           3.74      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   4871.60   
Median E2E Latency (ms):                 4807.72   
---------------Time to First Token----------------
Mean TTFT (ms):                          610.00    
Median TTFT (ms):                        720.42    
P99 TTFT (ms):                           720.92    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           8.34      
Median ITL (ms):                         5.96      
P95 ITL (ms):                            16.10     
P99 ITL (ms):                            31.97     
Max ITL (ms):                            624.06    
==================================================
[2025-09-13 07:40:59] INFO:     127.0.0.1:47760 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:40:59] INFO:     127.0.0.1:47762 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:41:00 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:41:00 TP0] Decode batch. #running-req: 1, #token: 4688, token usage: 0.01, accept len: 3.37, cuda graph: True, gen throughput (token/s): 196.81, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:41:01] INFO:     127.0.0.1:47776 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:41:01] INFO:     127.0.0.1:47786 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:41:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:41:01] INFO:     127.0.0.1:47802 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:41:01] INFO:     127.0.0.1:47818 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:41:01] INFO:     127.0.0.1:47820 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:41:01] INFO:     127.0.0.1:47824 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:41:01] INFO:     127.0.0.1:47830 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:41:01] INFO:     127.0.0.1:47832 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:41:01 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:41:02 TP0] Decode batch. #running-req: 8, #token: 14874, token usage: 0.02, accept len: 3.23, cuda graph: True, gen throughput (token/s): 391.25, #queue-req: 0, 
[2025-09-13 07:41:03 TP0] Decode batch. #running-req: 8, #token: 16095, token usage: 0.03, accept len: 3.82, cuda graph: True, gen throughput (token/s): 955.51, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:03<00:55,  3.68s/it][2025-09-13 07:41:04] INFO:     127.0.0.1:47848 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:41:05 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:41:05 TP0] Decode batch. #running-req: 8, #token: 12966, token usage: 0.02, accept len: 4.42, cuda graph: True, gen throughput (token/s): 993.66, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:24,  1.75s/it][2025-09-13 07:41:05] INFO:     127.0.0.1:47856 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:41:05 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:41:05] INFO:     127.0.0.1:47870 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:41:05 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:04<00:10,  1.18it/s][2025-09-13 07:41:05] INFO:     127.0.0.1:47880 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:41:06 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:07,  1.45it/s][2025-09-13 07:41:06] INFO:     127.0.0.1:47884 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:41:06 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:06,  1.45it/s][2025-09-13 07:41:07] INFO:     127.0.0.1:47900 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:41:07 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:05<00:04,  1.86it/s][2025-09-13 07:41:07] INFO:     127.0.0.1:47908 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:41:07 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:41:07 TP0] Decode batch. #running-req: 8, #token: 10464, token usage: 0.02, accept len: 3.23, cuda graph: True, gen throughput (token/s): 493.20, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:05,  1.53it/s][2025-09-13 07:41:08] INFO:     127.0.0.1:37132 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:41:08 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:41:08 TP0] Decode batch. #running-req: 8, #token: 15048, token usage: 0.02, accept len: 3.33, cuda graph: True, gen throughput (token/s): 712.92, #queue-req: 0, 
[2025-09-13 07:41:10 TP0] Decode batch. #running-req: 8, #token: 16377, token usage: 0.03, accept len: 4.15, cuda graph: True, gen throughput (token/s): 1041.10, #queue-req: 0, 
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 13/16 [00:09<00:01,  2.11it/s][2025-09-13 07:41:11 TP0] Decode batch. #running-req: 3, #token: 8632, token usage: 0.01, accept len: 4.33, cuda graph: True, gen throughput (token/s): 749.37, #queue-req: 0, 
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 15/16 [00:10<00:00,  1.95it/s][2025-09-13 07:41:12 TP0] Decode batch. #running-req: 1, #token: 3217, token usage: 0.01, accept len: 3.77, cuda graph: True, gen throughput (token/s): 365.29, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.45it/s]
[2025-09-13 07:41:12] INFO:     127.0.0.1:37146 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.03     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8082      
Request throughput (req/s):              1.45      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         742.75    
Total token throughput (tok/s):          742.75    
Concurrency:                             7.17      
Accept length:                           3.75      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   4942.28   
Median E2E Latency (ms):                 5054.57   
---------------Time to First Token----------------
Mean TTFT (ms):                          230.37    
Median TTFT (ms):                        273.64    
P99 TTFT (ms):                           293.72    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.22      
Median ITL (ms):                         5.92      
P95 ITL (ms):                            30.48     
P99 ITL (ms):                            52.41     
Max ITL (ms):                            266.24    
==================================================
[2025-09-13 07:41:12] INFO:     127.0.0.1:37158 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-09-13 07:41:12 TP5] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2612, in run_scheduler_process
    scheduler.event_loop_normal()
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 811, in event_loop_normal
    recv_reqs = self.recv_requests()
                ^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 1095, in recv_requests
    recv_reqs = broadcast_pyobj(
                ^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/utils.py", line 1059, in broadcast_pyobj
    dist.broadcast(tensor_size, src=src, group=dist_group)
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
    work.wait()
RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [172.17.0.8]:5815

[2025-09-13 07:41:12] Received sigquit from a child process. It usually means the child failed.
/usr/lib/python3.12/multiprocessing/resource_tracker.py:147: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.
  warnings.warn('resource_tracker: process died unexpectedly, '
[2025-09-13 07:41:12 TP4] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2612, in run_scheduler_process
    scheduler.event_loop_normal()
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 811, in event_loop_normal
    recv_reqs = self.recv_requests()
                ^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 1095, in recv_requests
    recv_reqs = broadcast_pyobj(
                ^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/utils.py", line 1059, in broadcast_pyobj
    dist.broadcast(tensor_size, src=src, group=dist_group)
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
    work.wait()
RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [172.17.0.8]:31376

Finish i=36: batch_size=8, steps=6, topk=1, num_draft_tokens=6, speed=117.37 token/s, step_time=31.93 ms
Start i=37: batch_size=8, steps=6, topk=2, num_draft_tokens=4
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 6 --speculative-eagle-topk 2 --speculative-num-draft-tokens 4 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:41:23.078000 339006 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:41:23.078000 339006 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:41:23] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=99327182, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=6, speculative_eagle_topk=2, speculative_num_draft_tokens=4, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:41:23] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:41:32.292000 339265 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:41:32.292000 339265 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:41:32.382000 339272 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:41:32.382000 339272 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 07:41:32.566000 339270 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:41:32.566000 339270 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:41:32.613000 339266 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:41:32.613000 339266 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:41:32.704000 339268 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:41:32.704000 339268 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:41:32.722000 339264 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:41:32.722000 339264 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:41:32.726000 339269 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:41:32.726000 339269 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:41:32.728000 339267 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:41:32.728000 339267 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:41:32.743000 339271 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:41:32.743000 339271 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:41:33 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:41:33 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:41:33 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:41:35 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:41:38 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:41:39 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:41:39 TP0] Detected fp8 checkpoint.
[2025-09-13 07:41:40 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 28/1024 [00:00<00:04, 228.41it/s]
Loading safetensors checkpoint shards:   5% Completed | 51/1024 [00:00<00:15, 61.71it/s]
Loading safetensors checkpoint shards:   6% Completed | 63/1024 [00:01<00:19, 49.86it/s]
Loading safetensors checkpoint shards:   7% Completed | 71/1024 [00:01<00:19, 47.88it/s]
Loading safetensors checkpoint shards:   8% Completed | 78/1024 [00:01<00:20, 45.96it/s]
Loading safetensors checkpoint shards:   8% Completed | 84/1024 [00:01<00:20, 46.68it/s]
Loading safetensors checkpoint shards:   9% Completed | 90/1024 [00:01<00:19, 46.71it/s]
Loading safetensors checkpoint shards:   9% Completed | 96/1024 [00:01<00:21, 44.00it/s]
Loading safetensors checkpoint shards:  10% Completed | 101/1024 [00:01<00:21, 43.01it/s]
Loading safetensors checkpoint shards:  10% Completed | 106/1024 [00:02<00:20, 43.98it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:21, 41.96it/s]
Loading safetensors checkpoint shards:  11% Completed | 116/1024 [00:02<00:21, 42.51it/s]
Loading safetensors checkpoint shards:  12% Completed | 121/1024 [00:02<00:38, 23.55it/s]
Loading safetensors checkpoint shards:  12% Completed | 125/1024 [00:02<00:34, 25.95it/s]
Loading safetensors checkpoint shards:  13% Completed | 130/1024 [00:03<00:29, 30.13it/s]
Loading safetensors checkpoint shards:  13% Completed | 134/1024 [00:03<00:28, 31.32it/s]
Loading safetensors checkpoint shards:  14% Completed | 140/1024 [00:03<00:24, 36.18it/s]
Loading safetensors checkpoint shards:  14% Completed | 145/1024 [00:03<00:23, 37.17it/s]
Loading safetensors checkpoint shards:  15% Completed | 150/1024 [00:03<00:22, 39.22it/s]
Loading safetensors checkpoint shards:  15% Completed | 155/1024 [00:03<00:21, 40.30it/s]
Loading safetensors checkpoint shards:  16% Completed | 160/1024 [00:03<00:20, 42.23it/s]
Loading safetensors checkpoint shards:  16% Completed | 165/1024 [00:03<00:21, 40.88it/s]
Loading safetensors checkpoint shards:  17% Completed | 170/1024 [00:03<00:21, 39.81it/s]
Loading safetensors checkpoint shards:  17% Completed | 175/1024 [00:04<00:20, 41.85it/s]
Loading safetensors checkpoint shards:  18% Completed | 180/1024 [00:04<00:20, 41.66it/s]
Loading safetensors checkpoint shards:  18% Completed | 185/1024 [00:04<00:19, 43.74it/s]
Loading safetensors checkpoint shards:  19% Completed | 190/1024 [00:04<00:18, 44.15it/s]
Loading safetensors checkpoint shards:  19% Completed | 196/1024 [00:04<00:17, 46.11it/s]
Loading safetensors checkpoint shards:  20% Completed | 201/1024 [00:04<00:18, 45.71it/s]
Loading safetensors checkpoint shards:  20% Completed | 206/1024 [00:04<00:17, 45.92it/s]
Loading safetensors checkpoint shards:  21% Completed | 211/1024 [00:04<00:17, 45.22it/s]
Loading safetensors checkpoint shards:  21% Completed | 216/1024 [00:04<00:17, 45.23it/s]
Loading safetensors checkpoint shards:  22% Completed | 221/1024 [00:05<00:19, 40.99it/s]
Loading safetensors checkpoint shards:  22% Completed | 226/1024 [00:05<00:19, 40.05it/s]
Loading safetensors checkpoint shards:  23% Completed | 231/1024 [00:05<00:20, 38.62it/s]
Loading safetensors checkpoint shards:  23% Completed | 235/1024 [00:05<00:21, 37.44it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:05<00:20, 38.64it/s]
Loading safetensors checkpoint shards:  24% Completed | 244/1024 [00:05<00:20, 37.19it/s]
Loading safetensors checkpoint shards:  24% Completed | 249/1024 [00:05<00:19, 40.42it/s]
Loading safetensors checkpoint shards:  25% Completed | 254/1024 [00:05<00:20, 37.37it/s]
Loading safetensors checkpoint shards:  25% Completed | 258/1024 [00:06<00:20, 37.00it/s]
Loading safetensors checkpoint shards:  26% Completed | 263/1024 [00:06<00:19, 38.82it/s]
Loading safetensors checkpoint shards:  26% Completed | 267/1024 [00:06<00:19, 38.64it/s]
Loading safetensors checkpoint shards:  27% Completed | 272/1024 [00:06<00:19, 39.44it/s]
Loading safetensors checkpoint shards:  27% Completed | 276/1024 [00:06<00:20, 37.09it/s]
Loading safetensors checkpoint shards:  27% Completed | 280/1024 [00:06<00:20, 36.85it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:06<00:18, 38.96it/s]
Loading safetensors checkpoint shards:  28% Completed | 289/1024 [00:06<00:19, 38.11it/s]
Loading safetensors checkpoint shards:  29% Completed | 294/1024 [00:07<00:18, 38.66it/s]
Loading safetensors checkpoint shards:  29% Completed | 298/1024 [00:07<00:18, 38.35it/s]
Loading safetensors checkpoint shards:  29% Completed | 302/1024 [00:07<00:18, 38.02it/s]
Loading safetensors checkpoint shards:  30% Completed | 307/1024 [00:07<00:18, 38.85it/s]
Loading safetensors checkpoint shards:  30% Completed | 311/1024 [00:07<00:18, 38.19it/s]
Loading safetensors checkpoint shards:  31% Completed | 316/1024 [00:07<00:17, 39.99it/s]
Loading safetensors checkpoint shards:  31% Completed | 320/1024 [00:07<00:17, 39.82it/s]
Loading safetensors checkpoint shards:  32% Completed | 324/1024 [00:08<00:37, 18.67it/s]
Loading safetensors checkpoint shards:  32% Completed | 329/1024 [00:08<00:30, 22.99it/s]
Loading safetensors checkpoint shards:  33% Completed | 333/1024 [00:08<00:26, 25.78it/s]
Loading safetensors checkpoint shards:  33% Completed | 338/1024 [00:08<00:22, 29.84it/s]
Loading safetensors checkpoint shards:  33% Completed | 343/1024 [00:08<00:20, 32.58it/s]
Loading safetensors checkpoint shards:  34% Completed | 347/1024 [00:08<00:20, 33.75it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:08<00:16, 39.87it/s]
Loading safetensors checkpoint shards:  35% Completed | 359/1024 [00:09<00:16, 40.79it/s]
Loading safetensors checkpoint shards:  36% Completed | 364/1024 [00:09<00:15, 41.71it/s]
Loading safetensors checkpoint shards:  36% Completed | 370/1024 [00:09<00:15, 43.39it/s]
Loading safetensors checkpoint shards:  37% Completed | 376/1024 [00:09<00:13, 47.14it/s]
Loading safetensors checkpoint shards:  37% Completed | 381/1024 [00:09<00:14, 45.93it/s]
Loading safetensors checkpoint shards:  38% Completed | 388/1024 [00:09<00:12, 51.38it/s]
Loading safetensors checkpoint shards:  38% Completed | 394/1024 [00:09<00:11, 52.91it/s]
Loading safetensors checkpoint shards:  39% Completed | 400/1024 [00:09<00:11, 53.35it/s]
Loading safetensors checkpoint shards:  40% Completed | 407/1024 [00:09<00:10, 56.82it/s]
Loading safetensors checkpoint shards:  40% Completed | 414/1024 [00:10<00:10, 59.49it/s]
Loading safetensors checkpoint shards:  41% Completed | 420/1024 [00:10<00:10, 57.99it/s]
Loading safetensors checkpoint shards:  42% Completed | 427/1024 [00:10<00:09, 59.98it/s]
Loading safetensors checkpoint shards:  42% Completed | 434/1024 [00:10<00:09, 59.08it/s]
Loading safetensors checkpoint shards:  43% Completed | 440/1024 [00:10<00:10, 58.18it/s]
Loading safetensors checkpoint shards:  44% Completed | 446/1024 [00:10<00:10, 54.58it/s]
Loading safetensors checkpoint shards:  44% Completed | 452/1024 [00:10<00:12, 44.01it/s]
Loading safetensors checkpoint shards:  45% Completed | 457/1024 [00:10<00:13, 42.59it/s]
Loading safetensors checkpoint shards:  45% Completed | 462/1024 [00:11<00:12, 43.37it/s]
Loading safetensors checkpoint shards:  46% Completed | 467/1024 [00:11<00:14, 38.35it/s]
Loading safetensors checkpoint shards:  46% Completed | 473/1024 [00:11<00:13, 41.73it/s]
Loading safetensors checkpoint shards:  47% Completed | 478/1024 [00:11<00:13, 41.38it/s]
Loading safetensors checkpoint shards:  47% Completed | 483/1024 [00:11<00:12, 42.30it/s]
Loading safetensors checkpoint shards:  48% Completed | 488/1024 [00:11<00:13, 39.92it/s]
Loading safetensors checkpoint shards:  48% Completed | 493/1024 [00:11<00:13, 40.49it/s]
Loading safetensors checkpoint shards:  49% Completed | 498/1024 [00:11<00:14, 37.43it/s]
Loading safetensors checkpoint shards:  49% Completed | 503/1024 [00:12<00:13, 37.91it/s]
Loading safetensors checkpoint shards:  50% Completed | 508/1024 [00:12<00:12, 40.79it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:12<00:24, 20.85it/s]
Loading safetensors checkpoint shards:  51% Completed | 519/1024 [00:12<00:19, 25.97it/s]
Loading safetensors checkpoint shards:  51% Completed | 525/1024 [00:12<00:16, 31.17it/s]
Loading safetensors checkpoint shards:  52% Completed | 531/1024 [00:13<00:13, 36.24it/s]
Loading safetensors checkpoint shards:  52% Completed | 537/1024 [00:13<00:11, 40.62it/s]
Loading safetensors checkpoint shards:  53% Completed | 542/1024 [00:13<00:12, 38.06it/s]
Loading safetensors checkpoint shards:  53% Completed | 547/1024 [00:13<00:12, 38.04it/s]
Loading safetensors checkpoint shards:  54% Completed | 552/1024 [00:13<00:11, 39.40it/s]
Loading safetensors checkpoint shards:  54% Completed | 557/1024 [00:13<00:12, 38.29it/s]
Loading safetensors checkpoint shards:  55% Completed | 562/1024 [00:13<00:12, 38.27it/s]
Loading safetensors checkpoint shards:  55% Completed | 566/1024 [00:13<00:12, 35.66it/s]
Loading safetensors checkpoint shards:  56% Completed | 570/1024 [00:14<00:13, 33.10it/s]
Loading safetensors checkpoint shards:  56% Completed | 574/1024 [00:14<00:15, 28.76it/s]
Loading safetensors checkpoint shards:  56% Completed | 578/1024 [00:14<00:17, 25.69it/s]
Loading safetensors checkpoint shards:  57% Completed | 581/1024 [00:14<00:17, 25.85it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:14<00:15, 27.52it/s]
Loading safetensors checkpoint shards:  57% Completed | 588/1024 [00:14<00:16, 25.66it/s]
Loading safetensors checkpoint shards:  58% Completed | 591/1024 [00:14<00:16, 25.50it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:15<00:14, 29.56it/s]
Loading safetensors checkpoint shards:  59% Completed | 600/1024 [00:15<00:13, 31.61it/s]
Loading safetensors checkpoint shards:  59% Completed | 605/1024 [00:15<00:12, 34.86it/s]
Loading safetensors checkpoint shards:  59% Completed | 609/1024 [00:15<00:11, 35.32it/s]
Loading safetensors checkpoint shards:  60% Completed | 613/1024 [00:15<00:11, 35.42it/s]
Loading safetensors checkpoint shards:  60% Completed | 618/1024 [00:15<00:10, 37.52it/s]
Loading safetensors checkpoint shards:  61% Completed | 623/1024 [00:15<00:10, 38.35it/s]
Loading safetensors checkpoint shards:  61% Completed | 628/1024 [00:15<00:10, 38.80it/s]
Loading safetensors checkpoint shards:  62% Completed | 632/1024 [00:16<00:10, 37.12it/s]
Loading safetensors checkpoint shards:  62% Completed | 636/1024 [00:16<00:10, 36.90it/s]
Loading safetensors checkpoint shards:  62% Completed | 640/1024 [00:16<00:10, 37.16it/s]
Loading safetensors checkpoint shards:  63% Completed | 645/1024 [00:16<00:10, 37.87it/s]
Loading safetensors checkpoint shards:  63% Completed | 650/1024 [00:16<00:09, 39.25it/s]
Loading safetensors checkpoint shards:  64% Completed | 655/1024 [00:16<00:09, 40.08it/s]
Loading safetensors checkpoint shards:  64% Completed | 660/1024 [00:16<00:09, 39.38it/s]
Loading safetensors checkpoint shards:  65% Completed | 664/1024 [00:16<00:09, 38.50it/s]
Loading safetensors checkpoint shards:  65% Completed | 669/1024 [00:16<00:08, 39.75it/s]
Loading safetensors checkpoint shards:  66% Completed | 674/1024 [00:17<00:08, 40.80it/s]
Loading safetensors checkpoint shards:  66% Completed | 679/1024 [00:17<00:08, 40.57it/s]
Loading safetensors checkpoint shards:  67% Completed | 684/1024 [00:17<00:08, 41.30it/s]
Loading safetensors checkpoint shards:  67% Completed | 689/1024 [00:17<00:08, 41.65it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:17<00:07, 43.17it/s]
Loading safetensors checkpoint shards:  68% Completed | 699/1024 [00:17<00:07, 42.18it/s]
Loading safetensors checkpoint shards:  69% Completed | 704/1024 [00:17<00:08, 39.79it/s]
Loading safetensors checkpoint shards:  69% Completed | 709/1024 [00:17<00:07, 39.69it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:18<00:07, 40.42it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:18<00:07, 39.73it/s]
Loading safetensors checkpoint shards:  71% Completed | 724/1024 [00:18<00:07, 40.63it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:18<00:07, 41.30it/s]
Loading safetensors checkpoint shards:  72% Completed | 734/1024 [00:18<00:07, 40.59it/s]
Loading safetensors checkpoint shards:  72% Completed | 739/1024 [00:18<00:06, 41.19it/s]
Loading safetensors checkpoint shards:  73% Completed | 744/1024 [00:18<00:06, 41.51it/s]
Loading safetensors checkpoint shards:  73% Completed | 749/1024 [00:18<00:06, 40.41it/s]
Loading safetensors checkpoint shards:  74% Completed | 754/1024 [00:19<00:06, 40.26it/s]
Loading safetensors checkpoint shards:  74% Completed | 759/1024 [00:19<00:06, 39.22it/s]
Loading safetensors checkpoint shards:  75% Completed | 764/1024 [00:19<00:06, 39.95it/s]
Loading safetensors checkpoint shards:  75% Completed | 769/1024 [00:19<00:06, 40.80it/s]
Loading safetensors checkpoint shards:  76% Completed | 774/1024 [00:19<00:06, 40.67it/s]
Loading safetensors checkpoint shards:  76% Completed | 779/1024 [00:19<00:05, 41.48it/s]
Loading safetensors checkpoint shards:  77% Completed | 784/1024 [00:20<00:12, 19.18it/s]
Loading safetensors checkpoint shards:  77% Completed | 788/1024 [00:20<00:10, 21.92it/s]
Loading safetensors checkpoint shards:  77% Completed | 793/1024 [00:20<00:08, 25.75it/s]
Loading safetensors checkpoint shards:  78% Completed | 798/1024 [00:20<00:07, 29.21it/s]
Loading safetensors checkpoint shards:  78% Completed | 803/1024 [00:20<00:06, 33.11it/s]
Loading safetensors checkpoint shards:  79% Completed | 808/1024 [00:20<00:05, 36.22it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:20<00:05, 38.52it/s]
Loading safetensors checkpoint shards:  80% Completed | 818/1024 [00:21<00:05, 36.86it/s]
Loading safetensors checkpoint shards:  80% Completed | 823/1024 [00:21<00:05, 38.09it/s]
Loading safetensors checkpoint shards:  81% Completed | 828/1024 [00:21<00:04, 39.87it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:21<00:04, 41.51it/s]
Loading safetensors checkpoint shards:  82% Completed | 838/1024 [00:21<00:04, 41.67it/s]
Loading safetensors checkpoint shards:  82% Completed | 843/1024 [00:21<00:04, 41.45it/s]
Loading safetensors checkpoint shards:  83% Completed | 848/1024 [00:21<00:04, 42.40it/s]
Loading safetensors checkpoint shards:  83% Completed | 853/1024 [00:21<00:04, 42.40it/s]
Loading safetensors checkpoint shards:  84% Completed | 858/1024 [00:22<00:04, 41.24it/s]
Loading safetensors checkpoint shards:  84% Completed | 863/1024 [00:22<00:03, 40.88it/s]
Loading safetensors checkpoint shards:  85% Completed | 868/1024 [00:22<00:03, 40.79it/s]
Loading safetensors checkpoint shards:  85% Completed | 873/1024 [00:22<00:03, 40.82it/s]
Loading safetensors checkpoint shards:  86% Completed | 878/1024 [00:22<00:03, 40.16it/s]
Loading safetensors checkpoint shards:  86% Completed | 883/1024 [00:22<00:03, 40.53it/s]
Loading safetensors checkpoint shards:  87% Completed | 888/1024 [00:22<00:03, 41.36it/s]
Loading safetensors checkpoint shards:  87% Completed | 893/1024 [00:22<00:03, 40.89it/s]
Loading safetensors checkpoint shards:  88% Completed | 898/1024 [00:23<00:03, 41.36it/s]
Loading safetensors checkpoint shards:  88% Completed | 903/1024 [00:23<00:02, 41.10it/s]
Loading safetensors checkpoint shards:  89% Completed | 908/1024 [00:23<00:02, 40.37it/s]
Loading safetensors checkpoint shards:  89% Completed | 913/1024 [00:23<00:02, 39.02it/s]
Loading safetensors checkpoint shards:  90% Completed | 918/1024 [00:23<00:02, 40.55it/s]
Loading safetensors checkpoint shards:  90% Completed | 923/1024 [00:23<00:02, 39.21it/s]
Loading safetensors checkpoint shards:  91% Completed | 927/1024 [00:23<00:02, 38.72it/s]
Loading safetensors checkpoint shards:  91% Completed | 931/1024 [00:23<00:02, 37.46it/s]
Loading safetensors checkpoint shards:  91% Completed | 935/1024 [00:23<00:02, 37.52it/s]
Loading safetensors checkpoint shards:  92% Completed | 940/1024 [00:24<00:02, 38.06it/s]
Loading safetensors checkpoint shards:  92% Completed | 944/1024 [00:24<00:02, 38.31it/s]
Loading safetensors checkpoint shards:  93% Completed | 948/1024 [00:24<00:02, 37.59it/s]
Loading safetensors checkpoint shards:  93% Completed | 952/1024 [00:24<00:01, 37.40it/s]
Loading safetensors checkpoint shards:  93% Completed | 956/1024 [00:24<00:01, 37.26it/s]
Loading safetensors checkpoint shards:  94% Completed | 960/1024 [00:24<00:01, 37.04it/s]
Loading safetensors checkpoint shards:  94% Completed | 964/1024 [00:24<00:01, 36.09it/s]
Loading safetensors checkpoint shards:  95% Completed | 968/1024 [00:24<00:01, 36.49it/s]
Loading safetensors checkpoint shards:  95% Completed | 972/1024 [00:24<00:01, 35.67it/s]
Loading safetensors checkpoint shards:  95% Completed | 976/1024 [00:25<00:01, 36.06it/s]
Loading safetensors checkpoint shards:  96% Completed | 980/1024 [00:25<00:01, 36.52it/s]
Loading safetensors checkpoint shards:  97% Completed | 994/1024 [00:25<00:00, 64.14it/s]
Loading safetensors checkpoint shards:  98% Completed | 1003/1024 [00:25<00:00, 68.87it/s]
Loading safetensors checkpoint shards:  99% Completed | 1015/1024 [00:25<00:00, 81.58it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 40.06it/s]

[2025-09-13 07:42:06 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:42:07 TP1] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:42:07 TP0] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:42:07 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:42:07 TP7] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:42:07 TP2] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:42:07 TP3] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:42:07 TP6] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:42:07 TP4] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:42:07 TP5] KV Cache is allocated. #tokens: 620185, KV size: 40.59 GB
[2025-09-13 07:42:07 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:42:08 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.53 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:42:08 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:42:08 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:42:09 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:42:09 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:42:09 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:42:09 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:42:09 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:42:09 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:42:09 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25954.49it/s]
[2025-09-13 07:42:09 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:42:09 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26890.93it/s]
[2025-09-13 07:42:10 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:42:10 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28548.78it/s]
[2025-09-13 07:42:10 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:42:10 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27852.57it/s]
[2025-09-13 07:42:11 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:42:11 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28546.77it/s]
[2025-09-13 07:42:12 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.22 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.16it/s]
[2025-09-13 07:42:15 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:42:15 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:42:15 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:42:15 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:42:15 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:42:15 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:42:15 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:42:15 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:42:15 TP0] Capture cuda graph end. Time elapsed: 7.62 s. mem usage=0.36 GB. avail mem=17.20 GB.
[2025-09-13 07:42:15 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:42:15 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:42:15 TP0] Init torch distributed begin.
[2025-09-13 07:42:15 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:42:15 TP0] Load weight begin. avail mem=17.20 GB
[2025-09-13 07:42:15 TP0] Detected fp8 checkpoint.
[2025-09-13 07:42:15 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 19/1024 [00:00<00:05, 177.48it/s]
Loading safetensors checkpoint shards:   5% Completed | 48/1024 [00:00<00:04, 239.82it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:00<00:02, 398.80it/s]
Loading safetensors checkpoint shards:  16% Completed | 168/1024 [00:00<00:01, 474.71it/s]
Loading safetensors checkpoint shards:  22% Completed | 229/1024 [00:00<00:01, 521.40it/s]
Loading safetensors checkpoint shards:  28% Completed | 290/1024 [00:00<00:01, 550.94it/s]
Loading safetensors checkpoint shards:  34% Completed | 352/1024 [00:00<00:01, 570.88it/s]
Loading safetensors checkpoint shards:  41% Completed | 415/1024 [00:00<00:01, 589.02it/s]
Loading safetensors checkpoint shards:  47% Completed | 478/1024 [00:00<00:00, 599.56it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:01<00:00, 607.11it/s]
Loading safetensors checkpoint shards:  59% Completed | 605/1024 [00:01<00:00, 616.13it/s]
Loading safetensors checkpoint shards:  65% Completed | 667/1024 [00:01<00:00, 608.97it/s]
Loading safetensors checkpoint shards:  71% Completed | 728/1024 [00:01<00:00, 602.30it/s]
Loading safetensors checkpoint shards:  77% Completed | 789/1024 [00:01<00:00, 595.09it/s]
Loading safetensors checkpoint shards:  83% Completed | 849/1024 [00:01<00:00, 592.71it/s]
Loading safetensors checkpoint shards:  89% Completed | 909/1024 [00:01<00:00, 587.44it/s]
Loading safetensors checkpoint shards:  95% Completed | 968/1024 [00:01<00:00, 582.15it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:01<00:00, 513.73it/s]

[2025-09-13 07:42:17 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.21 GB, mem usage=1.99 GB.
[2025-09-13 07:42:17 TP2] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:42:17 TP0] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:42:17 TP6] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:42:17 TP0] Memory pool end. avail mem=14.54 GB
[2025-09-13 07:42:17 TP5] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:42:17 TP4] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:42:17 TP7] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:42:17 TP1] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:42:17 TP3] KV Cache is allocated. #tokens: 620185, KV size: 0.67 GB
[2025-09-13 07:42:18 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:42:18 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:42:18 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:42:18 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:42:18 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:42:18 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:42:18 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:42:18 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.17 GB
Capturing batches (bs=1 avail_mem=14.59 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  2.91it/s][2025-09-13 07:42:24 TP5] Registering 120 cuda graph addresses
[2025-09-13 07:42:24 TP2] Registering 120 cuda graph addresses
[2025-09-13 07:42:24 TP1] Registering 120 cuda graph addresses
[2025-09-13 07:42:24 TP3] Registering 120 cuda graph addresses
[2025-09-13 07:42:24 TP6] Registering 120 cuda graph addresses
[2025-09-13 07:42:24 TP4] Registering 120 cuda graph addresses
[2025-09-13 07:42:24 TP7] Registering 120 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.59 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.39it/s]
[2025-09-13 07:42:24 TP0] Registering 120 cuda graph addresses
[2025-09-13 07:42:24 TP0] Capture draft cuda graph end. Time elapsed: 6.43 s. mem usage=0.39 GB. avail mem=14.59 GB.
[2025-09-13 07:42:24 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.59 GB
[2025-09-13 07:42:24 TP4] Capture draft cuda graph end. Time elapsed: 6.44 s. mem usage=0.39 GB. avail mem=14.55 GB.
[2025-09-13 07:42:24 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.55 GB
[2025-09-13 07:42:24 TP3] Capture draft cuda graph end. Time elapsed: 6.44 s. mem usage=0.39 GB. avail mem=14.55 GB.
[2025-09-13 07:42:24 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.55 GB
[2025-09-13 07:42:24 TP5] Capture draft cuda graph end. Time elapsed: 6.44 s. mem usage=0.39 GB. avail mem=14.55 GB.
[2025-09-13 07:42:24 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.55 GB
[2025-09-13 07:42:24 TP1] Capture draft cuda graph end. Time elapsed: 6.44 s. mem usage=0.39 GB. avail mem=14.55 GB.
[2025-09-13 07:42:24 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.55 GB
[2025-09-13 07:42:24 TP6] Capture draft cuda graph end. Time elapsed: 6.44 s. mem usage=0.39 GB. avail mem=14.55 GB.
[2025-09-13 07:42:24 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.55 GB
[2025-09-13 07:42:24 TP2] Capture draft cuda graph end. Time elapsed: 6.46 s. mem usage=0.39 GB. avail mem=14.55 GB.
[2025-09-13 07:42:24 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.55 GB
[2025-09-13 07:42:24 TP7] Capture draft cuda graph end. Time elapsed: 6.46 s. mem usage=0.39 GB. avail mem=14.78 GB.
[2025-09-13 07:42:24 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.78 GB
Capturing batches (bs=1 avail_mem=14.39 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:00<00:00, 19.52it/s][2025-09-13 07:42:25 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:42:25 TP2] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.39 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 19.23it/s]
[2025-09-13 07:42:25 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:42:25 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:42:25 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:42:25 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:42:25 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:42:25 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:42:25 TP6] Capture draft extend cuda graph end. Time elapsed: 1.16 s. mem usage=0.20 GB. avail mem=14.34 GB.
[2025-09-13 07:42:25 TP2] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.20 GB. avail mem=14.34 GB.
[2025-09-13 07:42:25 TP7] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.20 GB. avail mem=14.58 GB.
[2025-09-13 07:42:25 TP0] Capture draft extend cuda graph end. Time elapsed: 1.18 s. mem usage=0.20 GB. avail mem=14.38 GB.
[2025-09-13 07:42:25 TP4] Capture draft extend cuda graph end. Time elapsed: 1.17 s. mem usage=0.20 GB. avail mem=14.34 GB.
[2025-09-13 07:42:25 TP1] Capture draft extend cuda graph end. Time elapsed: 1.16 s. mem usage=0.20 GB. avail mem=14.34 GB.
[2025-09-13 07:42:25 TP3] Capture draft extend cuda graph end. Time elapsed: 1.16 s. mem usage=0.20 GB. avail mem=14.34 GB.
[2025-09-13 07:42:25 TP0] max_total_num_tokens=620185, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.38 GB
[2025-09-13 07:42:25 TP5] Capture draft extend cuda graph end. Time elapsed: 1.16 s. mem usage=0.20 GB. avail mem=14.34 GB.
[2025-09-13 07:42:26] INFO:     Started server process [339006]
[2025-09-13 07:42:26] INFO:     Waiting for application startup.
[2025-09-13 07:42:26] INFO:     Application startup complete.
[2025-09-13 07:42:26] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:42:27] INFO:     127.0.0.1:34778 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:42:27 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:42:27 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:42:27 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup:   0%|                                                                                                                      | 0/16384 [00:00<?, ?it/s][2025-09-13 07:42:27] INFO:     127.0.0.1:34794 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28353.61it/s]
[2025-09-13 07:42:28] INFO:     127.0.0.1:34784 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:28] The server is fired up and ready to roll!
[2025-09-13 07:42:37 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:42:38] INFO:     127.0.0.1:55288 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:42:38] INFO:     127.0.0.1:55764 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:38 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:42:40] INFO:     127.0.0.1:55766 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:40] INFO:     127.0.0.1:55774 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:42:40] INFO:     127.0.0.1:55786 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:40] INFO:     127.0.0.1:55800 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:40] INFO:     127.0.0.1:55812 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:40] INFO:     127.0.0.1:55824 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:40] INFO:     127.0.0.1:55836 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:40] INFO:     127.0.0.1:55838 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:40 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:42:40 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:42:40 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:42:40 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:42:40 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:42:40 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:42:40 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:42:40 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:42:40 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:42:40 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:42:41 TP0] Decode batch. #running-req: 8, #token: 14458, token usage: 0.02, accept len: 2.58, cuda graph: True, gen throughput (token/s): 35.67, #queue-req: 0, 
[2025-09-13 07:42:43 TP0] Decode batch. #running-req: 8, #token: 15391, token usage: 0.02, accept len: 2.92, cuda graph: True, gen throughput (token/s): 753.05, #queue-req: 0, 
[2025-09-13 07:42:44 TP0] Decode batch. #running-req: 8, #token: 16399, token usage: 0.03, accept len: 3.15, cuda graph: True, gen throughput (token/s): 807.94, #queue-req: 0, 
[2025-09-13 07:42:45 TP0] Decode batch. #running-req: 8, #token: 17399, token usage: 0.03, accept len: 3.12, cuda graph: True, gen throughput (token/s): 799.69, #queue-req: 0, 
 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 7/8 [00:06<00:00,  2.29it/s][2025-09-13 07:42:46 TP0] Decode batch. #running-req: 1, #token: 0, token usage: 0.00, accept len: 3.20, cuda graph: True, gen throughput (token/s): 494.78, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.22it/s]
[2025-09-13 07:42:46] INFO:     127.0.0.1:55854 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.54      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4076      
Request throughput (req/s):              1.22      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         626.57    
Total token throughput (tok/s):          626.57    
Concurrency:                             7.40      
Accept length:                           3.00      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   6043.77   
Median E2E Latency (ms):                 6090.12   
---------------Time to First Token----------------
Mean TTFT (ms):                          608.25    
Median TTFT (ms):                        718.95    
P99 TTFT (ms):                           719.46    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.64     
Median ITL (ms):                         7.82      
P95 ITL (ms):                            28.58     
P99 ITL (ms):                            31.87     
Max ITL (ms):                            723.62    
==================================================
[2025-09-13 07:42:46] INFO:     127.0.0.1:55864 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:42:46] INFO:     127.0.0.1:55876 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:42:48] INFO:     127.0.0.1:57182 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:48] INFO:     127.0.0.1:57184 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:48 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:42:48] INFO:     127.0.0.1:57188 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:48] INFO:     127.0.0.1:57200 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:48] INFO:     127.0.0.1:57208 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:48] INFO:     127.0.0.1:57216 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:48] INFO:     127.0.0.1:57224 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:48] INFO:     127.0.0.1:57230 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:48 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:42:49 TP0] Decode batch. #running-req: 8, #token: 14531, token usage: 0.02, accept len: 2.64, cuda graph: True, gen throughput (token/s): 257.99, #queue-req: 0, 
[2025-09-13 07:42:50 TP0] Decode batch. #running-req: 8, #token: 15470, token usage: 0.02, accept len: 2.93, cuda graph: True, gen throughput (token/s): 757.21, #queue-req: 0, 
[2025-09-13 07:42:51 TP0] Decode batch. #running-req: 8, #token: 16476, token usage: 0.03, accept len: 3.14, cuda graph: True, gen throughput (token/s): 805.26, #queue-req: 0, 
[2025-09-13 07:42:53 TP0] Decode batch. #running-req: 8, #token: 17474, token usage: 0.03, accept len: 3.12, cuda graph: True, gen throughput (token/s): 799.67, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:13,  4.91s/it][2025-09-13 07:42:53] INFO:     127.0.0.1:57240 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:53 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:05<00:32,  2.35s/it][2025-09-13 07:42:53] INFO:     127.0.0.1:57256 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:53 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:42:53] INFO:     127.0.0.1:57266 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:53 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:12,  1.04s/it][2025-09-13 07:42:54] INFO:     127.0.0.1:57274 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:54 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:06<00:08,  1.23it/s][2025-09-13 07:42:54] INFO:     127.0.0.1:57278 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:54 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:06<00:06,  1.58it/s][2025-09-13 07:42:54] INFO:     127.0.0.1:57292 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:54 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:04,  2.00it/s][2025-09-13 07:42:54] INFO:     127.0.0.1:57300 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:55 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:07<00:03,  2.24it/s][2025-09-13 07:42:55] INFO:     127.0.0.1:57302 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:42:55 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:42:55 TP0] Decode batch. #running-req: 8, #token: 13870, token usage: 0.02, accept len: 3.00, cuda graph: True, gen throughput (token/s): 374.32, #queue-req: 0, 
[2025-09-13 07:42:56 TP0] Decode batch. #running-req: 8, #token: 14770, token usage: 0.02, accept len: 2.81, cuda graph: True, gen throughput (token/s): 737.01, #queue-req: 0, 
[2025-09-13 07:42:58 TP0] Decode batch. #running-req: 8, #token: 15786, token usage: 0.03, accept len: 3.17, cuda graph: True, gen throughput (token/s): 817.68, #queue-req: 0, 
[2025-09-13 07:42:59 TP0] Decode batch. #running-req: 8, #token: 15863, token usage: 0.03, accept len: 3.10, cuda graph: True, gen throughput (token/s): 796.34, #queue-req: 0, 
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 14/16 [00:12<00:00,  2.15it/s][2025-09-13 07:43:00 TP0] Decode batch. #running-req: 2, #token: 6501, token usage: 0.01, accept len: 3.23, cuda graph: True, gen throughput (token/s): 652.77, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:12<00:00,  1.28it/s]
[2025-09-13 07:43:00] INFO:     127.0.0.1:41308 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  12.52     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8083      
Request throughput (req/s):              1.28      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         654.26    
Total token throughput (tok/s):          654.26    
Concurrency:                             7.59      
Accept length:                           3.01      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5941.78   
Median E2E Latency (ms):                 5791.82   
---------------Time to First Token----------------
Mean TTFT (ms):                          230.82    
Median TTFT (ms):                        272.64    
P99 TTFT (ms):                           292.41    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           11.18     
Median ITL (ms):                         7.81      
P95 ITL (ms):                            30.55     
P99 ITL (ms):                            66.11     
Max ITL (ms):                            264.46    
==================================================
[2025-09-13 07:43:00] INFO:     127.0.0.1:41314 - "GET /get_server_info HTTP/1.1" 200 OK
[2025-09-13 07:43:00 TP6] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2612, in run_scheduler_process
    scheduler.event_loop_normal()
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 811, in event_loop_normal
    recv_reqs = self.recv_requests()
                ^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 1095, in recv_requests
    recv_reqs = broadcast_pyobj(
                ^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/utils.py", line 1059, in broadcast_pyobj
    dist.broadcast(tensor_size, src=src, group=dist_group)
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
    work.wait()
RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [172.17.0.8]:10146

[2025-09-13 07:43:00 TP7] Scheduler hit an exception: Traceback (most recent call last):
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2612, in run_scheduler_process
    scheduler.event_loop_normal()
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 811, in event_loop_normal
    recv_reqs = self.recv_requests()
                ^^^^^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 1095, in recv_requests
    recv_reqs = broadcast_pyobj(
                ^^^^^^^^^^^^^^^^
  File "/sgl-workspace/sglang/python/sglang/srt/utils.py", line 1059, in broadcast_pyobj
    dist.broadcast(tensor_size, src=src, group=dist_group)
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py", line 2830, in broadcast
    work.wait()
RuntimeError: [/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:544] Connection closed by peer [172.17.0.8]:57249

[2025-09-13 07:43:00] Received sigquit from a child process. It usually means the child failed.
/usr/lib/python3.12/multiprocessing/resource_tracker.py:147: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.
  warnings.warn('resource_tracker: process died unexpectedly, '
/usr/lib/python3.12/multiprocessing/resource_tracker.py:147: UserWarning: resource_tracker: process died unexpectedly, relaunching.  Some resources might leak.
  warnings.warn('resource_tracker: process died unexpectedly, '
Finish i=37: batch_size=8, steps=6, topk=2, num_draft_tokens=4, speed=97.17 token/s, step_time=31.01 ms
Start i=38: batch_size=8, steps=6, topk=2, num_draft_tokens=6
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 6 --speculative-eagle-topk 2 --speculative-num-draft-tokens 6 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:43:11.686000 346106 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:43:11.686000 346106 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:43:12] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=226896249, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=6, speculative_eagle_topk=2, speculative_num_draft_tokens=6, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:43:12] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:43:20.905000 346332 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:43:20.905000 346332 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:43:21.010000 346331 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:43:21.010000 346331 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:43:21.029000 346329 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:43:21.029000 346329 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 07:43:21.178000 346334 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:43:21.178000 346334 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:43:21.216000 346328 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:43:21.216000 346328 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:43:21.251000 346330 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:43:21.251000 346330 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:43:21.295000 346327 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:43:21.295000 346327 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:43:21.377000 346326 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:43:21.377000 346326 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:43:21.491000 346333 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:43:21.491000 346333 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:43:21 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:43:21 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:43:21 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:43:23 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:43:26 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:43:27 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:43:27 TP0] Detected fp8 checkpoint.
[2025-09-13 07:43:28 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 27/1024 [00:00<00:03, 263.40it/s]
Loading safetensors checkpoint shards:   5% Completed | 54/1024 [00:00<00:12, 75.77it/s]
Loading safetensors checkpoint shards:   7% Completed | 68/1024 [00:01<00:19, 50.07it/s]
Loading safetensors checkpoint shards:   8% Completed | 77/1024 [00:01<00:21, 44.87it/s]
Loading safetensors checkpoint shards:   8% Completed | 84/1024 [00:01<00:21, 44.01it/s]
Loading safetensors checkpoint shards:   9% Completed | 90/1024 [00:01<00:21, 43.31it/s]
Loading safetensors checkpoint shards:   9% Completed | 96/1024 [00:01<00:22, 41.99it/s]
Loading safetensors checkpoint shards:  10% Completed | 101/1024 [00:02<00:21, 42.35it/s]
Loading safetensors checkpoint shards:  10% Completed | 106/1024 [00:02<00:36, 25.41it/s]
Loading safetensors checkpoint shards:  11% Completed | 110/1024 [00:02<00:33, 27.27it/s]
Loading safetensors checkpoint shards:  11% Completed | 114/1024 [00:02<00:31, 29.33it/s]
Loading safetensors checkpoint shards:  12% Completed | 119/1024 [00:02<00:28, 32.27it/s]
Loading safetensors checkpoint shards:  12% Completed | 123/1024 [00:02<00:26, 33.77it/s]
Loading safetensors checkpoint shards:  12% Completed | 128/1024 [00:03<00:24, 36.47it/s]
Loading safetensors checkpoint shards:  13% Completed | 133/1024 [00:03<00:25, 34.40it/s]
Loading safetensors checkpoint shards:  14% Completed | 139/1024 [00:03<00:23, 38.02it/s]
Loading safetensors checkpoint shards:  14% Completed | 144/1024 [00:03<00:23, 37.59it/s]
Loading safetensors checkpoint shards:  14% Completed | 148/1024 [00:03<00:24, 36.26it/s]
Loading safetensors checkpoint shards:  15% Completed | 153/1024 [00:03<00:23, 37.84it/s]
Loading safetensors checkpoint shards:  15% Completed | 157/1024 [00:03<00:23, 37.41it/s]
Loading safetensors checkpoint shards:  16% Completed | 162/1024 [00:03<00:21, 39.69it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:04<00:22, 38.53it/s]
Loading safetensors checkpoint shards:  17% Completed | 172/1024 [00:04<00:21, 40.51it/s]
Loading safetensors checkpoint shards:  17% Completed | 177/1024 [00:04<00:20, 40.43it/s]
Loading safetensors checkpoint shards:  18% Completed | 182/1024 [00:04<00:21, 39.85it/s]
Loading safetensors checkpoint shards:  18% Completed | 187/1024 [00:04<00:21, 38.35it/s]
Loading safetensors checkpoint shards:  19% Completed | 191/1024 [00:04<00:21, 38.25it/s]
Loading safetensors checkpoint shards:  19% Completed | 196/1024 [00:04<00:20, 40.10it/s]
Loading safetensors checkpoint shards:  20% Completed | 201/1024 [00:04<00:21, 38.50it/s]
Loading safetensors checkpoint shards:  20% Completed | 205/1024 [00:04<00:21, 38.73it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:05<00:21, 37.38it/s]
Loading safetensors checkpoint shards:  21% Completed | 213/1024 [00:05<00:21, 37.58it/s]
Loading safetensors checkpoint shards:  21% Completed | 218/1024 [00:05<00:20, 38.50it/s]
Loading safetensors checkpoint shards:  22% Completed | 222/1024 [00:05<00:21, 37.77it/s]
Loading safetensors checkpoint shards:  22% Completed | 226/1024 [00:05<00:20, 38.33it/s]
Loading safetensors checkpoint shards:  22% Completed | 230/1024 [00:05<00:21, 37.50it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:05<00:21, 37.07it/s]
Loading safetensors checkpoint shards:  23% Completed | 239/1024 [00:05<00:20, 38.05it/s]
Loading safetensors checkpoint shards:  24% Completed | 243/1024 [00:06<00:20, 37.68it/s]
Loading safetensors checkpoint shards:  24% Completed | 247/1024 [00:06<00:21, 36.95it/s]
Loading safetensors checkpoint shards:  25% Completed | 252/1024 [00:06<00:19, 40.42it/s]
Loading safetensors checkpoint shards:  25% Completed | 257/1024 [00:06<00:19, 38.94it/s]
Loading safetensors checkpoint shards:  26% Completed | 262/1024 [00:06<00:18, 40.17it/s]
Loading safetensors checkpoint shards:  26% Completed | 267/1024 [00:06<00:19, 39.72it/s]
Loading safetensors checkpoint shards:  27% Completed | 272/1024 [00:06<00:18, 40.83it/s]
Loading safetensors checkpoint shards:  27% Completed | 277/1024 [00:06<00:19, 39.01it/s]
Loading safetensors checkpoint shards:  27% Completed | 281/1024 [00:06<00:19, 39.05it/s]
Loading safetensors checkpoint shards:  28% Completed | 286/1024 [00:07<00:18, 40.90it/s]
Loading safetensors checkpoint shards:  28% Completed | 291/1024 [00:07<00:18, 39.82it/s]
Loading safetensors checkpoint shards:  29% Completed | 296/1024 [00:07<00:17, 42.00it/s]
Loading safetensors checkpoint shards:  29% Completed | 301/1024 [00:07<00:17, 41.07it/s]
Loading safetensors checkpoint shards:  30% Completed | 306/1024 [00:07<00:35, 20.28it/s]
Loading safetensors checkpoint shards:  30% Completed | 310/1024 [00:08<00:30, 23.06it/s]
Loading safetensors checkpoint shards:  31% Completed | 314/1024 [00:08<00:27, 25.81it/s]
Loading safetensors checkpoint shards:  31% Completed | 319/1024 [00:08<00:23, 29.73it/s]
Loading safetensors checkpoint shards:  32% Completed | 323/1024 [00:08<00:22, 31.21it/s]
Loading safetensors checkpoint shards:  32% Completed | 328/1024 [00:08<00:20, 34.31it/s]
Loading safetensors checkpoint shards:  32% Completed | 332/1024 [00:08<00:19, 34.87it/s]
Loading safetensors checkpoint shards:  33% Completed | 336/1024 [00:08<00:19, 35.16it/s]
Loading safetensors checkpoint shards:  33% Completed | 341/1024 [00:08<00:18, 37.59it/s]
Loading safetensors checkpoint shards:  34% Completed | 345/1024 [00:08<00:18, 36.26it/s]
Loading safetensors checkpoint shards:  34% Completed | 350/1024 [00:09<00:17, 37.89it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:09<00:17, 37.31it/s]
Loading safetensors checkpoint shards:  35% Completed | 358/1024 [00:09<00:17, 37.23it/s]
Loading safetensors checkpoint shards:  35% Completed | 363/1024 [00:09<00:17, 38.84it/s]
Loading safetensors checkpoint shards:  36% Completed | 367/1024 [00:09<00:17, 38.58it/s]
Loading safetensors checkpoint shards:  36% Completed | 372/1024 [00:09<00:16, 40.56it/s]
Loading safetensors checkpoint shards:  37% Completed | 377/1024 [00:09<00:16, 39.48it/s]
Loading safetensors checkpoint shards:  37% Completed | 382/1024 [00:09<00:15, 41.63it/s]
Loading safetensors checkpoint shards:  38% Completed | 387/1024 [00:10<00:15, 41.09it/s]
Loading safetensors checkpoint shards:  38% Completed | 392/1024 [00:10<00:16, 38.71it/s]
Loading safetensors checkpoint shards:  39% Completed | 397/1024 [00:10<00:15, 40.14it/s]
Loading safetensors checkpoint shards:  39% Completed | 402/1024 [00:10<00:16, 38.50it/s]
Loading safetensors checkpoint shards:  40% Completed | 407/1024 [00:10<00:15, 40.01it/s]
Loading safetensors checkpoint shards:  40% Completed | 412/1024 [00:10<00:15, 38.94it/s]
Loading safetensors checkpoint shards:  41% Completed | 417/1024 [00:10<00:15, 39.08it/s]
Loading safetensors checkpoint shards:  41% Completed | 421/1024 [00:10<00:15, 38.94it/s]
Loading safetensors checkpoint shards:  42% Completed | 425/1024 [00:11<00:15, 37.82it/s]
Loading safetensors checkpoint shards:  42% Completed | 430/1024 [00:11<00:15, 38.76it/s]
Loading safetensors checkpoint shards:  42% Completed | 434/1024 [00:11<00:16, 36.69it/s]
Loading safetensors checkpoint shards:  43% Completed | 439/1024 [00:11<00:15, 38.40it/s]
Loading safetensors checkpoint shards:  43% Completed | 444/1024 [00:11<00:14, 39.02it/s]
Loading safetensors checkpoint shards:  44% Completed | 449/1024 [00:11<00:14, 40.18it/s]
Loading safetensors checkpoint shards:  44% Completed | 454/1024 [00:11<00:13, 40.91it/s]
Loading safetensors checkpoint shards:  45% Completed | 460/1024 [00:11<00:12, 44.72it/s]
Loading safetensors checkpoint shards:  46% Completed | 466/1024 [00:11<00:11, 47.35it/s]
Loading safetensors checkpoint shards:  46% Completed | 472/1024 [00:12<00:11, 47.30it/s]
Loading safetensors checkpoint shards:  47% Completed | 477/1024 [00:12<00:12, 43.12it/s]
Loading safetensors checkpoint shards:  47% Completed | 482/1024 [00:12<00:13, 39.31it/s]
Loading safetensors checkpoint shards:  48% Completed | 487/1024 [00:12<00:13, 38.46it/s]
Loading safetensors checkpoint shards:  48% Completed | 491/1024 [00:12<00:14, 36.78it/s]
Loading safetensors checkpoint shards:  48% Completed | 496/1024 [00:12<00:13, 39.19it/s]
Loading safetensors checkpoint shards:  49% Completed | 501/1024 [00:12<00:13, 39.51it/s]
Loading safetensors checkpoint shards:  49% Completed | 506/1024 [00:12<00:12, 40.23it/s]
Loading safetensors checkpoint shards:  50% Completed | 511/1024 [00:13<00:12, 39.50it/s]
Loading safetensors checkpoint shards:  50% Completed | 516/1024 [00:13<00:12, 41.49it/s]
Loading safetensors checkpoint shards:  51% Completed | 521/1024 [00:13<00:12, 40.24it/s]
Loading safetensors checkpoint shards:  51% Completed | 526/1024 [00:13<00:12, 41.28it/s]
Loading safetensors checkpoint shards:  52% Completed | 531/1024 [00:13<00:12, 40.46it/s]
Loading safetensors checkpoint shards:  52% Completed | 536/1024 [00:13<00:12, 39.34it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:13<00:11, 40.26it/s]
Loading safetensors checkpoint shards:  53% Completed | 546/1024 [00:13<00:12, 39.16it/s]
Loading safetensors checkpoint shards:  54% Completed | 550/1024 [00:14<00:26, 17.83it/s]
Loading safetensors checkpoint shards:  54% Completed | 554/1024 [00:14<00:22, 20.65it/s]
Loading safetensors checkpoint shards:  54% Completed | 558/1024 [00:14<00:20, 22.62it/s]
Loading safetensors checkpoint shards:  55% Completed | 563/1024 [00:14<00:17, 26.43it/s]
Loading safetensors checkpoint shards:  55% Completed | 567/1024 [00:15<00:16, 28.12it/s]
Loading safetensors checkpoint shards:  56% Completed | 572/1024 [00:15<00:14, 31.69it/s]
Loading safetensors checkpoint shards:  56% Completed | 576/1024 [00:15<00:14, 31.85it/s]
Loading safetensors checkpoint shards:  57% Completed | 580/1024 [00:15<00:13, 33.08it/s]
Loading safetensors checkpoint shards:  57% Completed | 586/1024 [00:15<00:11, 37.44it/s]
Loading safetensors checkpoint shards:  58% Completed | 590/1024 [00:15<00:11, 36.78it/s]
Loading safetensors checkpoint shards:  58% Completed | 595/1024 [00:15<00:11, 38.95it/s]
Loading safetensors checkpoint shards:  59% Completed | 600/1024 [00:15<00:11, 38.20it/s]
Loading safetensors checkpoint shards:  59% Completed | 605/1024 [00:16<00:10, 40.29it/s]
Loading safetensors checkpoint shards:  60% Completed | 610/1024 [00:16<00:10, 39.12it/s]
Loading safetensors checkpoint shards:  60% Completed | 614/1024 [00:16<00:10, 38.88it/s]
Loading safetensors checkpoint shards:  60% Completed | 619/1024 [00:16<00:09, 41.53it/s]
Loading safetensors checkpoint shards:  61% Completed | 624/1024 [00:16<00:09, 41.62it/s]
Loading safetensors checkpoint shards:  61% Completed | 629/1024 [00:16<00:09, 41.33it/s]
Loading safetensors checkpoint shards:  62% Completed | 634/1024 [00:16<00:09, 39.68it/s]
Loading safetensors checkpoint shards:  62% Completed | 639/1024 [00:16<00:09, 39.55it/s]
Loading safetensors checkpoint shards:  63% Completed | 644/1024 [00:16<00:09, 39.76it/s]
Loading safetensors checkpoint shards:  63% Completed | 648/1024 [00:17<00:09, 38.78it/s]
Loading safetensors checkpoint shards:  64% Completed | 652/1024 [00:17<00:09, 39.06it/s]
Loading safetensors checkpoint shards:  64% Completed | 657/1024 [00:17<00:09, 39.57it/s]
Loading safetensors checkpoint shards:  65% Completed | 661/1024 [00:17<00:09, 36.92it/s]
Loading safetensors checkpoint shards:  65% Completed | 665/1024 [00:17<00:09, 37.18it/s]
Loading safetensors checkpoint shards:  65% Completed | 669/1024 [00:17<00:09, 37.86it/s]
Loading safetensors checkpoint shards:  66% Completed | 674/1024 [00:17<00:09, 38.81it/s]
Loading safetensors checkpoint shards:  66% Completed | 678/1024 [00:17<00:08, 38.62it/s]
Loading safetensors checkpoint shards:  67% Completed | 683/1024 [00:18<00:08, 39.80it/s]
Loading safetensors checkpoint shards:  67% Completed | 688/1024 [00:18<00:08, 40.33it/s]
Loading safetensors checkpoint shards:  68% Completed | 693/1024 [00:18<00:07, 41.82it/s]
Loading safetensors checkpoint shards:  68% Completed | 698/1024 [00:18<00:07, 41.02it/s]
Loading safetensors checkpoint shards:  69% Completed | 703/1024 [00:18<00:08, 39.62it/s]
Loading safetensors checkpoint shards:  69% Completed | 707/1024 [00:18<00:08, 39.37it/s]
Loading safetensors checkpoint shards:  69% Completed | 711/1024 [00:18<00:08, 38.61it/s]
Loading safetensors checkpoint shards:  70% Completed | 716/1024 [00:18<00:07, 39.26it/s]
Loading safetensors checkpoint shards:  70% Completed | 720/1024 [00:18<00:07, 39.08it/s]
Loading safetensors checkpoint shards:  71% Completed | 725/1024 [00:19<00:07, 39.77it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:19<00:07, 39.75it/s]
Loading safetensors checkpoint shards:  72% Completed | 733/1024 [00:19<00:07, 38.52it/s]
Loading safetensors checkpoint shards:  72% Completed | 737/1024 [00:19<00:07, 38.23it/s]
Loading safetensors checkpoint shards:  72% Completed | 742/1024 [00:19<00:07, 39.04it/s]
Loading safetensors checkpoint shards:  73% Completed | 747/1024 [00:19<00:07, 38.46it/s]
Loading safetensors checkpoint shards:  73% Completed | 752/1024 [00:19<00:06, 39.12it/s]
Loading safetensors checkpoint shards:  74% Completed | 757/1024 [00:19<00:06, 39.35it/s]
Loading safetensors checkpoint shards:  74% Completed | 761/1024 [00:19<00:06, 39.20it/s]
Loading safetensors checkpoint shards:  75% Completed | 765/1024 [00:20<00:06, 38.98it/s]
Loading safetensors checkpoint shards:  75% Completed | 770/1024 [00:20<00:06, 39.89it/s]
Loading safetensors checkpoint shards:  76% Completed | 774/1024 [00:20<00:06, 39.58it/s]
Loading safetensors checkpoint shards:  76% Completed | 778/1024 [00:20<00:06, 39.61it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:20<00:06, 39.69it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:20<00:06, 38.49it/s]
Loading safetensors checkpoint shards:  77% Completed | 791/1024 [00:20<00:06, 38.78it/s]
Loading safetensors checkpoint shards:  78% Completed | 795/1024 [00:20<00:05, 38.93it/s]
Loading safetensors checkpoint shards:  78% Completed | 799/1024 [00:20<00:05, 39.00it/s]
Loading safetensors checkpoint shards:  79% Completed | 804/1024 [00:21<00:05, 40.66it/s]
Loading safetensors checkpoint shards:  79% Completed | 809/1024 [00:21<00:05, 40.37it/s]
Loading safetensors checkpoint shards:  79% Completed | 814/1024 [00:21<00:05, 40.51it/s]
Loading safetensors checkpoint shards:  80% Completed | 819/1024 [00:21<00:05, 38.58it/s]
Loading safetensors checkpoint shards:  80% Completed | 824/1024 [00:21<00:05, 39.07it/s]
Loading safetensors checkpoint shards:  81% Completed | 829/1024 [00:21<00:04, 39.41it/s]
Loading safetensors checkpoint shards:  81% Completed | 834/1024 [00:21<00:04, 39.63it/s]
Loading safetensors checkpoint shards:  82% Completed | 838/1024 [00:21<00:04, 39.66it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:22<00:04, 39.72it/s]
Loading safetensors checkpoint shards:  83% Completed | 846/1024 [00:22<00:10, 16.24it/s]
Loading safetensors checkpoint shards:  83% Completed | 851/1024 [00:22<00:08, 20.41it/s]
Loading safetensors checkpoint shards:  84% Completed | 856/1024 [00:22<00:06, 24.55it/s]
Loading safetensors checkpoint shards:  84% Completed | 860/1024 [00:22<00:06, 27.15it/s]
Loading safetensors checkpoint shards:  84% Completed | 865/1024 [00:23<00:05, 30.83it/s]
Loading safetensors checkpoint shards:  85% Completed | 870/1024 [00:23<00:04, 33.94it/s]
Loading safetensors checkpoint shards:  85% Completed | 875/1024 [00:23<00:04, 35.36it/s]
Loading safetensors checkpoint shards:  86% Completed | 880/1024 [00:23<00:03, 37.47it/s]
Loading safetensors checkpoint shards:  86% Completed | 885/1024 [00:23<00:03, 39.14it/s]
Loading safetensors checkpoint shards:  87% Completed | 890/1024 [00:23<00:03, 39.42it/s]
Loading safetensors checkpoint shards:  87% Completed | 895/1024 [00:23<00:03, 40.64it/s]
Loading safetensors checkpoint shards:  88% Completed | 900/1024 [00:23<00:03, 41.29it/s]
Loading safetensors checkpoint shards:  88% Completed | 905/1024 [00:24<00:02, 41.81it/s]
Loading safetensors checkpoint shards:  89% Completed | 910/1024 [00:24<00:02, 41.82it/s]
Loading safetensors checkpoint shards:  89% Completed | 915/1024 [00:24<00:02, 43.10it/s]
Loading safetensors checkpoint shards:  90% Completed | 920/1024 [00:24<00:02, 42.88it/s]
Loading safetensors checkpoint shards:  90% Completed | 925/1024 [00:24<00:02, 42.61it/s]
Loading safetensors checkpoint shards:  91% Completed | 930/1024 [00:24<00:02, 42.09it/s]
Loading safetensors checkpoint shards:  91% Completed | 935/1024 [00:24<00:02, 42.76it/s]
Loading safetensors checkpoint shards:  92% Completed | 940/1024 [00:24<00:01, 43.47it/s]
Loading safetensors checkpoint shards:  92% Completed | 945/1024 [00:24<00:01, 42.87it/s]
Loading safetensors checkpoint shards:  93% Completed | 950/1024 [00:25<00:01, 43.38it/s]
Loading safetensors checkpoint shards:  93% Completed | 955/1024 [00:25<00:01, 44.26it/s]
Loading safetensors checkpoint shards:  94% Completed | 960/1024 [00:25<00:01, 45.20it/s]
Loading safetensors checkpoint shards:  94% Completed | 965/1024 [00:25<00:01, 44.48it/s]
Loading safetensors checkpoint shards:  95% Completed | 970/1024 [00:25<00:01, 44.64it/s]
Loading safetensors checkpoint shards:  95% Completed | 975/1024 [00:25<00:01, 44.88it/s]
Loading safetensors checkpoint shards:  96% Completed | 980/1024 [00:25<00:00, 45.45it/s]
Loading safetensors checkpoint shards:  97% Completed | 995/1024 [00:25<00:00, 73.94it/s]
Loading safetensors checkpoint shards:  98% Completed | 1004/1024 [00:25<00:00, 77.77it/s]
Loading safetensors checkpoint shards:  99% Completed | 1017/1024 [00:26<00:00, 92.45it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:26<00:00, 39.26it/s]

[2025-09-13 07:43:54 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:43:57 TP2] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:43:57 TP6] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:43:57 TP4] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:43:57 TP5] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:43:57 TP7] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:43:57 TP3] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:43:57 TP1] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:43:57 TP0] KV Cache is allocated. #tokens: 620201, KV size: 40.59 GB
[2025-09-13 07:43:57 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:43:57 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:43:57 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.52 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:43:58 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:43:58 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:43:58 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:43:58 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:43:58 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:43:58 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:43:58 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:43:58 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:43:58 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26091.10it/s]
[2025-09-13 07:43:59 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:43:59 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27144.53it/s]
[2025-09-13 07:43:59 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:43:59 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28476.52it/s]
[2025-09-13 07:44:00 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:44:00 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27838.43it/s]
[2025-09-13 07:44:01 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:44:01 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28728.04it/s]
[2025-09-13 07:44:01 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.23 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.87it/s][2025-09-13 07:44:04 TP7] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.23 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.17it/s]
[2025-09-13 07:44:04 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:44:04 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:44:04 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:44:04 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:44:04 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:44:04 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:44:04 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:44:04 TP0] Capture cuda graph end. Time elapsed: 7.54 s. mem usage=0.35 GB. avail mem=17.21 GB.
[2025-09-13 07:44:05 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:44:05 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:44:05 TP0] Init torch distributed begin.
[2025-09-13 07:44:05 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:44:05 TP0] Load weight begin. avail mem=17.21 GB
[2025-09-13 07:44:05 TP0] Detected fp8 checkpoint.
[2025-09-13 07:44:05 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 177.86it/s]
Loading safetensors checkpoint shards:   4% Completed | 42/1024 [00:00<00:04, 212.73it/s]
Loading safetensors checkpoint shards:  10% Completed | 101/1024 [00:00<00:02, 383.15it/s]
Loading safetensors checkpoint shards:  16% Completed | 162/1024 [00:00<00:01, 471.38it/s]
Loading safetensors checkpoint shards:  22% Completed | 222/1024 [00:00<00:01, 514.84it/s]
Loading safetensors checkpoint shards:  28% Completed | 284/1024 [00:00<00:01, 548.78it/s]
Loading safetensors checkpoint shards:  34% Completed | 345/1024 [00:00<00:01, 567.22it/s]
Loading safetensors checkpoint shards:  40% Completed | 408/1024 [00:00<00:01, 583.94it/s]
Loading safetensors checkpoint shards:  46% Completed | 469/1024 [00:00<00:00, 590.10it/s]
Loading safetensors checkpoint shards:  52% Completed | 532/1024 [00:01<00:00, 599.74it/s]
Loading safetensors checkpoint shards:  58% Completed | 595/1024 [00:01<00:00, 606.16it/s]
Loading safetensors checkpoint shards:  64% Completed | 656/1024 [00:01<00:00, 599.18it/s]
Loading safetensors checkpoint shards:  70% Completed | 716/1024 [00:01<00:00, 593.47it/s]
Loading safetensors checkpoint shards:  76% Completed | 776/1024 [00:01<00:00, 587.15it/s]
Loading safetensors checkpoint shards:  82% Completed | 835/1024 [00:01<00:00, 584.40it/s]
Loading safetensors checkpoint shards:  87% Completed | 894/1024 [00:01<00:00, 580.30it/s]
Loading safetensors checkpoint shards:  93% Completed | 953/1024 [00:01<00:00, 578.41it/s]
Loading safetensors checkpoint shards:  99% Completed | 1011/1024 [00:01<00:00, 406.96it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 507.22it/s]

[2025-09-13 07:44:07 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.22 GB, mem usage=1.99 GB.
[2025-09-13 07:44:07 TP0] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:44:07 TP0] Memory pool end. avail mem=14.55 GB
[2025-09-13 07:44:07 TP3] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:44:07 TP1] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:44:07 TP7] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:44:07 TP5] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:44:07 TP2] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:44:07 TP6] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:44:07 TP4] KV Cache is allocated. #tokens: 620201, KV size: 0.67 GB
[2025-09-13 07:44:07 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.18 GB
[2025-09-13 07:44:07 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:44:07 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:44:07 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:44:07 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:44:07 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.99 GB
[2025-09-13 07:44:07 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:44:07 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
Capturing batches (bs=1 avail_mem=14.61 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  2.95it/s][2025-09-13 07:44:14 TP1] Registering 120 cuda graph addresses
[2025-09-13 07:44:14 TP3] Registering 120 cuda graph addresses
[2025-09-13 07:44:14 TP7] Registering 120 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.61 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.40it/s]
[2025-09-13 07:44:14 TP0] Registering 120 cuda graph addresses
[2025-09-13 07:44:14 TP5] Registering 120 cuda graph addresses
[2025-09-13 07:44:14 TP6] Registering 120 cuda graph addresses
[2025-09-13 07:44:14 TP2] Registering 120 cuda graph addresses
[2025-09-13 07:44:14 TP4] Registering 120 cuda graph addresses
[2025-09-13 07:44:14 TP3] Capture draft cuda graph end. Time elapsed: 6.41 s. mem usage=0.38 GB. avail mem=14.56 GB.
[2025-09-13 07:44:14 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.56 GB
[2025-09-13 07:44:14 TP5] Capture draft cuda graph end. Time elapsed: 6.42 s. mem usage=0.38 GB. avail mem=14.56 GB.
[2025-09-13 07:44:14 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.56 GB
[2025-09-13 07:44:14 TP2] Capture draft cuda graph end. Time elapsed: 6.35 s. mem usage=0.38 GB. avail mem=14.56 GB.
[2025-09-13 07:44:14 TP0] Capture draft cuda graph end. Time elapsed: 6.35 s. mem usage=0.39 GB. avail mem=14.60 GB.
[2025-09-13 07:44:14 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.56 GB
[2025-09-13 07:44:14 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.60 GB
[2025-09-13 07:44:14 TP7] Capture draft cuda graph end. Time elapsed: 6.42 s. mem usage=0.38 GB. avail mem=14.79 GB.
[2025-09-13 07:44:14 TP6] Capture draft cuda graph end. Time elapsed: 6.35 s. mem usage=0.38 GB. avail mem=14.56 GB.
[2025-09-13 07:44:14 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 07:44:14 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.56 GB
[2025-09-13 07:44:14 TP1] Capture draft cuda graph end. Time elapsed: 6.42 s. mem usage=0.38 GB. avail mem=14.56 GB.
[2025-09-13 07:44:14 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.56 GB
[2025-09-13 07:44:14 TP4] Capture draft cuda graph end. Time elapsed: 6.42 s. mem usage=0.38 GB. avail mem=14.56 GB.
[2025-09-13 07:44:14 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.56 GB
Capturing batches (bs=1 avail_mem=14.40 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 18.10it/s]
[2025-09-13 07:44:15 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:44:15 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:44:15 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:44:15 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:44:15 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:44:15 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:44:15 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:44:15 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:44:15 TP1] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.20 GB. avail mem=14.36 GB.
[2025-09-13 07:44:15 TP2] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.20 GB. avail mem=14.36 GB.
[2025-09-13 07:44:15 TP0] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.20 GB. avail mem=14.40 GB.
[2025-09-13 07:44:15 TP6] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.20 GB. avail mem=14.36 GB.
[2025-09-13 07:44:15 TP0] max_total_num_tokens=620201, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.40 GB
[2025-09-13 07:44:15 TP5] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.20 GB. avail mem=14.36 GB.
[2025-09-13 07:44:15 TP3] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.20 GB. avail mem=14.36 GB.
[2025-09-13 07:44:15 TP4] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.20 GB. avail mem=14.36 GB.
[2025-09-13 07:44:15 TP7] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.20 GB. avail mem=14.59 GB.
[2025-09-13 07:44:15] INFO:     Started server process [346106]
[2025-09-13 07:44:15] INFO:     Waiting for application startup.
[2025-09-13 07:44:15] INFO:     Application startup complete.
[2025-09-13 07:44:15] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:44:15] INFO:     127.0.0.1:34800 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:44:16] INFO:     127.0.0.1:34812 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:44:16 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:44:16 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:44:16 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28498.50it/s]
[2025-09-13 07:44:18] INFO:     127.0.0.1:34824 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:18] The server is fired up and ready to roll!
[2025-09-13 07:44:25 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:44:26] INFO:     127.0.0.1:36774 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:44:27] INFO:     127.0.0.1:36784 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:27 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:44:28] INFO:     127.0.0.1:58804 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:28] INFO:     127.0.0.1:58818 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:44:28] INFO:     127.0.0.1:58822 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:28] INFO:     127.0.0.1:58830 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:28] INFO:     127.0.0.1:58834 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:28] INFO:     127.0.0.1:58846 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:28] INFO:     127.0.0.1:58862 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:28] INFO:     127.0.0.1:58866 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:28 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:44:29 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:44:29 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:44:29 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:44:29 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:44:29 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:44:29 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:44:29 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:44:29 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:44:29 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:44:30 TP0] Decode batch. #running-req: 8, #token: 14525, token usage: 0.02, accept len: 2.87, cuda graph: True, gen throughput (token/s): 42.31, #queue-req: 0, 
[2025-09-13 07:44:31 TP0] Decode batch. #running-req: 8, #token: 15614, token usage: 0.03, accept len: 3.40, cuda graph: True, gen throughput (token/s): 837.46, #queue-req: 0, 
[2025-09-13 07:44:33 TP0] Decode batch. #running-req: 8, #token: 16770, token usage: 0.03, accept len: 3.61, cuda graph: True, gen throughput (token/s): 868.77, #queue-req: 0, 
 38%|█████████████████████████████████████████████████▏                                                                                 | 3/8 [00:05<00:07,  1.42s/it][2025-09-13 07:44:34 TP0] Decode batch. #running-req: 5, #token: 11785, token usage: 0.02, accept len: 3.26, cuda graph: True, gen throughput (token/s): 733.60, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.21it/s]
[2025-09-13 07:44:35] INFO:     127.0.0.1:58868 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.59      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4080      
Request throughput (req/s):              1.21      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         621.20    
Total token throughput (tok/s):          621.20    
Concurrency:                             7.03      
Accept length:                           3.32      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5793.65   
Median E2E Latency (ms):                 5654.59   
---------------Time to First Token----------------
Mean TTFT (ms):                          622.21    
Median TTFT (ms):                        734.81    
P99 TTFT (ms):                           735.37    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.12     
Median ITL (ms):                         7.86      
P95 ITL (ms):                            29.73     
P99 ITL (ms):                            33.57     
Max ITL (ms):                            746.32    
==================================================
[2025-09-13 07:44:35] INFO:     127.0.0.1:58876 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:44:35] INFO:     127.0.0.1:58884 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:44:35 TP0] Decode batch. #running-req: 1, #token: 4683, token usage: 0.01, accept len: 3.27, cuda graph: True, gen throughput (token/s): 224.85, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:44:36] INFO:     127.0.0.1:58890 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:36] INFO:     127.0.0.1:58906 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:44:36] INFO:     127.0.0.1:58916 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:36] INFO:     127.0.0.1:58924 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:36] INFO:     127.0.0.1:58926 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:36] INFO:     127.0.0.1:58934 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:36] INFO:     127.0.0.1:58936 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:36] INFO:     127.0.0.1:58938 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:36 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:44:38 TP0] Decode batch. #running-req: 8, #token: 14788, token usage: 0.02, accept len: 3.10, cuda graph: True, gen throughput (token/s): 357.43, #queue-req: 0, 
[2025-09-13 07:44:39 TP0] Decode batch. #running-req: 8, #token: 15968, token usage: 0.03, accept len: 3.69, cuda graph: True, gen throughput (token/s): 897.95, #queue-req: 0, 
[2025-09-13 07:44:40 TP0] Decode batch. #running-req: 8, #token: 17227, token usage: 0.03, accept len: 3.93, cuda graph: True, gen throughput (token/s): 948.91, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:03,  4.25s/it][2025-09-13 07:44:41] INFO:     127.0.0.1:46420 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:41 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:27,  1.96s/it][2025-09-13 07:44:41] INFO:     127.0.0.1:46436 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:04<00:15,  1.19s/it][2025-09-13 07:44:41] INFO:     127.0.0.1:46452 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:41 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.16it/s][2025-09-13 07:44:42] INFO:     127.0.0.1:46458 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:42 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:07,  1.52it/s][2025-09-13 07:44:42] INFO:     127.0.0.1:46460 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:42 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.80it/s][2025-09-13 07:44:42] INFO:     127.0.0.1:46464 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:42 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:44:43 TP0] Decode batch. #running-req: 8, #token: 9047, token usage: 0.01, accept len: 3.32, cuda graph: True, gen throughput (token/s): 467.84, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:04,  2.00it/s][2025-09-13 07:44:43] INFO:     127.0.0.1:46472 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:43 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:07<00:05,  1.41it/s][2025-09-13 07:44:44] INFO:     127.0.0.1:46482 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:44:44 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:44:44 TP0] Decode batch. #running-req: 8, #token: 14770, token usage: 0.02, accept len: 3.27, cuda graph: True, gen throughput (token/s): 628.49, #queue-req: 0, 
[2025-09-13 07:44:45 TP0] Decode batch. #running-req: 8, #token: 15991, token usage: 0.03, accept len: 3.82, cuda graph: True, gen throughput (token/s): 943.22, #queue-req: 0, 
 62%|████████████████████████████████████████████████████████████████████████████████▋                                                | 10/16 [00:10<00:05,  1.03it/s][2025-09-13 07:44:47 TP0] Decode batch. #running-req: 6, #token: 12956, token usage: 0.02, accept len: 4.02, cuda graph: True, gen throughput (token/s): 887.17, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.42it/s]
[2025-09-13 07:44:48] INFO:     127.0.0.1:39206 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.29     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8094      
Request throughput (req/s):              1.42      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         725.72    
Total token throughput (tok/s):          725.72    
Concurrency:                             7.55      
Accept length:                           3.49      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5329.98   
Median E2E Latency (ms):                 5315.67   
---------------Time to First Token----------------
Mean TTFT (ms):                          231.87    
Median TTFT (ms):                        237.21    
P99 TTFT (ms):                           299.61    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.98      
Median ITL (ms):                         6.57      
P95 ITL (ms):                            30.87     
P99 ITL (ms):                            54.67     
Max ITL (ms):                            270.94    
==================================================
[2025-09-13 07:44:48] INFO:     127.0.0.1:39222 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=38: batch_size=8, steps=6, topk=2, num_draft_tokens=6, speed=106.71 token/s, step_time=32.72 ms
Start i=39: batch_size=8, steps=6, topk=2, num_draft_tokens=8
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 6 --speculative-eagle-topk 2 --speculative-num-draft-tokens 8 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:44:58.711000 353674 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:44:58.711000 353674 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:44:59] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=806647854, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=6, speculative_eagle_topk=2, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:44:59] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:45:08.107000 354068 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:45:08.107000 354068 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:45:08.151000 354071 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:45:08.151000 354071 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:45:08.274000 354070 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:45:08.274000 354070 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:45:08.274000 354069 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:45:08.274000 354069 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:45:08.327000 354072 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:45:08.327000 354072 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:45:08.337000 354073 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:45:08.337000 354073 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 07:45:08.380000 354066 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:45:08.380000 354066 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:45:08.407000 354067 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:45:08.407000 354067 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:45:08.433000 354074 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:45:08.433000 354074 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:45:08 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:45:08 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:45:08 TP0] Init torch distributed begin.
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:45:10 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:45:13 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:45:15 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:45:15 TP0] Detected fp8 checkpoint.
[2025-09-13 07:45:15 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 35/1024 [00:00<00:03, 252.02it/s]
Loading safetensors checkpoint shards:   6% Completed | 61/1024 [00:00<00:12, 77.57it/s]
Loading safetensors checkpoint shards:   7% Completed | 75/1024 [00:01<00:16, 57.69it/s]
Loading safetensors checkpoint shards:   8% Completed | 84/1024 [00:01<00:18, 51.92it/s]
Loading safetensors checkpoint shards:   9% Completed | 91/1024 [00:01<00:18, 50.55it/s]
Loading safetensors checkpoint shards:   9% Completed | 97/1024 [00:02<00:31, 29.38it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:02<00:29, 30.89it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:02<00:27, 33.25it/s]
Loading safetensors checkpoint shards:  11% Completed | 112/1024 [00:02<00:26, 34.68it/s]
Loading safetensors checkpoint shards:  11% Completed | 117/1024 [00:02<00:24, 37.25it/s]
Loading safetensors checkpoint shards:  12% Completed | 122/1024 [00:02<00:23, 38.51it/s]
Loading safetensors checkpoint shards:  12% Completed | 128/1024 [00:02<00:21, 41.99it/s]
Loading safetensors checkpoint shards:  13% Completed | 133/1024 [00:02<00:21, 41.55it/s]
Loading safetensors checkpoint shards:  14% Completed | 141/1024 [00:02<00:17, 50.15it/s]
Loading safetensors checkpoint shards:  14% Completed | 147/1024 [00:03<00:16, 51.63it/s]
Loading safetensors checkpoint shards:  15% Completed | 154/1024 [00:03<00:16, 54.33it/s]
Loading safetensors checkpoint shards:  16% Completed | 163/1024 [00:03<00:13, 61.61it/s]
Loading safetensors checkpoint shards:  17% Completed | 170/1024 [00:03<00:14, 59.62it/s]
Loading safetensors checkpoint shards:  17% Completed | 178/1024 [00:03<00:13, 62.98it/s]
Loading safetensors checkpoint shards:  18% Completed | 185/1024 [00:03<00:13, 64.01it/s]
Loading safetensors checkpoint shards:  19% Completed | 194/1024 [00:03<00:11, 70.71it/s]
Loading safetensors checkpoint shards:  20% Completed | 202/1024 [00:03<00:11, 72.81it/s]
Loading safetensors checkpoint shards:  21% Completed | 210/1024 [00:03<00:11, 70.09it/s]
Loading safetensors checkpoint shards:  21% Completed | 218/1024 [00:04<00:11, 67.35it/s]
Loading safetensors checkpoint shards:  22% Completed | 225/1024 [00:04<00:12, 64.55it/s]
Loading safetensors checkpoint shards:  23% Completed | 232/1024 [00:04<00:12, 64.83it/s]
Loading safetensors checkpoint shards:  23% Completed | 239/1024 [00:04<00:12, 62.71it/s]
Loading safetensors checkpoint shards:  24% Completed | 246/1024 [00:05<00:26, 29.55it/s]
Loading safetensors checkpoint shards:  25% Completed | 253/1024 [00:05<00:22, 34.89it/s]
Loading safetensors checkpoint shards:  25% Completed | 259/1024 [00:05<00:19, 38.27it/s]
Loading safetensors checkpoint shards:  26% Completed | 265/1024 [00:05<00:19, 39.34it/s]
Loading safetensors checkpoint shards:  26% Completed | 270/1024 [00:05<00:19, 39.50it/s]
Loading safetensors checkpoint shards:  27% Completed | 277/1024 [00:05<00:16, 45.21it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:05<00:13, 53.07it/s]
Loading safetensors checkpoint shards:  29% Completed | 292/1024 [00:05<00:13, 55.72it/s]
Loading safetensors checkpoint shards:  29% Completed | 300/1024 [00:05<00:11, 61.69it/s]
Loading safetensors checkpoint shards:  30% Completed | 308/1024 [00:06<00:10, 65.59it/s]
Loading safetensors checkpoint shards:  31% Completed | 317/1024 [00:06<00:09, 70.91it/s]
Loading safetensors checkpoint shards:  32% Completed | 325/1024 [00:06<00:09, 71.47it/s]
Loading safetensors checkpoint shards:  33% Completed | 333/1024 [00:06<00:10, 68.03it/s]
Loading safetensors checkpoint shards:  33% Completed | 342/1024 [00:06<00:09, 71.87it/s]
Loading safetensors checkpoint shards:  34% Completed | 350/1024 [00:06<00:09, 71.39it/s]
Loading safetensors checkpoint shards:  35% Completed | 358/1024 [00:06<00:09, 70.85it/s]
Loading safetensors checkpoint shards:  36% Completed | 366/1024 [00:06<00:10, 61.99it/s]
Loading safetensors checkpoint shards:  36% Completed | 373/1024 [00:06<00:10, 63.73it/s]
Loading safetensors checkpoint shards:  37% Completed | 380/1024 [00:07<00:10, 61.91it/s]
Loading safetensors checkpoint shards:  38% Completed | 388/1024 [00:07<00:09, 66.22it/s]
Loading safetensors checkpoint shards:  39% Completed | 395/1024 [00:07<00:09, 65.92it/s]
Loading safetensors checkpoint shards:  39% Completed | 402/1024 [00:07<00:09, 66.13it/s]
Loading safetensors checkpoint shards:  40% Completed | 410/1024 [00:08<00:21, 28.70it/s]
Loading safetensors checkpoint shards:  41% Completed | 416/1024 [00:08<00:18, 32.33it/s]
Loading safetensors checkpoint shards:  41% Completed | 422/1024 [00:08<00:17, 34.71it/s]
Loading safetensors checkpoint shards:  42% Completed | 428/1024 [00:08<00:15, 37.85it/s]
Loading safetensors checkpoint shards:  42% Completed | 433/1024 [00:08<00:15, 38.14it/s]
Loading safetensors checkpoint shards:  43% Completed | 439/1024 [00:08<00:14, 40.63it/s]
Loading safetensors checkpoint shards:  43% Completed | 444/1024 [00:08<00:13, 42.07it/s]
Loading safetensors checkpoint shards:  44% Completed | 451/1024 [00:08<00:12, 47.26it/s]
Loading safetensors checkpoint shards:  45% Completed | 457/1024 [00:09<00:12, 47.22it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:09<00:11, 48.03it/s]
Loading safetensors checkpoint shards:  46% Completed | 469/1024 [00:09<00:11, 48.53it/s]
Loading safetensors checkpoint shards:  46% Completed | 476/1024 [00:09<00:10, 52.47it/s]
Loading safetensors checkpoint shards:  47% Completed | 484/1024 [00:09<00:09, 57.46it/s]
Loading safetensors checkpoint shards:  48% Completed | 490/1024 [00:09<00:09, 57.54it/s]
Loading safetensors checkpoint shards:  49% Completed | 498/1024 [00:09<00:08, 61.44it/s]
Loading safetensors checkpoint shards:  49% Completed | 506/1024 [00:09<00:07, 65.40it/s]
Loading safetensors checkpoint shards:  50% Completed | 514/1024 [00:09<00:07, 67.40it/s]
Loading safetensors checkpoint shards:  51% Completed | 521/1024 [00:10<00:08, 59.68it/s]
Loading safetensors checkpoint shards:  52% Completed | 528/1024 [00:10<00:09, 53.16it/s]
Loading safetensors checkpoint shards:  52% Completed | 534/1024 [00:10<00:10, 48.36it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:10<00:09, 53.21it/s]
Loading safetensors checkpoint shards:  53% Completed | 547/1024 [00:10<00:08, 54.54it/s]
Loading safetensors checkpoint shards:  54% Completed | 555/1024 [00:10<00:07, 59.43it/s]
Loading safetensors checkpoint shards:  55% Completed | 562/1024 [00:10<00:07, 59.68it/s]
Loading safetensors checkpoint shards:  56% Completed | 569/1024 [00:11<00:09, 47.49it/s]
Loading safetensors checkpoint shards:  56% Completed | 575/1024 [00:11<00:11, 40.08it/s]
Loading safetensors checkpoint shards:  57% Completed | 580/1024 [00:11<00:12, 35.23it/s]
Loading safetensors checkpoint shards:  57% Completed | 586/1024 [00:11<00:11, 39.15it/s]
Loading safetensors checkpoint shards:  58% Completed | 591/1024 [00:11<00:11, 37.65it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:11<00:11, 38.42it/s]
Loading safetensors checkpoint shards:  59% Completed | 601/1024 [00:11<00:11, 35.76it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:12<00:11, 37.56it/s]
Loading safetensors checkpoint shards:  60% Completed | 610/1024 [00:12<00:25, 16.18it/s]
Loading safetensors checkpoint shards:  60% Completed | 614/1024 [00:12<00:21, 18.73it/s]
Loading safetensors checkpoint shards:  60% Completed | 619/1024 [00:13<00:18, 22.28it/s]
Loading safetensors checkpoint shards:  61% Completed | 623/1024 [00:13<00:17, 22.86it/s]
Loading safetensors checkpoint shards:  61% Completed | 627/1024 [00:13<00:15, 24.89it/s]
Loading safetensors checkpoint shards:  62% Completed | 631/1024 [00:13<00:14, 26.37it/s]
Loading safetensors checkpoint shards:  62% Completed | 635/1024 [00:13<00:13, 28.62it/s]
Loading safetensors checkpoint shards:  62% Completed | 640/1024 [00:13<00:12, 31.59it/s]
Loading safetensors checkpoint shards:  63% Completed | 644/1024 [00:13<00:12, 31.18it/s]
Loading safetensors checkpoint shards:  63% Completed | 648/1024 [00:13<00:11, 32.72it/s]
Loading safetensors checkpoint shards:  64% Completed | 652/1024 [00:14<00:12, 30.27it/s]
Loading safetensors checkpoint shards:  64% Completed | 656/1024 [00:14<00:12, 28.88it/s]
Loading safetensors checkpoint shards:  64% Completed | 660/1024 [00:14<00:12, 28.36it/s]
Loading safetensors checkpoint shards:  65% Completed | 664/1024 [00:14<00:12, 29.39it/s]
Loading safetensors checkpoint shards:  65% Completed | 669/1024 [00:14<00:10, 32.30it/s]
Loading safetensors checkpoint shards:  66% Completed | 673/1024 [00:14<00:10, 32.49it/s]
Loading safetensors checkpoint shards:  66% Completed | 677/1024 [00:14<00:11, 30.70it/s]
Loading safetensors checkpoint shards:  67% Completed | 681/1024 [00:15<00:10, 32.58it/s]
Loading safetensors checkpoint shards:  67% Completed | 685/1024 [00:15<00:10, 32.98it/s]
Loading safetensors checkpoint shards:  67% Completed | 689/1024 [00:15<00:10, 33.07it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:15<00:08, 37.16it/s]
Loading safetensors checkpoint shards:  68% Completed | 698/1024 [00:15<00:09, 35.50it/s]
Loading safetensors checkpoint shards:  69% Completed | 702/1024 [00:15<00:09, 34.47it/s]
Loading safetensors checkpoint shards:  69% Completed | 707/1024 [00:15<00:08, 36.86it/s]
Loading safetensors checkpoint shards:  70% Completed | 712/1024 [00:15<00:08, 38.34it/s]
Loading safetensors checkpoint shards:  70% Completed | 716/1024 [00:15<00:08, 38.19it/s]
Loading safetensors checkpoint shards:  70% Completed | 721/1024 [00:16<00:07, 39.69it/s]
Loading safetensors checkpoint shards:  71% Completed | 725/1024 [00:16<00:07, 39.18it/s]
Loading safetensors checkpoint shards:  71% Completed | 731/1024 [00:16<00:06, 44.69it/s]
Loading safetensors checkpoint shards:  72% Completed | 738/1024 [00:16<00:05, 49.58it/s]
Loading safetensors checkpoint shards:  73% Completed | 744/1024 [00:16<00:05, 51.81it/s]
Loading safetensors checkpoint shards:  73% Completed | 750/1024 [00:16<00:05, 48.47it/s]
Loading safetensors checkpoint shards:  74% Completed | 756/1024 [00:16<00:05, 50.91it/s]
Loading safetensors checkpoint shards:  74% Completed | 762/1024 [00:16<00:05, 51.39it/s]
Loading safetensors checkpoint shards:  75% Completed | 769/1024 [00:16<00:04, 56.44it/s]
Loading safetensors checkpoint shards:  76% Completed | 775/1024 [00:17<00:04, 55.80it/s]
Loading safetensors checkpoint shards:  76% Completed | 781/1024 [00:17<00:04, 52.05it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:17<00:04, 52.17it/s]
Loading safetensors checkpoint shards:  77% Completed | 793/1024 [00:17<00:04, 50.84it/s]
Loading safetensors checkpoint shards:  78% Completed | 799/1024 [00:17<00:05, 41.57it/s]
Loading safetensors checkpoint shards:  79% Completed | 804/1024 [00:17<00:05, 38.81it/s]
Loading safetensors checkpoint shards:  79% Completed | 809/1024 [00:17<00:06, 35.36it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:18<00:06, 34.07it/s]
Loading safetensors checkpoint shards:  80% Completed | 817/1024 [00:18<00:06, 31.15it/s]
Loading safetensors checkpoint shards:  80% Completed | 821/1024 [00:18<00:07, 28.94it/s]
Loading safetensors checkpoint shards:  81% Completed | 825/1024 [00:18<00:06, 30.48it/s]
Loading safetensors checkpoint shards:  81% Completed | 829/1024 [00:19<00:14, 13.02it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:19<00:12, 15.90it/s]
Loading safetensors checkpoint shards:  82% Completed | 837/1024 [00:19<00:09, 18.91it/s]
Loading safetensors checkpoint shards:  82% Completed | 840/1024 [00:19<00:08, 20.48it/s]
Loading safetensors checkpoint shards:  82% Completed | 844/1024 [00:19<00:07, 22.91it/s]
Loading safetensors checkpoint shards:  83% Completed | 848/1024 [00:19<00:06, 25.60it/s]
Loading safetensors checkpoint shards:  83% Completed | 852/1024 [00:20<00:06, 26.07it/s]
Loading safetensors checkpoint shards:  83% Completed | 855/1024 [00:20<00:06, 26.33it/s]
Loading safetensors checkpoint shards:  84% Completed | 858/1024 [00:20<00:06, 26.57it/s]
Loading safetensors checkpoint shards:  84% Completed | 861/1024 [00:20<00:06, 26.93it/s]
Loading safetensors checkpoint shards:  84% Completed | 865/1024 [00:20<00:05, 28.37it/s]
Loading safetensors checkpoint shards:  85% Completed | 869/1024 [00:20<00:05, 29.47it/s]
Loading safetensors checkpoint shards:  85% Completed | 873/1024 [00:20<00:04, 30.24it/s]
Loading safetensors checkpoint shards:  86% Completed | 877/1024 [00:20<00:04, 31.28it/s]
Loading safetensors checkpoint shards:  86% Completed | 881/1024 [00:20<00:04, 31.33it/s]
Loading safetensors checkpoint shards:  86% Completed | 885/1024 [00:21<00:04, 30.66it/s]
Loading safetensors checkpoint shards:  87% Completed | 889/1024 [00:21<00:04, 31.10it/s]
Loading safetensors checkpoint shards:  87% Completed | 893/1024 [00:21<00:04, 30.49it/s]
Loading safetensors checkpoint shards:  88% Completed | 897/1024 [00:21<00:04, 29.99it/s]
Loading safetensors checkpoint shards:  88% Completed | 901/1024 [00:21<00:04, 29.73it/s]
Loading safetensors checkpoint shards:  88% Completed | 904/1024 [00:21<00:04, 29.46it/s]
Loading safetensors checkpoint shards:  89% Completed | 908/1024 [00:21<00:03, 30.91it/s]
Loading safetensors checkpoint shards:  89% Completed | 912/1024 [00:22<00:03, 30.59it/s]
Loading safetensors checkpoint shards:  89% Completed | 916/1024 [00:22<00:03, 30.45it/s]
Loading safetensors checkpoint shards:  90% Completed | 920/1024 [00:22<00:03, 29.94it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:22<00:03, 30.27it/s]
Loading safetensors checkpoint shards:  91% Completed | 928/1024 [00:22<00:03, 27.71it/s]
Loading safetensors checkpoint shards:  91% Completed | 931/1024 [00:22<00:03, 28.07it/s]
Loading safetensors checkpoint shards:  91% Completed | 934/1024 [00:22<00:03, 28.32it/s]
Loading safetensors checkpoint shards:  92% Completed | 938/1024 [00:22<00:02, 29.44it/s]
Loading safetensors checkpoint shards:  92% Completed | 941/1024 [00:23<00:02, 29.02it/s]
Loading safetensors checkpoint shards:  92% Completed | 944/1024 [00:23<00:02, 29.05it/s]
Loading safetensors checkpoint shards:  93% Completed | 948/1024 [00:23<00:02, 30.51it/s]
Loading safetensors checkpoint shards:  93% Completed | 952/1024 [00:23<00:02, 30.48it/s]
Loading safetensors checkpoint shards:  93% Completed | 956/1024 [00:23<00:02, 32.68it/s]
Loading safetensors checkpoint shards:  94% Completed | 960/1024 [00:23<00:01, 32.28it/s]
Loading safetensors checkpoint shards:  94% Completed | 964/1024 [00:23<00:01, 31.99it/s]
Loading safetensors checkpoint shards:  95% Completed | 968/1024 [00:23<00:01, 32.43it/s]
Loading safetensors checkpoint shards:  95% Completed | 972/1024 [00:23<00:01, 32.26it/s]
Loading safetensors checkpoint shards:  95% Completed | 976/1024 [00:24<00:01, 31.14it/s]
Loading safetensors checkpoint shards:  96% Completed | 980/1024 [00:24<00:01, 31.24it/s]
Loading safetensors checkpoint shards:  96% Completed | 985/1024 [00:24<00:01, 35.17it/s]
Loading safetensors checkpoint shards:  97% Completed | 991/1024 [00:24<00:00, 39.95it/s]
Loading safetensors checkpoint shards:  98% Completed | 1006/1024 [00:24<00:00, 68.77it/s]
Loading safetensors checkpoint shards:  99% Completed | 1016/1024 [00:24<00:00, 75.83it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:24<00:00, 41.37it/s]

[2025-09-13 07:45:40 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:45:43 TP1] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:45:43 TP6] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:45:43 TP5] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:45:43 TP2] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:45:43 TP7] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:45:43 TP3] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:45:43 TP0] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:45:43 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:45:43 TP4] KV Cache is allocated. #tokens: 620217, KV size: 40.59 GB
[2025-09-13 07:45:43 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:45:43 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.51 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:45:44 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:45:44 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:45:44 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:45:44 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:45:44 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:45:44 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:45:45 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:45:45 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:45:45 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25297.59it/s]
[2025-09-13 07:45:45 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:45:45 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25994.82it/s]
[2025-09-13 07:45:46 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:45:46 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28399.36it/s]
[2025-09-13 07:45:46 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:45:46 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27576.29it/s]
[2025-09-13 07:45:47 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:45:47 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28490.17it/s]
[2025-09-13 07:45:47 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.20 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.13it/s]
[2025-09-13 07:45:51 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:45:51 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:45:51 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:45:51 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:45:51 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:45:51 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:45:51 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:45:51 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:45:51 TP0] Capture cuda graph end. Time elapsed: 7.83 s. mem usage=0.39 GB. avail mem=17.17 GB.
[2025-09-13 07:45:51 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:45:51 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:45:51 TP0] Init torch distributed begin.
[2025-09-13 07:45:51 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:45:51 TP0] Load weight begin. avail mem=17.17 GB
[2025-09-13 07:45:51 TP0] Detected fp8 checkpoint.
[2025-09-13 07:45:51 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 17/1024 [00:00<00:06, 167.02it/s]
Loading safetensors checkpoint shards:   4% Completed | 39/1024 [00:00<00:04, 197.15it/s]
Loading safetensors checkpoint shards:  10% Completed | 98/1024 [00:00<00:02, 373.93it/s]
Loading safetensors checkpoint shards:  16% Completed | 159/1024 [00:00<00:01, 464.29it/s]
Loading safetensors checkpoint shards:  21% Completed | 218/1024 [00:00<00:01, 507.67it/s]
Loading safetensors checkpoint shards:  27% Completed | 277/1024 [00:00<00:01, 533.87it/s]
Loading safetensors checkpoint shards:  33% Completed | 336/1024 [00:00<00:01, 549.58it/s]
Loading safetensors checkpoint shards:  39% Completed | 396/1024 [00:00<00:01, 563.03it/s]
Loading safetensors checkpoint shards:  44% Completed | 454/1024 [00:00<00:01, 568.08it/s]
Loading safetensors checkpoint shards:  50% Completed | 512/1024 [00:01<00:00, 571.35it/s]
Loading safetensors checkpoint shards:  56% Completed | 573/1024 [00:01<00:00, 580.45it/s]
Loading safetensors checkpoint shards:  62% Completed | 634/1024 [00:01<00:00, 586.85it/s]
Loading safetensors checkpoint shards:  68% Completed | 693/1024 [00:01<00:00, 583.45it/s]
Loading safetensors checkpoint shards:  73% Completed | 752/1024 [00:01<00:00, 578.75it/s]
Loading safetensors checkpoint shards:  79% Completed | 810/1024 [00:01<00:00, 577.80it/s]
Loading safetensors checkpoint shards:  85% Completed | 868/1024 [00:01<00:00, 576.56it/s]
Loading safetensors checkpoint shards:  90% Completed | 926/1024 [00:01<00:00, 575.78it/s]
Loading safetensors checkpoint shards:  96% Completed | 984/1024 [00:01<00:00, 552.24it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 496.27it/s]

[2025-09-13 07:45:53 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.18 GB, mem usage=1.99 GB.
[2025-09-13 07:45:53 TP0] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:45:53 TP1] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:45:53 TP7] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:45:53 TP6] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:45:53 TP0] Memory pool end. avail mem=14.52 GB
[2025-09-13 07:45:53 TP3] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:45:53 TP5] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:45:53 TP4] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:45:53 TP2] KV Cache is allocated. #tokens: 620217, KV size: 0.67 GB
[2025-09-13 07:45:54 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:45:54 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:45:54 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:45:54 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:45:54 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.95 GB
[2025-09-13 07:45:54 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:45:54 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:45:54 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.14 GB
Capturing batches (bs=1 avail_mem=14.57 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  2.97it/s][2025-09-13 07:46:00 TP3] Registering 120 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.57 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.39it/s]
[2025-09-13 07:46:00 TP0] Registering 120 cuda graph addresses
[2025-09-13 07:46:00 TP2] Registering 120 cuda graph addresses
[2025-09-13 07:46:00 TP1] Registering 120 cuda graph addresses
[2025-09-13 07:46:00 TP6] Registering 120 cuda graph addresses
[2025-09-13 07:46:00 TP4] Registering 120 cuda graph addresses
[2025-09-13 07:46:00 TP5] Registering 120 cuda graph addresses
[2025-09-13 07:46:00 TP7] Registering 120 cuda graph addresses
[2025-09-13 07:46:00 TP2] Capture draft cuda graph end. Time elapsed: 6.53 s. mem usage=0.38 GB. avail mem=14.52 GB.
[2025-09-13 07:46:00 TP7] Capture draft cuda graph end. Time elapsed: 6.45 s. mem usage=0.38 GB. avail mem=14.76 GB.
[2025-09-13 07:46:00 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.76 GB
[2025-09-13 07:46:00 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:46:00 TP4] Capture draft cuda graph end. Time elapsed: 6.53 s. mem usage=0.38 GB. avail mem=14.52 GB.
[2025-09-13 07:46:00 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:46:00 TP0] Capture draft cuda graph end. Time elapsed: 6.47 s. mem usage=0.39 GB. avail mem=14.56 GB.
[2025-09-13 07:46:00 TP5] Capture draft cuda graph end. Time elapsed: 6.47 s. mem usage=0.38 GB. avail mem=14.52 GB.
[2025-09-13 07:46:00 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.56 GB
[2025-09-13 07:46:00 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:46:00 TP6] Capture draft cuda graph end. Time elapsed: 6.53 s. mem usage=0.38 GB. avail mem=14.52 GB.
[2025-09-13 07:46:00 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:46:00 TP1] Capture draft cuda graph end. Time elapsed: 6.47 s. mem usage=0.38 GB. avail mem=14.52 GB.
[2025-09-13 07:46:00 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
[2025-09-13 07:46:00 TP3] Capture draft cuda graph end. Time elapsed: 6.47 s. mem usage=0.38 GB. avail mem=14.52 GB.
[2025-09-13 07:46:00 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.52 GB
Capturing batches (bs=1 avail_mem=14.36 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 19.60it/s]
[2025-09-13 07:46:02 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:46:02 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:46:02 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:46:02 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:46:02 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:46:02 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:46:02 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:46:02 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:46:02 TP1] Capture draft extend cuda graph end. Time elapsed: 1.20 s. mem usage=0.20 GB. avail mem=14.32 GB.
[2025-09-13 07:46:02 TP7] Capture draft extend cuda graph end. Time elapsed: 1.20 s. mem usage=0.20 GB. avail mem=14.55 GB.
[2025-09-13 07:46:02 TP3] Capture draft extend cuda graph end. Time elapsed: 1.20 s. mem usage=0.20 GB. avail mem=14.32 GB.
[2025-09-13 07:46:02 TP0] Capture draft extend cuda graph end. Time elapsed: 1.20 s. mem usage=0.20 GB. avail mem=14.36 GB.
[2025-09-13 07:46:02 TP4] Capture draft extend cuda graph end. Time elapsed: 1.20 s. mem usage=0.20 GB. avail mem=14.32 GB.
[2025-09-13 07:46:02 TP0] max_total_num_tokens=620217, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.36 GB
[2025-09-13 07:46:02 TP5] Capture draft extend cuda graph end. Time elapsed: 1.20 s. mem usage=0.20 GB. avail mem=14.32 GB.
[2025-09-13 07:46:02 TP6] Capture draft extend cuda graph end. Time elapsed: 1.20 s. mem usage=0.20 GB. avail mem=14.32 GB.
[2025-09-13 07:46:02 TP2] Capture draft extend cuda graph end. Time elapsed: 1.21 s. mem usage=0.20 GB. avail mem=14.32 GB.
[2025-09-13 07:46:02] INFO:     Started server process [353674]
[2025-09-13 07:46:02] INFO:     Waiting for application startup.
[2025-09-13 07:46:02] INFO:     Application startup complete.
[2025-09-13 07:46:02] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:46:03] INFO:     127.0.0.1:35696 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:46:03] INFO:     127.0.0.1:35706 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:46:03 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:46:03 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:46:03 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 29084.30it/s]
[2025-09-13 07:46:04] INFO:     127.0.0.1:35716 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:04] The server is fired up and ready to roll!
[2025-09-13 07:46:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:46:14] INFO:     127.0.0.1:49770 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:46:14] INFO:     127.0.0.1:49786 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:14 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:46:16] INFO:     127.0.0.1:49792 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:16] INFO:     127.0.0.1:49802 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:46:16] INFO:     127.0.0.1:49808 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:16] INFO:     127.0.0.1:49816 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:16] INFO:     127.0.0.1:49824 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:16] INFO:     127.0.0.1:49830 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:16] INFO:     127.0.0.1:49832 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:16] INFO:     127.0.0.1:49836 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:16 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:46:16 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:46:16 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:46:16 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:46:16 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:46:16 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:46:16 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:46:16 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:46:16 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:46:16 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:46:17 TP0] Decode batch. #running-req: 8, #token: 14657, token usage: 0.02, accept len: 3.25, cuda graph: True, gen throughput (token/s): 48.91, #queue-req: 0, 
[2025-09-13 07:46:19 TP0] Decode batch. #running-req: 8, #token: 15976, token usage: 0.03, accept len: 4.12, cuda graph: True, gen throughput (token/s): 973.04, #queue-req: 0, 
 12%|████████████████▍                                                                                                                  | 1/8 [00:04<00:28,  4.00s/it][2025-09-13 07:46:20 TP0] Decode batch. #running-req: 7, #token: 16774, token usage: 0.03, accept len: 4.65, cuda graph: True, gen throughput (token/s): 1040.25, #queue-req: 0, 
 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 7/8 [00:05<00:00,  2.40it/s][2025-09-13 07:46:21 TP0] Decode batch. #running-req: 1, #token: 1456, token usage: 0.00, accept len: 3.89, cuda graph: True, gen throughput (token/s): 420.60, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.30it/s]
[2025-09-13 07:46:22] INFO:     127.0.0.1:56882 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.15      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4073      
Request throughput (req/s):              1.30      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         665.99    
Total token throughput (tok/s):          665.99    
Concurrency:                             6.57      
Accept length:                           4.04      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5054.13   
Median E2E Latency (ms):                 5104.64   
---------------Time to First Token----------------
Mean TTFT (ms):                          616.24    
Median TTFT (ms):                        729.06    
P99 TTFT (ms):                           729.58    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           8.68      
Median ITL (ms):                         5.98      
P95 ITL (ms):                            17.22     
P99 ITL (ms):                            34.11     
Max ITL (ms):                            734.62    
==================================================
[2025-09-13 07:46:22] INFO:     127.0.0.1:56888 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:46:22] INFO:     127.0.0.1:56892 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:46:23] INFO:     127.0.0.1:56904 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:23] INFO:     127.0.0.1:56914 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:46:23] INFO:     127.0.0.1:56926 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:23] INFO:     127.0.0.1:56930 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:23] INFO:     127.0.0.1:56936 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:23] INFO:     127.0.0.1:56942 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:23] INFO:     127.0.0.1:56948 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:23] INFO:     127.0.0.1:56960 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:23 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:46:24 TP0] Decode batch. #running-req: 8, #token: 14147, token usage: 0.02, accept len: 2.90, cuda graph: True, gen throughput (token/s): 137.37, #queue-req: 0, 
[2025-09-13 07:46:25 TP0] Decode batch. #running-req: 8, #token: 15288, token usage: 0.02, accept len: 3.57, cuda graph: True, gen throughput (token/s): 853.14, #queue-req: 0, 
[2025-09-13 07:46:26 TP0] Decode batch. #running-req: 8, #token: 16795, token usage: 0.03, accept len: 4.71, cuda graph: True, gen throughput (token/s): 1095.52, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:03<00:51,  3.44s/it][2025-09-13 07:46:27] INFO:     127.0.0.1:56976 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:27 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:26,  1.89s/it][2025-09-13 07:46:27] INFO:     127.0.0.1:56986 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:04<00:14,  1.14s/it][2025-09-13 07:46:28] INFO:     127.0.0.1:56162 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:28 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:04<00:10,  1.14it/s][2025-09-13 07:46:28] INFO:     127.0.0.1:56168 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:28 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:46:28 TP0] Decode batch. #running-req: 8, #token: 11009, token usage: 0.02, accept len: 3.98, cuda graph: True, gen throughput (token/s): 620.69, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:07,  1.46it/s][2025-09-13 07:46:28] INFO:     127.0.0.1:56170 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:28 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.82it/s][2025-09-13 07:46:29] INFO:     127.0.0.1:56186 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:29 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:05,  1.79it/s][2025-09-13 07:46:29] INFO:     127.0.0.1:56192 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:04,  1.73it/s][2025-09-13 07:46:30] INFO:     127.0.0.1:56208 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:46:30 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:46:30 TP0] Decode batch. #running-req: 8, #token: 14659, token usage: 0.02, accept len: 3.61, cuda graph: True, gen throughput (token/s): 559.02, #queue-req: 0, 
[2025-09-13 07:46:32 TP0] Decode batch. #running-req: 8, #token: 16056, token usage: 0.03, accept len: 4.37, cuda graph: True, gen throughput (token/s): 1026.42, #queue-req: 0, 
 69%|████████████████████████████████████████████████████████████████████████████████████████▋                                        | 11/16 [00:09<00:03,  1.35it/s][2025-09-13 07:46:33 TP0] Decode batch. #running-req: 5, #token: 9226, token usage: 0.01, accept len: 4.82, cuda graph: True, gen throughput (token/s): 897.30, #queue-req: 0, 
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 14/16 [00:10<00:00,  2.41it/s][2025-09-13 07:46:34 TP0] Decode batch. #running-req: 1, #token: 3225, token usage: 0.01, accept len: 4.08, cuda graph: True, gen throughput (token/s): 356.87, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.46it/s]
[2025-09-13 07:46:34] INFO:     127.0.0.1:56212 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  10.97     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8082      
Request throughput (req/s):              1.46      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         746.50    
Total token throughput (tok/s):          746.50    
Concurrency:                             7.26      
Accept length:                           4.06      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   4978.29   
Median E2E Latency (ms):                 4919.63   
---------------Time to First Token----------------
Mean TTFT (ms):                          221.11    
Median TTFT (ms):                        241.39    
P99 TTFT (ms):                           272.50    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.31      
Median ITL (ms):                         5.75      
P95 ITL (ms):                            24.71     
P99 ITL (ms):                            44.97     
Max ITL (ms):                            283.52    
==================================================
[2025-09-13 07:46:34] INFO:     127.0.0.1:56216 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=39: batch_size=8, steps=6, topk=2, num_draft_tokens=8, speed=119.74 token/s, step_time=33.94 ms
Start i=40: batch_size=8, steps=6, topk=2, num_draft_tokens=12
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 6 --speculative-eagle-topk 2 --speculative-num-draft-tokens 12 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:46:45.362000 359507 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:46:45.362000 359507 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:46:45] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=434937209, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=6, speculative_eagle_topk=2, speculative_num_draft_tokens=12, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:46:46] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:46:54.630000 359722 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:46:54.630000 359722 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:46:54.720000 359715 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:46:54.720000 359715 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:46:54.917000 359721 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:46:54.917000 359721 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:46:54.984000 359718 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:46:54.984000 359718 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:46:54.990000 359720 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:46:54.990000 359720 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:46:55.008000 359717 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:46:55.008000 359717 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:46:55.029000 359719 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:46:55.029000 359719 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:46:55.031000 359716 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:46:55.031000 359716 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:46:55.071000 359723 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:46:55.071000 359723 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:46:55 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:46:55 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:46:55 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:46:56 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:47:00 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:47:01 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:47:01 TP0] Detected fp8 checkpoint.
[2025-09-13 07:47:02 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 17/1024 [00:00<00:06, 156.28it/s]
Loading safetensors checkpoint shards:   3% Completed | 33/1024 [00:00<00:12, 81.11it/s]
Loading safetensors checkpoint shards:   4% Completed | 43/1024 [00:00<00:16, 60.86it/s]
Loading safetensors checkpoint shards:   5% Completed | 51/1024 [00:00<00:19, 49.40it/s]
Loading safetensors checkpoint shards:   6% Completed | 57/1024 [00:01<00:21, 45.31it/s]
Loading safetensors checkpoint shards:   6% Completed | 62/1024 [00:01<00:22, 42.07it/s]
Loading safetensors checkpoint shards:   7% Completed | 67/1024 [00:01<00:23, 41.21it/s]
Loading safetensors checkpoint shards:   7% Completed | 72/1024 [00:01<00:22, 42.43it/s]
Loading safetensors checkpoint shards:   8% Completed | 77/1024 [00:01<00:23, 40.79it/s]
Loading safetensors checkpoint shards:   8% Completed | 83/1024 [00:01<00:22, 42.45it/s]
Loading safetensors checkpoint shards:   9% Completed | 88/1024 [00:01<00:22, 42.36it/s]
Loading safetensors checkpoint shards:   9% Completed | 93/1024 [00:01<00:22, 40.62it/s]
Loading safetensors checkpoint shards:  10% Completed | 98/1024 [00:02<00:22, 40.37it/s]
Loading safetensors checkpoint shards:  10% Completed | 103/1024 [00:02<00:23, 39.97it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:02<00:22, 40.06it/s]
Loading safetensors checkpoint shards:  11% Completed | 113/1024 [00:02<00:22, 39.97it/s]
Loading safetensors checkpoint shards:  12% Completed | 118/1024 [00:02<00:21, 42.34it/s]
Loading safetensors checkpoint shards:  12% Completed | 123/1024 [00:03<00:39, 22.55it/s]
Loading safetensors checkpoint shards:  12% Completed | 128/1024 [00:03<00:34, 26.10it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:03<00:32, 27.36it/s]
Loading safetensors checkpoint shards:  13% Completed | 136/1024 [00:03<00:30, 29.27it/s]
Loading safetensors checkpoint shards:  14% Completed | 142/1024 [00:03<00:25, 33.93it/s]
Loading safetensors checkpoint shards:  14% Completed | 146/1024 [00:03<00:25, 34.40it/s]
Loading safetensors checkpoint shards:  15% Completed | 150/1024 [00:03<00:24, 35.40it/s]
Loading safetensors checkpoint shards:  15% Completed | 154/1024 [00:03<00:24, 35.53it/s]
Loading safetensors checkpoint shards:  15% Completed | 158/1024 [00:03<00:24, 35.89it/s]
Loading safetensors checkpoint shards:  16% Completed | 163/1024 [00:04<00:22, 37.75it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:04<00:23, 36.04it/s]
Loading safetensors checkpoint shards:  17% Completed | 172/1024 [00:04<00:22, 38.09it/s]
Loading safetensors checkpoint shards:  17% Completed | 176/1024 [00:04<00:22, 38.09it/s]
Loading safetensors checkpoint shards:  18% Completed | 180/1024 [00:04<00:23, 36.53it/s]
Loading safetensors checkpoint shards:  18% Completed | 185/1024 [00:04<00:22, 38.08it/s]
Loading safetensors checkpoint shards:  18% Completed | 189/1024 [00:04<00:22, 37.51it/s]
Loading safetensors checkpoint shards:  19% Completed | 194/1024 [00:04<00:21, 38.85it/s]
Loading safetensors checkpoint shards:  19% Completed | 198/1024 [00:04<00:21, 38.46it/s]
Loading safetensors checkpoint shards:  20% Completed | 202/1024 [00:05<00:21, 38.71it/s]
Loading safetensors checkpoint shards:  20% Completed | 206/1024 [00:05<00:21, 38.86it/s]
Loading safetensors checkpoint shards:  21% Completed | 210/1024 [00:05<00:21, 38.57it/s]
Loading safetensors checkpoint shards:  21% Completed | 214/1024 [00:05<00:21, 38.13it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:05<00:21, 38.10it/s]
Loading safetensors checkpoint shards:  22% Completed | 223/1024 [00:05<00:21, 37.55it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:05<00:20, 38.16it/s]
Loading safetensors checkpoint shards:  23% Completed | 231/1024 [00:05<00:21, 37.49it/s]
Loading safetensors checkpoint shards:  23% Completed | 235/1024 [00:05<00:21, 36.82it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:06<00:20, 38.36it/s]
Loading safetensors checkpoint shards:  24% Completed | 244/1024 [00:06<00:20, 37.97it/s]
Loading safetensors checkpoint shards:  24% Completed | 249/1024 [00:06<00:18, 41.19it/s]
Loading safetensors checkpoint shards:  25% Completed | 254/1024 [00:06<00:19, 38.87it/s]
Loading safetensors checkpoint shards:  25% Completed | 258/1024 [00:06<00:19, 39.08it/s]
Loading safetensors checkpoint shards:  26% Completed | 263/1024 [00:06<00:18, 40.47it/s]
Loading safetensors checkpoint shards:  26% Completed | 268/1024 [00:06<00:18, 40.34it/s]
Loading safetensors checkpoint shards:  27% Completed | 273/1024 [00:06<00:18, 41.49it/s]
Loading safetensors checkpoint shards:  27% Completed | 278/1024 [00:07<00:18, 39.71it/s]
Loading safetensors checkpoint shards:  28% Completed | 283/1024 [00:07<00:18, 40.10it/s]
Loading safetensors checkpoint shards:  28% Completed | 288/1024 [00:07<00:18, 39.26it/s]
Loading safetensors checkpoint shards:  29% Completed | 292/1024 [00:07<00:19, 38.16it/s]
Loading safetensors checkpoint shards:  29% Completed | 297/1024 [00:07<00:18, 40.19it/s]
Loading safetensors checkpoint shards:  29% Completed | 302/1024 [00:07<00:17, 40.15it/s]
Loading safetensors checkpoint shards:  30% Completed | 307/1024 [00:07<00:17, 41.11it/s]
Loading safetensors checkpoint shards:  30% Completed | 312/1024 [00:07<00:17, 41.31it/s]
Loading safetensors checkpoint shards:  31% Completed | 318/1024 [00:07<00:16, 43.78it/s]
Loading safetensors checkpoint shards:  32% Completed | 323/1024 [00:08<00:34, 20.24it/s]
Loading safetensors checkpoint shards:  32% Completed | 328/1024 [00:08<00:29, 23.80it/s]
Loading safetensors checkpoint shards:  32% Completed | 332/1024 [00:08<00:26, 25.89it/s]
Loading safetensors checkpoint shards:  33% Completed | 336/1024 [00:08<00:24, 28.25it/s]
Loading safetensors checkpoint shards:  33% Completed | 341/1024 [00:09<00:21, 31.91it/s]
Loading safetensors checkpoint shards:  34% Completed | 345/1024 [00:09<00:20, 32.40it/s]
Loading safetensors checkpoint shards:  34% Completed | 350/1024 [00:09<00:19, 35.07it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:09<00:18, 35.74it/s]
Loading safetensors checkpoint shards:  35% Completed | 358/1024 [00:09<00:18, 36.62it/s]
Loading safetensors checkpoint shards:  35% Completed | 363/1024 [00:09<00:17, 37.93it/s]
Loading safetensors checkpoint shards:  36% Completed | 367/1024 [00:09<00:17, 37.36it/s]
Loading safetensors checkpoint shards:  36% Completed | 372/1024 [00:09<00:16, 38.97it/s]
Loading safetensors checkpoint shards:  37% Completed | 376/1024 [00:09<00:16, 38.49it/s]
Loading safetensors checkpoint shards:  37% Completed | 380/1024 [00:10<00:17, 36.98it/s]
Loading safetensors checkpoint shards:  38% Completed | 385/1024 [00:10<00:16, 39.09it/s]
Loading safetensors checkpoint shards:  38% Completed | 389/1024 [00:10<00:16, 38.62it/s]
Loading safetensors checkpoint shards:  38% Completed | 394/1024 [00:10<00:15, 39.49it/s]
Loading safetensors checkpoint shards:  39% Completed | 398/1024 [00:10<00:16, 39.01it/s]
Loading safetensors checkpoint shards:  39% Completed | 402/1024 [00:10<00:16, 38.76it/s]
Loading safetensors checkpoint shards:  40% Completed | 407/1024 [00:10<00:15, 40.72it/s]
Loading safetensors checkpoint shards:  40% Completed | 412/1024 [00:10<00:15, 39.40it/s]
Loading safetensors checkpoint shards:  41% Completed | 417/1024 [00:10<00:15, 40.01it/s]
Loading safetensors checkpoint shards:  41% Completed | 422/1024 [00:11<00:14, 40.29it/s]
Loading safetensors checkpoint shards:  42% Completed | 428/1024 [00:11<00:13, 43.88it/s]
Loading safetensors checkpoint shards:  42% Completed | 433/1024 [00:11<00:13, 43.12it/s]
Loading safetensors checkpoint shards:  43% Completed | 439/1024 [00:11<00:12, 46.55it/s]
Loading safetensors checkpoint shards:  43% Completed | 444/1024 [00:11<00:13, 43.54it/s]
Loading safetensors checkpoint shards:  44% Completed | 449/1024 [00:11<00:13, 42.84it/s]
Loading safetensors checkpoint shards:  44% Completed | 454/1024 [00:11<00:13, 43.02it/s]
Loading safetensors checkpoint shards:  45% Completed | 460/1024 [00:11<00:12, 46.29it/s]
Loading safetensors checkpoint shards:  45% Completed | 465/1024 [00:11<00:12, 46.07it/s]
Loading safetensors checkpoint shards:  46% Completed | 470/1024 [00:12<00:11, 46.82it/s]
Loading safetensors checkpoint shards:  46% Completed | 476/1024 [00:12<00:11, 49.66it/s]
Loading safetensors checkpoint shards:  47% Completed | 482/1024 [00:12<00:10, 51.28it/s]
Loading safetensors checkpoint shards:  48% Completed | 488/1024 [00:12<00:11, 46.06it/s]
Loading safetensors checkpoint shards:  48% Completed | 493/1024 [00:12<00:11, 44.49it/s]
Loading safetensors checkpoint shards:  49% Completed | 498/1024 [00:12<00:12, 42.88it/s]
Loading safetensors checkpoint shards:  49% Completed | 503/1024 [00:12<00:12, 41.93it/s]
Loading safetensors checkpoint shards:  50% Completed | 509/1024 [00:12<00:11, 44.03it/s]
Loading safetensors checkpoint shards:  50% Completed | 514/1024 [00:13<00:11, 43.06it/s]
Loading safetensors checkpoint shards:  51% Completed | 519/1024 [00:13<00:11, 44.35it/s]
Loading safetensors checkpoint shards:  51% Completed | 524/1024 [00:13<00:11, 44.90it/s]
Loading safetensors checkpoint shards:  52% Completed | 530/1024 [00:13<00:10, 48.52it/s]
Loading safetensors checkpoint shards:  52% Completed | 535/1024 [00:13<00:21, 22.47it/s]
Loading safetensors checkpoint shards:  53% Completed | 540/1024 [00:14<00:18, 26.20it/s]
Loading safetensors checkpoint shards:  53% Completed | 544/1024 [00:14<00:16, 28.63it/s]
Loading safetensors checkpoint shards:  54% Completed | 549/1024 [00:14<00:15, 30.74it/s]
Loading safetensors checkpoint shards:  54% Completed | 553/1024 [00:14<00:15, 30.33it/s]
Loading safetensors checkpoint shards:  54% Completed | 557/1024 [00:14<00:15, 30.87it/s]
Loading safetensors checkpoint shards:  55% Completed | 561/1024 [00:14<00:14, 32.44it/s]
Loading safetensors checkpoint shards:  55% Completed | 565/1024 [00:14<00:15, 30.46it/s]
Loading safetensors checkpoint shards:  56% Completed | 569/1024 [00:14<00:14, 31.09it/s]
Loading safetensors checkpoint shards:  56% Completed | 574/1024 [00:15<00:13, 33.69it/s]
Loading safetensors checkpoint shards:  56% Completed | 578/1024 [00:15<00:13, 32.35it/s]
Loading safetensors checkpoint shards:  57% Completed | 583/1024 [00:15<00:12, 36.15it/s]
Loading safetensors checkpoint shards:  57% Completed | 587/1024 [00:15<00:12, 34.96it/s]
Loading safetensors checkpoint shards:  58% Completed | 591/1024 [00:15<00:13, 32.08it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:15<00:11, 36.41it/s]
Loading safetensors checkpoint shards:  59% Completed | 601/1024 [00:15<00:11, 37.99it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:15<00:10, 39.06it/s]
Loading safetensors checkpoint shards:  60% Completed | 611/1024 [00:16<00:10, 39.39it/s]
Loading safetensors checkpoint shards:  60% Completed | 616/1024 [00:16<00:09, 41.40it/s]
Loading safetensors checkpoint shards:  61% Completed | 621/1024 [00:16<00:09, 40.99it/s]
Loading safetensors checkpoint shards:  61% Completed | 626/1024 [00:16<00:09, 41.91it/s]
Loading safetensors checkpoint shards:  62% Completed | 631/1024 [00:16<00:09, 41.58it/s]
Loading safetensors checkpoint shards:  62% Completed | 636/1024 [00:16<00:09, 41.12it/s]
Loading safetensors checkpoint shards:  63% Completed | 641/1024 [00:16<00:09, 40.81it/s]
Loading safetensors checkpoint shards:  63% Completed | 646/1024 [00:16<00:09, 39.21it/s]
Loading safetensors checkpoint shards:  63% Completed | 650/1024 [00:16<00:09, 39.11it/s]
Loading safetensors checkpoint shards:  64% Completed | 655/1024 [00:17<00:09, 39.34it/s]
Loading safetensors checkpoint shards:  64% Completed | 659/1024 [00:17<00:09, 38.45it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:17<00:09, 37.40it/s]
Loading safetensors checkpoint shards:  65% Completed | 668/1024 [00:17<00:09, 38.01it/s]
Loading safetensors checkpoint shards:  66% Completed | 673/1024 [00:17<00:09, 38.86it/s]
Loading safetensors checkpoint shards:  66% Completed | 677/1024 [00:17<00:09, 37.82it/s]
Loading safetensors checkpoint shards:  67% Completed | 681/1024 [00:17<00:09, 37.56it/s]
Loading safetensors checkpoint shards:  67% Completed | 685/1024 [00:17<00:09, 37.16it/s]
Loading safetensors checkpoint shards:  67% Completed | 689/1024 [00:18<00:08, 37.41it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:18<00:08, 40.46it/s]
Loading safetensors checkpoint shards:  68% Completed | 699/1024 [00:18<00:07, 40.94it/s]
Loading safetensors checkpoint shards:  69% Completed | 704/1024 [00:18<00:07, 40.61it/s]
Loading safetensors checkpoint shards:  69% Completed | 709/1024 [00:18<00:07, 41.58it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:18<00:07, 41.83it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:18<00:07, 40.93it/s]
Loading safetensors checkpoint shards:  71% Completed | 724/1024 [00:18<00:07, 41.63it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:18<00:06, 42.50it/s]
Loading safetensors checkpoint shards:  72% Completed | 734/1024 [00:19<00:06, 41.80it/s]
Loading safetensors checkpoint shards:  72% Completed | 739/1024 [00:19<00:06, 41.44it/s]
Loading safetensors checkpoint shards:  73% Completed | 744/1024 [00:19<00:06, 42.30it/s]
Loading safetensors checkpoint shards:  73% Completed | 749/1024 [00:19<00:06, 41.47it/s]
Loading safetensors checkpoint shards:  74% Completed | 754/1024 [00:19<00:06, 41.91it/s]
Loading safetensors checkpoint shards:  74% Completed | 759/1024 [00:19<00:06, 42.20it/s]
Loading safetensors checkpoint shards:  75% Completed | 764/1024 [00:19<00:06, 42.43it/s]
Loading safetensors checkpoint shards:  75% Completed | 769/1024 [00:19<00:05, 43.02it/s]
Loading safetensors checkpoint shards:  76% Completed | 774/1024 [00:20<00:05, 41.98it/s]
Loading safetensors checkpoint shards:  76% Completed | 779/1024 [00:20<00:05, 42.62it/s]
Loading safetensors checkpoint shards:  77% Completed | 784/1024 [00:20<00:05, 43.23it/s]
Loading safetensors checkpoint shards:  77% Completed | 789/1024 [00:20<00:05, 42.50it/s]
Loading safetensors checkpoint shards:  78% Completed | 794/1024 [00:20<00:05, 43.38it/s]
Loading safetensors checkpoint shards:  78% Completed | 799/1024 [00:20<00:05, 44.03it/s]
Loading safetensors checkpoint shards:  79% Completed | 804/1024 [00:20<00:04, 45.02it/s]
Loading safetensors checkpoint shards:  79% Completed | 809/1024 [00:21<00:11, 19.19it/s]
Loading safetensors checkpoint shards:  79% Completed | 814/1024 [00:21<00:09, 23.22it/s]
Loading safetensors checkpoint shards:  80% Completed | 818/1024 [00:21<00:07, 26.00it/s]
Loading safetensors checkpoint shards:  80% Completed | 823/1024 [00:21<00:06, 29.24it/s]
Loading safetensors checkpoint shards:  81% Completed | 828/1024 [00:21<00:06, 32.61it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:21<00:05, 35.90it/s]
Loading safetensors checkpoint shards:  82% Completed | 838/1024 [00:21<00:04, 38.25it/s]
Loading safetensors checkpoint shards:  82% Completed | 843/1024 [00:22<00:04, 39.40it/s]
Loading safetensors checkpoint shards:  83% Completed | 848/1024 [00:22<00:04, 40.81it/s]
Loading safetensors checkpoint shards:  83% Completed | 853/1024 [00:22<00:04, 41.77it/s]
Loading safetensors checkpoint shards:  84% Completed | 858/1024 [00:22<00:04, 41.13it/s]
Loading safetensors checkpoint shards:  84% Completed | 863/1024 [00:22<00:03, 41.34it/s]
Loading safetensors checkpoint shards:  85% Completed | 868/1024 [00:22<00:03, 41.80it/s]
Loading safetensors checkpoint shards:  85% Completed | 873/1024 [00:22<00:03, 42.12it/s]
Loading safetensors checkpoint shards:  86% Completed | 878/1024 [00:22<00:03, 40.77it/s]
Loading safetensors checkpoint shards:  86% Completed | 883/1024 [00:23<00:03, 41.56it/s]
Loading safetensors checkpoint shards:  87% Completed | 888/1024 [00:23<00:03, 42.26it/s]
Loading safetensors checkpoint shards:  87% Completed | 893/1024 [00:23<00:03, 41.77it/s]
Loading safetensors checkpoint shards:  88% Completed | 898/1024 [00:23<00:02, 42.04it/s]
Loading safetensors checkpoint shards:  88% Completed | 903/1024 [00:23<00:02, 42.74it/s]
Loading safetensors checkpoint shards:  89% Completed | 908/1024 [00:23<00:02, 43.17it/s]
Loading safetensors checkpoint shards:  89% Completed | 913/1024 [00:23<00:02, 41.61it/s]
Loading safetensors checkpoint shards:  90% Completed | 919/1024 [00:23<00:02, 43.89it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:24<00:02, 43.56it/s]
Loading safetensors checkpoint shards:  91% Completed | 929/1024 [00:24<00:02, 43.45it/s]
Loading safetensors checkpoint shards:  91% Completed | 934/1024 [00:24<00:02, 42.21it/s]
Loading safetensors checkpoint shards:  92% Completed | 939/1024 [00:24<00:01, 42.76it/s]
Loading safetensors checkpoint shards:  92% Completed | 944/1024 [00:24<00:01, 43.07it/s]
Loading safetensors checkpoint shards:  93% Completed | 949/1024 [00:24<00:01, 42.18it/s]
Loading safetensors checkpoint shards:  93% Completed | 954/1024 [00:24<00:01, 42.18it/s]
Loading safetensors checkpoint shards:  94% Completed | 959/1024 [00:24<00:01, 43.05it/s]
Loading safetensors checkpoint shards:  94% Completed | 964/1024 [00:24<00:01, 41.98it/s]
Loading safetensors checkpoint shards:  95% Completed | 969/1024 [00:25<00:01, 42.30it/s]
Loading safetensors checkpoint shards:  95% Completed | 974/1024 [00:25<00:01, 41.92it/s]
Loading safetensors checkpoint shards:  96% Completed | 979/1024 [00:25<00:01, 42.98it/s]
Loading safetensors checkpoint shards:  97% Completed | 996/1024 [00:25<00:00, 76.02it/s]
Loading safetensors checkpoint shards:  98% Completed | 1006/1024 [00:25<00:00, 80.67it/s]
Loading safetensors checkpoint shards:  99% Completed | 1017/1024 [00:25<00:00, 88.04it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 39.95it/s]

[2025-09-13 07:47:28 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:47:29 TP7] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:47:29 TP4] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:47:29 TP0] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:47:29 TP3] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:47:29 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:47:29 TP2] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:47:29 TP1] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:47:30 TP5] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:47:30 TP6] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:47:30 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:47:30 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.50 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s][2025-09-13 07:47:31 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:47:31 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:47:32 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:47:32 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:47:32 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:47:32 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:47:32 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:47:32 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:47:32 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26373.14it/s]
[2025-09-13 07:47:32 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:47:32 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27675.08it/s]
[2025-09-13 07:47:33 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:47:33 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 29054.06it/s]
[2025-09-13 07:47:33 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:47:33 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28427.18it/s]
[2025-09-13 07:47:34 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:47:34 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 29146.95it/s]
[2025-09-13 07:47:34 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.16 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.07it/s]
[2025-09-13 07:47:38 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:47:38 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:47:38 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:47:38 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:47:38 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:47:38 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:47:38 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:47:38 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:47:38 TP0] Capture cuda graph end. Time elapsed: 8.22 s. mem usage=0.43 GB. avail mem=17.14 GB.
[2025-09-13 07:47:38 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:47:38 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:47:38 TP0] Init torch distributed begin.
[2025-09-13 07:47:38 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:47:38 TP0] Load weight begin. avail mem=17.14 GB
[2025-09-13 07:47:38 TP0] Detected fp8 checkpoint.
[2025-09-13 07:47:38 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 179.86it/s]
Loading safetensors checkpoint shards:   4% Completed | 45/1024 [00:00<00:04, 231.31it/s]
Loading safetensors checkpoint shards:  10% Completed | 104/1024 [00:00<00:02, 393.66it/s]
Loading safetensors checkpoint shards:  16% Completed | 163/1024 [00:00<00:01, 468.97it/s]
Loading safetensors checkpoint shards:  22% Completed | 222/1024 [00:00<00:01, 511.32it/s]
Loading safetensors checkpoint shards:  28% Completed | 282/1024 [00:00<00:01, 541.00it/s]
Loading safetensors checkpoint shards:  33% Completed | 341/1024 [00:00<00:01, 555.84it/s]
Loading safetensors checkpoint shards:  39% Completed | 402/1024 [00:00<00:01, 571.09it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:00<00:00, 580.27it/s]
Loading safetensors checkpoint shards:  51% Completed | 524/1024 [00:01<00:00, 588.32it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:01<00:00, 594.03it/s]
Loading safetensors checkpoint shards:  63% Completed | 645/1024 [00:01<00:00, 593.42it/s]
Loading safetensors checkpoint shards:  69% Completed | 705/1024 [00:01<00:00, 588.00it/s]
Loading safetensors checkpoint shards:  75% Completed | 764/1024 [00:01<00:00, 583.72it/s]
Loading safetensors checkpoint shards:  80% Completed | 823/1024 [00:01<00:00, 583.37it/s]
Loading safetensors checkpoint shards:  86% Completed | 882/1024 [00:01<00:00, 580.75it/s]
Loading safetensors checkpoint shards:  92% Completed | 941/1024 [00:01<00:00, 445.47it/s]
Loading safetensors checkpoint shards:  97% Completed | 991/1024 [00:02<00:00, 381.51it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 471.19it/s]

[2025-09-13 07:47:41 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.15 GB, mem usage=1.99 GB.
[2025-09-13 07:47:41 TP0] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:47:41 TP0] Memory pool end. avail mem=14.48 GB
[2025-09-13 07:47:41 TP2] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:47:41 TP3] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:47:41 TP7] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:47:41 TP6] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:47:41 TP1] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:47:41 TP4] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:47:41 TP5] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:47:41 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:47:41 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:47:41 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:47:41 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:47:41 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.11 GB
[2025-09-13 07:47:41 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:47:41 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:47:41 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
Capturing batches (bs=1 avail_mem=14.53 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  2.97it/s][2025-09-13 07:47:47 TP6] Registering 120 cuda graph addresses
[2025-09-13 07:47:47 TP1] Registering 120 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.53 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.41it/s]
[2025-09-13 07:47:47 TP3] Registering 120 cuda graph addresses
[2025-09-13 07:47:47 TP0] Registering 120 cuda graph addresses
[2025-09-13 07:47:47 TP5] Registering 120 cuda graph addresses
[2025-09-13 07:47:47 TP7] Registering 120 cuda graph addresses
[2025-09-13 07:47:47 TP4] Registering 120 cuda graph addresses
[2025-09-13 07:47:47 TP2] Registering 120 cuda graph addresses
[2025-09-13 07:47:47 TP7] Capture draft cuda graph end. Time elapsed: 6.42 s. mem usage=0.38 GB. avail mem=14.72 GB.
[2025-09-13 07:47:47 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.72 GB
[2025-09-13 07:47:47 TP1] Capture draft cuda graph end. Time elapsed: 6.42 s. mem usage=0.38 GB. avail mem=14.49 GB.
[2025-09-13 07:47:47 TP5] Capture draft cuda graph end. Time elapsed: 6.42 s. mem usage=0.38 GB. avail mem=14.49 GB.
[2025-09-13 07:47:47 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.49 GB
[2025-09-13 07:47:47 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.49 GB
[2025-09-13 07:47:47 TP6] Capture draft cuda graph end. Time elapsed: 6.37 s. mem usage=0.38 GB. avail mem=14.49 GB.
[2025-09-13 07:47:47 TP0] Capture draft cuda graph end. Time elapsed: 6.38 s. mem usage=0.39 GB. avail mem=14.53 GB.
[2025-09-13 07:47:47 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.49 GB
[2025-09-13 07:47:47 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.53 GB
[2025-09-13 07:47:47 TP3] Capture draft cuda graph end. Time elapsed: 6.43 s. mem usage=0.38 GB. avail mem=14.49 GB.
[2025-09-13 07:47:47 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.49 GB
[2025-09-13 07:47:47 TP4] Capture draft cuda graph end. Time elapsed: 6.43 s. mem usage=0.38 GB. avail mem=14.49 GB.
[2025-09-13 07:47:47 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.49 GB
[2025-09-13 07:47:47 TP2] Capture draft cuda graph end. Time elapsed: 6.36 s. mem usage=0.38 GB. avail mem=14.49 GB.
[2025-09-13 07:47:47 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.49 GB
Capturing batches (bs=1 avail_mem=14.32 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:00<00:00, 22.64it/s][2025-09-13 07:47:48 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:47:48 TP1] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.32 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 22.37it/s]
[2025-09-13 07:47:48 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:47:48 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:47:48 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:47:48 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:47:48 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:47:48 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:47:48 TP2] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.21 GB. avail mem=14.28 GB.
[2025-09-13 07:47:48 TP0] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.20 GB. avail mem=14.32 GB.
[2025-09-13 07:47:48 TP0] max_total_num_tokens=620249, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.32 GB
[2025-09-13 07:47:48 TP5] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.21 GB. avail mem=14.28 GB.
[2025-09-13 07:47:48 TP6] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.21 GB. avail mem=14.28 GB.
[2025-09-13 07:47:48 TP4] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.21 GB. avail mem=14.28 GB.
[2025-09-13 07:47:48 TP1] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.21 GB. avail mem=14.28 GB.
[2025-09-13 07:47:48 TP7] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.21 GB. avail mem=14.52 GB.
[2025-09-13 07:47:48 TP3] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.21 GB. avail mem=14.28 GB.
[2025-09-13 07:47:49] INFO:     Started server process [359507]
[2025-09-13 07:47:49] INFO:     Waiting for application startup.
[2025-09-13 07:47:49] INFO:     Application startup complete.
[2025-09-13 07:47:49] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:47:49] INFO:     127.0.0.1:45590 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:47:50] INFO:     127.0.0.1:45600 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:47:50 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:47:50 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:47:50 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28047.53it/s]
[2025-09-13 07:47:51] INFO:     127.0.0.1:45602 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:47:51] The server is fired up and ready to roll!
[2025-09-13 07:47:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:48:00] INFO:     127.0.0.1:56816 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:48:01] INFO:     127.0.0.1:56824 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:01 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:48:02] INFO:     127.0.0.1:56836 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:02] INFO:     127.0.0.1:56838 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:48:02] INFO:     127.0.0.1:56850 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:02] INFO:     127.0.0.1:56866 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:02] INFO:     127.0.0.1:56876 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:02] INFO:     127.0.0.1:56882 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:02] INFO:     127.0.0.1:56892 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:02] INFO:     127.0.0.1:56906 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:02 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:48:03 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:48:03 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:48:03 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:48:03 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:48:03 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:48:03 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:48:03 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:48:03 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:48:03 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:48:04 TP0] Decode batch. #running-req: 8, #token: 14679, token usage: 0.02, accept len: 3.34, cuda graph: True, gen throughput (token/s): 51.33, #queue-req: 0, 
[2025-09-13 07:48:05 TP0] Decode batch. #running-req: 8, #token: 16071, token usage: 0.03, accept len: 4.35, cuda graph: True, gen throughput (token/s): 949.62, #queue-req: 0, 
 12%|████████████████▍                                                                                                                  | 1/8 [00:04<00:31,  4.49s/it][2025-09-13 07:48:07 TP0] Decode batch. #running-req: 6, #token: 9485, token usage: 0.02, accept len: 4.51, cuda graph: True, gen throughput (token/s): 927.16, #queue-req: 0, 
 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 7/8 [00:05<00:00,  2.28it/s][2025-09-13 07:48:08 TP0] Decode batch. #running-req: 1, #token: 1499, token usage: 0.00, accept len: 4.10, cuda graph: True, gen throughput (token/s): 409.93, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.28it/s]
[2025-09-13 07:48:08] INFO:     127.0.0.1:60168 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.25      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4079      
Request throughput (req/s):              1.28      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         655.08    
Total token throughput (tok/s):          655.08    
Concurrency:                             6.86      
Accept length:                           4.12      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5363.90   
Median E2E Latency (ms):                 5460.96   
---------------Time to First Token----------------
Mean TTFT (ms):                          684.22    
Median TTFT (ms):                        798.34    
P99 TTFT (ms):                           798.85    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.16      
Median ITL (ms):                         6.19      
P95 ITL (ms):                            18.43     
P99 ITL (ms):                            36.73     
Max ITL (ms):                            746.61    
==================================================
[2025-09-13 07:48:08] INFO:     127.0.0.1:60176 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:48:08] INFO:     127.0.0.1:60190 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:08 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:48:10] INFO:     127.0.0.1:60196 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:10] INFO:     127.0.0.1:60198 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:48:10] INFO:     127.0.0.1:60210 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:10] INFO:     127.0.0.1:60222 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:10] INFO:     127.0.0.1:60236 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:10] INFO:     127.0.0.1:60238 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:10] INFO:     127.0.0.1:60248 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:10] INFO:     127.0.0.1:60254 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:10 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:48:11 TP0] Decode batch. #running-req: 8, #token: 14647, token usage: 0.02, accept len: 3.39, cuda graph: True, gen throughput (token/s): 290.15, #queue-req: 0, 
[2025-09-13 07:48:12 TP0] Decode batch. #running-req: 8, #token: 16044, token usage: 0.03, accept len: 4.37, cuda graph: True, gen throughput (token/s): 949.41, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:03<00:58,  3.88s/it][2025-09-13 07:48:14] INFO:     127.0.0.1:60262 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:14 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:48:14] INFO:     127.0.0.1:60276 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:14 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:48:14 TP0] Decode batch. #running-req: 8, #token: 12307, token usage: 0.02, accept len: 4.45, cuda graph: True, gen throughput (token/s): 758.58, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:04<00:18,  1.39s/it][2025-09-13 07:48:15] INFO:     127.0.0.1:60288 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:15 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:12,  1.03s/it][2025-09-13 07:48:15] INFO:     127.0.0.1:60302 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:15 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:09,  1.21it/s][2025-09-13 07:48:15] INFO:     127.0.0.1:60308 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:15 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:06,  1.53it/s][2025-09-13 07:48:16] INFO:     127.0.0.1:60316 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:16 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:04,  1.95it/s][2025-09-13 07:48:16] INFO:     127.0.0.1:60322 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:48:16 TP0] Decode batch. #running-req: 8, #token: 10634, token usage: 0.02, accept len: 3.90, cuda graph: True, gen throughput (token/s): 574.44, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:04,  1.74it/s][2025-09-13 07:48:17] INFO:     127.0.0.1:60330 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:48:17 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:48:18 TP0] Decode batch. #running-req: 8, #token: 15270, token usage: 0.02, accept len: 3.49, cuda graph: True, gen throughput (token/s): 662.80, #queue-req: 0, 
[2025-09-13 07:48:20 TP0] Decode batch. #running-req: 8, #token: 16728, token usage: 0.03, accept len: 4.56, cuda graph: True, gen throughput (token/s): 998.89, #queue-req: 0, 
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 13/16 [00:10<00:01,  1.81it/s][2025-09-13 07:48:21 TP0] Decode batch. #running-req: 2, #token: 4216, token usage: 0.01, accept len: 4.43, cuda graph: True, gen throughput (token/s): 599.84, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.40it/s]
[2025-09-13 07:48:21] INFO:     127.0.0.1:43666 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.47     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8075      
Request throughput (req/s):              1.39      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         714.04    
Total token throughput (tok/s):          714.04    
Concurrency:                             7.41      
Accept length:                           4.10      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5310.96   
Median E2E Latency (ms):                 5432.52   
---------------Time to First Token----------------
Mean TTFT (ms):                          250.83    
Median TTFT (ms):                        284.08    
P99 TTFT (ms):                           419.29    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.90      
Median ITL (ms):                         6.30      
P95 ITL (ms):                            24.30     
P99 ITL (ms):                            49.89     
Max ITL (ms):                            270.71    
==================================================
[2025-09-13 07:48:21] INFO:     127.0.0.1:43678 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=40: batch_size=8, steps=6, topk=2, num_draft_tokens=12, speed=111.70 token/s, step_time=36.70 ms
Start i=41: batch_size=8, steps=6, topk=3, num_draft_tokens=4
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 6 --speculative-eagle-topk 3 --speculative-num-draft-tokens 4 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:48:32.494000 365237 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:48:32.494000 365237 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:48:32] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=519907064, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=6, speculative_eagle_topk=3, speculative_num_draft_tokens=4, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:48:33] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:48:41.726000 365449 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:48:41.726000 365449 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:48:41.784000 365444 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:48:41.784000 365444 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:48:41.810000 365442 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:48:41.810000 365442 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:48:41.892000 365450 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:48:41.892000 365450 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:48:41.925000 365446 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:48:41.925000 365446 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:48:41.925000 365443 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:48:41.925000 365443 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:48:42.045000 365447 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:48:42.045000 365447 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:48:42.060000 365445 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:48:42.060000 365445 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:48:42.127000 365448 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:48:42.127000 365448 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:48:42 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:48:42 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:48:42 TP0] Init torch distributed begin.
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:48:44 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:48:47 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:48:48 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:48:48 TP0] Detected fp8 checkpoint.
[2025-09-13 07:48:49 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 25/1024 [00:00<00:04, 223.14it/s]
Loading safetensors checkpoint shards:   5% Completed | 48/1024 [00:00<00:13, 71.96it/s]
Loading safetensors checkpoint shards:   6% Completed | 60/1024 [00:00<00:16, 56.73it/s]
Loading safetensors checkpoint shards:   7% Completed | 69/1024 [00:01<00:20, 47.41it/s]
Loading safetensors checkpoint shards:   7% Completed | 76/1024 [00:01<00:21, 44.47it/s]
Loading safetensors checkpoint shards:   8% Completed | 82/1024 [00:01<00:22, 41.26it/s]
Loading safetensors checkpoint shards:   8% Completed | 87/1024 [00:01<00:23, 40.71it/s]
Loading safetensors checkpoint shards:   9% Completed | 92/1024 [00:01<00:23, 39.26it/s]
Loading safetensors checkpoint shards:   9% Completed | 97/1024 [00:01<00:23, 39.87it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:02<00:23, 39.98it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:02<00:40, 22.81it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:36, 25.32it/s]
Loading safetensors checkpoint shards:  11% Completed | 116/1024 [00:02<00:30, 29.45it/s]
Loading safetensors checkpoint shards:  12% Completed | 121/1024 [00:02<00:28, 32.18it/s]
Loading safetensors checkpoint shards:  12% Completed | 125/1024 [00:03<00:27, 33.16it/s]
Loading safetensors checkpoint shards:  13% Completed | 130/1024 [00:03<00:25, 35.52it/s]
Loading safetensors checkpoint shards:  13% Completed | 134/1024 [00:03<00:25, 35.17it/s]
Loading safetensors checkpoint shards:  14% Completed | 140/1024 [00:03<00:22, 39.32it/s]
Loading safetensors checkpoint shards:  14% Completed | 145/1024 [00:03<00:22, 38.87it/s]
Loading safetensors checkpoint shards:  15% Completed | 150/1024 [00:03<00:22, 39.46it/s]
Loading safetensors checkpoint shards:  15% Completed | 155/1024 [00:03<00:22, 38.79it/s]
Loading safetensors checkpoint shards:  16% Completed | 159/1024 [00:03<00:22, 37.71it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:03<00:22, 38.50it/s]
Loading safetensors checkpoint shards:  16% Completed | 168/1024 [00:04<00:22, 37.43it/s]
Loading safetensors checkpoint shards:  17% Completed | 173/1024 [00:04<00:22, 38.56it/s]
Loading safetensors checkpoint shards:  17% Completed | 177/1024 [00:04<00:22, 37.54it/s]
Loading safetensors checkpoint shards:  18% Completed | 181/1024 [00:04<00:23, 36.29it/s]
Loading safetensors checkpoint shards:  18% Completed | 186/1024 [00:04<00:21, 38.28it/s]
Loading safetensors checkpoint shards:  19% Completed | 190/1024 [00:04<00:22, 37.67it/s]
Loading safetensors checkpoint shards:  19% Completed | 195/1024 [00:04<00:20, 39.99it/s]
Loading safetensors checkpoint shards:  20% Completed | 200/1024 [00:04<00:21, 39.22it/s]
Loading safetensors checkpoint shards:  20% Completed | 205/1024 [00:05<00:20, 40.31it/s]
Loading safetensors checkpoint shards:  21% Completed | 210/1024 [00:05<00:20, 40.36it/s]
Loading safetensors checkpoint shards:  21% Completed | 215/1024 [00:05<00:19, 42.49it/s]
Loading safetensors checkpoint shards:  21% Completed | 220/1024 [00:05<00:19, 41.03it/s]
Loading safetensors checkpoint shards:  22% Completed | 225/1024 [00:05<00:19, 41.55it/s]
Loading safetensors checkpoint shards:  22% Completed | 230/1024 [00:05<00:18, 41.85it/s]
Loading safetensors checkpoint shards:  23% Completed | 235/1024 [00:05<00:19, 41.36it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:05<00:18, 43.32it/s]
Loading safetensors checkpoint shards:  24% Completed | 245/1024 [00:05<00:18, 42.18it/s]
Loading safetensors checkpoint shards:  25% Completed | 251/1024 [00:06<00:17, 43.86it/s]
Loading safetensors checkpoint shards:  25% Completed | 256/1024 [00:06<00:18, 41.16it/s]
Loading safetensors checkpoint shards:  25% Completed | 261/1024 [00:06<00:18, 41.23it/s]
Loading safetensors checkpoint shards:  26% Completed | 266/1024 [00:06<00:18, 40.67it/s]
Loading safetensors checkpoint shards:  26% Completed | 271/1024 [00:06<00:17, 41.95it/s]
Loading safetensors checkpoint shards:  27% Completed | 276/1024 [00:06<00:19, 38.56it/s]
Loading safetensors checkpoint shards:  27% Completed | 280/1024 [00:06<00:20, 36.81it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:07<00:18, 39.53it/s]
Loading safetensors checkpoint shards:  28% Completed | 290/1024 [00:07<00:19, 37.86it/s]
Loading safetensors checkpoint shards:  29% Completed | 295/1024 [00:07<00:18, 38.99it/s]
Loading safetensors checkpoint shards:  29% Completed | 299/1024 [00:07<00:19, 38.06it/s]
Loading safetensors checkpoint shards:  30% Completed | 303/1024 [00:07<00:19, 37.76it/s]
Loading safetensors checkpoint shards:  30% Completed | 307/1024 [00:07<00:38, 18.52it/s]
Loading safetensors checkpoint shards:  30% Completed | 311/1024 [00:08<00:33, 21.46it/s]
Loading safetensors checkpoint shards:  31% Completed | 316/1024 [00:08<00:27, 25.95it/s]
Loading safetensors checkpoint shards:  31% Completed | 320/1024 [00:08<00:24, 28.40it/s]
Loading safetensors checkpoint shards:  32% Completed | 324/1024 [00:08<00:23, 29.97it/s]
Loading safetensors checkpoint shards:  32% Completed | 329/1024 [00:08<00:20, 33.90it/s]
Loading safetensors checkpoint shards:  33% Completed | 333/1024 [00:08<00:19, 34.78it/s]
Loading safetensors checkpoint shards:  33% Completed | 338/1024 [00:08<00:18, 37.20it/s]
Loading safetensors checkpoint shards:  33% Completed | 342/1024 [00:08<00:18, 37.37it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:08<00:18, 36.38it/s]
Loading safetensors checkpoint shards:  34% Completed | 351/1024 [00:09<00:17, 38.94it/s]
Loading safetensors checkpoint shards:  35% Completed | 355/1024 [00:09<00:17, 38.38it/s]
Loading safetensors checkpoint shards:  35% Completed | 359/1024 [00:09<00:17, 37.76it/s]
Loading safetensors checkpoint shards:  36% Completed | 364/1024 [00:09<00:17, 38.44it/s]
Loading safetensors checkpoint shards:  36% Completed | 369/1024 [00:09<00:15, 41.16it/s]
Loading safetensors checkpoint shards:  37% Completed | 375/1024 [00:09<00:14, 44.76it/s]
Loading safetensors checkpoint shards:  37% Completed | 380/1024 [00:09<00:14, 45.79it/s]
Loading safetensors checkpoint shards:  38% Completed | 386/1024 [00:09<00:13, 48.50it/s]
Loading safetensors checkpoint shards:  38% Completed | 391/1024 [00:09<00:13, 48.60it/s]
Loading safetensors checkpoint shards:  39% Completed | 396/1024 [00:10<00:15, 41.01it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:10<00:16, 38.66it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:10<00:16, 37.69it/s]
Loading safetensors checkpoint shards:  40% Completed | 410/1024 [00:10<00:16, 37.62it/s]
Loading safetensors checkpoint shards:  40% Completed | 414/1024 [00:10<00:16, 37.68it/s]
Loading safetensors checkpoint shards:  41% Completed | 419/1024 [00:10<00:15, 38.69it/s]
Loading safetensors checkpoint shards:  41% Completed | 423/1024 [00:10<00:15, 38.42it/s]
Loading safetensors checkpoint shards:  42% Completed | 428/1024 [00:10<00:14, 40.29it/s]
Loading safetensors checkpoint shards:  42% Completed | 433/1024 [00:11<00:14, 39.95it/s]
Loading safetensors checkpoint shards:  43% Completed | 438/1024 [00:11<00:13, 41.99it/s]
Loading safetensors checkpoint shards:  43% Completed | 443/1024 [00:11<00:14, 40.92it/s]
Loading safetensors checkpoint shards:  44% Completed | 448/1024 [00:11<00:13, 42.13it/s]
Loading safetensors checkpoint shards:  44% Completed | 453/1024 [00:11<00:13, 42.47it/s]
Loading safetensors checkpoint shards:  45% Completed | 458/1024 [00:11<00:13, 42.47it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:11<00:12, 43.40it/s]
Loading safetensors checkpoint shards:  46% Completed | 468/1024 [00:11<00:12, 43.19it/s]
Loading safetensors checkpoint shards:  46% Completed | 474/1024 [00:12<00:11, 47.53it/s]
Loading safetensors checkpoint shards:  47% Completed | 479/1024 [00:12<00:11, 46.87it/s]
Loading safetensors checkpoint shards:  47% Completed | 485/1024 [00:12<00:11, 48.39it/s]
Loading safetensors checkpoint shards:  48% Completed | 490/1024 [00:12<00:11, 45.70it/s]
Loading safetensors checkpoint shards:  48% Completed | 495/1024 [00:12<00:11, 46.83it/s]
Loading safetensors checkpoint shards:  49% Completed | 500/1024 [00:12<00:11, 45.94it/s]
Loading safetensors checkpoint shards:  49% Completed | 505/1024 [00:12<00:11, 46.00it/s]
Loading safetensors checkpoint shards:  50% Completed | 510/1024 [00:12<00:11, 44.31it/s]
Loading safetensors checkpoint shards:  50% Completed | 515/1024 [00:12<00:11, 45.57it/s]
Loading safetensors checkpoint shards:  51% Completed | 520/1024 [00:13<00:11, 44.03it/s]
Loading safetensors checkpoint shards:  51% Completed | 525/1024 [00:13<00:11, 43.82it/s]
Loading safetensors checkpoint shards:  52% Completed | 531/1024 [00:13<00:10, 45.73it/s]
Loading safetensors checkpoint shards:  52% Completed | 536/1024 [00:13<00:11, 43.78it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:13<00:10, 44.55it/s]
Loading safetensors checkpoint shards:  53% Completed | 546/1024 [00:13<00:11, 42.46it/s]
Loading safetensors checkpoint shards:  54% Completed | 551/1024 [00:14<00:22, 20.86it/s]
Loading safetensors checkpoint shards:  54% Completed | 555/1024 [00:14<00:20, 23.41it/s]
Loading safetensors checkpoint shards:  55% Completed | 559/1024 [00:14<00:17, 26.17it/s]
Loading safetensors checkpoint shards:  55% Completed | 563/1024 [00:14<00:16, 28.39it/s]
Loading safetensors checkpoint shards:  55% Completed | 568/1024 [00:14<00:14, 32.36it/s]
Loading safetensors checkpoint shards:  56% Completed | 574/1024 [00:14<00:11, 38.04it/s]
Loading safetensors checkpoint shards:  57% Completed | 580/1024 [00:14<00:10, 42.40it/s]
Loading safetensors checkpoint shards:  57% Completed | 588/1024 [00:14<00:08, 49.47it/s]
Loading safetensors checkpoint shards:  58% Completed | 594/1024 [00:15<00:08, 50.55it/s]
Loading safetensors checkpoint shards:  59% Completed | 600/1024 [00:15<00:08, 51.28it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:15<00:07, 52.56it/s]
Loading safetensors checkpoint shards:  60% Completed | 613/1024 [00:15<00:07, 56.88it/s]
Loading safetensors checkpoint shards:  61% Completed | 620/1024 [00:15<00:06, 60.20it/s]
Loading safetensors checkpoint shards:  61% Completed | 627/1024 [00:15<00:06, 60.99it/s]
Loading safetensors checkpoint shards:  62% Completed | 634/1024 [00:15<00:06, 55.83it/s]
Loading safetensors checkpoint shards:  62% Completed | 640/1024 [00:15<00:06, 55.84it/s]
Loading safetensors checkpoint shards:  63% Completed | 646/1024 [00:15<00:07, 52.18it/s]
Loading safetensors checkpoint shards:  64% Completed | 652/1024 [00:16<00:07, 49.40it/s]
Loading safetensors checkpoint shards:  64% Completed | 658/1024 [00:16<00:07, 51.69it/s]
Loading safetensors checkpoint shards:  65% Completed | 664/1024 [00:16<00:07, 49.19it/s]
Loading safetensors checkpoint shards:  66% Completed | 671/1024 [00:16<00:06, 53.32it/s]
Loading safetensors checkpoint shards:  66% Completed | 677/1024 [00:16<00:06, 54.89it/s]
Loading safetensors checkpoint shards:  67% Completed | 684/1024 [00:16<00:05, 56.79it/s]
Loading safetensors checkpoint shards:  67% Completed | 691/1024 [00:16<00:05, 57.73it/s]
Loading safetensors checkpoint shards:  68% Completed | 699/1024 [00:16<00:05, 63.27it/s]
Loading safetensors checkpoint shards:  69% Completed | 706/1024 [00:17<00:05, 60.50it/s]
Loading safetensors checkpoint shards:  70% Completed | 713/1024 [00:17<00:05, 57.66it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:17<00:05, 57.55it/s]
Loading safetensors checkpoint shards:  71% Completed | 726/1024 [00:17<00:04, 60.70it/s]
Loading safetensors checkpoint shards:  72% Completed | 733/1024 [00:17<00:04, 62.82it/s]
Loading safetensors checkpoint shards:  72% Completed | 740/1024 [00:17<00:04, 57.59it/s]
Loading safetensors checkpoint shards:  73% Completed | 747/1024 [00:17<00:04, 57.45it/s]
Loading safetensors checkpoint shards:  74% Completed | 756/1024 [00:17<00:04, 64.21it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:18<00:09, 28.01it/s]
Loading safetensors checkpoint shards:  75% Completed | 768/1024 [00:18<00:08, 30.75it/s]
Loading safetensors checkpoint shards:  75% Completed | 773/1024 [00:18<00:07, 33.53it/s]
Loading safetensors checkpoint shards:  76% Completed | 781/1024 [00:18<00:05, 41.33it/s]
Loading safetensors checkpoint shards:  77% Completed | 788/1024 [00:18<00:05, 46.71it/s]
Loading safetensors checkpoint shards:  78% Completed | 796/1024 [00:18<00:04, 53.92it/s]
Loading safetensors checkpoint shards:  78% Completed | 803/1024 [00:19<00:03, 57.17it/s]
Loading safetensors checkpoint shards:  79% Completed | 811/1024 [00:19<00:03, 61.44it/s]
Loading safetensors checkpoint shards:  80% Completed | 818/1024 [00:19<00:03, 63.29it/s]
Loading safetensors checkpoint shards:  81% Completed | 826/1024 [00:19<00:03, 65.75it/s]
Loading safetensors checkpoint shards:  81% Completed | 834/1024 [00:19<00:02, 69.10it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:19<00:02, 69.77it/s]
Loading safetensors checkpoint shards:  83% Completed | 850/1024 [00:19<00:02, 67.92it/s]
Loading safetensors checkpoint shards:  84% Completed | 858/1024 [00:19<00:02, 69.62it/s]
Loading safetensors checkpoint shards:  85% Completed | 867/1024 [00:19<00:02, 74.05it/s]
Loading safetensors checkpoint shards:  85% Completed | 875/1024 [00:20<00:02, 71.47it/s]
Loading safetensors checkpoint shards:  86% Completed | 883/1024 [00:20<00:01, 70.80it/s]
Loading safetensors checkpoint shards:  87% Completed | 891/1024 [00:20<00:01, 67.86it/s]
Loading safetensors checkpoint shards:  88% Completed | 899/1024 [00:20<00:01, 67.31it/s]
Loading safetensors checkpoint shards:  88% Completed | 906/1024 [00:20<00:01, 66.73it/s]
Loading safetensors checkpoint shards:  89% Completed | 913/1024 [00:20<00:01, 62.39it/s]
Loading safetensors checkpoint shards:  90% Completed | 922/1024 [00:20<00:01, 68.16it/s]
Loading safetensors checkpoint shards:  91% Completed | 930/1024 [00:20<00:01, 67.85it/s]
Loading safetensors checkpoint shards:  92% Completed | 937/1024 [00:21<00:01, 65.43it/s]
Loading safetensors checkpoint shards:  92% Completed | 944/1024 [00:21<00:01, 66.10it/s]
Loading safetensors checkpoint shards:  93% Completed | 951/1024 [00:21<00:01, 63.29it/s]
Loading safetensors checkpoint shards:  94% Completed | 958/1024 [00:21<00:01, 62.70it/s]
Loading safetensors checkpoint shards:  94% Completed | 965/1024 [00:21<00:01, 54.75it/s]
Loading safetensors checkpoint shards:  95% Completed | 971/1024 [00:21<00:01, 48.65it/s]
Loading safetensors checkpoint shards:  95% Completed | 977/1024 [00:21<00:00, 47.56it/s]
Loading safetensors checkpoint shards:  96% Completed | 986/1024 [00:21<00:00, 54.86it/s]
Loading safetensors checkpoint shards:  98% Completed | 1003/1024 [00:22<00:00, 80.86it/s]
Loading safetensors checkpoint shards: 100% Completed | 1023/1024 [00:22<00:00, 110.24it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:22<00:00, 46.16it/s]
 
[2025-09-13 07:49:17 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:49:17 TP5] KV Cache is allocated. #tokens: 620233, KV size: 40.59 GB
[2025-09-13 07:49:17 TP7] KV Cache is allocated. #tokens: 620233, KV size: 40.59 GB
[2025-09-13 07:49:17 TP0] KV Cache is allocated. #tokens: 620233, KV size: 40.59 GB
[2025-09-13 07:49:17 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:49:17 TP1] KV Cache is allocated. #tokens: 620233, KV size: 40.59 GB
[2025-09-13 07:49:17 TP2] KV Cache is allocated. #tokens: 620233, KV size: 40.59 GB
[2025-09-13 07:49:17 TP3] KV Cache is allocated. #tokens: 620233, KV size: 40.59 GB
[2025-09-13 07:49:17 TP4] KV Cache is allocated. #tokens: 620233, KV size: 40.59 GB
[2025-09-13 07:49:17 TP6] KV Cache is allocated. #tokens: 620233, KV size: 40.59 GB
[2025-09-13 07:49:17 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:49:18 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.53 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:49:18 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:49:18 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:49:19 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:49:19 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:49:19 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:49:19 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:49:19 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:49:19 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:49:19 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26174.94it/s]
[2025-09-13 07:49:19 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:49:19 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 24699.63it/s]
[2025-09-13 07:49:20 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:49:20 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28599.03it/s]
[2025-09-13 07:49:20 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:49:20 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27874.73it/s]
[2025-09-13 07:49:21 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:49:21 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28995.23it/s]
[2025-09-13 07:49:22 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.22 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.14it/s]
[2025-09-13 07:49:25 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:49:25 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:49:25 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:49:25 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:49:25 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:49:25 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:49:25 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:49:25 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:49:25 TP0] Capture cuda graph end. Time elapsed: 7.66 s. mem usage=0.36 GB. avail mem=17.20 GB.
[2025-09-13 07:49:25 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:49:25 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:49:25 TP0] Init torch distributed begin.
[2025-09-13 07:49:25 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:49:25 TP0] Load weight begin. avail mem=17.20 GB
[2025-09-13 07:49:25 TP0] Detected fp8 checkpoint.
[2025-09-13 07:49:25 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 19/1024 [00:00<00:05, 179.72it/s]
Loading safetensors checkpoint shards:   4% Completed | 45/1024 [00:00<00:04, 223.71it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:00<00:02, 403.02it/s]
Loading safetensors checkpoint shards:  17% Completed | 172/1024 [00:00<00:01, 494.08it/s]
Loading safetensors checkpoint shards:  23% Completed | 233/1024 [00:00<00:01, 534.52it/s]
Loading safetensors checkpoint shards:  29% Completed | 296/1024 [00:00<00:01, 563.79it/s]
Loading safetensors checkpoint shards:  35% Completed | 357/1024 [00:00<00:01, 577.65it/s]
Loading safetensors checkpoint shards:  41% Completed | 420/1024 [00:00<00:01, 591.08it/s]
Loading safetensors checkpoint shards:  47% Completed | 483/1024 [00:00<00:00, 600.65it/s]
Loading safetensors checkpoint shards:  53% Completed | 545/1024 [00:01<00:00, 603.56it/s]
Loading safetensors checkpoint shards:  59% Completed | 608/1024 [00:01<00:00, 609.51it/s]
Loading safetensors checkpoint shards:  65% Completed | 669/1024 [00:01<00:00, 597.38it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:01<00:00, 582.76it/s]
Loading safetensors checkpoint shards:  77% Completed | 788/1024 [00:01<00:00, 569.99it/s]
Loading safetensors checkpoint shards:  83% Completed | 846/1024 [00:01<00:00, 569.65it/s]
Loading safetensors checkpoint shards:  88% Completed | 904/1024 [00:01<00:00, 564.15it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:01<00:00, 562.66it/s]
Loading safetensors checkpoint shards:  99% Completed | 1018/1024 [00:02<00:00, 361.57it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 498.35it/s]

[2025-09-13 07:49:27 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.21 GB, mem usage=1.99 GB.
[2025-09-13 07:49:27 TP6] KV Cache is allocated. #tokens: 620233, KV size: 0.67 GB
[2025-09-13 07:49:27 TP2] KV Cache is allocated. #tokens: 620233, KV size: 0.67 GB
[2025-09-13 07:49:27 TP3] KV Cache is allocated. #tokens: 620233, KV size: 0.67 GB
[2025-09-13 07:49:27 TP5] KV Cache is allocated. #tokens: 620233, KV size: 0.67 GB
[2025-09-13 07:49:27 TP7] KV Cache is allocated. #tokens: 620233, KV size: 0.67 GB
[2025-09-13 07:49:27 TP0] KV Cache is allocated. #tokens: 620233, KV size: 0.67 GB
[2025-09-13 07:49:27 TP0] Memory pool end. avail mem=14.54 GB
[2025-09-13 07:49:27 TP4] KV Cache is allocated. #tokens: 620233, KV size: 0.67 GB
[2025-09-13 07:49:27 TP1] KV Cache is allocated. #tokens: 620233, KV size: 0.67 GB
[2025-09-13 07:49:28 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:49:28 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:49:28 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:49:28 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.17 GB
[2025-09-13 07:49:28 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:49:28 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:49:28 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:49:28 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
Capturing batches (bs=1 avail_mem=14.54 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.43it/s]
[2025-09-13 07:49:34 TP3] Registering 120 cuda graph addresses
[2025-09-13 07:49:34 TP2] Registering 120 cuda graph addresses
[2025-09-13 07:49:34 TP6] Registering 120 cuda graph addresses
[2025-09-13 07:49:34 TP4] Registering 120 cuda graph addresses
[2025-09-13 07:49:34 TP0] Registering 120 cuda graph addresses
[2025-09-13 07:49:34 TP1] Registering 120 cuda graph addresses
[2025-09-13 07:49:34 TP7] Registering 120 cuda graph addresses
[2025-09-13 07:49:34 TP5] Registering 120 cuda graph addresses
[2025-09-13 07:49:34 TP4] Capture draft cuda graph end. Time elapsed: 6.31 s. mem usage=0.44 GB. avail mem=14.50 GB.
[2025-09-13 07:49:34 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 07:49:34 TP6] Capture draft cuda graph end. Time elapsed: 6.31 s. mem usage=0.44 GB. avail mem=14.50 GB.
[2025-09-13 07:49:34 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 07:49:34 TP1] Capture draft cuda graph end. Time elapsed: 6.31 s. mem usage=0.44 GB. avail mem=14.50 GB.
[2025-09-13 07:49:34 TP7] Capture draft cuda graph end. Time elapsed: 6.31 s. mem usage=0.44 GB. avail mem=14.73 GB.
[2025-09-13 07:49:34 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.73 GB
[2025-09-13 07:49:34 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 07:49:34 TP5] Capture draft cuda graph end. Time elapsed: 6.31 s. mem usage=0.44 GB. avail mem=14.50 GB.
[2025-09-13 07:49:34 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 07:49:34 TP0] Capture draft cuda graph end. Time elapsed: 6.31 s. mem usage=0.44 GB. avail mem=14.54 GB.
[2025-09-13 07:49:34 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.54 GB
[2025-09-13 07:49:34 TP3] Capture draft cuda graph end. Time elapsed: 6.31 s. mem usage=0.44 GB. avail mem=14.50 GB.
[2025-09-13 07:49:34 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
[2025-09-13 07:49:34 TP2] Capture draft cuda graph end. Time elapsed: 6.31 s. mem usage=0.44 GB. avail mem=14.50 GB.
[2025-09-13 07:49:34 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.50 GB
Capturing batches (bs=1 avail_mem=14.34 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 24.58it/s]
[2025-09-13 07:49:35 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:49:35 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:49:35 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:49:35 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:49:35 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:49:35 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:49:35 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:49:35 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:49:35 TP6] Capture draft extend cuda graph end. Time elapsed: 1.17 s. mem usage=0.20 GB. avail mem=14.30 GB.
[2025-09-13 07:49:35 TP5] Capture draft extend cuda graph end. Time elapsed: 1.17 s. mem usage=0.20 GB. avail mem=14.30 GB.
[2025-09-13 07:49:35 TP0] Capture draft extend cuda graph end. Time elapsed: 1.17 s. mem usage=0.20 GB. avail mem=14.34 GB.
[2025-09-13 07:49:35 TP7] Capture draft extend cuda graph end. Time elapsed: 1.17 s. mem usage=0.20 GB. avail mem=14.53 GB.
[2025-09-13 07:49:35 TP3] Capture draft extend cuda graph end. Time elapsed: 1.17 s. mem usage=0.20 GB. avail mem=14.30 GB.
[2025-09-13 07:49:35 TP0] max_total_num_tokens=620233, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.34 GB
[2025-09-13 07:49:35 TP2] Capture draft extend cuda graph end. Time elapsed: 1.17 s. mem usage=0.20 GB. avail mem=14.30 GB.
[2025-09-13 07:49:35 TP4] Capture draft extend cuda graph end. Time elapsed: 1.18 s. mem usage=0.20 GB. avail mem=14.30 GB.
[2025-09-13 07:49:35 TP1] Capture draft extend cuda graph end. Time elapsed: 1.18 s. mem usage=0.20 GB. avail mem=14.30 GB.
[2025-09-13 07:49:36] INFO:     Started server process [365237]
[2025-09-13 07:49:36] INFO:     Waiting for application startup.
[2025-09-13 07:49:36] INFO:     Application startup complete.
[2025-09-13 07:49:36] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:49:36] INFO:     127.0.0.1:56016 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:49:37] INFO:     127.0.0.1:56018 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:49:37 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:49:37 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:49:37 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28792.72it/s]
[2025-09-13 07:49:38] INFO:     127.0.0.1:56032 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:38] The server is fired up and ready to roll!
[2025-09-13 07:49:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:49:47] INFO:     127.0.0.1:36806 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:49:48] INFO:     127.0.0.1:43004 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:48 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:49:49] INFO:     127.0.0.1:43006 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:49] INFO:     127.0.0.1:43010 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:49 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:49:49] INFO:     127.0.0.1:43016 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:49] INFO:     127.0.0.1:43026 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:49] INFO:     127.0.0.1:43028 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:49] INFO:     127.0.0.1:43036 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:49] INFO:     127.0.0.1:43052 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:49] INFO:     127.0.0.1:43060 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:49 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:49:50 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:49:50 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:49:50 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:49:50 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:49:50 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:49:50 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:49:50 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:49:50 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:49:50 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:49:51 TP0] Decode batch. #running-req: 8, #token: 14458, token usage: 0.02, accept len: 2.58, cuda graph: True, gen throughput (token/s): 36.69, #queue-req: 0, 
[2025-09-13 07:49:52 TP0] Decode batch. #running-req: 8, #token: 15377, token usage: 0.02, accept len: 2.87, cuda graph: True, gen throughput (token/s): 726.08, #queue-req: 0, 
[2025-09-13 07:49:53 TP0] Decode batch. #running-req: 8, #token: 16363, token usage: 0.03, accept len: 3.08, cuda graph: True, gen throughput (token/s): 776.92, #queue-req: 0, 
[2025-09-13 07:49:55 TP0] Decode batch. #running-req: 8, #token: 17341, token usage: 0.03, accept len: 3.06, cuda graph: True, gen throughput (token/s): 770.40, #queue-req: 0, 
 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 7/8 [00:06<00:00,  2.60it/s][2025-09-13 07:49:56 TP0] Decode batch. #running-req: 1, #token: 1447, token usage: 0.00, accept len: 3.05, cuda graph: True, gen throughput (token/s): 465.51, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.12it/s]
[2025-09-13 07:49:56] INFO:     127.0.0.1:43064 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  7.18      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4068      
Request throughput (req/s):              1.11      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         570.60    
Total token throughput (tok/s):          570.60    
Concurrency:                             6.96      
Accept length:                           2.94      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   6244.85   
Median E2E Latency (ms):                 6204.41   
---------------Time to First Token----------------
Mean TTFT (ms):                          626.04    
Median TTFT (ms):                        742.13    
P99 TTFT (ms):                           742.65    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           11.00     
Median ITL (ms):                         7.96      
P95 ITL (ms):                            30.13     
P99 ITL (ms):                            34.45     
Max ITL (ms):                            745.89    
==================================================
[2025-09-13 07:49:56] INFO:     127.0.0.1:43070 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:49:56] INFO:     127.0.0.1:43072 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:56 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:49:58] INFO:     127.0.0.1:49258 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:58] INFO:     127.0.0.1:49264 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:49:58] INFO:     127.0.0.1:49268 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:58] INFO:     127.0.0.1:49274 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:58] INFO:     127.0.0.1:49276 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:58] INFO:     127.0.0.1:49280 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:58] INFO:     127.0.0.1:49292 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:58] INFO:     127.0.0.1:49294 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:49:58 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:49:58 TP0] Decode batch. #running-req: 8, #token: 13966, token usage: 0.02, accept len: 2.43, cuda graph: True, gen throughput (token/s): 65.86, #queue-req: 0, 
[2025-09-13 07:49:59 TP0] Decode batch. #running-req: 8, #token: 14838, token usage: 0.02, accept len: 2.73, cuda graph: True, gen throughput (token/s): 714.31, #queue-req: 0, 
[2025-09-13 07:50:01 TP0] Decode batch. #running-req: 8, #token: 15806, token usage: 0.03, accept len: 3.02, cuda graph: True, gen throughput (token/s): 766.35, #queue-req: 0, 
[2025-09-13 07:50:02 TP0] Decode batch. #running-req: 8, #token: 16781, token usage: 0.03, accept len: 3.05, cuda graph: True, gen throughput (token/s): 771.25, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:14,  4.97s/it][2025-09-13 07:50:03] INFO:     127.0.0.1:49304 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:50:03 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:05<00:32,  2.30s/it][2025-09-13 07:50:03] INFO:     127.0.0.1:49310 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:50:03 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:17,  1.38s/it][2025-09-13 07:50:03] INFO:     127.0.0.1:49320 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:50:03 TP0] Decode batch. #running-req: 7, #token: 11906, token usage: 0.02, accept len: 3.07, cuda graph: True, gen throughput (token/s): 595.73, #queue-req: 0, 
[2025-09-13 07:50:03 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:06<00:11,  1.02it/s][2025-09-13 07:50:04] INFO:     127.0.0.1:49324 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:50:04 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:06<00:08,  1.33it/s][2025-09-13 07:50:04] INFO:     127.0.0.1:49332 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:50:04 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:06<00:06,  1.59it/s][2025-09-13 07:50:05] INFO:     127.0.0.1:49334 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:50:05] INFO:     127.0.0.1:49348 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:50:05 TP0] Prefill batch. #new-seq: 2, #new-token: 2369, #cached-token: 1751, token usage: 0.01, #running-req: 6, #queue-req: 0, 
[2025-09-13 07:50:05 TP0] Decode batch. #running-req: 8, #token: 10562, token usage: 0.02, accept len: 2.75, cuda graph: True, gen throughput (token/s): 477.45, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:07<00:04,  1.69it/s][2025-09-13 07:50:06] INFO:     127.0.0.1:49352 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:50:06 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:50:07 TP0] Decode batch. #running-req: 8, #token: 14987, token usage: 0.02, accept len: 2.83, cuda graph: True, gen throughput (token/s): 612.07, #queue-req: 0, 
[2025-09-13 07:50:08 TP0] Decode batch. #running-req: 8, #token: 16020, token usage: 0.03, accept len: 3.23, cuda graph: True, gen throughput (token/s): 820.91, #queue-req: 0, 
 62%|████████████████████████████████████████████████████████████████████████████████▋                                                | 10/16 [00:11<00:05,  1.03it/s][2025-09-13 07:50:09 TP0] Decode batch. #running-req: 6, #token: 15040, token usage: 0.02, accept len: 3.24, cuda graph: True, gen throughput (token/s): 771.98, #queue-req: 0, 
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 13/16 [00:12<00:01,  1.80it/s][2025-09-13 07:50:10 TP0] Decode batch. #running-req: 3, #token: 8842, token usage: 0.01, accept len: 2.99, cuda graph: True, gen throughput (token/s): 482.35, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:12<00:00,  1.24it/s]
[2025-09-13 07:50:11] INFO:     127.0.0.1:43744 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  12.94     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8076      
Request throughput (req/s):              1.24      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         633.01    
Total token throughput (tok/s):          633.01    
Concurrency:                             7.41      
Accept length:                           2.96      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5990.98   
Median E2E Latency (ms):                 5930.80   
---------------Time to First Token----------------
Mean TTFT (ms):                          223.22    
Median TTFT (ms):                        235.11    
P99 TTFT (ms):                           280.68    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           11.29     
Median ITL (ms):                         7.91      
P95 ITL (ms):                            31.07     
P99 ITL (ms):                            66.79     
Max ITL (ms):                            267.14    
==================================================
[2025-09-13 07:50:11] INFO:     127.0.0.1:43752 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=41: batch_size=8, steps=6, topk=3, num_draft_tokens=4, speed=93.81 token/s, step_time=31.58 ms
Start i=42: batch_size=8, steps=6, topk=3, num_draft_tokens=6
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 6 --speculative-eagle-topk 3 --speculative-num-draft-tokens 6 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:50:21.844000 370806 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:50:21.844000 370806 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:50:22] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=604039227, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=6, speculative_eagle_topk=3, speculative_num_draft_tokens=6, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:50:22] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:50:30.958000 371040 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:50:30.958000 371040 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:50:31.034000 371037 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:50:31.034000 371037 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:50:31.183000 371041 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:50:31.183000 371041 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:50:31.207000 371039 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:50:31.207000 371039 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 07:50:31.271000 371033 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:50:31.271000 371033 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:50:31.325000 371036 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:50:31.325000 371036 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:50:31.333000 371038 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:50:31.333000 371038 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:50:31.356000 371034 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:50:31.356000 371034 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:50:31.371000 371035 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:50:31.371000 371035 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:50:31 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:50:31 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:50:31 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:50:33 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:50:36 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:50:38 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:50:38 TP0] Detected fp8 checkpoint.
[2025-09-13 07:50:38 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 27/1024 [00:00<00:03, 269.00it/s]
Loading safetensors checkpoint shards:   5% Completed | 54/1024 [00:00<00:16, 60.27it/s]
Loading safetensors checkpoint shards:   7% Completed | 68/1024 [00:01<00:18, 52.15it/s]
Loading safetensors checkpoint shards:   8% Completed | 78/1024 [00:01<00:19, 48.38it/s]
Loading safetensors checkpoint shards:   8% Completed | 86/1024 [00:01<00:17, 52.62it/s]
Loading safetensors checkpoint shards:   9% Completed | 94/1024 [00:01<00:18, 51.39it/s]
Loading safetensors checkpoint shards:  10% Completed | 101/1024 [00:02<00:30, 30.76it/s]
Loading safetensors checkpoint shards:  10% Completed | 106/1024 [00:02<00:28, 32.65it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:26, 34.09it/s]
Loading safetensors checkpoint shards:  12% Completed | 118/1024 [00:02<00:23, 38.38it/s]
Loading safetensors checkpoint shards:  12% Completed | 124/1024 [00:02<00:21, 42.12it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:02<00:18, 49.39it/s]
Loading safetensors checkpoint shards:  14% Completed | 139/1024 [00:02<00:16, 54.01it/s]
Loading safetensors checkpoint shards:  14% Completed | 147/1024 [00:02<00:14, 59.64it/s]
Loading safetensors checkpoint shards:  15% Completed | 155/1024 [00:03<00:13, 63.77it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:03<00:12, 67.73it/s]
Loading safetensors checkpoint shards:  17% Completed | 173/1024 [00:03<00:11, 73.17it/s]
Loading safetensors checkpoint shards:  18% Completed | 181/1024 [00:03<00:11, 70.98it/s]
Loading safetensors checkpoint shards:  18% Completed | 189/1024 [00:03<00:11, 71.08it/s]
Loading safetensors checkpoint shards:  19% Completed | 198/1024 [00:03<00:11, 75.00it/s]
Loading safetensors checkpoint shards:  20% Completed | 206/1024 [00:03<00:11, 72.18it/s]
Loading safetensors checkpoint shards:  21% Completed | 214/1024 [00:03<00:12, 63.00it/s]
Loading safetensors checkpoint shards:  22% Completed | 221/1024 [00:04<00:14, 56.90it/s]
Loading safetensors checkpoint shards:  22% Completed | 228/1024 [00:04<00:13, 58.37it/s]
Loading safetensors checkpoint shards:  23% Completed | 235/1024 [00:04<00:13, 57.56it/s]
Loading safetensors checkpoint shards:  24% Completed | 241/1024 [00:04<00:32, 24.25it/s]
Loading safetensors checkpoint shards:  24% Completed | 247/1024 [00:05<00:27, 28.38it/s]
Loading safetensors checkpoint shards:  25% Completed | 252/1024 [00:05<00:24, 31.69it/s]
Loading safetensors checkpoint shards:  25% Completed | 257/1024 [00:05<00:22, 33.54it/s]
Loading safetensors checkpoint shards:  26% Completed | 262/1024 [00:05<00:21, 35.44it/s]
Loading safetensors checkpoint shards:  26% Completed | 267/1024 [00:05<00:20, 36.97it/s]
Loading safetensors checkpoint shards:  27% Completed | 273/1024 [00:05<00:18, 41.01it/s]
Loading safetensors checkpoint shards:  27% Completed | 279/1024 [00:05<00:16, 45.52it/s]
Loading safetensors checkpoint shards:  28% Completed | 287/1024 [00:05<00:13, 53.25it/s]
Loading safetensors checkpoint shards:  29% Completed | 293/1024 [00:06<00:13, 53.66it/s]
Loading safetensors checkpoint shards:  29% Completed | 300/1024 [00:06<00:12, 56.93it/s]
Loading safetensors checkpoint shards:  30% Completed | 308/1024 [00:06<00:11, 62.88it/s]
Loading safetensors checkpoint shards:  31% Completed | 317/1024 [00:06<00:10, 68.36it/s]
Loading safetensors checkpoint shards:  32% Completed | 324/1024 [00:06<00:10, 67.26it/s]
Loading safetensors checkpoint shards:  33% Completed | 333/1024 [00:06<00:09, 73.21it/s]
Loading safetensors checkpoint shards:  33% Completed | 343/1024 [00:06<00:08, 78.95it/s]
Loading safetensors checkpoint shards:  34% Completed | 351/1024 [00:06<00:08, 78.99it/s]
Loading safetensors checkpoint shards:  35% Completed | 359/1024 [00:06<00:08, 74.32it/s]
Loading safetensors checkpoint shards:  36% Completed | 367/1024 [00:07<00:10, 64.16it/s]
Loading safetensors checkpoint shards:  37% Completed | 374/1024 [00:07<00:11, 59.06it/s]
Loading safetensors checkpoint shards:  37% Completed | 381/1024 [00:07<00:13, 45.99it/s]
Loading safetensors checkpoint shards:  38% Completed | 387/1024 [00:07<00:14, 43.58it/s]
Loading safetensors checkpoint shards:  38% Completed | 392/1024 [00:07<00:14, 42.15it/s]
Loading safetensors checkpoint shards:  39% Completed | 397/1024 [00:07<00:14, 43.84it/s]
Loading safetensors checkpoint shards:  39% Completed | 403/1024 [00:07<00:13, 46.31it/s]
Loading safetensors checkpoint shards:  40% Completed | 408/1024 [00:08<00:34, 17.74it/s]
Loading safetensors checkpoint shards:  40% Completed | 412/1024 [00:08<00:31, 19.47it/s]
Loading safetensors checkpoint shards:  41% Completed | 416/1024 [00:08<00:28, 21.48it/s]
Loading safetensors checkpoint shards:  41% Completed | 420/1024 [00:09<00:29, 20.67it/s]
Loading safetensors checkpoint shards:  41% Completed | 423/1024 [00:09<00:27, 22.16it/s]
Loading safetensors checkpoint shards:  42% Completed | 427/1024 [00:09<00:24, 24.36it/s]
Loading safetensors checkpoint shards:  42% Completed | 430/1024 [00:09<00:23, 25.00it/s]
Loading safetensors checkpoint shards:  42% Completed | 433/1024 [00:09<00:26, 22.36it/s]
Loading safetensors checkpoint shards:  43% Completed | 438/1024 [00:09<00:20, 28.19it/s]
Loading safetensors checkpoint shards:  43% Completed | 442/1024 [00:09<00:23, 25.00it/s]
Loading safetensors checkpoint shards:  44% Completed | 446/1024 [00:10<00:20, 27.72it/s]
Loading safetensors checkpoint shards:  44% Completed | 450/1024 [00:10<00:20, 27.35it/s]
Loading safetensors checkpoint shards:  44% Completed | 453/1024 [00:10<00:22, 24.93it/s]
Loading safetensors checkpoint shards:  45% Completed | 456/1024 [00:10<00:23, 23.96it/s]
Loading safetensors checkpoint shards:  45% Completed | 459/1024 [00:10<00:23, 24.02it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:10<00:22, 24.67it/s]
Loading safetensors checkpoint shards:  46% Completed | 466/1024 [00:10<00:22, 25.21it/s]
Loading safetensors checkpoint shards:  46% Completed | 469/1024 [00:11<00:23, 23.86it/s]
Loading safetensors checkpoint shards:  46% Completed | 473/1024 [00:11<00:21, 25.99it/s]
Loading safetensors checkpoint shards:  46% Completed | 476/1024 [00:11<00:22, 24.53it/s]
Loading safetensors checkpoint shards:  47% Completed | 479/1024 [00:11<00:23, 23.49it/s]
Loading safetensors checkpoint shards:  47% Completed | 483/1024 [00:11<00:21, 25.75it/s]
Loading safetensors checkpoint shards:  47% Completed | 486/1024 [00:11<00:21, 25.08it/s]
Loading safetensors checkpoint shards:  48% Completed | 489/1024 [00:11<00:21, 24.71it/s]
Loading safetensors checkpoint shards:  48% Completed | 492/1024 [00:12<00:23, 22.94it/s]
Loading safetensors checkpoint shards:  48% Completed | 496/1024 [00:12<00:20, 25.15it/s]
Loading safetensors checkpoint shards:  49% Completed | 500/1024 [00:12<00:18, 27.66it/s]
Loading safetensors checkpoint shards:  49% Completed | 503/1024 [00:12<00:19, 27.17it/s]
Loading safetensors checkpoint shards:  50% Completed | 508/1024 [00:12<00:16, 30.69it/s]
Loading safetensors checkpoint shards:  50% Completed | 512/1024 [00:12<00:16, 30.53it/s]
Loading safetensors checkpoint shards:  50% Completed | 517/1024 [00:12<00:15, 32.94it/s]
Loading safetensors checkpoint shards:  51% Completed | 521/1024 [00:12<00:16, 29.90it/s]
Loading safetensors checkpoint shards:  51% Completed | 525/1024 [00:13<00:18, 27.34it/s]
Loading safetensors checkpoint shards:  52% Completed | 529/1024 [00:13<00:16, 29.22it/s]
Loading safetensors checkpoint shards:  52% Completed | 533/1024 [00:13<00:17, 28.29it/s]
Loading safetensors checkpoint shards:  52% Completed | 536/1024 [00:13<00:17, 27.63it/s]
Loading safetensors checkpoint shards:  53% Completed | 540/1024 [00:13<00:15, 30.26it/s]
Loading safetensors checkpoint shards:  53% Completed | 544/1024 [00:13<00:15, 30.68it/s]
Loading safetensors checkpoint shards:  54% Completed | 549/1024 [00:13<00:13, 34.40it/s]
Loading safetensors checkpoint shards:  54% Completed | 553/1024 [00:13<00:13, 35.02it/s]
Loading safetensors checkpoint shards:  54% Completed | 557/1024 [00:14<00:13, 34.85it/s]
Loading safetensors checkpoint shards:  55% Completed | 561/1024 [00:14<00:15, 30.53it/s]
Loading safetensors checkpoint shards:  55% Completed | 565/1024 [00:14<00:16, 28.49it/s]
Loading safetensors checkpoint shards:  56% Completed | 569/1024 [00:14<00:15, 30.26it/s]
Loading safetensors checkpoint shards:  56% Completed | 574/1024 [00:14<00:13, 32.71it/s]
Loading safetensors checkpoint shards:  56% Completed | 578/1024 [00:14<00:13, 33.03it/s]
Loading safetensors checkpoint shards:  57% Completed | 584/1024 [00:14<00:11, 37.18it/s]
Loading safetensors checkpoint shards:  57% Completed | 588/1024 [00:14<00:11, 36.98it/s]
Loading safetensors checkpoint shards:  58% Completed | 592/1024 [00:15<00:12, 35.48it/s]
Loading safetensors checkpoint shards:  58% Completed | 597/1024 [00:15<00:11, 37.38it/s]
Loading safetensors checkpoint shards:  59% Completed | 601/1024 [00:15<00:11, 36.79it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:15<00:11, 37.29it/s]
Loading safetensors checkpoint shards:  60% Completed | 610/1024 [00:15<00:11, 36.87it/s]
Loading safetensors checkpoint shards:  60% Completed | 614/1024 [00:15<00:11, 36.36it/s]
Loading safetensors checkpoint shards:  60% Completed | 619/1024 [00:15<00:10, 37.77it/s]
Loading safetensors checkpoint shards:  61% Completed | 623/1024 [00:15<00:10, 37.63it/s]
Loading safetensors checkpoint shards:  61% Completed | 627/1024 [00:16<00:10, 37.03it/s]
Loading safetensors checkpoint shards:  62% Completed | 631/1024 [00:16<00:32, 11.95it/s]
Loading safetensors checkpoint shards:  62% Completed | 635/1024 [00:17<00:26, 14.84it/s]
Loading safetensors checkpoint shards:  62% Completed | 639/1024 [00:17<00:21, 18.03it/s]
Loading safetensors checkpoint shards:  63% Completed | 643/1024 [00:17<00:17, 21.23it/s]
Loading safetensors checkpoint shards:  63% Completed | 647/1024 [00:17<00:15, 23.65it/s]
Loading safetensors checkpoint shards:  64% Completed | 651/1024 [00:17<00:14, 26.56it/s]
Loading safetensors checkpoint shards:  64% Completed | 655/1024 [00:17<00:12, 28.93it/s]
Loading safetensors checkpoint shards:  64% Completed | 659/1024 [00:17<00:12, 30.08it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:17<00:11, 31.65it/s]
Loading safetensors checkpoint shards:  65% Completed | 667/1024 [00:17<00:10, 33.40it/s]
Loading safetensors checkpoint shards:  66% Completed | 671/1024 [00:18<00:10, 34.66it/s]
Loading safetensors checkpoint shards:  66% Completed | 676/1024 [00:18<00:09, 35.58it/s]
Loading safetensors checkpoint shards:  67% Completed | 681/1024 [00:18<00:09, 36.89it/s]
Loading safetensors checkpoint shards:  67% Completed | 686/1024 [00:18<00:08, 37.94it/s]
Loading safetensors checkpoint shards:  67% Completed | 690/1024 [00:18<00:08, 38.39it/s]
Loading safetensors checkpoint shards:  68% Completed | 695/1024 [00:18<00:08, 40.38it/s]
Loading safetensors checkpoint shards:  68% Completed | 700/1024 [00:18<00:08, 40.18it/s]
Loading safetensors checkpoint shards:  69% Completed | 705/1024 [00:18<00:08, 38.73it/s]
Loading safetensors checkpoint shards:  69% Completed | 709/1024 [00:19<00:08, 38.71it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:19<00:07, 39.95it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:19<00:07, 38.47it/s]
Loading safetensors checkpoint shards:  71% Completed | 723/1024 [00:19<00:07, 38.52it/s]
Loading safetensors checkpoint shards:  71% Completed | 728/1024 [00:19<00:07, 39.63it/s]
Loading safetensors checkpoint shards:  71% Completed | 732/1024 [00:19<00:07, 39.11it/s]
Loading safetensors checkpoint shards:  72% Completed | 737/1024 [00:19<00:07, 39.96it/s]
Loading safetensors checkpoint shards:  72% Completed | 742/1024 [00:19<00:06, 40.56it/s]
Loading safetensors checkpoint shards:  73% Completed | 747/1024 [00:19<00:06, 40.83it/s]
Loading safetensors checkpoint shards:  73% Completed | 752/1024 [00:20<00:06, 41.32it/s]
Loading safetensors checkpoint shards:  74% Completed | 757/1024 [00:20<00:06, 41.20it/s]
Loading safetensors checkpoint shards:  74% Completed | 762/1024 [00:20<00:06, 41.48it/s]
Loading safetensors checkpoint shards:  75% Completed | 767/1024 [00:20<00:06, 41.77it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:20<00:06, 40.48it/s]
Loading safetensors checkpoint shards:  76% Completed | 777/1024 [00:20<00:06, 40.65it/s]
Loading safetensors checkpoint shards:  76% Completed | 782/1024 [00:20<00:05, 40.60it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:20<00:06, 39.34it/s]
Loading safetensors checkpoint shards:  77% Completed | 792/1024 [00:21<00:05, 39.87it/s]
Loading safetensors checkpoint shards:  78% Completed | 797/1024 [00:21<00:05, 40.37it/s]
Loading safetensors checkpoint shards:  78% Completed | 802/1024 [00:21<00:05, 39.82it/s]
Loading safetensors checkpoint shards:  79% Completed | 807/1024 [00:21<00:05, 41.79it/s]
Loading safetensors checkpoint shards:  79% Completed | 812/1024 [00:21<00:05, 41.64it/s]
Loading safetensors checkpoint shards:  80% Completed | 817/1024 [00:21<00:05, 40.18it/s]
Loading safetensors checkpoint shards:  80% Completed | 822/1024 [00:21<00:05, 39.93it/s]
Loading safetensors checkpoint shards:  81% Completed | 827/1024 [00:21<00:04, 40.09it/s]
Loading safetensors checkpoint shards:  81% Completed | 832/1024 [00:22<00:04, 40.51it/s]
Loading safetensors checkpoint shards:  82% Completed | 837/1024 [00:22<00:04, 40.88it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:22<00:04, 40.36it/s]
Loading safetensors checkpoint shards:  83% Completed | 847/1024 [00:22<00:04, 39.16it/s]
Loading safetensors checkpoint shards:  83% Completed | 851/1024 [00:22<00:04, 39.20it/s]
Loading safetensors checkpoint shards:  83% Completed | 855/1024 [00:22<00:04, 39.33it/s]
Loading safetensors checkpoint shards:  84% Completed | 859/1024 [00:22<00:04, 38.46it/s]
Loading safetensors checkpoint shards:  84% Completed | 864/1024 [00:22<00:04, 39.13it/s]
Loading safetensors checkpoint shards:  85% Completed | 869/1024 [00:22<00:03, 39.77it/s]
Loading safetensors checkpoint shards:  85% Completed | 873/1024 [00:23<00:03, 39.72it/s]
Loading safetensors checkpoint shards:  86% Completed | 877/1024 [00:23<00:03, 38.14it/s]
Loading safetensors checkpoint shards:  86% Completed | 881/1024 [00:23<00:03, 38.46it/s]
Loading safetensors checkpoint shards:  86% Completed | 885/1024 [00:23<00:03, 38.79it/s]
Loading safetensors checkpoint shards:  87% Completed | 889/1024 [00:23<00:03, 38.41it/s]
Loading safetensors checkpoint shards:  87% Completed | 894/1024 [00:23<00:03, 39.33it/s]
Loading safetensors checkpoint shards:  88% Completed | 898/1024 [00:23<00:03, 39.37it/s]
Loading safetensors checkpoint shards:  88% Completed | 903/1024 [00:23<00:02, 40.52it/s]
Loading safetensors checkpoint shards:  89% Completed | 908/1024 [00:23<00:02, 41.76it/s]
Loading safetensors checkpoint shards:  89% Completed | 913/1024 [00:24<00:02, 40.41it/s]
Loading safetensors checkpoint shards:  90% Completed | 918/1024 [00:24<00:02, 42.70it/s]
Loading safetensors checkpoint shards:  90% Completed | 923/1024 [00:24<00:02, 40.90it/s]
Loading safetensors checkpoint shards:  91% Completed | 928/1024 [00:24<00:02, 39.72it/s]
Loading safetensors checkpoint shards:  91% Completed | 933/1024 [00:24<00:02, 37.99it/s]
Loading safetensors checkpoint shards:  92% Completed | 937/1024 [00:25<00:06, 13.43it/s]
Loading safetensors checkpoint shards:  92% Completed | 942/1024 [00:25<00:04, 17.08it/s]
Loading safetensors checkpoint shards:  92% Completed | 946/1024 [00:25<00:03, 20.01it/s]
Loading safetensors checkpoint shards:  93% Completed | 951/1024 [00:25<00:03, 24.26it/s]
Loading safetensors checkpoint shards:  93% Completed | 956/1024 [00:25<00:02, 28.07it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:26<00:02, 30.54it/s]
Loading safetensors checkpoint shards:  94% Completed | 966/1024 [00:26<00:01, 33.37it/s]
Loading safetensors checkpoint shards:  95% Completed | 970/1024 [00:26<00:01, 34.40it/s]
Loading safetensors checkpoint shards:  95% Completed | 975/1024 [00:26<00:01, 36.00it/s]
Loading safetensors checkpoint shards:  96% Completed | 980/1024 [00:26<00:01, 38.09it/s]
Loading safetensors checkpoint shards:  97% Completed | 998/1024 [00:26<00:00, 71.27it/s]
Loading safetensors checkpoint shards:  98% Completed | 1006/1024 [00:26<00:00, 71.67it/s]
Loading safetensors checkpoint shards: 100% Completed | 1020/1024 [00:26<00:00, 89.18it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:26<00:00, 38.12it/s]

[2025-09-13 07:51:05 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:51:06 TP7] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:51:06 TP5] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:51:06 TP0] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:51:06 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:51:06 TP4] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:51:06 TP2] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:51:06 TP6] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:51:06 TP1] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:51:06 TP3] KV Cache is allocated. #tokens: 620249, KV size: 40.59 GB
[2025-09-13 07:51:06 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:51:06 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.52 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:51:07 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:51:07 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
                                                                                                                                                                     [2025-09-13 07:51:07 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:51:07 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:51:07 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:51:07 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:51:07 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:51:07 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:51:07 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 24923.42it/s]
[2025-09-13 07:51:08 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:51:08 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25592.79it/s]
[2025-09-13 07:51:09 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:51:09 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26934.21it/s]
[2025-09-13 07:51:09 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:51:09 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26608.65it/s]
[2025-09-13 07:51:10 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:51:10 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27594.32it/s]
[2025-09-13 07:51:10 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.23 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.81it/s][2025-09-13 07:51:14 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:51:14 TP7] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.23 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.12it/s]
[2025-09-13 07:51:14 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:51:14 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:51:14 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:51:14 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:51:14 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:51:14 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:51:14 TP0] Capture cuda graph end. Time elapsed: 7.94 s. mem usage=0.35 GB. avail mem=17.21 GB.
[2025-09-13 07:51:14 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:51:14 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:51:14 TP0] Init torch distributed begin.
[2025-09-13 07:51:14 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:51:14 TP0] Load weight begin. avail mem=17.21 GB
[2025-09-13 07:51:14 TP0] Detected fp8 checkpoint.
[2025-09-13 07:51:14 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 19/1024 [00:00<00:05, 182.27it/s]
Loading safetensors checkpoint shards:   5% Completed | 50/1024 [00:00<00:03, 253.85it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:00<00:02, 397.50it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:00<00:01, 471.89it/s]
Loading safetensors checkpoint shards:  22% Completed | 226/1024 [00:00<00:01, 513.12it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:00<00:01, 538.21it/s]
Loading safetensors checkpoint shards:  34% Completed | 344/1024 [00:00<00:01, 553.87it/s]
Loading safetensors checkpoint shards:  39% Completed | 403/1024 [00:00<00:01, 564.27it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:00<00:00, 573.03it/s]
Loading safetensors checkpoint shards:  51% Completed | 523/1024 [00:01<00:00, 580.87it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:01<00:00, 589.74it/s]
Loading safetensors checkpoint shards:  63% Completed | 644/1024 [00:01<00:00, 586.72it/s]
Loading safetensors checkpoint shards:  69% Completed | 703/1024 [00:01<00:00, 579.49it/s]
Loading safetensors checkpoint shards:  74% Completed | 761/1024 [00:01<00:00, 572.58it/s]
Loading safetensors checkpoint shards:  80% Completed | 819/1024 [00:01<00:00, 570.64it/s]
Loading safetensors checkpoint shards:  86% Completed | 877/1024 [00:01<00:00, 566.66it/s]
Loading safetensors checkpoint shards:  91% Completed | 934/1024 [00:01<00:00, 566.16it/s]
Loading safetensors checkpoint shards:  97% Completed | 991/1024 [00:01<00:00, 496.83it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 500.65it/s]

[2025-09-13 07:51:16 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.22 GB, mem usage=1.99 GB.
[2025-09-13 07:51:16 TP7] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:51:16 TP6] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:51:16 TP1] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:51:16 TP2] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:51:16 TP3] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:51:16 TP5] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:51:16 TP4] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:51:16 TP0] KV Cache is allocated. #tokens: 620249, KV size: 0.67 GB
[2025-09-13 07:51:16 TP0] Memory pool end. avail mem=14.55 GB
[2025-09-13 07:51:17 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:51:17 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:51:17 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:51:17 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:51:17 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.18 GB
[2025-09-13 07:51:17 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:51:17 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.99 GB
[2025-09-13 07:51:17 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
Capturing batches (bs=1 avail_mem=14.55 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  3.09it/s][2025-09-13 07:51:23 TP1] Registering 120 cuda graph addresses
[2025-09-13 07:51:23 TP3] Registering 120 cuda graph addresses
[2025-09-13 07:51:23 TP7] Registering 120 cuda graph addresses
[2025-09-13 07:51:23 TP6] Registering 120 cuda graph addresses
[2025-09-13 07:51:23 TP2] Registering 120 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.55 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.44it/s]
[2025-09-13 07:51:23 TP0] Registering 120 cuda graph addresses
[2025-09-13 07:51:23 TP4] Registering 120 cuda graph addresses
[2025-09-13 07:51:23 TP5] Registering 120 cuda graph addresses
[2025-09-13 07:51:23 TP2] Capture draft cuda graph end. Time elapsed: 6.37 s. mem usage=0.43 GB. avail mem=14.51 GB.
[2025-09-13 07:51:23 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.51 GB
[2025-09-13 07:51:23 TP6] Capture draft cuda graph end. Time elapsed: 6.38 s. mem usage=0.43 GB. avail mem=14.51 GB.
[2025-09-13 07:51:23 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.51 GB
[2025-09-13 07:51:23 TP7] Capture draft cuda graph end. Time elapsed: 6.38 s. mem usage=0.43 GB. avail mem=14.74 GB.
[2025-09-13 07:51:23 TP1] Capture draft cuda graph end. Time elapsed: 6.38 s. mem usage=0.43 GB. avail mem=14.51 GB.
[2025-09-13 07:51:23 TP5] Capture draft cuda graph end. Time elapsed: 6.38 s. mem usage=0.43 GB. avail mem=14.51 GB.
[2025-09-13 07:51:23 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.74 GB
[2025-09-13 07:51:23 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.51 GB
[2025-09-13 07:51:23 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.51 GB
[2025-09-13 07:51:23 TP0] Capture draft cuda graph end. Time elapsed: 6.38 s. mem usage=0.44 GB. avail mem=14.55 GB.
[2025-09-13 07:51:23 TP4] Capture draft cuda graph end. Time elapsed: 6.38 s. mem usage=0.43 GB. avail mem=14.51 GB.
[2025-09-13 07:51:23 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.55 GB
[2025-09-13 07:51:23 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.51 GB
[2025-09-13 07:51:23 TP3] Capture draft cuda graph end. Time elapsed: 6.38 s. mem usage=0.43 GB. avail mem=14.51 GB.
[2025-09-13 07:51:23 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.51 GB
Capturing batches (bs=1 avail_mem=14.35 GB):  50%|███████████████████████████████████████████                                           | 4/8 [00:00<00:00, 36.04it/s][2025-09-13 07:51:24 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:51:24 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:51:24 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:51:24 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:51:24 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:51:24 TP2] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.35 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 41.37it/s]
[2025-09-13 07:51:24 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:51:24 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:51:24 TP7] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.20 GB. avail mem=14.54 GB.
[2025-09-13 07:51:24 TP0] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.20 GB. avail mem=14.35 GB.
[2025-09-13 07:51:24 TP0] max_total_num_tokens=620249, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.35 GB
[2025-09-13 07:51:24 TP1] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.20 GB. avail mem=14.31 GB.
[2025-09-13 07:51:24 TP4] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.20 GB. avail mem=14.31 GB.
[2025-09-13 07:51:24 TP6] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.20 GB. avail mem=14.31 GB.
[2025-09-13 07:51:24 TP2] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.20 GB. avail mem=14.31 GB.
[2025-09-13 07:51:24 TP3] Capture draft extend cuda graph end. Time elapsed: 1.13 s. mem usage=0.20 GB. avail mem=14.31 GB.
[2025-09-13 07:51:24 TP5] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.20 GB. avail mem=14.31 GB.
[2025-09-13 07:51:25] INFO:     Started server process [370806]
[2025-09-13 07:51:25] INFO:     Waiting for application startup.
[2025-09-13 07:51:25] INFO:     Application startup complete.
[2025-09-13 07:51:25] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:51:26] INFO:     127.0.0.1:54854 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:51:26 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:51:26 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:51:26 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup:   0%|                                                                                                                      | 0/16384 [00:00<?, ?it/s][2025-09-13 07:51:26] INFO:     127.0.0.1:54864 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27949.01it/s]
[2025-09-13 07:51:27] INFO:     127.0.0.1:54858 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:27] The server is fired up and ready to roll!
[2025-09-13 07:51:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:51:37] INFO:     127.0.0.1:38920 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:51:37] INFO:     127.0.0.1:38932 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:37 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:51:39] INFO:     127.0.0.1:45156 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:39] INFO:     127.0.0.1:45164 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:51:39] INFO:     127.0.0.1:45174 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:39] INFO:     127.0.0.1:45190 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:39] INFO:     127.0.0.1:45202 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:39] INFO:     127.0.0.1:45210 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:39] INFO:     127.0.0.1:45218 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:39] INFO:     127.0.0.1:45230 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:39 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:51:39 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:51:39 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:51:39 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:51:39 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:51:39 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:51:39 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:51:39 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:51:39 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:51:39 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:51:41 TP0] Decode batch. #running-req: 8, #token: 14516, token usage: 0.02, accept len: 2.83, cuda graph: True, gen throughput (token/s): 38.29, #queue-req: 0, 
[2025-09-13 07:51:42 TP0] Decode batch. #running-req: 8, #token: 15678, token usage: 0.03, accept len: 3.63, cuda graph: True, gen throughput (token/s): 887.64, #queue-req: 0, 
[2025-09-13 07:51:43 TP0] Decode batch. #running-req: 8, #token: 16918, token usage: 0.03, accept len: 3.88, cuda graph: True, gen throughput (token/s): 922.78, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████▌                                                                 | 4/8 [00:05<00:04,  1.02s/it][2025-09-13 07:51:45 TP0] Decode batch. #running-req: 4, #token: 4509, token usage: 0.01, accept len: 3.56, cuda graph: True, gen throughput (token/s): 640.22, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.16it/s]
[2025-09-13 07:51:46] INFO:     127.0.0.1:45238 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.92      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4062      
Request throughput (req/s):              1.16      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         592.11    
Total token throughput (tok/s):          592.11    
Concurrency:                             6.82      
Accept length:                           3.52      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5897.92   
Median E2E Latency (ms):                 5859.53   
---------------Time to First Token----------------
Mean TTFT (ms):                          655.90    
Median TTFT (ms):                        771.90    
P99 TTFT (ms):                           772.42    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.26     
Median ITL (ms):                         6.76      
P95 ITL (ms):                            27.99     
P99 ITL (ms):                            40.70     
Max ITL (ms):                            769.14    
==================================================
[2025-09-13 07:51:46] INFO:     127.0.0.1:45244 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:51:46] INFO:     127.0.0.1:45252 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:51:46 TP0] Decode batch. #running-req: 1, #token: 4670, token usage: 0.01, accept len: 3.07, cuda graph: True, gen throughput (token/s): 184.29, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:51:47] INFO:     127.0.0.1:45268 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:47] INFO:     127.0.0.1:45272 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:47 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:51:47] INFO:     127.0.0.1:45288 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:47] INFO:     127.0.0.1:45304 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:47] INFO:     127.0.0.1:45314 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:47] INFO:     127.0.0.1:45324 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:47] INFO:     127.0.0.1:45340 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:47] INFO:     127.0.0.1:45350 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:47 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:51:48 TP0] Decode batch. #running-req: 8, #token: 14666, token usage: 0.02, accept len: 3.02, cuda graph: True, gen throughput (token/s): 315.91, #queue-req: 0, 
[2025-09-13 07:51:50 TP0] Decode batch. #running-req: 8, #token: 15840, token usage: 0.03, accept len: 3.67, cuda graph: True, gen throughput (token/s): 890.79, #queue-req: 0, 
[2025-09-13 07:51:51 TP0] Decode batch. #running-req: 8, #token: 17067, token usage: 0.03, accept len: 3.83, cuda graph: True, gen throughput (token/s): 915.10, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:04,  4.31s/it][2025-09-13 07:51:51] INFO:     127.0.0.1:52234 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:51 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:28,  2.07s/it][2025-09-13 07:51:52] INFO:     127.0.0.1:52244 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:17,  1.32s/it][2025-09-13 07:51:52] INFO:     127.0.0.1:52250 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:52 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:11,  1.08it/s][2025-09-13 07:51:53] INFO:     127.0.0.1:52260 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:53 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:07,  1.50it/s][2025-09-13 07:51:53] INFO:     127.0.0.1:52274 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:53 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:51:53 TP0] Decode batch. #running-req: 8, #token: 8404, token usage: 0.01, accept len: 3.49, cuda graph: True, gen throughput (token/s): 491.65, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:06<00:05,  1.73it/s][2025-09-13 07:51:53] INFO:     127.0.0.1:52280 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:53 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:04,  2.11it/s][2025-09-13 07:51:54] INFO:     127.0.0.1:52290 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:54 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:07<00:05,  1.56it/s][2025-09-13 07:51:55] INFO:     127.0.0.1:52302 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:51:55 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:51:55 TP0] Decode batch. #running-req: 8, #token: 14621, token usage: 0.02, accept len: 3.13, cuda graph: True, gen throughput (token/s): 555.95, #queue-req: 0, 
[2025-09-13 07:51:56 TP0] Decode batch. #running-req: 8, #token: 15737, token usage: 0.03, accept len: 3.49, cuda graph: True, gen throughput (token/s): 845.30, #queue-req: 0, 
 56%|█████████████████████████████████████████████████████████████████████████▏                                                        | 9/16 [00:10<00:09,  1.39s/it][2025-09-13 07:51:58 TP0] Decode batch. #running-req: 7, #token: 13551, token usage: 0.02, accept len: 3.37, cuda graph: True, gen throughput (token/s): 804.09, #queue-req: 0, 
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 14/16 [00:11<00:00,  2.28it/s][2025-09-13 07:51:59 TP0] Decode batch. #running-req: 1, #token: 1877, token usage: 0.00, accept len: 3.58, cuda graph: True, gen throughput (token/s): 614.64, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.35it/s]
[2025-09-13 07:51:59] INFO:     127.0.0.1:47810 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.90     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8076      
Request throughput (req/s):              1.34      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         688.52    
Total token throughput (tok/s):          688.52    
Concurrency:                             7.64      
Accept length:                           3.47      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5677.63   
Median E2E Latency (ms):                 5744.72   
---------------Time to First Token----------------
Mean TTFT (ms):                          243.39    
Median TTFT (ms):                        258.20    
P99 TTFT (ms):                           312.70    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.63     
Median ITL (ms):                         6.77      
P95 ITL (ms):                            32.30     
P99 ITL (ms):                            56.36     
Max ITL (ms):                            268.82    
==================================================
[2025-09-13 07:51:59] INFO:     127.0.0.1:47822 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=42: batch_size=8, steps=6, topk=3, num_draft_tokens=6, speed=105.08 token/s, step_time=32.98 ms
Start i=43: batch_size=8, steps=6, topk=3, num_draft_tokens=8
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 6 --speculative-eagle-topk 3 --speculative-num-draft-tokens 8 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:52:10.218000 376470 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:52:10.218000 376470 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:52:10] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=850590003, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=6, speculative_eagle_topk=3, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:52:11] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:52:19.486000 376681 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:52:19.486000 376681 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:52:19.675000 376678 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:52:19.675000 376678 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:52:19.783000 376675 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:52:19.783000 376675 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:52:19.799000 376677 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:52:19.799000 376677 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:52:19.814000 376676 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:52:19.814000 376676 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:52:19.838000 376680 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:52:19.838000 376680 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:52:19.842000 376682 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:52:19.842000 376682 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:52:19.928000 376679 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:52:19.928000 376679 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:52:19.941000 376683 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:52:19.941000 376683 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:52:20 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:52:20 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:52:20 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:52:22 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:52:25 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:52:26 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:52:26 TP0] Detected fp8 checkpoint.
[2025-09-13 07:52:27 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 25/1024 [00:00<00:04, 242.81it/s]
Loading safetensors checkpoint shards:   5% Completed | 50/1024 [00:00<00:13, 69.92it/s]
Loading safetensors checkpoint shards:   6% Completed | 63/1024 [00:00<00:15, 61.27it/s]
Loading safetensors checkpoint shards:   7% Completed | 73/1024 [00:01<00:15, 61.56it/s]
Loading safetensors checkpoint shards:   8% Completed | 81/1024 [00:01<00:16, 58.79it/s]
Loading safetensors checkpoint shards:   9% Completed | 88/1024 [00:01<00:16, 55.40it/s]
Loading safetensors checkpoint shards:   9% Completed | 95/1024 [00:01<00:18, 49.24it/s]
Loading safetensors checkpoint shards:  10% Completed | 101/1024 [00:02<00:32, 28.64it/s]
Loading safetensors checkpoint shards:  11% Completed | 109/1024 [00:02<00:26, 34.75it/s]
Loading safetensors checkpoint shards:  11% Completed | 114/1024 [00:02<00:25, 35.67it/s]
Loading safetensors checkpoint shards:  12% Completed | 119/1024 [00:02<00:24, 36.56it/s]
Loading safetensors checkpoint shards:  12% Completed | 124/1024 [00:02<00:24, 37.20it/s]
Loading safetensors checkpoint shards:  13% Completed | 129/1024 [00:02<00:23, 37.98it/s]
Loading safetensors checkpoint shards:  13% Completed | 134/1024 [00:02<00:23, 37.99it/s]
Loading safetensors checkpoint shards:  14% Completed | 140/1024 [00:02<00:21, 42.07it/s]
Loading safetensors checkpoint shards:  14% Completed | 145/1024 [00:03<00:20, 42.51it/s]
Loading safetensors checkpoint shards:  15% Completed | 150/1024 [00:03<00:20, 43.49it/s]
Loading safetensors checkpoint shards:  15% Completed | 155/1024 [00:03<00:19, 43.53it/s]
Loading safetensors checkpoint shards:  16% Completed | 161/1024 [00:03<00:18, 45.52it/s]
Loading safetensors checkpoint shards:  16% Completed | 166/1024 [00:03<00:19, 44.08it/s]
Loading safetensors checkpoint shards:  17% Completed | 172/1024 [00:03<00:18, 45.97it/s]
Loading safetensors checkpoint shards:  17% Completed | 177/1024 [00:03<00:18, 45.79it/s]
Loading safetensors checkpoint shards:  18% Completed | 182/1024 [00:03<00:18, 46.31it/s]
Loading safetensors checkpoint shards:  18% Completed | 187/1024 [00:03<00:18, 45.19it/s]
Loading safetensors checkpoint shards:  19% Completed | 192/1024 [00:04<00:18, 45.11it/s]
Loading safetensors checkpoint shards:  19% Completed | 198/1024 [00:04<00:17, 46.70it/s]
Loading safetensors checkpoint shards:  20% Completed | 203/1024 [00:04<00:18, 44.18it/s]
Loading safetensors checkpoint shards:  20% Completed | 208/1024 [00:04<00:17, 45.47it/s]
Loading safetensors checkpoint shards:  21% Completed | 213/1024 [00:04<00:18, 44.39it/s]
Loading safetensors checkpoint shards:  21% Completed | 218/1024 [00:04<00:17, 45.81it/s]
Loading safetensors checkpoint shards:  22% Completed | 223/1024 [00:04<00:18, 43.77it/s]
Loading safetensors checkpoint shards:  22% Completed | 228/1024 [00:04<00:18, 43.93it/s]
Loading safetensors checkpoint shards:  23% Completed | 233/1024 [00:05<00:18, 43.56it/s]
Loading safetensors checkpoint shards:  23% Completed | 238/1024 [00:05<00:17, 44.79it/s]
Loading safetensors checkpoint shards:  24% Completed | 243/1024 [00:05<00:17, 44.64it/s]
Loading safetensors checkpoint shards:  24% Completed | 249/1024 [00:05<00:16, 48.00it/s]
Loading safetensors checkpoint shards:  25% Completed | 254/1024 [00:05<00:17, 44.71it/s]
Loading safetensors checkpoint shards:  25% Completed | 259/1024 [00:05<00:17, 43.93it/s]
Loading safetensors checkpoint shards:  26% Completed | 264/1024 [00:05<00:16, 45.24it/s]
Loading safetensors checkpoint shards:  26% Completed | 269/1024 [00:05<00:16, 45.07it/s]
Loading safetensors checkpoint shards:  27% Completed | 275/1024 [00:05<00:16, 45.44it/s]
Loading safetensors checkpoint shards:  27% Completed | 280/1024 [00:06<00:16, 45.03it/s]
Loading safetensors checkpoint shards:  28% Completed | 286/1024 [00:06<00:15, 46.16it/s]
Loading safetensors checkpoint shards:  28% Completed | 291/1024 [00:06<00:16, 44.57it/s]
Loading safetensors checkpoint shards:  29% Completed | 297/1024 [00:06<00:29, 24.92it/s]
Loading safetensors checkpoint shards:  29% Completed | 302/1024 [00:06<00:25, 28.22it/s]
Loading safetensors checkpoint shards:  30% Completed | 307/1024 [00:06<00:22, 32.15it/s]
Loading safetensors checkpoint shards:  30% Completed | 312/1024 [00:07<00:20, 35.16it/s]
Loading safetensors checkpoint shards:  31% Completed | 318/1024 [00:07<00:18, 39.22it/s]
Loading safetensors checkpoint shards:  32% Completed | 323/1024 [00:07<00:17, 39.33it/s]
Loading safetensors checkpoint shards:  32% Completed | 328/1024 [00:07<00:16, 41.68it/s]
Loading safetensors checkpoint shards:  33% Completed | 333/1024 [00:07<00:16, 41.48it/s]
Loading safetensors checkpoint shards:  33% Completed | 338/1024 [00:07<00:15, 43.46it/s]
Loading safetensors checkpoint shards:  33% Completed | 343/1024 [00:07<00:15, 42.68it/s]
Loading safetensors checkpoint shards:  34% Completed | 348/1024 [00:07<00:16, 41.50it/s]
Loading safetensors checkpoint shards:  34% Completed | 353/1024 [00:08<00:16, 40.91it/s]
Loading safetensors checkpoint shards:  35% Completed | 358/1024 [00:08<00:16, 40.47it/s]
Loading safetensors checkpoint shards:  35% Completed | 363/1024 [00:08<00:15, 42.23it/s]
Loading safetensors checkpoint shards:  36% Completed | 368/1024 [00:08<00:15, 41.86it/s]
Loading safetensors checkpoint shards:  36% Completed | 373/1024 [00:08<00:15, 43.27it/s]
Loading safetensors checkpoint shards:  37% Completed | 378/1024 [00:08<00:15, 41.36it/s]
Loading safetensors checkpoint shards:  37% Completed | 383/1024 [00:08<00:14, 42.76it/s]
Loading safetensors checkpoint shards:  38% Completed | 388/1024 [00:08<00:14, 42.90it/s]
Loading safetensors checkpoint shards:  38% Completed | 393/1024 [00:08<00:14, 43.78it/s]
Loading safetensors checkpoint shards:  39% Completed | 398/1024 [00:09<00:14, 42.31it/s]
Loading safetensors checkpoint shards:  39% Completed | 403/1024 [00:09<00:14, 42.11it/s]
Loading safetensors checkpoint shards:  40% Completed | 408/1024 [00:09<00:14, 43.62it/s]
Loading safetensors checkpoint shards:  40% Completed | 413/1024 [00:09<00:14, 42.67it/s]
Loading safetensors checkpoint shards:  41% Completed | 418/1024 [00:09<00:14, 41.44it/s]
Loading safetensors checkpoint shards:  41% Completed | 423/1024 [00:09<00:14, 40.57it/s]
Loading safetensors checkpoint shards:  42% Completed | 428/1024 [00:09<00:14, 40.89it/s]
Loading safetensors checkpoint shards:  42% Completed | 433/1024 [00:09<00:15, 37.95it/s]
Loading safetensors checkpoint shards:  43% Completed | 438/1024 [00:10<00:15, 38.79it/s]
Loading safetensors checkpoint shards:  43% Completed | 442/1024 [00:10<00:15, 37.69it/s]
Loading safetensors checkpoint shards:  44% Completed | 446/1024 [00:10<00:15, 37.59it/s]
Loading safetensors checkpoint shards:  44% Completed | 450/1024 [00:10<00:15, 37.96it/s]
Loading safetensors checkpoint shards:  44% Completed | 454/1024 [00:10<00:15, 37.19it/s]
Loading safetensors checkpoint shards:  45% Completed | 458/1024 [00:10<00:15, 36.88it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:10<00:14, 37.50it/s]
Loading safetensors checkpoint shards:  46% Completed | 467/1024 [00:10<00:14, 37.15it/s]
Loading safetensors checkpoint shards:  46% Completed | 473/1024 [00:10<00:13, 40.68it/s]
Loading safetensors checkpoint shards:  47% Completed | 478/1024 [00:11<00:13, 39.24it/s]
Loading safetensors checkpoint shards:  47% Completed | 483/1024 [00:11<00:13, 41.20it/s]
Loading safetensors checkpoint shards:  48% Completed | 488/1024 [00:11<00:13, 38.36it/s]
Loading safetensors checkpoint shards:  48% Completed | 492/1024 [00:11<00:14, 37.93it/s]
Loading safetensors checkpoint shards:  49% Completed | 497/1024 [00:11<00:13, 40.09it/s]
Loading safetensors checkpoint shards:  49% Completed | 502/1024 [00:11<00:12, 40.88it/s]
Loading safetensors checkpoint shards:  50% Completed | 507/1024 [00:11<00:12, 41.48it/s]
Loading safetensors checkpoint shards:  50% Completed | 512/1024 [00:11<00:13, 39.20it/s]
Loading safetensors checkpoint shards:  51% Completed | 518/1024 [00:12<00:11, 43.93it/s]
Loading safetensors checkpoint shards:  51% Completed | 523/1024 [00:12<00:11, 43.95it/s]
Loading safetensors checkpoint shards:  52% Completed | 531/1024 [00:12<00:09, 51.89it/s]
Loading safetensors checkpoint shards:  52% Completed | 537/1024 [00:13<00:24, 20.00it/s]
Loading safetensors checkpoint shards:  53% Completed | 544/1024 [00:13<00:18, 25.92it/s]
Loading safetensors checkpoint shards:  54% Completed | 551/1024 [00:13<00:14, 32.06it/s]
Loading safetensors checkpoint shards:  54% Completed | 557/1024 [00:13<00:13, 34.70it/s]
Loading safetensors checkpoint shards:  55% Completed | 562/1024 [00:13<00:12, 37.11it/s]
Loading safetensors checkpoint shards:  55% Completed | 567/1024 [00:13<00:11, 38.40it/s]
Loading safetensors checkpoint shards:  56% Completed | 574/1024 [00:13<00:10, 43.05it/s]
Loading safetensors checkpoint shards:  57% Completed | 579/1024 [00:13<00:09, 44.63it/s]
Loading safetensors checkpoint shards:  57% Completed | 586/1024 [00:13<00:08, 49.33it/s]
Loading safetensors checkpoint shards:  58% Completed | 592/1024 [00:14<00:08, 48.33it/s]
Loading safetensors checkpoint shards:  58% Completed | 598/1024 [00:14<00:10, 42.46it/s]
Loading safetensors checkpoint shards:  59% Completed | 603/1024 [00:14<00:10, 39.67it/s]
Loading safetensors checkpoint shards:  59% Completed | 608/1024 [00:14<00:11, 36.98it/s]
Loading safetensors checkpoint shards:  60% Completed | 612/1024 [00:14<00:11, 34.39it/s]
Loading safetensors checkpoint shards:  60% Completed | 617/1024 [00:14<00:11, 36.38it/s]
Loading safetensors checkpoint shards:  61% Completed | 621/1024 [00:14<00:11, 34.75it/s]
Loading safetensors checkpoint shards:  61% Completed | 625/1024 [00:15<00:12, 32.35it/s]
Loading safetensors checkpoint shards:  61% Completed | 629/1024 [00:15<00:11, 34.13it/s]
Loading safetensors checkpoint shards:  62% Completed | 633/1024 [00:15<00:11, 34.09it/s]
Loading safetensors checkpoint shards:  62% Completed | 637/1024 [00:15<00:11, 34.84it/s]
Loading safetensors checkpoint shards:  63% Completed | 641/1024 [00:15<00:10, 35.09it/s]
Loading safetensors checkpoint shards:  63% Completed | 645/1024 [00:15<00:11, 33.92it/s]
Loading safetensors checkpoint shards:  63% Completed | 649/1024 [00:15<00:10, 34.31it/s]
Loading safetensors checkpoint shards:  64% Completed | 653/1024 [00:15<00:10, 34.87it/s]
Loading safetensors checkpoint shards:  64% Completed | 657/1024 [00:16<00:10, 35.10it/s]
Loading safetensors checkpoint shards:  65% Completed | 661/1024 [00:16<00:10, 33.68it/s]
Loading safetensors checkpoint shards:  65% Completed | 665/1024 [00:16<00:10, 34.03it/s]
Loading safetensors checkpoint shards:  65% Completed | 669/1024 [00:16<00:10, 35.45it/s]
Loading safetensors checkpoint shards:  66% Completed | 673/1024 [00:16<00:09, 35.61it/s]
Loading safetensors checkpoint shards:  66% Completed | 677/1024 [00:16<00:09, 35.07it/s]
Loading safetensors checkpoint shards:  67% Completed | 681/1024 [00:16<00:09, 36.14it/s]
Loading safetensors checkpoint shards:  67% Completed | 685/1024 [00:16<00:09, 36.22it/s]
Loading safetensors checkpoint shards:  67% Completed | 689/1024 [00:16<00:09, 36.55it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:17<00:08, 38.94it/s]
Loading safetensors checkpoint shards:  68% Completed | 698/1024 [00:17<00:08, 38.00it/s]
Loading safetensors checkpoint shards:  69% Completed | 702/1024 [00:17<00:08, 36.08it/s]
Loading safetensors checkpoint shards:  69% Completed | 706/1024 [00:17<00:09, 35.15it/s]
Loading safetensors checkpoint shards:  69% Completed | 710/1024 [00:17<00:09, 34.83it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:17<00:08, 35.18it/s]
Loading safetensors checkpoint shards:  70% Completed | 718/1024 [00:17<00:08, 34.69it/s]
Loading safetensors checkpoint shards:  71% Completed | 722/1024 [00:17<00:08, 35.45it/s]
Loading safetensors checkpoint shards:  71% Completed | 726/1024 [00:17<00:08, 35.83it/s]
Loading safetensors checkpoint shards:  71% Completed | 730/1024 [00:18<00:08, 36.15it/s]
Loading safetensors checkpoint shards:  72% Completed | 734/1024 [00:18<00:08, 35.31it/s]
Loading safetensors checkpoint shards:  72% Completed | 738/1024 [00:18<00:08, 34.90it/s]
Loading safetensors checkpoint shards:  72% Completed | 742/1024 [00:18<00:08, 34.66it/s]
Loading safetensors checkpoint shards:  73% Completed | 746/1024 [00:18<00:07, 34.99it/s]
Loading safetensors checkpoint shards:  73% Completed | 750/1024 [00:18<00:07, 34.78it/s]
Loading safetensors checkpoint shards:  74% Completed | 754/1024 [00:18<00:07, 36.09it/s]
Loading safetensors checkpoint shards:  74% Completed | 758/1024 [00:18<00:07, 36.98it/s]
Loading safetensors checkpoint shards:  74% Completed | 762/1024 [00:18<00:06, 37.75it/s]
Loading safetensors checkpoint shards:  75% Completed | 767/1024 [00:19<00:06, 39.45it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:19<00:06, 38.79it/s]
Loading safetensors checkpoint shards:  76% Completed | 777/1024 [00:19<00:06, 40.05it/s]
Loading safetensors checkpoint shards:  76% Completed | 782/1024 [00:19<00:05, 40.74it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:19<00:05, 40.20it/s]
Loading safetensors checkpoint shards:  77% Completed | 792/1024 [00:19<00:05, 40.24it/s]
Loading safetensors checkpoint shards:  78% Completed | 797/1024 [00:20<00:12, 18.37it/s]
Loading safetensors checkpoint shards:  78% Completed | 801/1024 [00:20<00:10, 21.30it/s]
Loading safetensors checkpoint shards:  79% Completed | 806/1024 [00:20<00:08, 25.38it/s]
Loading safetensors checkpoint shards:  79% Completed | 811/1024 [00:20<00:07, 28.69it/s]
Loading safetensors checkpoint shards:  80% Completed | 815/1024 [00:20<00:06, 30.16it/s]
Loading safetensors checkpoint shards:  80% Completed | 819/1024 [00:20<00:06, 31.13it/s]
Loading safetensors checkpoint shards:  80% Completed | 823/1024 [00:20<00:06, 32.75it/s]
Loading safetensors checkpoint shards:  81% Completed | 827/1024 [00:21<00:05, 34.40it/s]
Loading safetensors checkpoint shards:  81% Completed | 831/1024 [00:21<00:05, 35.38it/s]
Loading safetensors checkpoint shards:  82% Completed | 835/1024 [00:21<00:05, 36.26it/s]
Loading safetensors checkpoint shards:  82% Completed | 839/1024 [00:21<00:05, 36.40it/s]
Loading safetensors checkpoint shards:  82% Completed | 843/1024 [00:21<00:05, 35.50it/s]
Loading safetensors checkpoint shards:  83% Completed | 847/1024 [00:21<00:04, 36.18it/s]
Loading safetensors checkpoint shards:  83% Completed | 851/1024 [00:21<00:04, 36.92it/s]
Loading safetensors checkpoint shards:  83% Completed | 855/1024 [00:21<00:04, 36.92it/s]
Loading safetensors checkpoint shards:  84% Completed | 859/1024 [00:21<00:04, 35.82it/s]
Loading safetensors checkpoint shards:  84% Completed | 863/1024 [00:22<00:04, 36.26it/s]
Loading safetensors checkpoint shards:  85% Completed | 867/1024 [00:22<00:04, 36.29it/s]
Loading safetensors checkpoint shards:  85% Completed | 871/1024 [00:22<00:04, 36.46it/s]
Loading safetensors checkpoint shards:  85% Completed | 875/1024 [00:22<00:04, 35.46it/s]
Loading safetensors checkpoint shards:  86% Completed | 879/1024 [00:22<00:04, 34.61it/s]
Loading safetensors checkpoint shards:  86% Completed | 883/1024 [00:22<00:03, 35.35it/s]
Loading safetensors checkpoint shards:  87% Completed | 887/1024 [00:22<00:03, 35.83it/s]
Loading safetensors checkpoint shards:  87% Completed | 891/1024 [00:22<00:03, 35.06it/s]
Loading safetensors checkpoint shards:  87% Completed | 895/1024 [00:22<00:03, 35.91it/s]
Loading safetensors checkpoint shards:  88% Completed | 899/1024 [00:23<00:03, 36.55it/s]
Loading safetensors checkpoint shards:  88% Completed | 903/1024 [00:23<00:03, 37.12it/s]
Loading safetensors checkpoint shards:  89% Completed | 907/1024 [00:23<00:03, 37.49it/s]
Loading safetensors checkpoint shards:  89% Completed | 911/1024 [00:23<00:02, 38.03it/s]
Loading safetensors checkpoint shards:  89% Completed | 916/1024 [00:23<00:02, 39.52it/s]
Loading safetensors checkpoint shards:  90% Completed | 920/1024 [00:23<00:02, 39.10it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:23<00:02, 38.79it/s]
Loading safetensors checkpoint shards:  91% Completed | 929/1024 [00:23<00:02, 39.41it/s]
Loading safetensors checkpoint shards:  91% Completed | 933/1024 [00:23<00:02, 38.34it/s]
Loading safetensors checkpoint shards:  92% Completed | 938/1024 [00:24<00:02, 39.27it/s]
Loading safetensors checkpoint shards:  92% Completed | 943/1024 [00:24<00:02, 39.66it/s]
Loading safetensors checkpoint shards:  92% Completed | 947/1024 [00:24<00:01, 39.11it/s]
Loading safetensors checkpoint shards:  93% Completed | 952/1024 [00:24<00:01, 40.51it/s]
Loading safetensors checkpoint shards:  93% Completed | 957/1024 [00:24<00:01, 41.10it/s]
Loading safetensors checkpoint shards:  94% Completed | 962/1024 [00:24<00:01, 41.18it/s]
Loading safetensors checkpoint shards:  94% Completed | 967/1024 [00:24<00:01, 42.10it/s]
Loading safetensors checkpoint shards:  95% Completed | 972/1024 [00:24<00:01, 41.95it/s]
Loading safetensors checkpoint shards:  95% Completed | 977/1024 [00:24<00:01, 42.77it/s]
Loading safetensors checkpoint shards:  96% Completed | 986/1024 [00:25<00:00, 53.94it/s]
Loading safetensors checkpoint shards:  98% Completed | 1005/1024 [00:25<00:00, 85.34it/s]
Loading safetensors checkpoint shards:  99% Completed | 1014/1024 [00:25<00:00, 85.65it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 40.38it/s]

[2025-09-13 07:52:53 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:52:55 TP0] KV Cache is allocated. #tokens: 620265, KV size: 40.59 GB
[2025-09-13 07:52:55 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:52:55 TP5] KV Cache is allocated. #tokens: 620265, KV size: 40.59 GB
[2025-09-13 07:52:55 TP3] KV Cache is allocated. #tokens: 620265, KV size: 40.59 GB
[2025-09-13 07:52:55 TP4] KV Cache is allocated. #tokens: 620265, KV size: 40.59 GB
[2025-09-13 07:52:55 TP1] KV Cache is allocated. #tokens: 620265, KV size: 40.59 GB
[2025-09-13 07:52:55 TP6] KV Cache is allocated. #tokens: 620265, KV size: 40.59 GB
[2025-09-13 07:52:55 TP2] KV Cache is allocated. #tokens: 620265, KV size: 40.59 GB
[2025-09-13 07:52:55 TP7] KV Cache is allocated. #tokens: 620265, KV size: 40.59 GB
[2025-09-13 07:52:55 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:52:55 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.51 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:52:56 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:52:56 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:52:56 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:52:56 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:52:56 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:52:56 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:52:56 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:52:56 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:52:56 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25371.81it/s]
[2025-09-13 07:52:57 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:52:57 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25479.03it/s]
[2025-09-13 07:52:57 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:52:57 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26929.75it/s]
[2025-09-13 07:52:58 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:52:58 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26486.33it/s]
[2025-09-13 07:52:59 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:52:59 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27481.32it/s]
[2025-09-13 07:52:59 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.20 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.11it/s]
[2025-09-13 07:53:03 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:53:03 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:53:03 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:53:03 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:53:03 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:53:03 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:53:03 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:53:03 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:53:03 TP0] Capture cuda graph end. Time elapsed: 7.98 s. mem usage=0.39 GB. avail mem=17.17 GB.
[2025-09-13 07:53:03 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:53:03 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:53:03 TP0] Init torch distributed begin.
[2025-09-13 07:53:03 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:53:03 TP0] Load weight begin. avail mem=17.17 GB
[2025-09-13 07:53:03 TP0] Detected fp8 checkpoint.
[2025-09-13 07:53:03 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 177.43it/s]
Loading safetensors checkpoint shards:   4% Completed | 43/1024 [00:00<00:04, 218.68it/s]
Loading safetensors checkpoint shards:  10% Completed | 101/1024 [00:00<00:02, 381.36it/s]
Loading safetensors checkpoint shards:  16% Completed | 161/1024 [00:00<00:01, 465.69it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:00<00:01, 506.47it/s]
Loading safetensors checkpoint shards:  27% Completed | 279/1024 [00:00<00:01, 534.90it/s]
Loading safetensors checkpoint shards:  33% Completed | 338/1024 [00:00<00:01, 552.37it/s]
Loading safetensors checkpoint shards:  39% Completed | 398/1024 [00:00<00:01, 567.09it/s]
Loading safetensors checkpoint shards:  45% Completed | 457/1024 [00:00<00:00, 572.21it/s]
Loading safetensors checkpoint shards:  50% Completed | 517/1024 [00:01<00:00, 580.52it/s]
Loading safetensors checkpoint shards:  56% Completed | 576/1024 [00:01<00:00, 582.01it/s]
Loading safetensors checkpoint shards:  62% Completed | 636/1024 [00:01<00:00, 584.22it/s]
Loading safetensors checkpoint shards:  68% Completed | 695/1024 [00:01<00:00, 577.09it/s]
Loading safetensors checkpoint shards:  74% Completed | 753/1024 [00:01<00:00, 572.37it/s]
Loading safetensors checkpoint shards:  79% Completed | 811/1024 [00:01<00:00, 573.63it/s]
Loading safetensors checkpoint shards:  85% Completed | 869/1024 [00:01<00:00, 571.39it/s]
Loading safetensors checkpoint shards:  91% Completed | 927/1024 [00:01<00:00, 572.59it/s]
Loading safetensors checkpoint shards:  96% Completed | 985/1024 [00:01<00:00, 540.65it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 498.67it/s]

[2025-09-13 07:53:05 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.18 GB, mem usage=1.99 GB.
[2025-09-13 07:53:05 TP0] KV Cache is allocated. #tokens: 620265, KV size: 0.67 GB
[2025-09-13 07:53:05 TP6] KV Cache is allocated. #tokens: 620265, KV size: 0.67 GB
[2025-09-13 07:53:05 TP7] KV Cache is allocated. #tokens: 620265, KV size: 0.67 GB
[2025-09-13 07:53:05 TP5] KV Cache is allocated. #tokens: 620265, KV size: 0.67 GB
[2025-09-13 07:53:05 TP0] Memory pool end. avail mem=14.52 GB
[2025-09-13 07:53:05 TP2] KV Cache is allocated. #tokens: 620265, KV size: 0.67 GB
[2025-09-13 07:53:05 TP1] KV Cache is allocated. #tokens: 620265, KV size: 0.67 GB
[2025-09-13 07:53:05 TP3] KV Cache is allocated. #tokens: 620265, KV size: 0.67 GB
[2025-09-13 07:53:05 TP4] KV Cache is allocated. #tokens: 620265, KV size: 0.67 GB
[2025-09-13 07:53:06 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:53:06 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.14 GB
[2025-09-13 07:53:06 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.95 GB
[2025-09-13 07:53:06 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:53:06 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:53:06 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:53:06 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:53:06 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
Capturing batches (bs=1 avail_mem=14.52 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.41it/s]
[2025-09-13 07:53:12 TP1] Registering 120 cuda graph addresses
[2025-09-13 07:53:12 TP2] Registering 120 cuda graph addresses
[2025-09-13 07:53:12 TP6] Registering 120 cuda graph addresses
[2025-09-13 07:53:12 TP3] Registering 120 cuda graph addresses
[2025-09-13 07:53:12 TP0] Registering 120 cuda graph addresses
[2025-09-13 07:53:12 TP5] Registering 120 cuda graph addresses
[2025-09-13 07:53:12 TP4] Registering 120 cuda graph addresses
[2025-09-13 07:53:12 TP7] Registering 120 cuda graph addresses
[2025-09-13 07:53:12 TP3] Capture draft cuda graph end. Time elapsed: 6.45 s. mem usage=0.43 GB. avail mem=14.47 GB.
[2025-09-13 07:53:12 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.47 GB
[2025-09-13 07:53:12 TP0] Capture draft cuda graph end. Time elapsed: 6.45 s. mem usage=0.44 GB. avail mem=14.51 GB.
[2025-09-13 07:53:12 TP4] Capture draft cuda graph end. Time elapsed: 6.45 s. mem usage=0.43 GB. avail mem=14.47 GB.
[2025-09-13 07:53:12 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.47 GB
[2025-09-13 07:53:12 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.51 GB
[2025-09-13 07:53:12 TP6] Capture draft cuda graph end. Time elapsed: 6.45 s. mem usage=0.43 GB. avail mem=14.47 GB.
[2025-09-13 07:53:12 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.47 GB
[2025-09-13 07:53:12 TP7] Capture draft cuda graph end. Time elapsed: 6.45 s. mem usage=0.43 GB. avail mem=14.71 GB.
[2025-09-13 07:53:12 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.71 GB
[2025-09-13 07:53:12 TP2] Capture draft cuda graph end. Time elapsed: 6.45 s. mem usage=0.43 GB. avail mem=14.47 GB.
[2025-09-13 07:53:12 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.47 GB
[2025-09-13 07:53:12 TP1] Capture draft cuda graph end. Time elapsed: 6.45 s. mem usage=0.43 GB. avail mem=14.47 GB.
[2025-09-13 07:53:12 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.47 GB
[2025-09-13 07:53:12 TP5] Capture draft cuda graph end. Time elapsed: 6.45 s. mem usage=0.43 GB. avail mem=14.47 GB.
[2025-09-13 07:53:12 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.47 GB
Capturing batches (bs=1 avail_mem=14.31 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:00<00:00, 19.55it/s][2025-09-13 07:53:13 TP5] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.31 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 19.05it/s]
[2025-09-13 07:53:13 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:53:13 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:53:13 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:53:13 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:53:13 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:53:13 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:53:13 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:53:13 TP1] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.20 GB. avail mem=14.27 GB.
[2025-09-13 07:53:13 TP7] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.20 GB. avail mem=14.50 GB.
[2025-09-13 07:53:13 TP5] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.20 GB. avail mem=14.27 GB.
[2025-09-13 07:53:13 TP6] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.20 GB. avail mem=14.27 GB.
[2025-09-13 07:53:13 TP0] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.20 GB. avail mem=14.31 GB.
[2025-09-13 07:53:13 TP0] max_total_num_tokens=620265, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.31 GB
[2025-09-13 07:53:13 TP2] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.20 GB. avail mem=14.27 GB.
[2025-09-13 07:53:13 TP3] Capture draft extend cuda graph end. Time elapsed: 1.15 s. mem usage=0.20 GB. avail mem=14.27 GB.
[2025-09-13 07:53:13 TP4] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.20 GB. avail mem=14.27 GB.
[2025-09-13 07:53:14] INFO:     Started server process [376470]
[2025-09-13 07:53:14] INFO:     Waiting for application startup.
[2025-09-13 07:53:14] INFO:     Application startup complete.
[2025-09-13 07:53:14] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:53:14] INFO:     127.0.0.1:39434 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:53:15] INFO:     127.0.0.1:39440 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:53:15 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:53:15 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:53:15 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27880.61it/s]
[2025-09-13 07:53:16] INFO:     127.0.0.1:39442 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:16] The server is fired up and ready to roll!
[2025-09-13 07:53:24 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:53:25] INFO:     127.0.0.1:53238 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:53:26] INFO:     127.0.0.1:53250 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:26 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:53:27] INFO:     127.0.0.1:53252 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:27] INFO:     127.0.0.1:53266 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:53:27] INFO:     127.0.0.1:53280 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:27] INFO:     127.0.0.1:53292 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:27] INFO:     127.0.0.1:53308 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:27] INFO:     127.0.0.1:53324 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:27] INFO:     127.0.0.1:53332 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:27] INFO:     127.0.0.1:53348 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:27 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:53:28 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:53:28 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:53:28 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:53:28 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:53:28 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:53:28 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:53:28 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:53:28 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:53:28 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:53:29 TP0] Decode batch. #running-req: 8, #token: 14608, token usage: 0.02, accept len: 3.05, cuda graph: True, gen throughput (token/s): 46.58, #queue-req: 0, 
[2025-09-13 07:53:30 TP0] Decode batch. #running-req: 8, #token: 15961, token usage: 0.03, accept len: 4.23, cuda graph: True, gen throughput (token/s): 984.57, #queue-req: 0, 
[2025-09-13 07:53:32 TP0] Decode batch. #running-req: 8, #token: 17322, token usage: 0.03, accept len: 4.25, cuda graph: True, gen throughput (token/s): 977.34, #queue-req: 0, 
 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 7/8 [00:05<00:00,  2.88it/s][2025-09-13 07:53:33 TP0] Decode batch. #running-req: 1, #token: 1425, token usage: 0.00, accept len: 3.83, cuda graph: True, gen throughput (token/s): 449.55, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.25it/s]
[2025-09-13 07:53:33] INFO:     127.0.0.1:44548 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.39      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4075      
Request throughput (req/s):              1.25      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         640.74    
Total token throughput (tok/s):          640.74    
Concurrency:                             6.60      
Accept length:                           3.90      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5270.77   
Median E2E Latency (ms):                 5209.49   
---------------Time to First Token----------------
Mean TTFT (ms):                          613.33    
Median TTFT (ms):                        725.30    
P99 TTFT (ms):                           725.75    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.11      
Median ITL (ms):                         6.87      
P95 ITL (ms):                            17.47     
P99 ITL (ms):                            34.68     
Max ITL (ms):                            735.77    
==================================================
[2025-09-13 07:53:33] INFO:     127.0.0.1:44552 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:53:33] INFO:     127.0.0.1:44568 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:33 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:53:35] INFO:     127.0.0.1:44572 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:35] INFO:     127.0.0.1:44588 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:35 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:53:35] INFO:     127.0.0.1:44598 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:35] INFO:     127.0.0.1:44612 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:35] INFO:     127.0.0.1:44622 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:35] INFO:     127.0.0.1:44630 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:35] INFO:     127.0.0.1:44640 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:35] INFO:     127.0.0.1:44646 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:35 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:53:35 TP0] Decode batch. #running-req: 8, #token: 13953, token usage: 0.02, accept len: 2.89, cuda graph: True, gen throughput (token/s): 69.28, #queue-req: 0, 
[2025-09-13 07:53:36 TP0] Decode batch. #running-req: 8, #token: 15088, token usage: 0.02, accept len: 3.55, cuda graph: True, gen throughput (token/s): 842.60, #queue-req: 0, 
[2025-09-13 07:53:38 TP0] Decode batch. #running-req: 8, #token: 16558, token usage: 0.03, accept len: 4.59, cuda graph: True, gen throughput (token/s): 1055.47, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:03<00:53,  3.57s/it][2025-09-13 07:53:38] INFO:     127.0.0.1:56094 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:38 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:27,  1.95s/it][2025-09-13 07:53:39] INFO:     127.0.0.1:56102 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:04<00:15,  1.20s/it][2025-09-13 07:53:39] INFO:     127.0.0.1:56118 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:39 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:53:40 TP0] Decode batch. #running-req: 8, #token: 12112, token usage: 0.02, accept len: 4.20, cuda graph: True, gen throughput (token/s): 698.60, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.18it/s][2025-09-13 07:53:40] INFO:     127.0.0.1:56132 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:40 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:06,  1.60it/s][2025-09-13 07:53:40] INFO:     127.0.0.1:56144 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:40 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.97it/s][2025-09-13 07:53:40] INFO:     127.0.0.1:56148 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:40 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:05<00:03,  2.40it/s][2025-09-13 07:53:40] INFO:     127.0.0.1:56162 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:41 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:53:42 TP0] Decode batch. #running-req: 8, #token: 10855, token usage: 0.02, accept len: 3.23, cuda graph: True, gen throughput (token/s): 516.73, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:07<00:06,  1.21it/s][2025-09-13 07:53:42] INFO:     127.0.0.1:56172 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:53:42 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:53:43 TP0] Decode batch. #running-req: 8, #token: 15520, token usage: 0.03, accept len: 3.58, cuda graph: True, gen throughput (token/s): 712.62, #queue-req: 0, 
 56%|█████████████████████████████████████████████████████████████████████████▏                                                        | 9/16 [00:09<00:08,  1.23s/it][2025-09-13 07:53:45 TP0] Decode batch. #running-req: 7, #token: 15389, token usage: 0.02, accept len: 3.81, cuda graph: True, gen throughput (token/s): 853.40, #queue-req: 0, 
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 14/16 [00:11<00:00,  2.18it/s][2025-09-13 07:53:46 TP0] Decode batch. #running-req: 2, #token: 7663, token usage: 0.01, accept len: 3.51, cuda graph: True, gen throughput (token/s): 403.12, #queue-req: 0, 
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 15/16 [00:11<00:00,  2.08it/s][2025-09-13 07:53:47 TP0] Decode batch. #running-req: 1, #token: 5468, token usage: 0.01, accept len: 3.45, cuda graph: True, gen throughput (token/s): 230.79, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:12<00:00,  1.26it/s]
[2025-09-13 07:53:47] INFO:     127.0.0.1:38100 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  12.66     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8072      
Request throughput (req/s):              1.26      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         647.01    
Total token throughput (tok/s):          647.01    
Concurrency:                             6.90      
Accept length:                           3.81      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5463.90   
Median E2E Latency (ms):                 5547.91   
---------------Time to First Token----------------
Mean TTFT (ms):                          227.26    
Median TTFT (ms):                        249.30    
P99 TTFT (ms):                           281.36    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.25     
Median ITL (ms):                         6.90      
P95 ITL (ms):                            33.63     
P99 ITL (ms):                            54.47     
Max ITL (ms):                            284.69    
==================================================
[2025-09-13 07:53:47] INFO:     127.0.0.1:38110 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=43: batch_size=8, steps=6, topk=3, num_draft_tokens=8, speed=110.10 token/s, step_time=34.63 ms
Start i=44: batch_size=8, steps=6, topk=3, num_draft_tokens=12
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 6 --speculative-eagle-topk 3 --speculative-num-draft-tokens 12 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:53:58.537000 382138 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:53:58.537000 382138 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:53:58] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=922515267, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=6, speculative_eagle_topk=3, speculative_num_draft_tokens=12, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:53:59] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:54:07.703000 382349 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:54:07.703000 382349 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:54:07.775000 382350 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:54:07.775000 382350 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:54:07.954000 382353 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:54:07.954000 382353 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:54:08.003000 382348 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:54:08.003000 382348 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:54:08.019000 382351 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:54:08.019000 382351 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:54:08.153000 382345 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:54:08.153000 382345 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:54:08.183000 382352 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:54:08.183000 382352 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:54:08.207000 382346 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:54:08.207000 382346 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:54:08.251000 382347 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:54:08.251000 382347 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:54:08 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:54:08 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:54:08 TP0] Init torch distributed begin.
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:54:10 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:54:13 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:54:14 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:54:14 TP0] Detected fp8 checkpoint.
[2025-09-13 07:54:15 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 24/1024 [00:00<00:04, 219.71it/s]
Loading safetensors checkpoint shards:   4% Completed | 46/1024 [00:00<00:16, 60.39it/s]
Loading safetensors checkpoint shards:   6% Completed | 58/1024 [00:00<00:18, 52.45it/s]
Loading safetensors checkpoint shards:   7% Completed | 67/1024 [00:01<00:20, 47.78it/s]
Loading safetensors checkpoint shards:   7% Completed | 74/1024 [00:01<00:20, 47.07it/s]
Loading safetensors checkpoint shards:   8% Completed | 80/1024 [00:01<00:21, 43.98it/s]
Loading safetensors checkpoint shards:   8% Completed | 85/1024 [00:01<00:21, 44.68it/s]
Loading safetensors checkpoint shards:   9% Completed | 90/1024 [00:01<00:21, 43.59it/s]
Loading safetensors checkpoint shards:   9% Completed | 95/1024 [00:01<00:22, 40.99it/s]
Loading safetensors checkpoint shards:  10% Completed | 100/1024 [00:02<00:22, 41.49it/s]
Loading safetensors checkpoint shards:  10% Completed | 106/1024 [00:02<00:20, 43.94it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:21, 43.32it/s]
Loading safetensors checkpoint shards:  11% Completed | 117/1024 [00:02<00:19, 46.04it/s]
Loading safetensors checkpoint shards:  12% Completed | 122/1024 [00:02<00:38, 23.71it/s]
Loading safetensors checkpoint shards:  12% Completed | 127/1024 [00:02<00:32, 27.59it/s]
Loading safetensors checkpoint shards:  13% Completed | 131/1024 [00:03<00:30, 29.53it/s]
Loading safetensors checkpoint shards:  13% Completed | 135/1024 [00:03<00:29, 30.64it/s]
Loading safetensors checkpoint shards:  14% Completed | 141/1024 [00:03<00:24, 36.18it/s]
Loading safetensors checkpoint shards:  14% Completed | 146/1024 [00:03<00:23, 38.16it/s]
Loading safetensors checkpoint shards:  15% Completed | 151/1024 [00:03<00:21, 39.92it/s]
Loading safetensors checkpoint shards:  15% Completed | 156/1024 [00:03<00:21, 40.58it/s]
Loading safetensors checkpoint shards:  16% Completed | 162/1024 [00:03<00:19, 43.25it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:03<00:20, 42.30it/s]
Loading safetensors checkpoint shards:  17% Completed | 173/1024 [00:04<00:19, 44.78it/s]
Loading safetensors checkpoint shards:  17% Completed | 178/1024 [00:04<00:19, 44.36it/s]
Loading safetensors checkpoint shards:  18% Completed | 183/1024 [00:04<00:18, 44.50it/s]
Loading safetensors checkpoint shards:  18% Completed | 188/1024 [00:04<00:18, 44.27it/s]
Loading safetensors checkpoint shards:  19% Completed | 194/1024 [00:04<00:18, 45.97it/s]
Loading safetensors checkpoint shards:  19% Completed | 199/1024 [00:04<00:18, 45.58it/s]
Loading safetensors checkpoint shards:  20% Completed | 204/1024 [00:04<00:17, 45.79it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:04<00:18, 45.20it/s]
Loading safetensors checkpoint shards:  21% Completed | 214/1024 [00:04<00:18, 44.04it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:05<00:18, 43.55it/s]
Loading safetensors checkpoint shards:  22% Completed | 224/1024 [00:05<00:18, 43.25it/s]
Loading safetensors checkpoint shards:  22% Completed | 229/1024 [00:05<00:18, 43.00it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:05<00:18, 41.85it/s]
Loading safetensors checkpoint shards:  23% Completed | 239/1024 [00:05<00:18, 43.45it/s]
Loading safetensors checkpoint shards:  24% Completed | 244/1024 [00:05<00:18, 43.11it/s]
Loading safetensors checkpoint shards:  24% Completed | 250/1024 [00:05<00:16, 46.91it/s]
Loading safetensors checkpoint shards:  25% Completed | 255/1024 [00:05<00:17, 44.36it/s]
Loading safetensors checkpoint shards:  25% Completed | 260/1024 [00:05<00:16, 45.72it/s]
Loading safetensors checkpoint shards:  26% Completed | 265/1024 [00:06<00:16, 44.80it/s]
Loading safetensors checkpoint shards:  26% Completed | 270/1024 [00:06<00:16, 44.59it/s]
Loading safetensors checkpoint shards:  27% Completed | 275/1024 [00:06<00:16, 44.54it/s]
Loading safetensors checkpoint shards:  27% Completed | 280/1024 [00:06<00:17, 43.31it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:06<00:16, 44.69it/s]
Loading safetensors checkpoint shards:  28% Completed | 290/1024 [00:06<00:17, 42.66it/s]
Loading safetensors checkpoint shards:  29% Completed | 295/1024 [00:06<00:17, 42.48it/s]
Loading safetensors checkpoint shards:  29% Completed | 300/1024 [00:06<00:17, 40.25it/s]
Loading safetensors checkpoint shards:  30% Completed | 305/1024 [00:07<00:17, 40.97it/s]
Loading safetensors checkpoint shards:  30% Completed | 310/1024 [00:07<00:17, 40.07it/s]
Loading safetensors checkpoint shards:  31% Completed | 315/1024 [00:07<00:16, 41.94it/s]
Loading safetensors checkpoint shards:  31% Completed | 320/1024 [00:07<00:16, 41.63it/s]
Loading safetensors checkpoint shards:  32% Completed | 325/1024 [00:07<00:32, 21.45it/s]
Loading safetensors checkpoint shards:  32% Completed | 330/1024 [00:08<00:27, 24.92it/s]
Loading safetensors checkpoint shards:  33% Completed | 335/1024 [00:08<00:24, 28.44it/s]
Loading safetensors checkpoint shards:  33% Completed | 341/1024 [00:08<00:19, 34.33it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:08<00:19, 34.26it/s]
Loading safetensors checkpoint shards:  34% Completed | 351/1024 [00:08<00:18, 37.01it/s]
Loading safetensors checkpoint shards:  35% Completed | 356/1024 [00:08<00:17, 38.62it/s]
Loading safetensors checkpoint shards:  35% Completed | 361/1024 [00:08<00:16, 40.66it/s]
Loading safetensors checkpoint shards:  36% Completed | 366/1024 [00:08<00:16, 39.47it/s]
Loading safetensors checkpoint shards:  36% Completed | 371/1024 [00:08<00:16, 40.27it/s]
Loading safetensors checkpoint shards:  37% Completed | 376/1024 [00:09<00:15, 41.63it/s]
Loading safetensors checkpoint shards:  37% Completed | 381/1024 [00:09<00:16, 39.87it/s]
Loading safetensors checkpoint shards:  38% Completed | 387/1024 [00:09<00:14, 43.56it/s]
Loading safetensors checkpoint shards:  38% Completed | 392/1024 [00:09<00:14, 44.89it/s]
Loading safetensors checkpoint shards:  39% Completed | 399/1024 [00:09<00:12, 49.96it/s]
Loading safetensors checkpoint shards:  40% Completed | 405/1024 [00:09<00:11, 52.17it/s]
Loading safetensors checkpoint shards:  40% Completed | 411/1024 [00:09<00:11, 52.78it/s]
Loading safetensors checkpoint shards:  41% Completed | 417/1024 [00:09<00:11, 52.10it/s]
Loading safetensors checkpoint shards:  41% Completed | 423/1024 [00:09<00:11, 52.54it/s]
Loading safetensors checkpoint shards:  42% Completed | 430/1024 [00:10<00:10, 56.92it/s]
Loading safetensors checkpoint shards:  43% Completed | 436/1024 [00:10<00:10, 55.49it/s]
Loading safetensors checkpoint shards:  43% Completed | 443/1024 [00:10<00:10, 57.52it/s]
Loading safetensors checkpoint shards:  44% Completed | 449/1024 [00:10<00:11, 51.73it/s]
Loading safetensors checkpoint shards:  44% Completed | 455/1024 [00:10<00:12, 45.63it/s]
Loading safetensors checkpoint shards:  45% Completed | 460/1024 [00:10<00:12, 44.98it/s]
Loading safetensors checkpoint shards:  45% Completed | 465/1024 [00:10<00:14, 39.79it/s]
Loading safetensors checkpoint shards:  46% Completed | 470/1024 [00:11<00:14, 38.82it/s]
Loading safetensors checkpoint shards:  46% Completed | 474/1024 [00:11<00:14, 36.72it/s]
Loading safetensors checkpoint shards:  47% Completed | 478/1024 [00:11<00:17, 31.13it/s]
Loading safetensors checkpoint shards:  47% Completed | 482/1024 [00:11<00:17, 31.51it/s]
Loading safetensors checkpoint shards:  47% Completed | 486/1024 [00:11<00:16, 32.60it/s]
Loading safetensors checkpoint shards:  48% Completed | 490/1024 [00:11<00:16, 33.19it/s]
Loading safetensors checkpoint shards:  48% Completed | 494/1024 [00:11<00:15, 34.32it/s]
Loading safetensors checkpoint shards:  49% Completed | 498/1024 [00:11<00:16, 32.37it/s]
Loading safetensors checkpoint shards:  49% Completed | 502/1024 [00:12<00:15, 32.69it/s]
Loading safetensors checkpoint shards:  49% Completed | 506/1024 [00:12<00:15, 33.27it/s]
Loading safetensors checkpoint shards:  50% Completed | 510/1024 [00:12<00:34, 14.86it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:12<00:31, 16.34it/s]
Loading safetensors checkpoint shards:  50% Completed | 517/1024 [00:13<00:25, 19.92it/s]
Loading safetensors checkpoint shards:  51% Completed | 520/1024 [00:13<00:23, 21.54it/s]
Loading safetensors checkpoint shards:  51% Completed | 523/1024 [00:13<00:22, 22.56it/s]
Loading safetensors checkpoint shards:  51% Completed | 527/1024 [00:13<00:20, 24.22it/s]
Loading safetensors checkpoint shards:  52% Completed | 530/1024 [00:13<00:20, 24.23it/s]
Loading safetensors checkpoint shards:  52% Completed | 534/1024 [00:13<00:18, 26.46it/s]
Loading safetensors checkpoint shards:  53% Completed | 539/1024 [00:13<00:15, 30.89it/s]
Loading safetensors checkpoint shards:  53% Completed | 543/1024 [00:13<00:14, 32.94it/s]
Loading safetensors checkpoint shards:  54% Completed | 549/1024 [00:14<00:12, 38.06it/s]
Loading safetensors checkpoint shards:  54% Completed | 554/1024 [00:14<00:11, 39.77it/s]
Loading safetensors checkpoint shards:  55% Completed | 559/1024 [00:14<00:11, 40.92it/s]
Loading safetensors checkpoint shards:  55% Completed | 564/1024 [00:14<00:11, 41.00it/s]
Loading safetensors checkpoint shards:  56% Completed | 569/1024 [00:14<00:11, 40.54it/s]
Loading safetensors checkpoint shards:  56% Completed | 574/1024 [00:14<00:11, 39.86it/s]
Loading safetensors checkpoint shards:  57% Completed | 579/1024 [00:14<00:10, 41.85it/s]
Loading safetensors checkpoint shards:  57% Completed | 588/1024 [00:14<00:08, 53.61it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:14<00:07, 60.34it/s]
Loading safetensors checkpoint shards:  59% Completed | 606/1024 [00:15<00:06, 66.14it/s]
Loading safetensors checkpoint shards:  60% Completed | 616/1024 [00:15<00:05, 73.91it/s]
Loading safetensors checkpoint shards:  61% Completed | 626/1024 [00:15<00:04, 79.68it/s]
Loading safetensors checkpoint shards:  62% Completed | 635/1024 [00:15<00:05, 77.01it/s]
Loading safetensors checkpoint shards:  63% Completed | 643/1024 [00:15<00:04, 76.48it/s]
Loading safetensors checkpoint shards:  64% Completed | 651/1024 [00:15<00:05, 68.74it/s]
Loading safetensors checkpoint shards:  64% Completed | 659/1024 [00:15<00:05, 65.80it/s]
Loading safetensors checkpoint shards:  65% Completed | 666/1024 [00:15<00:05, 61.36it/s]
Loading safetensors checkpoint shards:  66% Completed | 673/1024 [00:16<00:05, 58.59it/s]
Loading safetensors checkpoint shards:  66% Completed | 679/1024 [00:16<00:06, 56.36it/s]
Loading safetensors checkpoint shards:  67% Completed | 686/1024 [00:16<00:05, 58.12it/s]
Loading safetensors checkpoint shards:  68% Completed | 693/1024 [00:16<00:05, 59.60it/s]
Loading safetensors checkpoint shards:  68% Completed | 700/1024 [00:16<00:06, 53.30it/s]
Loading safetensors checkpoint shards:  69% Completed | 706/1024 [00:16<00:06, 48.37it/s]
Loading safetensors checkpoint shards:  69% Completed | 711/1024 [00:16<00:06, 46.30it/s]
Loading safetensors checkpoint shards:  70% Completed | 716/1024 [00:16<00:06, 44.08it/s]
Loading safetensors checkpoint shards:  70% Completed | 721/1024 [00:17<00:07, 40.15it/s]
Loading safetensors checkpoint shards:  71% Completed | 726/1024 [00:17<00:17, 17.47it/s]
Loading safetensors checkpoint shards:  71% Completed | 732/1024 [00:17<00:13, 22.16it/s]
Loading safetensors checkpoint shards:  72% Completed | 737/1024 [00:18<00:11, 25.91it/s]
Loading safetensors checkpoint shards:  72% Completed | 741/1024 [00:18<00:10, 27.92it/s]
Loading safetensors checkpoint shards:  73% Completed | 745/1024 [00:18<00:09, 29.80it/s]
Loading safetensors checkpoint shards:  73% Completed | 749/1024 [00:18<00:09, 28.22it/s]
Loading safetensors checkpoint shards:  74% Completed | 753/1024 [00:18<00:09, 28.63it/s]
Loading safetensors checkpoint shards:  74% Completed | 758/1024 [00:18<00:08, 33.21it/s]
Loading safetensors checkpoint shards:  75% Completed | 764/1024 [00:18<00:06, 37.32it/s]
Loading safetensors checkpoint shards:  75% Completed | 770/1024 [00:18<00:06, 42.30it/s]
Loading safetensors checkpoint shards:  76% Completed | 776/1024 [00:19<00:05, 45.54it/s]
Loading safetensors checkpoint shards:  76% Completed | 782/1024 [00:19<00:05, 46.74it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:19<00:05, 42.08it/s]
Loading safetensors checkpoint shards:  77% Completed | 793/1024 [00:19<00:05, 43.45it/s]
Loading safetensors checkpoint shards:  78% Completed | 798/1024 [00:19<00:05, 44.98it/s]
Loading safetensors checkpoint shards:  79% Completed | 806/1024 [00:19<00:04, 53.20it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:19<00:03, 56.17it/s]
Loading safetensors checkpoint shards:  80% Completed | 819/1024 [00:19<00:03, 53.04it/s]
Loading safetensors checkpoint shards:  81% Completed | 827/1024 [00:19<00:03, 58.86it/s]
Loading safetensors checkpoint shards:  82% Completed | 835/1024 [00:20<00:02, 63.67it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:20<00:02, 64.36it/s]
Loading safetensors checkpoint shards:  83% Completed | 849/1024 [00:20<00:02, 64.50it/s]
Loading safetensors checkpoint shards:  84% Completed | 857/1024 [00:20<00:02, 67.36it/s]
Loading safetensors checkpoint shards:  84% Completed | 864/1024 [00:20<00:02, 66.94it/s]
Loading safetensors checkpoint shards:  85% Completed | 874/1024 [00:20<00:02, 71.18it/s]
Loading safetensors checkpoint shards:  86% Completed | 883/1024 [00:20<00:01, 74.67it/s]
Loading safetensors checkpoint shards:  87% Completed | 891/1024 [00:20<00:01, 73.38it/s]
Loading safetensors checkpoint shards:  88% Completed | 900/1024 [00:20<00:01, 76.93it/s]
Loading safetensors checkpoint shards:  89% Completed | 908/1024 [00:21<00:01, 76.70it/s]
Loading safetensors checkpoint shards:  89% Completed | 916/1024 [00:21<00:01, 71.39it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:21<00:01, 70.02it/s]
Loading safetensors checkpoint shards:  91% Completed | 932/1024 [00:21<00:01, 70.55it/s]
Loading safetensors checkpoint shards:  92% Completed | 940/1024 [00:21<00:01, 67.52it/s]
Loading safetensors checkpoint shards:  92% Completed | 947/1024 [00:21<00:01, 61.57it/s]
Loading safetensors checkpoint shards:  93% Completed | 954/1024 [00:21<00:01, 63.13it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:22<00:02, 21.99it/s]
Loading safetensors checkpoint shards:  94% Completed | 967/1024 [00:22<00:02, 26.09it/s]
Loading safetensors checkpoint shards:  95% Completed | 972/1024 [00:22<00:01, 28.08it/s]
Loading safetensors checkpoint shards:  95% Completed | 977/1024 [00:22<00:01, 30.66it/s]
Loading safetensors checkpoint shards:  96% Completed | 983/1024 [00:23<00:01, 35.60it/s]
Loading safetensors checkpoint shards:  97% Completed | 991/1024 [00:23<00:00, 43.45it/s]
Loading safetensors checkpoint shards:  97% Completed | 997/1024 [00:23<00:00, 44.09it/s]
Loading safetensors checkpoint shards:  98% Completed | 1003/1024 [00:23<00:00, 45.84it/s]
Loading safetensors checkpoint shards:  99% Completed | 1009/1024 [00:23<00:00, 44.61it/s]
Loading safetensors checkpoint shards:  99% Completed | 1014/1024 [00:23<00:00, 43.42it/s]
Loading safetensors checkpoint shards: 100% Completed | 1019/1024 [00:23<00:00, 43.65it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:23<00:00, 42.86it/s]

[2025-09-13 07:54:42 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:54:43 TP1] KV Cache is allocated. #tokens: 620297, KV size: 40.60 GB
[2025-09-13 07:54:43 TP6] KV Cache is allocated. #tokens: 620297, KV size: 40.60 GB
[2025-09-13 07:54:43 TP0] KV Cache is allocated. #tokens: 620297, KV size: 40.60 GB
[2025-09-13 07:54:43 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:54:43 TP7] KV Cache is allocated. #tokens: 620297, KV size: 40.60 GB
[2025-09-13 07:54:43 TP5] KV Cache is allocated. #tokens: 620297, KV size: 40.60 GB
[2025-09-13 07:54:43 TP3] KV Cache is allocated. #tokens: 620297, KV size: 40.60 GB
[2025-09-13 07:54:43 TP2] KV Cache is allocated. #tokens: 620297, KV size: 40.60 GB
[2025-09-13 07:54:43 TP4] KV Cache is allocated. #tokens: 620297, KV size: 40.60 GB
[2025-09-13 07:54:43 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:54:43 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.50 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:54:44 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:54:44 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:54:44 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:54:44 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:54:44 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:54:44 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:54:44 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:54:44 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:54:44 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26024.12it/s]
[2025-09-13 07:54:45 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:54:45 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27071.68it/s]
[2025-09-13 07:54:45 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:54:45 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28480.55it/s]
[2025-09-13 07:54:46 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:54:46 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27698.12it/s]
[2025-09-13 07:54:47 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:54:47 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28692.01it/s]
[2025-09-13 07:54:47 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.16 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.86it/s][2025-09-13 07:54:50 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:54:50 TP4] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.16 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.15it/s]
[2025-09-13 07:54:50 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:54:50 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:54:50 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:54:50 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:54:50 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:54:50 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:54:51 TP0] Capture cuda graph end. Time elapsed: 7.73 s. mem usage=0.43 GB. avail mem=17.14 GB.
[2025-09-13 07:54:51 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:54:51 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:54:51 TP0] Init torch distributed begin.
[2025-09-13 07:54:51 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:54:51 TP0] Load weight begin. avail mem=17.14 GB
[2025-09-13 07:54:51 TP0] Detected fp8 checkpoint.
[2025-09-13 07:54:51 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 173.01it/s]
Loading safetensors checkpoint shards:   4% Completed | 43/1024 [00:00<00:04, 217.12it/s]
Loading safetensors checkpoint shards:  10% Completed | 105/1024 [00:00<00:02, 397.64it/s]
Loading safetensors checkpoint shards:  16% Completed | 168/1024 [00:00<00:01, 486.15it/s]
Loading safetensors checkpoint shards:  22% Completed | 230/1024 [00:00<00:01, 532.87it/s]
Loading safetensors checkpoint shards:  29% Completed | 292/1024 [00:00<00:01, 560.76it/s]
Loading safetensors checkpoint shards:  34% Completed | 353/1024 [00:00<00:01, 576.09it/s]
Loading safetensors checkpoint shards:  41% Completed | 416/1024 [00:00<00:01, 590.76it/s]
Loading safetensors checkpoint shards:  47% Completed | 478/1024 [00:00<00:00, 598.53it/s]
Loading safetensors checkpoint shards:  53% Completed | 540/1024 [00:01<00:00, 604.22it/s]
Loading safetensors checkpoint shards:  59% Completed | 602/1024 [00:01<00:00, 607.52it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:01<00:00, 601.77it/s]
Loading safetensors checkpoint shards:  71% Completed | 724/1024 [00:01<00:00, 595.69it/s]
Loading safetensors checkpoint shards:  77% Completed | 784/1024 [00:01<00:00, 589.99it/s]
Loading safetensors checkpoint shards:  82% Completed | 844/1024 [00:01<00:00, 588.08it/s]
Loading safetensors checkpoint shards:  88% Completed | 903/1024 [00:01<00:00, 585.39it/s]
Loading safetensors checkpoint shards:  94% Completed | 962/1024 [00:01<00:00, 584.89it/s]
Loading safetensors checkpoint shards: 100% Completed | 1021/1024 [00:01<00:00, 390.45it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 510.89it/s]

[2025-09-13 07:54:53 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.15 GB, mem usage=1.99 GB.
[2025-09-13 07:54:53 TP6] KV Cache is allocated. #tokens: 620297, KV size: 0.67 GB
[2025-09-13 07:54:53 TP5] KV Cache is allocated. #tokens: 620297, KV size: 0.67 GB
[2025-09-13 07:54:53 TP3] KV Cache is allocated. #tokens: 620297, KV size: 0.67 GB
[2025-09-13 07:54:53 TP0] KV Cache is allocated. #tokens: 620297, KV size: 0.67 GB
[2025-09-13 07:54:53 TP2] KV Cache is allocated. #tokens: 620297, KV size: 0.67 GB
[2025-09-13 07:54:53 TP4] KV Cache is allocated. #tokens: 620297, KV size: 0.67 GB
[2025-09-13 07:54:53 TP1] KV Cache is allocated. #tokens: 620297, KV size: 0.67 GB
[2025-09-13 07:54:53 TP0] Memory pool end. avail mem=14.48 GB
[2025-09-13 07:54:53 TP7] KV Cache is allocated. #tokens: 620297, KV size: 0.67 GB
[2025-09-13 07:54:53 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:54:53 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:54:53 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:54:53 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:54:53 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 07:54:53 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.11 GB
[2025-09-13 07:54:53 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 07:54:53 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
Capturing batches (bs=1 avail_mem=14.48 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.42it/s]
[2025-09-13 07:55:00 TP6] Registering 120 cuda graph addresses
[2025-09-13 07:55:00 TP4] Registering 120 cuda graph addresses
[2025-09-13 07:55:00 TP7] Registering 120 cuda graph addresses
[2025-09-13 07:55:00 TP0] Registering 120 cuda graph addresses
[2025-09-13 07:55:00 TP3] Registering 120 cuda graph addresses
[2025-09-13 07:55:00 TP2] Registering 120 cuda graph addresses
[2025-09-13 07:55:00 TP1] Registering 120 cuda graph addresses
[2025-09-13 07:55:00 TP5] Registering 120 cuda graph addresses
[2025-09-13 07:55:00 TP1] Capture draft cuda graph end. Time elapsed: 6.43 s. mem usage=0.43 GB. avail mem=14.44 GB.
[2025-09-13 07:55:00 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
[2025-09-13 07:55:00 TP2] Capture draft cuda graph end. Time elapsed: 6.45 s. mem usage=0.43 GB. avail mem=14.44 GB.
[2025-09-13 07:55:00 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
[2025-09-13 07:55:00 TP3] Capture draft cuda graph end. Time elapsed: 6.45 s. mem usage=0.43 GB. avail mem=14.44 GB.
[2025-09-13 07:55:00 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
[2025-09-13 07:55:00 TP4] Capture draft cuda graph end. Time elapsed: 6.45 s. mem usage=0.43 GB. avail mem=14.44 GB.
[2025-09-13 07:55:00 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
[2025-09-13 07:55:00 TP7] Capture draft cuda graph end. Time elapsed: 6.47 s. mem usage=0.43 GB. avail mem=14.67 GB.
[2025-09-13 07:55:00 TP5] Capture draft cuda graph end. Time elapsed: 6.47 s. mem usage=0.43 GB. avail mem=14.44 GB.
[2025-09-13 07:55:00 TP0] Capture draft cuda graph end. Time elapsed: 6.47 s. mem usage=0.44 GB. avail mem=14.48 GB.
[2025-09-13 07:55:00 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.67 GB
[2025-09-13 07:55:00 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
[2025-09-13 07:55:00 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.48 GB
[2025-09-13 07:55:00 TP6] Capture draft cuda graph end. Time elapsed: 6.48 s. mem usage=0.43 GB. avail mem=14.44 GB.
[2025-09-13 07:55:00 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
Capturing batches (bs=1 avail_mem=14.28 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 19.62it/s]
[2025-09-13 07:55:01 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:55:01 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:55:01 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:55:01 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:55:01 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:55:01 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:55:01 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:55:01 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:55:01 TP2] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.21 GB. avail mem=14.23 GB.
[2025-09-13 07:55:01 TP4] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.21 GB. avail mem=14.23 GB.
[2025-09-13 07:55:01 TP1] Capture draft extend cuda graph end. Time elapsed: 1.14 s. mem usage=0.21 GB. avail mem=14.23 GB.
[2025-09-13 07:55:01 TP3] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.21 GB. avail mem=14.23 GB.
[2025-09-13 07:55:01 TP7] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.21 GB. avail mem=14.47 GB.
[2025-09-13 07:55:01 TP0] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.20 GB. avail mem=14.28 GB.
[2025-09-13 07:55:01 TP0] max_total_num_tokens=620297, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.28 GB
[2025-09-13 07:55:01 TP5] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.21 GB. avail mem=14.23 GB.
[2025-09-13 07:55:01 TP6] Capture draft extend cuda graph end. Time elapsed: 1.10 s. mem usage=0.21 GB. avail mem=14.23 GB.
[2025-09-13 07:55:02] INFO:     Started server process [382138]
[2025-09-13 07:55:02] INFO:     Waiting for application startup.
[2025-09-13 07:55:02] INFO:     Application startup complete.
[2025-09-13 07:55:02] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:55:03] INFO:     127.0.0.1:59854 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:55:03 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:55:03 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:55:03 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup:   0%|                                                                                                                      | 0/16384 [00:00<?, ?it/s][2025-09-13 07:55:03] INFO:     127.0.0.1:59864 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27897.16it/s]
[2025-09-13 07:55:04] INFO:     127.0.0.1:59862 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:04] The server is fired up and ready to roll!
[2025-09-13 07:55:13 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:55:14] INFO:     127.0.0.1:44614 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:55:14] INFO:     127.0.0.1:44622 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:14 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:55:15] INFO:     127.0.0.1:44636 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:15] INFO:     127.0.0.1:44648 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:15 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:55:15] INFO:     127.0.0.1:44652 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:15] INFO:     127.0.0.1:44668 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:15] INFO:     127.0.0.1:44670 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:15] INFO:     127.0.0.1:44678 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:15] INFO:     127.0.0.1:44692 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:15] INFO:     127.0.0.1:44696 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:16 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:55:16 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:55:16 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:55:16 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:55:16 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:55:16 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:55:16 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:55:16 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:55:16 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:55:16 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:55:17 TP0] Decode batch. #running-req: 8, #token: 14695, token usage: 0.02, accept len: 3.41, cuda graph: True, gen throughput (token/s): 49.70, #queue-req: 0, 
[2025-09-13 07:55:19 TP0] Decode batch. #running-req: 8, #token: 16056, token usage: 0.03, accept len: 4.25, cuda graph: True, gen throughput (token/s): 925.03, #queue-req: 0, 
 38%|█████████████████████████████████████████████████▏                                                                                 | 3/8 [00:04<00:06,  1.25s/it][2025-09-13 07:55:20 TP0] Decode batch. #running-req: 5, #token: 8511, token usage: 0.01, accept len: 4.64, cuda graph: True, gen throughput (token/s): 958.25, #queue-req: 0, 
 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 7/8 [00:05<00:00,  2.06it/s][2025-09-13 07:55:22 TP0] Decode batch. #running-req: 1, #token: 1510, token usage: 0.00, accept len: 4.03, cuda graph: True, gen throughput (token/s): 387.31, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.30it/s]
[2025-09-13 07:55:22] INFO:     127.0.0.1:45434 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.14      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4087      
Request throughput (req/s):              1.30      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         667.02    
Total token throughput (tok/s):          667.02    
Concurrency:                             6.87      
Accept length:                           4.14      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5273.93   
Median E2E Latency (ms):                 5314.25   
---------------Time to First Token----------------
Mean TTFT (ms):                          608.67    
Median TTFT (ms):                        719.63    
P99 TTFT (ms):                           720.22    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.13      
Median ITL (ms):                         6.16      
P95 ITL (ms):                            18.48     
P99 ITL (ms):                            36.80     
Max ITL (ms):                            732.23    
==================================================
[2025-09-13 07:55:22] INFO:     127.0.0.1:45440 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:55:22] INFO:     127.0.0.1:45456 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:22 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:55:23] INFO:     127.0.0.1:45460 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:23] INFO:     127.0.0.1:45462 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:55:23] INFO:     127.0.0.1:45472 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:23] INFO:     127.0.0.1:45486 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:23] INFO:     127.0.0.1:45500 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:23] INFO:     127.0.0.1:45506 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:23] INFO:     127.0.0.1:45518 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:23] INFO:     127.0.0.1:45534 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:23 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:55:24 TP0] Decode batch. #running-req: 8, #token: 14755, token usage: 0.02, accept len: 3.49, cuda graph: True, gen throughput (token/s): 323.00, #queue-req: 0, 
[2025-09-13 07:55:26 TP0] Decode batch. #running-req: 8, #token: 16121, token usage: 0.03, accept len: 4.27, cuda graph: True, gen throughput (token/s): 926.28, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:03<00:59,  3.94s/it][2025-09-13 07:55:27] INFO:     127.0.0.1:45548 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:27 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:55:27] INFO:     127.0.0.1:45554 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:27 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:04<00:16,  1.24s/it][2025-09-13 07:55:27] INFO:     127.0.0.1:60424 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:28 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:55:28 TP0] Decode batch. #running-req: 8, #token: 11777, token usage: 0.02, accept len: 4.46, cuda graph: True, gen throughput (token/s): 719.68, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:12,  1.04s/it][2025-09-13 07:55:28] INFO:     127.0.0.1:60428 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:28 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:08,  1.25it/s][2025-09-13 07:55:28] INFO:     127.0.0.1:60440 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:28 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:06,  1.46it/s][2025-09-13 07:55:29] INFO:     127.0.0.1:60446 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:29 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:05,  1.63it/s][2025-09-13 07:55:29] INFO:     127.0.0.1:60452 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:29 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:55:30 TP0] Decode batch. #running-req: 8, #token: 10774, token usage: 0.02, accept len: 4.09, cuda graph: True, gen throughput (token/s): 644.81, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:04,  1.69it/s][2025-09-13 07:55:30] INFO:     127.0.0.1:60458 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:55:30 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:55:31 TP0] Decode batch. #running-req: 8, #token: 15644, token usage: 0.03, accept len: 4.22, cuda graph: True, gen throughput (token/s): 793.64, #queue-req: 0, 
 69%|████████████████████████████████████████████████████████████████████████████████████████▋                                        | 11/16 [00:09<00:03,  1.57it/s][2025-09-13 07:55:33 TP0] Decode batch. #running-req: 5, #token: 8925, token usage: 0.01, accept len: 5.07, cuda graph: True, gen throughput (token/s): 903.83, #queue-req: 0, 
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 15/16 [00:10<00:00,  2.28it/s][2025-09-13 07:55:34 TP0] Decode batch. #running-req: 1, #token: 3223, token usage: 0.01, accept len: 5.04, cuda graph: True, gen throughput (token/s): 541.44, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.44it/s]
[2025-09-13 07:55:34] INFO:     127.0.0.1:60472 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.14     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8147      
Request throughput (req/s):              1.44      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         735.39    
Total token throughput (tok/s):          735.39    
Concurrency:                             7.23      
Accept length:                           4.25      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5034.04   
Median E2E Latency (ms):                 4894.87   
---------------Time to First Token----------------
Mean TTFT (ms):                          238.00    
Median TTFT (ms):                        277.14    
P99 TTFT (ms):                           388.79    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.39      
Median ITL (ms):                         6.08      
P95 ITL (ms):                            20.34     
P99 ITL (ms):                            44.60     
Max ITL (ms):                            276.30    
==================================================
[2025-09-13 07:55:34] INFO:     127.0.0.1:60474 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=44: batch_size=8, steps=6, topk=3, num_draft_tokens=12, speed=111.94 token/s, step_time=38.01 ms
Start i=45: batch_size=8, steps=6, topk=4, num_draft_tokens=4
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 6 --speculative-eagle-topk 4 --speculative-num-draft-tokens 4 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:55:45.219000 387767 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:55:45.219000 387767 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:55:45] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=536889333, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=6, speculative_eagle_topk=4, speculative_num_draft_tokens=4, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:55:45] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:55:54.785000 387974 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:55:54.785000 387974 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:55:54.786000 387976 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:55:54.786000 387976 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:55:54.797000 387977 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:55:54.797000 387977 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:55:54.842000 387978 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:55:54.842000 387978 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:55:54.845000 387975 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:55:54.845000 387975 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:55:54.948000 387979 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:55:54.948000 387979 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:55:55.013000 387972 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:55:55.013000 387972 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:55:55.046000 387973 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:55:55.046000 387973 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:55:55.055000 387980 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:55:55.055000 387980 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:55:55 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:55:55 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:55:55 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:55:57 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:56:00 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:56:01 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:56:01 TP0] Detected fp8 checkpoint.
[2025-09-13 07:56:02 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 28/1024 [00:00<00:03, 268.38it/s]
Loading safetensors checkpoint shards:   5% Completed | 55/1024 [00:00<00:11, 86.96it/s]
Loading safetensors checkpoint shards:   7% Completed | 70/1024 [00:01<00:16, 57.51it/s]
Loading safetensors checkpoint shards:   8% Completed | 80/1024 [00:01<00:20, 45.99it/s]
Loading safetensors checkpoint shards:   8% Completed | 87/1024 [00:01<00:20, 46.51it/s]
Loading safetensors checkpoint shards:   9% Completed | 94/1024 [00:01<00:20, 44.93it/s]
Loading safetensors checkpoint shards:  10% Completed | 100/1024 [00:02<00:33, 27.32it/s]
Loading safetensors checkpoint shards:  10% Completed | 105/1024 [00:02<00:31, 29.24it/s]
Loading safetensors checkpoint shards:  11% Completed | 110/1024 [00:02<00:31, 29.38it/s]
Loading safetensors checkpoint shards:  11% Completed | 116/1024 [00:02<00:27, 33.20it/s]
Loading safetensors checkpoint shards:  12% Completed | 122/1024 [00:02<00:25, 35.52it/s]
Loading safetensors checkpoint shards:  12% Completed | 127/1024 [00:02<00:24, 36.73it/s]
Loading safetensors checkpoint shards:  13% Completed | 132/1024 [00:03<00:24, 37.13it/s]
Loading safetensors checkpoint shards:  13% Completed | 137/1024 [00:03<00:22, 39.07it/s]
Loading safetensors checkpoint shards:  14% Completed | 142/1024 [00:03<00:21, 40.62it/s]
Loading safetensors checkpoint shards:  14% Completed | 147/1024 [00:03<00:21, 40.57it/s]
Loading safetensors checkpoint shards:  15% Completed | 152/1024 [00:03<00:22, 38.98it/s]
Loading safetensors checkpoint shards:  15% Completed | 158/1024 [00:03<00:21, 40.98it/s]
Loading safetensors checkpoint shards:  16% Completed | 163/1024 [00:03<00:19, 43.12it/s]
Loading safetensors checkpoint shards:  16% Completed | 168/1024 [00:03<00:21, 39.74it/s]
Loading safetensors checkpoint shards:  17% Completed | 173/1024 [00:04<00:20, 40.60it/s]
Loading safetensors checkpoint shards:  17% Completed | 178/1024 [00:04<00:21, 38.61it/s]
Loading safetensors checkpoint shards:  18% Completed | 182/1024 [00:04<00:21, 38.67it/s]
Loading safetensors checkpoint shards:  18% Completed | 187/1024 [00:04<00:21, 38.39it/s]
Loading safetensors checkpoint shards:  19% Completed | 191/1024 [00:04<00:22, 37.34it/s]
Loading safetensors checkpoint shards:  19% Completed | 196/1024 [00:04<00:21, 38.37it/s]
Loading safetensors checkpoint shards:  20% Completed | 200/1024 [00:04<00:21, 38.27it/s]
Loading safetensors checkpoint shards:  20% Completed | 205/1024 [00:04<00:20, 39.15it/s]
Loading safetensors checkpoint shards:  21% Completed | 210/1024 [00:04<00:20, 40.63it/s]
Loading safetensors checkpoint shards:  21% Completed | 215/1024 [00:05<00:18, 42.58it/s]
Loading safetensors checkpoint shards:  21% Completed | 220/1024 [00:05<00:20, 40.05it/s]
Loading safetensors checkpoint shards:  22% Completed | 225/1024 [00:05<00:19, 40.74it/s]
Loading safetensors checkpoint shards:  22% Completed | 230/1024 [00:05<00:18, 42.75it/s]
Loading safetensors checkpoint shards:  23% Completed | 235/1024 [00:05<00:19, 40.05it/s]
Loading safetensors checkpoint shards:  24% Completed | 241/1024 [00:05<00:17, 44.48it/s]
Loading safetensors checkpoint shards:  24% Completed | 246/1024 [00:05<00:17, 45.36it/s]
Loading safetensors checkpoint shards:  25% Completed | 252/1024 [00:05<00:16, 47.21it/s]
Loading safetensors checkpoint shards:  25% Completed | 257/1024 [00:06<00:16, 47.06it/s]
Loading safetensors checkpoint shards:  26% Completed | 264/1024 [00:06<00:14, 51.07it/s]
Loading safetensors checkpoint shards:  26% Completed | 270/1024 [00:06<00:35, 21.34it/s]
Loading safetensors checkpoint shards:  27% Completed | 274/1024 [00:06<00:32, 22.91it/s]
Loading safetensors checkpoint shards:  27% Completed | 278/1024 [00:07<00:31, 23.68it/s]
Loading safetensors checkpoint shards:  28% Completed | 283/1024 [00:07<00:26, 27.67it/s]
Loading safetensors checkpoint shards:  28% Completed | 288/1024 [00:07<00:24, 30.52it/s]
Loading safetensors checkpoint shards:  29% Completed | 292/1024 [00:07<00:22, 31.89it/s]
Loading safetensors checkpoint shards:  29% Completed | 297/1024 [00:07<00:20, 35.36it/s]
Loading safetensors checkpoint shards:  29% Completed | 302/1024 [00:07<00:19, 36.53it/s]
Loading safetensors checkpoint shards:  30% Completed | 306/1024 [00:07<00:19, 37.26it/s]
Loading safetensors checkpoint shards:  30% Completed | 310/1024 [00:07<00:19, 37.27it/s]
Loading safetensors checkpoint shards:  31% Completed | 314/1024 [00:07<00:18, 37.37it/s]
Loading safetensors checkpoint shards:  31% Completed | 319/1024 [00:08<00:17, 39.24it/s]
Loading safetensors checkpoint shards:  32% Completed | 324/1024 [00:08<00:18, 37.56it/s]
Loading safetensors checkpoint shards:  32% Completed | 329/1024 [00:08<00:17, 40.57it/s]
Loading safetensors checkpoint shards:  33% Completed | 334/1024 [00:08<00:18, 38.13it/s]
Loading safetensors checkpoint shards:  33% Completed | 339/1024 [00:08<00:17, 39.34it/s]
Loading safetensors checkpoint shards:  34% Completed | 344/1024 [00:08<00:17, 38.72it/s]
Loading safetensors checkpoint shards:  34% Completed | 349/1024 [00:08<00:17, 39.35it/s]
Loading safetensors checkpoint shards:  34% Completed | 353/1024 [00:08<00:17, 38.71it/s]
Loading safetensors checkpoint shards:  35% Completed | 357/1024 [00:09<00:17, 38.16it/s]
Loading safetensors checkpoint shards:  35% Completed | 362/1024 [00:09<00:16, 39.00it/s]
Loading safetensors checkpoint shards:  36% Completed | 366/1024 [00:09<00:17, 38.16it/s]
Loading safetensors checkpoint shards:  36% Completed | 370/1024 [00:09<00:17, 36.82it/s]
Loading safetensors checkpoint shards:  37% Completed | 375/1024 [00:09<00:16, 38.64it/s]
Loading safetensors checkpoint shards:  37% Completed | 379/1024 [00:09<00:17, 36.64it/s]
Loading safetensors checkpoint shards:  38% Completed | 384/1024 [00:09<00:16, 38.29it/s]
Loading safetensors checkpoint shards:  38% Completed | 388/1024 [00:09<00:16, 37.88it/s]
Loading safetensors checkpoint shards:  38% Completed | 392/1024 [00:10<00:17, 36.71it/s]
Loading safetensors checkpoint shards:  39% Completed | 397/1024 [00:10<00:16, 38.48it/s]
Loading safetensors checkpoint shards:  39% Completed | 401/1024 [00:10<00:16, 38.25it/s]
Loading safetensors checkpoint shards:  40% Completed | 406/1024 [00:10<00:15, 40.72it/s]
Loading safetensors checkpoint shards:  40% Completed | 411/1024 [00:10<00:15, 40.47it/s]
Loading safetensors checkpoint shards:  41% Completed | 416/1024 [00:10<00:14, 42.26it/s]
Loading safetensors checkpoint shards:  41% Completed | 421/1024 [00:10<00:14, 41.91it/s]
Loading safetensors checkpoint shards:  42% Completed | 428/1024 [00:10<00:12, 49.46it/s]
Loading safetensors checkpoint shards:  42% Completed | 434/1024 [00:10<00:12, 48.78it/s]
Loading safetensors checkpoint shards:  43% Completed | 440/1024 [00:11<00:11, 51.05it/s]
Loading safetensors checkpoint shards:  44% Completed | 446/1024 [00:11<00:11, 48.99it/s]
Loading safetensors checkpoint shards:  44% Completed | 451/1024 [00:11<00:12, 47.26it/s]
Loading safetensors checkpoint shards:  45% Completed | 456/1024 [00:11<00:12, 47.28it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:11<00:11, 50.54it/s]
Loading safetensors checkpoint shards:  46% Completed | 469/1024 [00:11<00:10, 50.80it/s]
Loading safetensors checkpoint shards:  46% Completed | 475/1024 [00:11<00:10, 50.89it/s]
Loading safetensors checkpoint shards:  47% Completed | 481/1024 [00:12<00:26, 20.76it/s]
Loading safetensors checkpoint shards:  47% Completed | 486/1024 [00:12<00:22, 23.99it/s]
Loading safetensors checkpoint shards:  48% Completed | 490/1024 [00:12<00:21, 25.12it/s]
Loading safetensors checkpoint shards:  48% Completed | 494/1024 [00:12<00:19, 26.92it/s]
Loading safetensors checkpoint shards:  49% Completed | 498/1024 [00:12<00:19, 27.03it/s]
Loading safetensors checkpoint shards:  49% Completed | 502/1024 [00:13<00:18, 28.66it/s]
Loading safetensors checkpoint shards:  50% Completed | 507/1024 [00:13<00:15, 32.89it/s]
Loading safetensors checkpoint shards:  50% Completed | 512/1024 [00:13<00:14, 36.43it/s]
Loading safetensors checkpoint shards:  51% Completed | 518/1024 [00:13<00:12, 40.32it/s]
Loading safetensors checkpoint shards:  51% Completed | 523/1024 [00:13<00:14, 34.26it/s]
Loading safetensors checkpoint shards:  51% Completed | 527/1024 [00:13<00:14, 34.42it/s]
Loading safetensors checkpoint shards:  52% Completed | 531/1024 [00:13<00:16, 29.61it/s]
Loading safetensors checkpoint shards:  52% Completed | 535/1024 [00:14<00:15, 31.32it/s]
Loading safetensors checkpoint shards:  53% Completed | 540/1024 [00:14<00:13, 35.58it/s]
Loading safetensors checkpoint shards:  53% Completed | 544/1024 [00:14<00:13, 34.56it/s]
Loading safetensors checkpoint shards:  54% Completed | 549/1024 [00:14<00:12, 37.51it/s]
Loading safetensors checkpoint shards:  54% Completed | 554/1024 [00:14<00:12, 38.60it/s]
Loading safetensors checkpoint shards:  54% Completed | 558/1024 [00:14<00:12, 37.57it/s]
Loading safetensors checkpoint shards:  55% Completed | 563/1024 [00:14<00:11, 40.25it/s]
Loading safetensors checkpoint shards:  55% Completed | 568/1024 [00:14<00:11, 39.96it/s]
Loading safetensors checkpoint shards:  56% Completed | 573/1024 [00:14<00:10, 41.44it/s]
Loading safetensors checkpoint shards:  56% Completed | 578/1024 [00:15<00:11, 38.99it/s]
Loading safetensors checkpoint shards:  57% Completed | 584/1024 [00:15<00:10, 42.93it/s]
Loading safetensors checkpoint shards:  58% Completed | 589/1024 [00:15<00:10, 41.93it/s]
Loading safetensors checkpoint shards:  58% Completed | 594/1024 [00:15<00:10, 42.08it/s]
Loading safetensors checkpoint shards:  58% Completed | 599/1024 [00:15<00:10, 41.07it/s]
Loading safetensors checkpoint shards:  59% Completed | 604/1024 [00:15<00:09, 42.07it/s]
Loading safetensors checkpoint shards:  59% Completed | 609/1024 [00:15<00:10, 40.40it/s]
Loading safetensors checkpoint shards:  60% Completed | 614/1024 [00:15<00:10, 40.65it/s]
Loading safetensors checkpoint shards:  60% Completed | 619/1024 [00:16<00:09, 42.45it/s]
Loading safetensors checkpoint shards:  61% Completed | 624/1024 [00:16<00:09, 41.99it/s]
Loading safetensors checkpoint shards:  61% Completed | 629/1024 [00:16<00:09, 41.85it/s]
Loading safetensors checkpoint shards:  62% Completed | 634/1024 [00:16<00:09, 40.25it/s]
Loading safetensors checkpoint shards:  62% Completed | 639/1024 [00:16<00:09, 40.13it/s]
Loading safetensors checkpoint shards:  63% Completed | 644/1024 [00:16<00:09, 39.98it/s]
Loading safetensors checkpoint shards:  63% Completed | 649/1024 [00:16<00:09, 38.55it/s]
Loading safetensors checkpoint shards:  64% Completed | 654/1024 [00:16<00:09, 39.63it/s]
Loading safetensors checkpoint shards:  64% Completed | 659/1024 [00:17<00:09, 39.78it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:17<00:09, 38.04it/s]
Loading safetensors checkpoint shards:  65% Completed | 668/1024 [00:17<00:09, 39.09it/s]
Loading safetensors checkpoint shards:  66% Completed | 673/1024 [00:17<00:08, 39.97it/s]
Loading safetensors checkpoint shards:  66% Completed | 678/1024 [00:17<00:08, 39.29it/s]
Loading safetensors checkpoint shards:  67% Completed | 683/1024 [00:17<00:08, 39.79it/s]
Loading safetensors checkpoint shards:  67% Completed | 688/1024 [00:17<00:08, 40.67it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:17<00:07, 43.50it/s]
Loading safetensors checkpoint shards:  68% Completed | 699/1024 [00:17<00:07, 43.89it/s]
Loading safetensors checkpoint shards:  69% Completed | 704/1024 [00:18<00:07, 42.72it/s]
Loading safetensors checkpoint shards:  69% Completed | 709/1024 [00:18<00:07, 42.76it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:18<00:07, 42.80it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:18<00:07, 39.75it/s]
Loading safetensors checkpoint shards:  71% Completed | 724/1024 [00:18<00:07, 39.94it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:18<00:07, 39.44it/s]
Loading safetensors checkpoint shards:  72% Completed | 733/1024 [00:18<00:07, 39.00it/s]
Loading safetensors checkpoint shards:  72% Completed | 738/1024 [00:18<00:07, 39.99it/s]
Loading safetensors checkpoint shards:  73% Completed | 743/1024 [00:19<00:06, 41.02it/s]
Loading safetensors checkpoint shards:  73% Completed | 748/1024 [00:19<00:16, 16.82it/s]
Loading safetensors checkpoint shards:  74% Completed | 753/1024 [00:19<00:13, 20.51it/s]
Loading safetensors checkpoint shards:  74% Completed | 758/1024 [00:20<00:10, 24.31it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:20<00:09, 28.03it/s]
Loading safetensors checkpoint shards:  75% Completed | 767/1024 [00:20<00:08, 30.08it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:20<00:07, 32.40it/s]
Loading safetensors checkpoint shards:  76% Completed | 777/1024 [00:20<00:07, 34.87it/s]
Loading safetensors checkpoint shards:  76% Completed | 782/1024 [00:20<00:06, 37.00it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:20<00:06, 37.50it/s]
Loading safetensors checkpoint shards:  77% Completed | 792/1024 [00:20<00:05, 39.20it/s]
Loading safetensors checkpoint shards:  78% Completed | 797/1024 [00:20<00:05, 40.65it/s]
Loading safetensors checkpoint shards:  78% Completed | 802/1024 [00:21<00:05, 39.97it/s]
Loading safetensors checkpoint shards:  79% Completed | 807/1024 [00:21<00:05, 41.86it/s]
Loading safetensors checkpoint shards:  79% Completed | 812/1024 [00:21<00:05, 41.44it/s]
Loading safetensors checkpoint shards:  80% Completed | 817/1024 [00:21<00:05, 40.42it/s]
Loading safetensors checkpoint shards:  80% Completed | 822/1024 [00:21<00:05, 39.06it/s]
Loading safetensors checkpoint shards:  81% Completed | 829/1024 [00:21<00:04, 45.41it/s]
Loading safetensors checkpoint shards:  82% Completed | 836/1024 [00:21<00:03, 50.94it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:21<00:03, 52.45it/s]
Loading safetensors checkpoint shards:  83% Completed | 848/1024 [00:22<00:03, 50.54it/s]
Loading safetensors checkpoint shards:  83% Completed | 854/1024 [00:22<00:03, 51.44it/s]
Loading safetensors checkpoint shards:  84% Completed | 860/1024 [00:22<00:03, 52.97it/s]
Loading safetensors checkpoint shards:  85% Completed | 868/1024 [00:22<00:02, 56.59it/s]
Loading safetensors checkpoint shards:  85% Completed | 874/1024 [00:22<00:02, 52.28it/s]
Loading safetensors checkpoint shards:  86% Completed | 880/1024 [00:22<00:03, 46.96it/s]
Loading safetensors checkpoint shards:  86% Completed | 885/1024 [00:22<00:03, 40.33it/s]
Loading safetensors checkpoint shards:  87% Completed | 890/1024 [00:22<00:03, 41.27it/s]
Loading safetensors checkpoint shards:  88% Completed | 897/1024 [00:23<00:02, 47.25it/s]
Loading safetensors checkpoint shards:  88% Completed | 904/1024 [00:23<00:02, 52.09it/s]
Loading safetensors checkpoint shards:  89% Completed | 911/1024 [00:23<00:02, 54.43it/s]
Loading safetensors checkpoint shards:  90% Completed | 917/1024 [00:23<00:01, 55.14it/s]
Loading safetensors checkpoint shards:  90% Completed | 923/1024 [00:23<00:01, 54.65it/s]
Loading safetensors checkpoint shards:  91% Completed | 929/1024 [00:23<00:01, 50.61it/s]
Loading safetensors checkpoint shards:  91% Completed | 935/1024 [00:23<00:01, 48.65it/s]
Loading safetensors checkpoint shards:  92% Completed | 941/1024 [00:23<00:01, 50.10it/s]
Loading safetensors checkpoint shards:  92% Completed | 947/1024 [00:24<00:01, 49.89it/s]
Loading safetensors checkpoint shards:  93% Completed | 954/1024 [00:24<00:01, 52.73it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:24<00:01, 52.86it/s]
Loading safetensors checkpoint shards:  95% Completed | 968/1024 [00:24<00:01, 55.83it/s]
Loading safetensors checkpoint shards:  95% Completed | 974/1024 [00:24<00:00, 54.98it/s]
Loading safetensors checkpoint shards:  96% Completed | 982/1024 [00:24<00:00, 61.46it/s]
Loading safetensors checkpoint shards:  97% Completed | 994/1024 [00:24<00:00, 77.11it/s]
Loading safetensors checkpoint shards:  99% Completed | 1009/1024 [00:24<00:00, 97.50it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:24<00:00, 41.13it/s]

[2025-09-13 07:56:28 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:56:30 TP3] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:56:30 TP5] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:56:30 TP7] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:56:30 TP6] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:56:30 TP2] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:56:30 TP0] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:56:30 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:56:30 TP1] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:56:30 TP4] KV Cache is allocated. #tokens: 620281, KV size: 40.59 GB
[2025-09-13 07:56:30 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:56:31 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.53 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:56:32 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:56:32 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 07:56:32 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:56:32 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:56:32 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:56:32 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:56:32 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:56:32 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:56:32 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25552.34it/s]
[2025-09-13 07:56:32 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:56:32 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26778.76it/s]
[2025-09-13 07:56:33 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:56:33 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28284.86it/s]
[2025-09-13 07:56:34 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:56:34 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27676.00it/s]
[2025-09-13 07:56:34 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:56:34 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28417.24it/s]
[2025-09-13 07:56:35 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.22 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.98it/s][2025-09-13 07:56:38 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:56:38 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:56:38 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:56:38 TP7] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.22 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.17it/s]
[2025-09-13 07:56:38 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:56:38 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:56:38 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:56:38 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:56:38 TP0] Capture cuda graph end. Time elapsed: 7.52 s. mem usage=0.36 GB. avail mem=17.20 GB.
[2025-09-13 07:56:38 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:56:38 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:56:38 TP0] Init torch distributed begin.
[2025-09-13 07:56:38 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:56:38 TP0] Load weight begin. avail mem=17.20 GB
[2025-09-13 07:56:38 TP0] Detected fp8 checkpoint.
[2025-09-13 07:56:38 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 19/1024 [00:00<00:05, 179.59it/s]
Loading safetensors checkpoint shards:   4% Completed | 46/1024 [00:00<00:04, 229.30it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:00<00:02, 404.24it/s]
Loading safetensors checkpoint shards:  17% Completed | 171/1024 [00:00<00:01, 491.52it/s]
Loading safetensors checkpoint shards:  23% Completed | 233/1024 [00:00<00:01, 537.00it/s]
Loading safetensors checkpoint shards:  29% Completed | 297/1024 [00:00<00:01, 569.86it/s]
Loading safetensors checkpoint shards:  35% Completed | 361/1024 [00:00<00:01, 592.21it/s]
Loading safetensors checkpoint shards:  41% Completed | 424/1024 [00:00<00:00, 602.78it/s]
Loading safetensors checkpoint shards:  48% Completed | 488/1024 [00:00<00:00, 611.78it/s]
Loading safetensors checkpoint shards:  54% Completed | 551/1024 [00:01<00:00, 616.90it/s]
Loading safetensors checkpoint shards:  60% Completed | 614/1024 [00:01<00:00, 619.85it/s]
Loading safetensors checkpoint shards:  66% Completed | 677/1024 [00:01<00:00, 609.80it/s]
Loading safetensors checkpoint shards:  72% Completed | 739/1024 [00:01<00:00, 602.02it/s]
Loading safetensors checkpoint shards:  78% Completed | 800/1024 [00:01<00:00, 594.12it/s]
Loading safetensors checkpoint shards:  84% Completed | 860/1024 [00:01<00:00, 591.06it/s]
Loading safetensors checkpoint shards:  90% Completed | 920/1024 [00:01<00:00, 582.53it/s]
Loading safetensors checkpoint shards:  96% Completed | 979/1024 [00:01<00:00, 572.63it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:01<00:00, 517.29it/s]

[2025-09-13 07:56:40 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.21 GB, mem usage=1.99 GB.
[2025-09-13 07:56:40 TP7] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:56:40 TP6] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:56:40 TP4] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:56:40 TP2] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:56:40 TP3] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:56:40 TP0] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:56:40 TP0] Memory pool end. avail mem=14.54 GB
[2025-09-13 07:56:40 TP5] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:56:40 TP1] KV Cache is allocated. #tokens: 620281, KV size: 0.67 GB
[2025-09-13 07:56:41 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:56:41 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:56:41 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:56:41 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.17 GB
[2025-09-13 07:56:41 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.98 GB
[2025-09-13 07:56:41 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:56:41 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
[2025-09-13 07:56:41 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.93 GB
Capturing batches (bs=1 avail_mem=14.49 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  3.00it/s][2025-09-13 07:56:47 TP2] Registering 120 cuda graph addresses
[2025-09-13 07:56:47 TP4] Registering 120 cuda graph addresses
[2025-09-13 07:56:47 TP3] Registering 120 cuda graph addresses
[2025-09-13 07:56:47 TP6] Registering 120 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.49 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.41it/s]
[2025-09-13 07:56:47 TP0] Registering 120 cuda graph addresses
[2025-09-13 07:56:47 TP7] Registering 120 cuda graph addresses
[2025-09-13 07:56:47 TP5] Registering 120 cuda graph addresses
[2025-09-13 07:56:47 TP1] Registering 120 cuda graph addresses
[2025-09-13 07:56:47 TP4] Capture draft cuda graph end. Time elapsed: 6.63 s. mem usage=0.49 GB. avail mem=14.44 GB.
[2025-09-13 07:56:47 TP7] Capture draft cuda graph end. Time elapsed: 6.58 s. mem usage=0.49 GB. avail mem=14.68 GB.
[2025-09-13 07:56:47 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.68 GB
[2025-09-13 07:56:47 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
[2025-09-13 07:56:47 TP5] Capture draft cuda graph end. Time elapsed: 6.57 s. mem usage=0.49 GB. avail mem=14.44 GB.
[2025-09-13 07:56:47 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
[2025-09-13 07:56:47 TP2] Capture draft cuda graph end. Time elapsed: 6.63 s. mem usage=0.49 GB. avail mem=14.44 GB.
[2025-09-13 07:56:47 TP1] Capture draft cuda graph end. Time elapsed: 6.58 s. mem usage=0.49 GB. avail mem=14.44 GB.
[2025-09-13 07:56:47 TP0] Capture draft cuda graph end. Time elapsed: 6.58 s. mem usage=0.49 GB. avail mem=14.48 GB.
[2025-09-13 07:56:47 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
[2025-09-13 07:56:47 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
[2025-09-13 07:56:47 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.48 GB
[2025-09-13 07:56:47 TP3] Capture draft cuda graph end. Time elapsed: 6.57 s. mem usage=0.49 GB. avail mem=14.44 GB.
[2025-09-13 07:56:47 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
[2025-09-13 07:56:47 TP6] Capture draft cuda graph end. Time elapsed: 6.64 s. mem usage=0.49 GB. avail mem=14.44 GB.
[2025-09-13 07:56:47 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.44 GB
Capturing batches (bs=1 avail_mem=14.28 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:00<00:00, 25.40it/s][2025-09-13 07:56:49 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:56:49 TP2] Registering 24 cuda graph addresses
[2025-09-13 07:56:49 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:56:49 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:56:49 TP6] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.28 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 24.55it/s]
[2025-09-13 07:56:49 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:56:49 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:56:49 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:56:49 TP1] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.20 GB. avail mem=14.24 GB.
[2025-09-13 07:56:49 TP7] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.20 GB. avail mem=14.47 GB.
[2025-09-13 07:56:49 TP4] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.20 GB. avail mem=14.24 GB.
[2025-09-13 07:56:49 TP2] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.20 GB. avail mem=14.24 GB.
[2025-09-13 07:56:49 TP3] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.20 GB. avail mem=14.24 GB.
[2025-09-13 07:56:49 TP5] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.20 GB. avail mem=14.24 GB.
[2025-09-13 07:56:49 TP6] Capture draft extend cuda graph end. Time elapsed: 1.11 s. mem usage=0.20 GB. avail mem=14.24 GB.
[2025-09-13 07:56:49 TP0] Capture draft extend cuda graph end. Time elapsed: 1.12 s. mem usage=0.20 GB. avail mem=14.28 GB.
[2025-09-13 07:56:49 TP0] max_total_num_tokens=620281, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.28 GB
[2025-09-13 07:56:49] INFO:     Started server process [387767]
[2025-09-13 07:56:49] INFO:     Waiting for application startup.
[2025-09-13 07:56:49] INFO:     Application startup complete.
[2025-09-13 07:56:49] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:56:49] INFO:     127.0.0.1:34790 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:56:50] INFO:     127.0.0.1:34804 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:56:50 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:56:50 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:56:50 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27626.08it/s]
[2025-09-13 07:56:51] INFO:     127.0.0.1:34818 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:56:51] The server is fired up and ready to roll!
[2025-09-13 07:56:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:57:00] INFO:     127.0.0.1:51120 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:57:01] INFO:     127.0.0.1:51122 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:01 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:57:02] INFO:     127.0.0.1:51132 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:02] INFO:     127.0.0.1:51148 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:02 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:57:02] INFO:     127.0.0.1:51164 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:02] INFO:     127.0.0.1:51178 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:02] INFO:     127.0.0.1:51192 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:02] INFO:     127.0.0.1:51194 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:02] INFO:     127.0.0.1:51202 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:02] INFO:     127.0.0.1:51212 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:02 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:57:03 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:57:03 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:57:03 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:57:03 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:57:03 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:57:03 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:57:03 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:57:03 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:57:03 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:57:04 TP0] Decode batch. #running-req: 8, #token: 14467, token usage: 0.02, accept len: 2.62, cuda graph: True, gen throughput (token/s): 38.42, #queue-req: 0, 
[2025-09-13 07:57:05 TP0] Decode batch. #running-req: 8, #token: 15394, token usage: 0.02, accept len: 2.90, cuda graph: True, gen throughput (token/s): 732.50, #queue-req: 0, 
[2025-09-13 07:57:06 TP0] Decode batch. #running-req: 8, #token: 16296, token usage: 0.03, accept len: 2.82, cuda graph: True, gen throughput (token/s): 712.41, #queue-req: 0, 
[2025-09-13 07:57:08 TP0] Decode batch. #running-req: 8, #token: 17281, token usage: 0.03, accept len: 3.08, cuda graph: True, gen throughput (token/s): 775.81, #queue-req: 0, 
 62%|█████████████████████████████████████████████████████████████████████████████████▉                                                 | 5/8 [00:06<00:02,  1.37it/s][2025-09-13 07:57:09 TP0] Decode batch. #running-req: 2, #token: 2170, token usage: 0.00, accept len: 3.10, cuda graph: True, gen throughput (token/s): 527.09, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.17it/s]
[2025-09-13 07:57:09] INFO:     127.0.0.1:49640 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.83      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4068      
Request throughput (req/s):              1.17      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         599.28    
Total token throughput (tok/s):          599.28    
Concurrency:                             7.39      
Accept length:                           2.91      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   6310.10   
Median E2E Latency (ms):                 6326.58   
---------------Time to First Token----------------
Mean TTFT (ms):                          623.43    
Median TTFT (ms):                        733.96    
P99 TTFT (ms):                           734.47    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           11.13     
Median ITL (ms):                         7.96      
P95 ITL (ms):                            30.61     
P99 ITL (ms):                            32.01     
Max ITL (ms):                            726.86    
==================================================
[2025-09-13 07:57:09] INFO:     127.0.0.1:49654 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:57:09] INFO:     127.0.0.1:49662 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:09 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:57:10] INFO:     127.0.0.1:49668 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:10] INFO:     127.0.0.1:49674 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:10 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:57:10] INFO:     127.0.0.1:49686 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:10] INFO:     127.0.0.1:49698 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:10] INFO:     127.0.0.1:49714 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:10] INFO:     127.0.0.1:49718 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:10] INFO:     127.0.0.1:49730 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:10] INFO:     127.0.0.1:49734 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:10 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:57:11 TP0] Decode batch. #running-req: 8, #token: 14393, token usage: 0.02, accept len: 2.61, cuda graph: True, gen throughput (token/s): 221.73, #queue-req: 0, 
[2025-09-13 07:57:13 TP0] Decode batch. #running-req: 8, #token: 15326, token usage: 0.02, accept len: 2.92, cuda graph: True, gen throughput (token/s): 740.55, #queue-req: 0, 
[2025-09-13 07:57:14 TP0] Decode batch. #running-req: 8, #token: 16224, token usage: 0.03, accept len: 2.81, cuda graph: True, gen throughput (token/s): 710.32, #queue-req: 0, 
[2025-09-13 07:57:15 TP0] Decode batch. #running-req: 8, #token: 17207, token usage: 0.03, accept len: 3.07, cuda graph: True, gen throughput (token/s): 775.72, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:05<01:15,  5.04s/it][2025-09-13 07:57:15] INFO:     127.0.0.1:49740 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:15 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:05<00:33,  2.41s/it][2025-09-13 07:57:16] INFO:     127.0.0.1:49746 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:16 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:19,  1.47s/it][2025-09-13 07:57:16] INFO:     127.0.0.1:49760 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:16 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:06<00:11,  1.01it/s][2025-09-13 07:57:17] INFO:     127.0.0.1:49774 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:17 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:06<00:08,  1.32it/s][2025-09-13 07:57:17] INFO:     127.0.0.1:49780 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:17 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:57:17 TP0] Decode batch. #running-req: 8, #token: 8396, token usage: 0.01, accept len: 3.03, cuda graph: True, gen throughput (token/s): 455.39, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:06<00:05,  1.68it/s][2025-09-13 07:57:17] INFO:     127.0.0.1:49784 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:17 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:07<00:04,  1.99it/s][2025-09-13 07:57:17] INFO:     127.0.0.1:50380 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:07<00:03,  2.42it/s][2025-09-13 07:57:18] INFO:     127.0.0.1:50396 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:57:18 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:57:19 TP0] Decode batch. #running-req: 8, #token: 14464, token usage: 0.02, accept len: 2.66, cuda graph: True, gen throughput (token/s): 489.20, #queue-req: 0, 
[2025-09-13 07:57:20 TP0] Decode batch. #running-req: 8, #token: 15365, token usage: 0.02, accept len: 2.82, cuda graph: True, gen throughput (token/s): 711.26, #queue-req: 0, 
[2025-09-13 07:57:21 TP0] Decode batch. #running-req: 8, #token: 16348, token usage: 0.03, accept len: 3.07, cuda graph: True, gen throughput (token/s): 766.80, #queue-req: 0, 
 62%|████████████████████████████████████████████████████████████████████████████████▋                                                | 10/16 [00:12<00:07,  1.25s/it][2025-09-13 07:57:23 TP0] Decode batch. #running-req: 6, #token: 11582, token usage: 0.02, accept len: 3.24, cuda graph: True, gen throughput (token/s): 787.94, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:12<00:00,  1.24it/s]
[2025-09-13 07:57:23] INFO:     127.0.0.1:50408 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  12.95     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8072      
Request throughput (req/s):              1.24      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         632.43    
Total token throughput (tok/s):          632.43    
Concurrency:                             7.72      
Accept length:                           2.92      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   6252.13   
Median E2E Latency (ms):                 6215.94   
---------------Time to First Token----------------
Mean TTFT (ms):                          222.55    
Median TTFT (ms):                        233.96    
P99 TTFT (ms):                           281.41    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           11.80     
Median ITL (ms):                         7.99      
P95 ITL (ms):                            31.54     
P99 ITL (ms):                            54.77     
Max ITL (ms):                            265.30    
==================================================
[2025-09-13 07:57:23] INFO:     127.0.0.1:50416 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=45: batch_size=8, steps=6, topk=4, num_draft_tokens=4, speed=92.24 token/s, step_time=31.64 ms
Start i=46: batch_size=8, steps=6, topk=4, num_draft_tokens=6
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 6 --speculative-eagle-topk 4 --speculative-num-draft-tokens 6 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:57:34.566000 393438 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:57:34.566000 393438 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:57:34] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=935963228, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=6, speculative_eagle_topk=4, speculative_num_draft_tokens=6, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:57:35] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:57:43.888000 393649 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:57:43.888000 393649 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:57:43.894000 393645 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:57:43.894000 393645 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:57:43.964000 393648 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:57:43.964000 393648 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:57:43.996000 393647 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:57:43.996000 393647 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:57:44.070000 393644 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:57:44.070000 393644 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:57:44.081000 393651 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:57:44.081000 393651 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
W0913 07:57:44.128000 393646 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:57:44.128000 393646 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:57:44.142000 393650 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:57:44.142000 393650 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:57:44.173000 393643 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:57:44.173000 393643 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:57:44 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:57:44 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:57:44 TP0] Init torch distributed begin.
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:57:46 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:57:49 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:57:50 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:57:50 TP0] Detected fp8 checkpoint.
[2025-09-13 07:57:51 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 25/1024 [00:00<00:04, 224.88it/s]
Loading safetensors checkpoint shards:   5% Completed | 48/1024 [00:00<00:14, 68.50it/s]
Loading safetensors checkpoint shards:   6% Completed | 60/1024 [00:00<00:15, 62.97it/s]
Loading safetensors checkpoint shards:   7% Completed | 69/1024 [00:01<00:17, 53.36it/s]
Loading safetensors checkpoint shards:   7% Completed | 76/1024 [00:01<00:17, 54.24it/s]
Loading safetensors checkpoint shards:   8% Completed | 83/1024 [00:01<00:18, 50.09it/s]
Loading safetensors checkpoint shards:   9% Completed | 89/1024 [00:01<00:20, 46.04it/s]
Loading safetensors checkpoint shards:   9% Completed | 94/1024 [00:01<00:23, 40.26it/s]
Loading safetensors checkpoint shards:  10% Completed | 99/1024 [00:01<00:22, 41.88it/s]
Loading safetensors checkpoint shards:  10% Completed | 104/1024 [00:02<00:35, 25.73it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:02<00:33, 27.58it/s]
Loading safetensors checkpoint shards:  11% Completed | 113/1024 [00:02<00:29, 30.91it/s]
Loading safetensors checkpoint shards:  12% Completed | 119/1024 [00:02<00:25, 35.18it/s]
Loading safetensors checkpoint shards:  12% Completed | 124/1024 [00:02<00:24, 36.84it/s]
Loading safetensors checkpoint shards:  13% Completed | 129/1024 [00:02<00:22, 39.48it/s]
Loading safetensors checkpoint shards:  13% Completed | 134/1024 [00:02<00:22, 39.03it/s]
Loading safetensors checkpoint shards:  14% Completed | 140/1024 [00:03<00:20, 42.84it/s]
Loading safetensors checkpoint shards:  14% Completed | 145/1024 [00:03<00:20, 42.74it/s]
Loading safetensors checkpoint shards:  15% Completed | 150/1024 [00:03<00:20, 42.94it/s]
Loading safetensors checkpoint shards:  15% Completed | 155/1024 [00:03<00:20, 41.81it/s]
Loading safetensors checkpoint shards:  16% Completed | 160/1024 [00:03<00:19, 43.32it/s]
Loading safetensors checkpoint shards:  16% Completed | 165/1024 [00:03<00:20, 41.55it/s]
Loading safetensors checkpoint shards:  17% Completed | 170/1024 [00:03<00:20, 41.44it/s]
Loading safetensors checkpoint shards:  17% Completed | 175/1024 [00:03<00:19, 42.96it/s]
Loading safetensors checkpoint shards:  18% Completed | 180/1024 [00:04<00:20, 41.14it/s]
Loading safetensors checkpoint shards:  18% Completed | 185/1024 [00:04<00:19, 42.50it/s]
Loading safetensors checkpoint shards:  19% Completed | 191/1024 [00:04<00:18, 45.52it/s]
Loading safetensors checkpoint shards:  19% Completed | 197/1024 [00:04<00:16, 49.31it/s]
Loading safetensors checkpoint shards:  20% Completed | 203/1024 [00:04<00:23, 35.50it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:04<00:20, 39.44it/s]
Loading safetensors checkpoint shards:  21% Completed | 214/1024 [00:04<00:20, 38.78it/s]
Loading safetensors checkpoint shards:  21% Completed | 220/1024 [00:04<00:18, 42.90it/s]
Loading safetensors checkpoint shards:  22% Completed | 226/1024 [00:05<00:17, 45.12it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:05<00:15, 50.67it/s]
Loading safetensors checkpoint shards:  24% Completed | 243/1024 [00:05<00:13, 58.70it/s]
Loading safetensors checkpoint shards:  25% Completed | 252/1024 [00:05<00:12, 64.10it/s]
Loading safetensors checkpoint shards:  25% Completed | 259/1024 [00:05<00:11, 64.98it/s]
Loading safetensors checkpoint shards:  26% Completed | 267/1024 [00:05<00:10, 68.97it/s]
Loading safetensors checkpoint shards:  27% Completed | 275/1024 [00:06<00:22, 32.59it/s]
Loading safetensors checkpoint shards:  27% Completed | 281/1024 [00:06<00:21, 34.04it/s]
Loading safetensors checkpoint shards:  28% Completed | 286/1024 [00:06<00:21, 34.30it/s]
Loading safetensors checkpoint shards:  28% Completed | 291/1024 [00:06<00:20, 35.03it/s]
Loading safetensors checkpoint shards:  29% Completed | 296/1024 [00:06<00:20, 35.87it/s]
Loading safetensors checkpoint shards:  29% Completed | 301/1024 [00:06<00:19, 37.18it/s]
Loading safetensors checkpoint shards:  30% Completed | 306/1024 [00:07<00:18, 38.18it/s]
Loading safetensors checkpoint shards:  30% Completed | 311/1024 [00:07<00:18, 39.43it/s]
Loading safetensors checkpoint shards:  31% Completed | 316/1024 [00:07<00:17, 39.97it/s]
Loading safetensors checkpoint shards:  31% Completed | 321/1024 [00:07<00:18, 38.02it/s]
Loading safetensors checkpoint shards:  32% Completed | 327/1024 [00:07<00:16, 41.53it/s]
Loading safetensors checkpoint shards:  32% Completed | 332/1024 [00:07<00:16, 41.89it/s]
Loading safetensors checkpoint shards:  33% Completed | 337/1024 [00:07<00:16, 41.94it/s]
Loading safetensors checkpoint shards:  33% Completed | 342/1024 [00:07<00:16, 40.32it/s]
Loading safetensors checkpoint shards:  34% Completed | 347/1024 [00:08<00:17, 37.93it/s]
Loading safetensors checkpoint shards:  34% Completed | 352/1024 [00:08<00:17, 38.92it/s]
Loading safetensors checkpoint shards:  35% Completed | 356/1024 [00:08<00:17, 37.87it/s]
Loading safetensors checkpoint shards:  35% Completed | 361/1024 [00:08<00:16, 40.62it/s]
Loading safetensors checkpoint shards:  36% Completed | 366/1024 [00:08<00:17, 36.95it/s]
Loading safetensors checkpoint shards:  36% Completed | 370/1024 [00:08<00:18, 36.07it/s]
Loading safetensors checkpoint shards:  37% Completed | 375/1024 [00:08<00:17, 37.79it/s]
Loading safetensors checkpoint shards:  37% Completed | 379/1024 [00:08<00:17, 37.84it/s]
Loading safetensors checkpoint shards:  37% Completed | 383/1024 [00:08<00:16, 38.01it/s]
Loading safetensors checkpoint shards:  38% Completed | 387/1024 [00:09<00:17, 37.44it/s]
Loading safetensors checkpoint shards:  38% Completed | 391/1024 [00:09<00:17, 35.30it/s]
Loading safetensors checkpoint shards:  39% Completed | 395/1024 [00:09<00:17, 35.09it/s]
Loading safetensors checkpoint shards:  39% Completed | 399/1024 [00:09<00:20, 31.05it/s]
Loading safetensors checkpoint shards:  39% Completed | 403/1024 [00:09<00:24, 25.48it/s]
Loading safetensors checkpoint shards:  40% Completed | 407/1024 [00:09<00:22, 26.93it/s]
Loading safetensors checkpoint shards:  40% Completed | 410/1024 [00:09<00:22, 27.02it/s]
Loading safetensors checkpoint shards:  40% Completed | 413/1024 [00:10<00:26, 23.44it/s]
Loading safetensors checkpoint shards:  41% Completed | 416/1024 [00:10<00:24, 24.81it/s]
Loading safetensors checkpoint shards:  41% Completed | 420/1024 [00:10<00:22, 26.87it/s]
Loading safetensors checkpoint shards:  41% Completed | 424/1024 [00:10<00:20, 29.25it/s]
Loading safetensors checkpoint shards:  42% Completed | 429/1024 [00:10<00:18, 32.92it/s]
Loading safetensors checkpoint shards:  42% Completed | 433/1024 [00:10<00:17, 32.98it/s]
Loading safetensors checkpoint shards:  43% Completed | 438/1024 [00:10<00:16, 35.65it/s]
Loading safetensors checkpoint shards:  43% Completed | 442/1024 [00:10<00:16, 36.16it/s]
Loading safetensors checkpoint shards:  44% Completed | 446/1024 [00:11<00:15, 36.57it/s]
Loading safetensors checkpoint shards:  44% Completed | 450/1024 [00:11<00:15, 36.72it/s]
Loading safetensors checkpoint shards:  44% Completed | 454/1024 [00:11<00:33, 16.80it/s]
Loading safetensors checkpoint shards:  45% Completed | 458/1024 [00:11<00:28, 20.11it/s]
Loading safetensors checkpoint shards:  45% Completed | 463/1024 [00:11<00:23, 24.01it/s]
Loading safetensors checkpoint shards:  46% Completed | 467/1024 [00:12<00:20, 26.85it/s]
Loading safetensors checkpoint shards:  46% Completed | 474/1024 [00:12<00:16, 34.33it/s]
Loading safetensors checkpoint shards:  47% Completed | 479/1024 [00:12<00:15, 34.78it/s]
Loading safetensors checkpoint shards:  47% Completed | 484/1024 [00:12<00:14, 37.04it/s]
Loading safetensors checkpoint shards:  48% Completed | 489/1024 [00:12<00:14, 36.17it/s]
Loading safetensors checkpoint shards:  48% Completed | 494/1024 [00:12<00:13, 38.43it/s]
Loading safetensors checkpoint shards:  49% Completed | 499/1024 [00:12<00:13, 39.12it/s]
Loading safetensors checkpoint shards:  49% Completed | 504/1024 [00:12<00:12, 40.99it/s]
Loading safetensors checkpoint shards:  50% Completed | 509/1024 [00:13<00:12, 41.07it/s]
Loading safetensors checkpoint shards:  50% Completed | 514/1024 [00:13<00:12, 40.34it/s]
Loading safetensors checkpoint shards:  51% Completed | 519/1024 [00:13<00:12, 41.20it/s]
Loading safetensors checkpoint shards:  51% Completed | 524/1024 [00:13<00:12, 39.05it/s]
Loading safetensors checkpoint shards:  52% Completed | 529/1024 [00:13<00:12, 40.82it/s]
Loading safetensors checkpoint shards:  52% Completed | 534/1024 [00:13<00:12, 39.32it/s]
Loading safetensors checkpoint shards:  53% Completed | 539/1024 [00:13<00:11, 41.08it/s]
Loading safetensors checkpoint shards:  53% Completed | 544/1024 [00:13<00:11, 40.17it/s]
Loading safetensors checkpoint shards:  54% Completed | 549/1024 [00:14<00:11, 41.16it/s]
Loading safetensors checkpoint shards:  54% Completed | 554/1024 [00:14<00:11, 39.84it/s]
Loading safetensors checkpoint shards:  55% Completed | 559/1024 [00:14<00:11, 39.53it/s]
Loading safetensors checkpoint shards:  55% Completed | 563/1024 [00:14<00:11, 39.38it/s]
Loading safetensors checkpoint shards:  55% Completed | 568/1024 [00:14<00:11, 39.97it/s]
Loading safetensors checkpoint shards:  56% Completed | 573/1024 [00:14<00:10, 41.99it/s]
Loading safetensors checkpoint shards:  56% Completed | 578/1024 [00:14<00:11, 40.44it/s]
Loading safetensors checkpoint shards:  57% Completed | 584/1024 [00:14<00:09, 44.73it/s]
Loading safetensors checkpoint shards:  58% Completed | 589/1024 [00:14<00:09, 44.47it/s]
Loading safetensors checkpoint shards:  58% Completed | 594/1024 [00:15<00:09, 44.52it/s]
Loading safetensors checkpoint shards:  58% Completed | 599/1024 [00:15<00:09, 42.74it/s]
Loading safetensors checkpoint shards:  59% Completed | 604/1024 [00:15<00:09, 43.10it/s]
Loading safetensors checkpoint shards:  59% Completed | 609/1024 [00:15<00:10, 40.29it/s]
Loading safetensors checkpoint shards:  60% Completed | 614/1024 [00:15<00:10, 39.63it/s]
Loading safetensors checkpoint shards:  60% Completed | 619/1024 [00:15<00:09, 40.64it/s]
Loading safetensors checkpoint shards:  61% Completed | 624/1024 [00:15<00:10, 39.45it/s]
Loading safetensors checkpoint shards:  61% Completed | 628/1024 [00:15<00:10, 38.50it/s]
Loading safetensors checkpoint shards:  62% Completed | 632/1024 [00:16<00:10, 36.81it/s]
Loading safetensors checkpoint shards:  62% Completed | 636/1024 [00:16<00:10, 36.95it/s]
Loading safetensors checkpoint shards:  62% Completed | 640/1024 [00:16<00:10, 36.58it/s]
Loading safetensors checkpoint shards:  63% Completed | 644/1024 [00:16<00:10, 36.33it/s]
Loading safetensors checkpoint shards:  63% Completed | 648/1024 [00:16<00:10, 35.04it/s]
Loading safetensors checkpoint shards:  64% Completed | 652/1024 [00:16<00:10, 34.70it/s]
Loading safetensors checkpoint shards:  64% Completed | 656/1024 [00:16<00:10, 35.58it/s]
Loading safetensors checkpoint shards:  64% Completed | 660/1024 [00:16<00:10, 35.33it/s]
Loading safetensors checkpoint shards:  65% Completed | 664/1024 [00:16<00:10, 34.73it/s]
Loading safetensors checkpoint shards:  65% Completed | 668/1024 [00:17<00:10, 35.03it/s]
Loading safetensors checkpoint shards:  66% Completed | 672/1024 [00:17<00:09, 35.71it/s]
Loading safetensors checkpoint shards:  66% Completed | 676/1024 [00:17<00:09, 35.81it/s]
Loading safetensors checkpoint shards:  66% Completed | 680/1024 [00:17<00:09, 36.77it/s]
Loading safetensors checkpoint shards:  67% Completed | 684/1024 [00:17<00:09, 37.23it/s]
Loading safetensors checkpoint shards:  67% Completed | 688/1024 [00:17<00:08, 38.01it/s]
Loading safetensors checkpoint shards:  68% Completed | 693/1024 [00:17<00:08, 40.81it/s]
Loading safetensors checkpoint shards:  68% Completed | 698/1024 [00:17<00:08, 40.51it/s]
Loading safetensors checkpoint shards:  69% Completed | 703/1024 [00:18<00:08, 38.72it/s]
Loading safetensors checkpoint shards:  69% Completed | 707/1024 [00:18<00:08, 38.33it/s]
Loading safetensors checkpoint shards:  69% Completed | 711/1024 [00:18<00:08, 38.24it/s]
Loading safetensors checkpoint shards:  70% Completed | 715/1024 [00:18<00:08, 38.08it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:18<00:08, 37.33it/s]
Loading safetensors checkpoint shards:  71% Completed | 723/1024 [00:18<00:08, 37.28it/s]
Loading safetensors checkpoint shards:  71% Completed | 727/1024 [00:18<00:07, 37.49it/s]
Loading safetensors checkpoint shards:  71% Completed | 731/1024 [00:18<00:07, 37.35it/s]
Loading safetensors checkpoint shards:  72% Completed | 735/1024 [00:19<00:17, 16.30it/s]
Loading safetensors checkpoint shards:  72% Completed | 739/1024 [00:19<00:14, 19.33it/s]
Loading safetensors checkpoint shards:  73% Completed | 743/1024 [00:19<00:12, 22.14it/s]
Loading safetensors checkpoint shards:  73% Completed | 747/1024 [00:19<00:11, 24.26it/s]
Loading safetensors checkpoint shards:  73% Completed | 751/1024 [00:19<00:10, 26.31it/s]
Loading safetensors checkpoint shards:  74% Completed | 755/1024 [00:19<00:09, 28.41it/s]
Loading safetensors checkpoint shards:  74% Completed | 759/1024 [00:20<00:08, 30.76it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:20<00:07, 32.81it/s]
Loading safetensors checkpoint shards:  75% Completed | 768/1024 [00:20<00:07, 35.12it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:20<00:07, 35.06it/s]
Loading safetensors checkpoint shards:  76% Completed | 776/1024 [00:20<00:06, 36.02it/s]
Loading safetensors checkpoint shards:  76% Completed | 780/1024 [00:20<00:06, 35.92it/s]
Loading safetensors checkpoint shards:  77% Completed | 784/1024 [00:20<00:06, 36.55it/s]
Loading safetensors checkpoint shards:  77% Completed | 788/1024 [00:20<00:06, 36.09it/s]
Loading safetensors checkpoint shards:  77% Completed | 792/1024 [00:20<00:06, 36.74it/s]
Loading safetensors checkpoint shards:  78% Completed | 796/1024 [00:21<00:06, 37.10it/s]
Loading safetensors checkpoint shards:  78% Completed | 800/1024 [00:21<00:05, 37.63it/s]
Loading safetensors checkpoint shards:  79% Completed | 805/1024 [00:21<00:05, 38.99it/s]
Loading safetensors checkpoint shards:  79% Completed | 809/1024 [00:21<00:05, 39.13it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:21<00:05, 38.68it/s]
Loading safetensors checkpoint shards:  80% Completed | 817/1024 [00:21<00:05, 37.46it/s]
Loading safetensors checkpoint shards:  80% Completed | 821/1024 [00:21<00:05, 36.74it/s]
Loading safetensors checkpoint shards:  81% Completed | 825/1024 [00:21<00:05, 36.77it/s]
Loading safetensors checkpoint shards:  81% Completed | 829/1024 [00:21<00:05, 36.35it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:22<00:05, 36.13it/s]
Loading safetensors checkpoint shards:  82% Completed | 837/1024 [00:22<00:05, 35.74it/s]
Loading safetensors checkpoint shards:  82% Completed | 841/1024 [00:22<00:05, 35.74it/s]
Loading safetensors checkpoint shards:  83% Completed | 845/1024 [00:22<00:05, 34.81it/s]
Loading safetensors checkpoint shards:  83% Completed | 849/1024 [00:22<00:05, 34.72it/s]
Loading safetensors checkpoint shards:  83% Completed | 853/1024 [00:22<00:04, 35.11it/s]
Loading safetensors checkpoint shards:  84% Completed | 857/1024 [00:22<00:04, 35.35it/s]
Loading safetensors checkpoint shards:  84% Completed | 861/1024 [00:22<00:04, 35.12it/s]
Loading safetensors checkpoint shards:  84% Completed | 865/1024 [00:22<00:04, 35.60it/s]
Loading safetensors checkpoint shards:  85% Completed | 869/1024 [00:23<00:04, 35.31it/s]
Loading safetensors checkpoint shards:  85% Completed | 873/1024 [00:23<00:04, 34.88it/s]
Loading safetensors checkpoint shards:  86% Completed | 877/1024 [00:23<00:04, 34.12it/s]
Loading safetensors checkpoint shards:  86% Completed | 881/1024 [00:23<00:04, 34.56it/s]
Loading safetensors checkpoint shards:  86% Completed | 885/1024 [00:23<00:03, 35.47it/s]
Loading safetensors checkpoint shards:  87% Completed | 889/1024 [00:23<00:03, 34.63it/s]
Loading safetensors checkpoint shards:  87% Completed | 893/1024 [00:23<00:03, 35.15it/s]
Loading safetensors checkpoint shards:  88% Completed | 897/1024 [00:23<00:03, 35.57it/s]
Loading safetensors checkpoint shards:  88% Completed | 901/1024 [00:23<00:03, 36.63it/s]
Loading safetensors checkpoint shards:  88% Completed | 905/1024 [00:24<00:03, 36.82it/s]
Loading safetensors checkpoint shards:  89% Completed | 909/1024 [00:24<00:03, 37.31it/s]
Loading safetensors checkpoint shards:  89% Completed | 913/1024 [00:24<00:03, 36.90it/s]
Loading safetensors checkpoint shards:  90% Completed | 918/1024 [00:24<00:02, 39.92it/s]
Loading safetensors checkpoint shards:  90% Completed | 923/1024 [00:24<00:02, 39.92it/s]
Loading safetensors checkpoint shards:  91% Completed | 928/1024 [00:24<00:02, 40.18it/s]
Loading safetensors checkpoint shards:  91% Completed | 933/1024 [00:24<00:02, 38.48it/s]
Loading safetensors checkpoint shards:  92% Completed | 937/1024 [00:24<00:02, 38.38it/s]
Loading safetensors checkpoint shards:  92% Completed | 941/1024 [00:24<00:02, 37.77it/s]
Loading safetensors checkpoint shards:  92% Completed | 945/1024 [00:25<00:02, 36.50it/s]
Loading safetensors checkpoint shards:  93% Completed | 949/1024 [00:25<00:02, 36.74it/s]
Loading safetensors checkpoint shards:  93% Completed | 953/1024 [00:25<00:01, 37.42it/s]
Loading safetensors checkpoint shards:  93% Completed | 957/1024 [00:25<00:01, 38.01it/s]
Loading safetensors checkpoint shards:  94% Completed | 961/1024 [00:25<00:01, 37.23it/s]
Loading safetensors checkpoint shards:  94% Completed | 965/1024 [00:25<00:01, 37.70it/s]
Loading safetensors checkpoint shards:  95% Completed | 970/1024 [00:25<00:01, 37.58it/s]
Loading safetensors checkpoint shards:  95% Completed | 974/1024 [00:25<00:01, 38.04it/s]
Loading safetensors checkpoint shards:  96% Completed | 978/1024 [00:25<00:01, 37.68it/s]
Loading safetensors checkpoint shards:  96% Completed | 986/1024 [00:26<00:00, 49.38it/s]
Loading safetensors checkpoint shards:  98% Completed | 1001/1024 [00:26<00:00, 76.55it/s]
Loading safetensors checkpoint shards:  99% Completed | 1009/1024 [00:26<00:00, 76.49it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:26<00:00, 38.84it/s]

[2025-09-13 07:58:18 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 07:58:19 TP2] KV Cache is allocated. #tokens: 620297, KV size: 40.60 GB
[2025-09-13 07:58:19 TP5] KV Cache is allocated. #tokens: 620297, KV size: 40.60 GB
[2025-09-13 07:58:19 TP3] KV Cache is allocated. #tokens: 620297, KV size: 40.60 GB
[2025-09-13 07:58:19 TP0] KV Cache is allocated. #tokens: 620297, KV size: 40.60 GB
[2025-09-13 07:58:19 TP4] KV Cache is allocated. #tokens: 620297, KV size: 40.60 GB
[2025-09-13 07:58:19 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 07:58:19 TP1] KV Cache is allocated. #tokens: 620297, KV size: 40.60 GB
[2025-09-13 07:58:19 TP7] KV Cache is allocated. #tokens: 620297, KV size: 40.60 GB
[2025-09-13 07:58:19 TP6] KV Cache is allocated. #tokens: 620297, KV size: 40.60 GB
[2025-09-13 07:58:19 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 07:58:19 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.52 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 07:58:20 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:58:20 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 

Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                                             Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
                                                                                                                                                                     [2025-09-13 07:58:20 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:58:20 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:58:20 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:58:20 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:58:20 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 07:58:20 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 07:58:21 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25255.37it/s]
[2025-09-13 07:58:21 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:58:21 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26302.34it/s]
[2025-09-13 07:58:22 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:58:22 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28022.56it/s]
[2025-09-13 07:58:22 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:58:22 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27830.74it/s]
[2025-09-13 07:58:23 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:58:23 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 29144.88it/s]
[2025-09-13 07:58:23 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.23 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.13it/s]
[2025-09-13 07:58:27 TP3] Registering 984 cuda graph addresses
[2025-09-13 07:58:27 TP2] Registering 984 cuda graph addresses
[2025-09-13 07:58:27 TP5] Registering 984 cuda graph addresses
[2025-09-13 07:58:27 TP0] Registering 984 cuda graph addresses
[2025-09-13 07:58:27 TP1] Registering 984 cuda graph addresses
[2025-09-13 07:58:27 TP7] Registering 984 cuda graph addresses
[2025-09-13 07:58:27 TP6] Registering 984 cuda graph addresses
[2025-09-13 07:58:27 TP4] Registering 984 cuda graph addresses
[2025-09-13 07:58:27 TP0] Capture cuda graph end. Time elapsed: 7.79 s. mem usage=0.35 GB. avail mem=17.21 GB.
[2025-09-13 07:58:27 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 07:58:27 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:58:27 TP0] Init torch distributed begin.
[2025-09-13 07:58:27 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 07:58:27 TP0] Load weight begin. avail mem=17.21 GB
[2025-09-13 07:58:27 TP0] Detected fp8 checkpoint.
[2025-09-13 07:58:27 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 177.57it/s]
Loading safetensors checkpoint shards:   4% Completed | 45/1024 [00:00<00:04, 229.44it/s]
Loading safetensors checkpoint shards:  10% Completed | 105/1024 [00:00<00:02, 394.81it/s]
Loading safetensors checkpoint shards:  16% Completed | 165/1024 [00:00<00:01, 473.24it/s]
Loading safetensors checkpoint shards:  22% Completed | 224/1024 [00:00<00:01, 513.70it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:00<00:01, 543.73it/s]
Loading safetensors checkpoint shards:  34% Completed | 344/1024 [00:00<00:01, 557.96it/s]
Loading safetensors checkpoint shards:  40% Completed | 405/1024 [00:00<00:01, 572.18it/s]
Loading safetensors checkpoint shards:  46% Completed | 466/1024 [00:00<00:00, 581.56it/s]
Loading safetensors checkpoint shards:  52% Completed | 528/1024 [00:01<00:00, 592.66it/s]
Loading safetensors checkpoint shards:  57% Completed | 588/1024 [00:01<00:00, 592.86it/s]
Loading safetensors checkpoint shards:  63% Completed | 648/1024 [00:01<00:00, 584.86it/s]
Loading safetensors checkpoint shards:  69% Completed | 707/1024 [00:01<00:00, 574.73it/s]
Loading safetensors checkpoint shards:  75% Completed | 765/1024 [00:01<00:00, 565.96it/s]
Loading safetensors checkpoint shards:  80% Completed | 822/1024 [00:01<00:00, 563.29it/s]
Loading safetensors checkpoint shards:  86% Completed | 879/1024 [00:01<00:00, 562.80it/s]
Loading safetensors checkpoint shards:  91% Completed | 936/1024 [00:01<00:00, 561.17it/s]
Loading safetensors checkpoint shards:  97% Completed | 993/1024 [00:01<00:00, 484.88it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 498.69it/s]

[2025-09-13 07:58:29 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.22 GB, mem usage=1.99 GB.
[2025-09-13 07:58:29 TP5] KV Cache is allocated. #tokens: 620297, KV size: 0.67 GB
[2025-09-13 07:58:29 TP0] KV Cache is allocated. #tokens: 620297, KV size: 0.67 GB
[2025-09-13 07:58:29 TP0] Memory pool end. avail mem=14.55 GB
[2025-09-13 07:58:29 TP7] KV Cache is allocated. #tokens: 620297, KV size: 0.67 GB
[2025-09-13 07:58:29 TP6] KV Cache is allocated. #tokens: 620297, KV size: 0.67 GB
[2025-09-13 07:58:29 TP4] KV Cache is allocated. #tokens: 620297, KV size: 0.67 GB
[2025-09-13 07:58:29 TP2] KV Cache is allocated. #tokens: 620297, KV size: 0.67 GB
[2025-09-13 07:58:29 TP3] KV Cache is allocated. #tokens: 620297, KV size: 0.67 GB
[2025-09-13 07:58:29 TP1] KV Cache is allocated. #tokens: 620297, KV size: 0.67 GB
[2025-09-13 07:58:30 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:58:30 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:58:30 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:58:30 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:58:30 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.99 GB
[2025-09-13 07:58:30 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:58:30 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.94 GB
[2025-09-13 07:58:30 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.18 GB
Capturing batches (bs=1 avail_mem=14.50 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.42it/s]
[2025-09-13 07:58:36 TP3] Registering 120 cuda graph addresses
[2025-09-13 07:58:36 TP2] Registering 120 cuda graph addresses
[2025-09-13 07:58:36 TP0] Registering 120 cuda graph addresses
[2025-09-13 07:58:36 TP1] Registering 120 cuda graph addresses
[2025-09-13 07:58:36 TP5] Registering 120 cuda graph addresses
[2025-09-13 07:58:36 TP7] Registering 120 cuda graph addresses
[2025-09-13 07:58:36 TP6] Registering 120 cuda graph addresses
[2025-09-13 07:58:36 TP4] Registering 120 cuda graph addresses
[2025-09-13 07:58:36 TP1] Capture draft cuda graph end. Time elapsed: 6.39 s. mem usage=0.49 GB. avail mem=14.45 GB.
[2025-09-13 07:58:36 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.45 GB
[2025-09-13 07:58:36 TP7] Capture draft cuda graph end. Time elapsed: 6.39 s. mem usage=0.49 GB. avail mem=14.69 GB.
[2025-09-13 07:58:36 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.69 GB
[2025-09-13 07:58:36 TP3] Capture draft cuda graph end. Time elapsed: 6.40 s. mem usage=0.49 GB. avail mem=14.45 GB.
[2025-09-13 07:58:36 TP5] Capture draft cuda graph end. Time elapsed: 6.40 s. mem usage=0.49 GB. avail mem=14.45 GB.
[2025-09-13 07:58:36 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.45 GB
[2025-09-13 07:58:36 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.45 GB
[2025-09-13 07:58:36 TP0] Capture draft cuda graph end. Time elapsed: 6.40 s. mem usage=0.49 GB. avail mem=14.49 GB.
[2025-09-13 07:58:36 TP4] Capture draft cuda graph end. Time elapsed: 6.40 s. mem usage=0.49 GB. avail mem=14.45 GB.
[2025-09-13 07:58:36 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.49 GB
[2025-09-13 07:58:36 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.45 GB
[2025-09-13 07:58:36 TP6] Capture draft cuda graph end. Time elapsed: 6.40 s. mem usage=0.49 GB. avail mem=14.45 GB.
[2025-09-13 07:58:36 TP2] Capture draft cuda graph end. Time elapsed: 6.40 s. mem usage=0.49 GB. avail mem=14.45 GB.
[2025-09-13 07:58:36 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.45 GB
[2025-09-13 07:58:36 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.45 GB
Capturing batches (bs=1 avail_mem=14.29 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:00<00:00, 17.99it/s][2025-09-13 07:58:37 TP3] Registering 24 cuda graph addresses
[2025-09-13 07:58:37 TP2] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.29 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 17.39it/s]
[2025-09-13 07:58:37 TP5] Registering 24 cuda graph addresses
[2025-09-13 07:58:37 TP0] Registering 24 cuda graph addresses
[2025-09-13 07:58:37 TP1] Registering 24 cuda graph addresses
[2025-09-13 07:58:37 TP7] Registering 24 cuda graph addresses
[2025-09-13 07:58:37 TP4] Registering 24 cuda graph addresses
[2025-09-13 07:58:37 TP6] Registering 24 cuda graph addresses
[2025-09-13 07:58:37 TP7] Capture draft extend cuda graph end. Time elapsed: 1.18 s. mem usage=0.20 GB. avail mem=14.48 GB.
[2025-09-13 07:58:37 TP1] Capture draft extend cuda graph end. Time elapsed: 1.19 s. mem usage=0.20 GB. avail mem=14.25 GB.
[2025-09-13 07:58:37 TP2] Capture draft extend cuda graph end. Time elapsed: 1.18 s. mem usage=0.20 GB. avail mem=14.25 GB.
[2025-09-13 07:58:37 TP3] Capture draft extend cuda graph end. Time elapsed: 1.19 s. mem usage=0.20 GB. avail mem=14.25 GB.
[2025-09-13 07:58:37 TP4] Capture draft extend cuda graph end. Time elapsed: 1.19 s. mem usage=0.20 GB. avail mem=14.25 GB.
[2025-09-13 07:58:37 TP6] Capture draft extend cuda graph end. Time elapsed: 1.19 s. mem usage=0.20 GB. avail mem=14.25 GB.
[2025-09-13 07:58:37 TP0] Capture draft extend cuda graph end. Time elapsed: 1.19 s. mem usage=0.20 GB. avail mem=14.29 GB.
[2025-09-13 07:58:37 TP5] Capture draft extend cuda graph end. Time elapsed: 1.19 s. mem usage=0.20 GB. avail mem=14.25 GB.
[2025-09-13 07:58:37 TP0] max_total_num_tokens=620297, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.29 GB
[2025-09-13 07:58:38] INFO:     Started server process [393438]
[2025-09-13 07:58:38] INFO:     Waiting for application startup.
[2025-09-13 07:58:38] INFO:     Application startup complete.
[2025-09-13 07:58:38] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 07:58:38] INFO:     127.0.0.1:53800 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 07:58:39] INFO:     127.0.0.1:53808 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 07:58:39 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:58:39 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 07:58:39 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28847.28it/s]
[2025-09-13 07:58:40] INFO:     127.0.0.1:53820 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:40] The server is fired up and ready to roll!
[2025-09-13 07:58:48 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:58:49] INFO:     127.0.0.1:51134 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:58:50] INFO:     127.0.0.1:51140 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:50 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 07:58:51] INFO:     127.0.0.1:51142 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:51] INFO:     127.0.0.1:51148 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:58:51] INFO:     127.0.0.1:51156 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:51] INFO:     127.0.0.1:51164 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:51] INFO:     127.0.0.1:51180 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:51] INFO:     127.0.0.1:51196 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:51] INFO:     127.0.0.1:51206 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:51] INFO:     127.0.0.1:51208 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:51 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 07:58:52 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:58:52 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:58:52 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:58:52 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:58:52 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:58:52 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:58:52 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:58:52 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 07:58:52 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 07:58:53 TP0] Decode batch. #running-req: 8, #token: 14538, token usage: 0.02, accept len: 2.93, cuda graph: True, gen throughput (token/s): 41.78, #queue-req: 0, 
[2025-09-13 07:58:54 TP0] Decode batch. #running-req: 8, #token: 15644, token usage: 0.03, accept len: 3.46, cuda graph: True, gen throughput (token/s): 835.90, #queue-req: 0, 
[2025-09-13 07:58:56 TP0] Decode batch. #running-req: 8, #token: 16843, token usage: 0.03, accept len: 3.75, cuda graph: True, gen throughput (token/s): 890.51, #queue-req: 0, 
 38%|█████████████████████████████████████████████████▏                                                                                 | 3/8 [00:05<00:07,  1.49s/it][2025-09-13 07:58:57 TP0] Decode batch. #running-req: 4, #token: 7064, token usage: 0.01, accept len: 3.68, cuda graph: True, gen throughput (token/s): 696.72, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.23it/s]
[2025-09-13 07:58:58] INFO:     127.0.0.1:41682 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.49      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4085      
Request throughput (req/s):              1.23      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         630.99    
Total token throughput (tok/s):          630.99    
Concurrency:                             6.95      
Accept length:                           3.49      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5635.80   
Median E2E Latency (ms):                 5659.47   
---------------Time to First Token----------------
Mean TTFT (ms):                          621.20    
Median TTFT (ms):                        734.14    
P99 TTFT (ms):                           734.80    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.81      
Median ITL (ms):                         6.79      
P95 ITL (ms):                            27.63     
P99 ITL (ms):                            33.84     
Max ITL (ms):                            738.15    
==================================================
[2025-09-13 07:58:58] INFO:     127.0.0.1:41686 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 07:58:58] INFO:     127.0.0.1:41694 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:58 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:58:58 TP0] Decode batch. #running-req: 1, #token: 4688, token usage: 0.01, accept len: 3.40, cuda graph: True, gen throughput (token/s): 177.10, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 07:58:59] INFO:     127.0.0.1:41700 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:59] INFO:     127.0.0.1:41716 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 07:58:59] INFO:     127.0.0.1:41722 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:59] INFO:     127.0.0.1:41734 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:59] INFO:     127.0.0.1:41744 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:59] INFO:     127.0.0.1:41754 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:59] INFO:     127.0.0.1:41756 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:59] INFO:     127.0.0.1:41766 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:58:59 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 07:59:01 TP0] Decode batch. #running-req: 8, #token: 14845, token usage: 0.02, accept len: 3.13, cuda graph: True, gen throughput (token/s): 374.11, #queue-req: 0, 
[2025-09-13 07:59:02 TP0] Decode batch. #running-req: 8, #token: 15933, token usage: 0.03, accept len: 3.40, cuda graph: True, gen throughput (token/s): 820.57, #queue-req: 0, 
[2025-09-13 07:59:03 TP0] Decode batch. #running-req: 8, #token: 17067, token usage: 0.03, accept len: 3.54, cuda graph: True, gen throughput (token/s): 849.83, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:03,  4.24s/it][2025-09-13 07:59:03] INFO:     127.0.0.1:41780 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:59:03 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:27,  1.95s/it][2025-09-13 07:59:04] INFO:     127.0.0.1:41782 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:59:04 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:17,  1.38s/it][2025-09-13 07:59:04] INFO:     127.0.0.1:41784 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:59:04 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:11,  1.05it/s][2025-09-13 07:59:05] INFO:     127.0.0.1:41796 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:59:05 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:08,  1.37it/s][2025-09-13 07:59:05] INFO:     127.0.0.1:41804 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:59:05 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:59:05 TP0] Decode batch. #running-req: 8, #token: 8466, token usage: 0.01, accept len: 3.68, cuda graph: True, gen throughput (token/s): 529.33, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:06<00:06,  1.64it/s][2025-09-13 07:59:05] INFO:     127.0.0.1:41810 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:59:05 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:04,  1.98it/s][2025-09-13 07:59:06] INFO:     127.0.0.1:41824 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:59:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:07<00:04,  1.89it/s][2025-09-13 07:59:06] INFO:     127.0.0.1:41830 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 07:59:06 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 07:59:07 TP0] Decode batch. #running-req: 8, #token: 14676, token usage: 0.02, accept len: 3.11, cuda graph: True, gen throughput (token/s): 551.24, #queue-req: 0, 
[2025-09-13 07:59:09 TP0] Decode batch. #running-req: 8, #token: 15846, token usage: 0.03, accept len: 3.66, cuda graph: True, gen throughput (token/s): 879.20, #queue-req: 0, 
 62%|████████████████████████████████████████████████████████████████████████████████▋                                                | 10/16 [00:10<00:06,  1.03s/it][2025-09-13 07:59:10 TP0] Decode batch. #running-req: 5, #token: 10154, token usage: 0.02, accept len: 4.58, cuda graph: True, gen throughput (token/s): 1034.35, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.39it/s]
[2025-09-13 07:59:11] INFO:     127.0.0.1:59588 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.48     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8131      
Request throughput (req/s):              1.39      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         713.29    
Total token throughput (tok/s):          713.29    
Concurrency:                             7.58      
Accept length:                           3.55      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5441.49   
Median E2E Latency (ms):                 5432.58   
---------------Time to First Token----------------
Mean TTFT (ms):                          225.97    
Median TTFT (ms):                        247.39    
P99 TTFT (ms):                           281.37    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.21     
Median ITL (ms):                         6.67      
P95 ITL (ms):                            32.56     
P99 ITL (ms):                            53.65     
Max ITL (ms):                            268.24    
==================================================
[2025-09-13 07:59:11] INFO:     127.0.0.1:59592 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=46: batch_size=8, steps=6, topk=4, num_draft_tokens=6, speed=106.73 token/s, step_time=33.22 ms
Start i=47: batch_size=8, steps=6, topk=4, num_draft_tokens=8
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 6 --speculative-eagle-topk 4 --speculative-num-draft-tokens 8 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:59:21.846000 399121 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:59:21.846000 399121 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 07:59:22] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=876007869, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=6, speculative_eagle_topk=4, speculative_num_draft_tokens=8, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:59:22] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 07:59:31.042000 399351 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:59:31.042000 399351 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:59:31.246000 399349 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:59:31.246000 399349 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:59:31.330000 399354 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:59:31.330000 399354 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:59:31.443000 399350 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:59:31.443000 399350 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 07:59:31.466000 399356 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:59:31.466000 399356 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:59:31.466000 399352 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:59:31.466000 399352 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 07:59:31.529000 399348 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:59:31.529000 399348 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 07:59:31.572000 399355 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:59:31.572000 399355 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 07:59:31.583000 399353 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 07:59:31.583000 399353 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 07:59:32 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 07:59:32 TP0] Chunked prefix cache is turned on.
[2025-09-13 07:59:32 TP0] Init torch distributed begin.
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:59:33 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 07:59:36 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 07:59:38 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 07:59:38 TP0] Detected fp8 checkpoint.
[2025-09-13 07:59:38 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 26/1024 [00:00<00:04, 237.20it/s]
Loading safetensors checkpoint shards:   5% Completed | 50/1024 [00:00<00:16, 58.67it/s]
Loading safetensors checkpoint shards:   6% Completed | 62/1024 [00:01<00:18, 51.49it/s]
Loading safetensors checkpoint shards:   7% Completed | 71/1024 [00:01<00:18, 50.48it/s]
Loading safetensors checkpoint shards:   8% Completed | 78/1024 [00:01<00:19, 47.83it/s]
Loading safetensors checkpoint shards:   8% Completed | 84/1024 [00:01<00:19, 48.35it/s]
Loading safetensors checkpoint shards:   9% Completed | 90/1024 [00:01<00:19, 47.58it/s]
Loading safetensors checkpoint shards:   9% Completed | 96/1024 [00:01<00:20, 44.76it/s]
Loading safetensors checkpoint shards:  10% Completed | 101/1024 [00:01<00:20, 43.99it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:02<00:20, 45.61it/s]
Loading safetensors checkpoint shards:  11% Completed | 112/1024 [00:02<00:20, 44.81it/s]
Loading safetensors checkpoint shards:  12% Completed | 118/1024 [00:02<00:19, 47.41it/s]
Loading safetensors checkpoint shards:  12% Completed | 123/1024 [00:02<00:34, 25.79it/s]
Loading safetensors checkpoint shards:  12% Completed | 128/1024 [00:02<00:30, 29.67it/s]
Loading safetensors checkpoint shards:  13% Completed | 133/1024 [00:02<00:28, 31.47it/s]
Loading safetensors checkpoint shards:  14% Completed | 139/1024 [00:03<00:24, 36.62it/s]
Loading safetensors checkpoint shards:  14% Completed | 144/1024 [00:03<00:22, 38.33it/s]
Loading safetensors checkpoint shards:  15% Completed | 149/1024 [00:03<00:21, 40.20it/s]
Loading safetensors checkpoint shards:  15% Completed | 154/1024 [00:03<00:21, 40.59it/s]
Loading safetensors checkpoint shards:  16% Completed | 159/1024 [00:03<00:20, 41.85it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:03<00:20, 42.78it/s]
Loading safetensors checkpoint shards:  17% Completed | 169/1024 [00:03<00:19, 43.28it/s]
Loading safetensors checkpoint shards:  17% Completed | 175/1024 [00:03<00:18, 45.16it/s]
Loading safetensors checkpoint shards:  18% Completed | 180/1024 [00:04<00:19, 43.92it/s]
Loading safetensors checkpoint shards:  18% Completed | 185/1024 [00:04<00:18, 45.49it/s]
Loading safetensors checkpoint shards:  19% Completed | 190/1024 [00:04<00:18, 45.02it/s]
Loading safetensors checkpoint shards:  19% Completed | 196/1024 [00:04<00:17, 47.15it/s]
Loading safetensors checkpoint shards:  20% Completed | 201/1024 [00:04<00:17, 46.05it/s]
Loading safetensors checkpoint shards:  20% Completed | 206/1024 [00:04<00:17, 46.05it/s]
Loading safetensors checkpoint shards:  21% Completed | 211/1024 [00:04<00:18, 45.03it/s]
Loading safetensors checkpoint shards:  21% Completed | 217/1024 [00:04<00:17, 46.58it/s]
Loading safetensors checkpoint shards:  22% Completed | 222/1024 [00:04<00:17, 44.64it/s]
Loading safetensors checkpoint shards:  22% Completed | 227/1024 [00:05<00:17, 44.46it/s]
Loading safetensors checkpoint shards:  23% Completed | 232/1024 [00:05<00:17, 44.58it/s]
Loading safetensors checkpoint shards:  23% Completed | 237/1024 [00:05<00:17, 45.99it/s]
Loading safetensors checkpoint shards:  24% Completed | 242/1024 [00:05<00:17, 45.35it/s]
Loading safetensors checkpoint shards:  24% Completed | 247/1024 [00:05<00:17, 45.15it/s]
Loading safetensors checkpoint shards:  25% Completed | 253/1024 [00:05<00:16, 47.42it/s]
Loading safetensors checkpoint shards:  25% Completed | 258/1024 [00:05<00:16, 45.82it/s]
Loading safetensors checkpoint shards:  26% Completed | 264/1024 [00:05<00:16, 47.38it/s]
Loading safetensors checkpoint shards:  26% Completed | 269/1024 [00:05<00:16, 46.85it/s]
Loading safetensors checkpoint shards:  27% Completed | 275/1024 [00:06<00:16, 46.70it/s]
Loading safetensors checkpoint shards:  27% Completed | 280/1024 [00:06<00:16, 45.85it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:06<00:15, 46.66it/s]
Loading safetensors checkpoint shards:  28% Completed | 290/1024 [00:06<00:16, 43.97it/s]
Loading safetensors checkpoint shards:  29% Completed | 296/1024 [00:06<00:15, 45.70it/s]
Loading safetensors checkpoint shards:  29% Completed | 301/1024 [00:06<00:16, 44.88it/s]
Loading safetensors checkpoint shards:  30% Completed | 306/1024 [00:06<00:15, 45.06it/s]
Loading safetensors checkpoint shards:  30% Completed | 311/1024 [00:06<00:16, 43.77it/s]
Loading safetensors checkpoint shards:  31% Completed | 317/1024 [00:06<00:15, 45.72it/s]
Loading safetensors checkpoint shards:  31% Completed | 322/1024 [00:07<00:15, 44.27it/s]
Loading safetensors checkpoint shards:  32% Completed | 327/1024 [00:07<00:29, 23.55it/s]
Loading safetensors checkpoint shards:  32% Completed | 332/1024 [00:07<00:25, 27.02it/s]
Loading safetensors checkpoint shards:  33% Completed | 337/1024 [00:07<00:22, 30.99it/s]
Loading safetensors checkpoint shards:  33% Completed | 342/1024 [00:07<00:20, 33.11it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:08<00:20, 33.74it/s]
Loading safetensors checkpoint shards:  34% Completed | 351/1024 [00:08<00:18, 35.92it/s]
Loading safetensors checkpoint shards:  35% Completed | 355/1024 [00:08<00:18, 35.86it/s]
Loading safetensors checkpoint shards:  35% Completed | 359/1024 [00:08<00:18, 36.89it/s]
Loading safetensors checkpoint shards:  35% Completed | 363/1024 [00:08<00:17, 37.66it/s]
Loading safetensors checkpoint shards:  36% Completed | 367/1024 [00:08<00:17, 37.09it/s]
Loading safetensors checkpoint shards:  36% Completed | 372/1024 [00:08<00:17, 38.24it/s]
Loading safetensors checkpoint shards:  37% Completed | 376/1024 [00:08<00:17, 37.32it/s]
Loading safetensors checkpoint shards:  37% Completed | 380/1024 [00:08<00:18, 35.74it/s]
Loading safetensors checkpoint shards:  38% Completed | 385/1024 [00:09<00:16, 38.56it/s]
Loading safetensors checkpoint shards:  38% Completed | 390/1024 [00:09<00:15, 40.34it/s]
Loading safetensors checkpoint shards:  39% Completed | 395/1024 [00:09<00:14, 42.79it/s]
Loading safetensors checkpoint shards:  39% Completed | 400/1024 [00:09<00:14, 43.10it/s]
Loading safetensors checkpoint shards:  40% Completed | 405/1024 [00:09<00:16, 37.37it/s]
Loading safetensors checkpoint shards:  40% Completed | 409/1024 [00:09<00:16, 37.07it/s]
Loading safetensors checkpoint shards:  40% Completed | 413/1024 [00:09<00:16, 37.46it/s]
Loading safetensors checkpoint shards:  41% Completed | 417/1024 [00:09<00:16, 37.73it/s]
Loading safetensors checkpoint shards:  41% Completed | 422/1024 [00:09<00:14, 40.36it/s]
Loading safetensors checkpoint shards:  42% Completed | 428/1024 [00:10<00:13, 45.56it/s]
Loading safetensors checkpoint shards:  42% Completed | 433/1024 [00:10<00:13, 44.37it/s]
Loading safetensors checkpoint shards:  43% Completed | 440/1024 [00:10<00:11, 50.27it/s]
Loading safetensors checkpoint shards:  44% Completed | 446/1024 [00:10<00:11, 52.27it/s]
Loading safetensors checkpoint shards:  44% Completed | 452/1024 [00:10<00:13, 42.26it/s]
Loading safetensors checkpoint shards:  45% Completed | 457/1024 [00:10<00:13, 40.67it/s]
Loading safetensors checkpoint shards:  45% Completed | 462/1024 [00:10<00:14, 39.03it/s]
Loading safetensors checkpoint shards:  46% Completed | 467/1024 [00:11<00:16, 33.03it/s]
Loading safetensors checkpoint shards:  46% Completed | 473/1024 [00:11<00:14, 36.80it/s]
Loading safetensors checkpoint shards:  47% Completed | 477/1024 [00:11<00:14, 37.31it/s]
Loading safetensors checkpoint shards:  47% Completed | 481/1024 [00:11<00:14, 37.58it/s]
Loading safetensors checkpoint shards:  47% Completed | 486/1024 [00:11<00:13, 39.61it/s]
Loading safetensors checkpoint shards:  48% Completed | 491/1024 [00:11<00:13, 38.70it/s]
Loading safetensors checkpoint shards:  48% Completed | 496/1024 [00:11<00:12, 41.24it/s]
Loading safetensors checkpoint shards:  49% Completed | 501/1024 [00:11<00:12, 40.75it/s]
Loading safetensors checkpoint shards:  49% Completed | 506/1024 [00:12<00:12, 41.17it/s]
Loading safetensors checkpoint shards:  50% Completed | 511/1024 [00:12<00:12, 40.77it/s]
Loading safetensors checkpoint shards:  50% Completed | 517/1024 [00:12<00:11, 43.10it/s]
Loading safetensors checkpoint shards:  51% Completed | 522/1024 [00:12<00:12, 41.53it/s]
Loading safetensors checkpoint shards:  51% Completed | 527/1024 [00:12<00:11, 43.30it/s]
Loading safetensors checkpoint shards:  52% Completed | 532/1024 [00:12<00:11, 43.18it/s]
Loading safetensors checkpoint shards:  52% Completed | 537/1024 [00:12<00:11, 44.14it/s]
Loading safetensors checkpoint shards:  53% Completed | 542/1024 [00:12<00:11, 43.03it/s]
Loading safetensors checkpoint shards:  53% Completed | 547/1024 [00:12<00:11, 42.91it/s]
Loading safetensors checkpoint shards:  54% Completed | 552/1024 [00:13<00:10, 44.44it/s]
Loading safetensors checkpoint shards:  54% Completed | 557/1024 [00:13<00:10, 42.93it/s]
Loading safetensors checkpoint shards:  55% Completed | 562/1024 [00:13<00:24, 19.23it/s]
Loading safetensors checkpoint shards:  55% Completed | 566/1024 [00:13<00:20, 21.90it/s]
Loading safetensors checkpoint shards:  56% Completed | 571/1024 [00:14<00:17, 26.16it/s]
Loading safetensors checkpoint shards:  56% Completed | 575/1024 [00:14<00:16, 27.88it/s]
Loading safetensors checkpoint shards:  57% Completed | 579/1024 [00:14<00:14, 30.36it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:14<00:12, 35.43it/s]
Loading safetensors checkpoint shards:  58% Completed | 590/1024 [00:14<00:12, 35.88it/s]
Loading safetensors checkpoint shards:  58% Completed | 595/1024 [00:14<00:11, 38.53it/s]
Loading safetensors checkpoint shards:  59% Completed | 600/1024 [00:14<00:10, 39.64it/s]
Loading safetensors checkpoint shards:  59% Completed | 605/1024 [00:14<00:09, 41.98it/s]
Loading safetensors checkpoint shards:  60% Completed | 610/1024 [00:14<00:10, 40.29it/s]
Loading safetensors checkpoint shards:  60% Completed | 615/1024 [00:15<00:09, 42.56it/s]
Loading safetensors checkpoint shards:  61% Completed | 620/1024 [00:15<00:09, 41.46it/s]
Loading safetensors checkpoint shards:  61% Completed | 625/1024 [00:15<00:09, 41.94it/s]
Loading safetensors checkpoint shards:  62% Completed | 630/1024 [00:15<00:08, 43.78it/s]
Loading safetensors checkpoint shards:  62% Completed | 636/1024 [00:15<00:08, 46.02it/s]
Loading safetensors checkpoint shards:  63% Completed | 641/1024 [00:15<00:08, 45.41it/s]
Loading safetensors checkpoint shards:  63% Completed | 646/1024 [00:15<00:08, 42.68it/s]
Loading safetensors checkpoint shards:  64% Completed | 652/1024 [00:15<00:08, 45.77it/s]
Loading safetensors checkpoint shards:  64% Completed | 658/1024 [00:15<00:07, 47.26it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:16<00:08, 42.84it/s]
Loading safetensors checkpoint shards:  65% Completed | 669/1024 [00:16<00:07, 45.29it/s]
Loading safetensors checkpoint shards:  66% Completed | 674/1024 [00:16<00:08, 39.39it/s]
Loading safetensors checkpoint shards:  66% Completed | 679/1024 [00:16<00:09, 36.19it/s]
Loading safetensors checkpoint shards:  67% Completed | 684/1024 [00:16<00:09, 37.47it/s]
Loading safetensors checkpoint shards:  67% Completed | 689/1024 [00:16<00:08, 38.96it/s]
Loading safetensors checkpoint shards:  68% Completed | 694/1024 [00:16<00:07, 41.26it/s]
Loading safetensors checkpoint shards:  68% Completed | 699/1024 [00:17<00:07, 40.68it/s]
Loading safetensors checkpoint shards:  69% Completed | 704/1024 [00:17<00:08, 39.87it/s]
Loading safetensors checkpoint shards:  69% Completed | 709/1024 [00:17<00:07, 40.21it/s]
Loading safetensors checkpoint shards:  70% Completed | 714/1024 [00:17<00:07, 40.84it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:17<00:07, 40.18it/s]
Loading safetensors checkpoint shards:  71% Completed | 724/1024 [00:17<00:07, 41.07it/s]
Loading safetensors checkpoint shards:  71% Completed | 729/1024 [00:17<00:07, 41.88it/s]
Loading safetensors checkpoint shards:  72% Completed | 734/1024 [00:17<00:07, 39.56it/s]
Loading safetensors checkpoint shards:  72% Completed | 738/1024 [00:18<00:07, 38.97it/s]
Loading safetensors checkpoint shards:  72% Completed | 742/1024 [00:18<00:07, 38.24it/s]
Loading safetensors checkpoint shards:  73% Completed | 746/1024 [00:18<00:07, 38.10it/s]
Loading safetensors checkpoint shards:  73% Completed | 750/1024 [00:18<00:07, 37.08it/s]
Loading safetensors checkpoint shards:  74% Completed | 754/1024 [00:18<00:07, 36.77it/s]
Loading safetensors checkpoint shards:  74% Completed | 758/1024 [00:18<00:07, 37.51it/s]
Loading safetensors checkpoint shards:  74% Completed | 762/1024 [00:18<00:06, 37.92it/s]
Loading safetensors checkpoint shards:  75% Completed | 766/1024 [00:18<00:06, 38.14it/s]
Loading safetensors checkpoint shards:  75% Completed | 770/1024 [00:18<00:06, 38.30it/s]
Loading safetensors checkpoint shards:  76% Completed | 774/1024 [00:19<00:06, 37.41it/s]
Loading safetensors checkpoint shards:  76% Completed | 778/1024 [00:19<00:06, 38.12it/s]
Loading safetensors checkpoint shards:  76% Completed | 783/1024 [00:19<00:06, 39.62it/s]
Loading safetensors checkpoint shards:  77% Completed | 787/1024 [00:19<00:06, 37.73it/s]
Loading safetensors checkpoint shards:  77% Completed | 791/1024 [00:19<00:06, 38.19it/s]
Loading safetensors checkpoint shards:  78% Completed | 795/1024 [00:19<00:05, 38.55it/s]
Loading safetensors checkpoint shards:  78% Completed | 799/1024 [00:19<00:05, 38.77it/s]
Loading safetensors checkpoint shards:  79% Completed | 804/1024 [00:19<00:05, 39.51it/s]
Loading safetensors checkpoint shards:  79% Completed | 808/1024 [00:19<00:05, 38.97it/s]
Loading safetensors checkpoint shards:  79% Completed | 812/1024 [00:19<00:05, 38.22it/s]
Loading safetensors checkpoint shards:  80% Completed | 816/1024 [00:20<00:05, 36.11it/s]
Loading safetensors checkpoint shards:  80% Completed | 820/1024 [00:20<00:05, 35.20it/s]
Loading safetensors checkpoint shards:  80% Completed | 824/1024 [00:20<00:05, 35.19it/s]
Loading safetensors checkpoint shards:  81% Completed | 828/1024 [00:20<00:05, 35.39it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:20<00:04, 39.05it/s]
Loading safetensors checkpoint shards:  82% Completed | 837/1024 [00:20<00:04, 37.70it/s]
Loading safetensors checkpoint shards:  82% Completed | 841/1024 [00:20<00:04, 37.41it/s]
Loading safetensors checkpoint shards:  83% Completed | 845/1024 [00:21<00:13, 12.96it/s]
Loading safetensors checkpoint shards:  83% Completed | 849/1024 [00:21<00:11, 15.89it/s]
Loading safetensors checkpoint shards:  83% Completed | 853/1024 [00:21<00:09, 18.93it/s]
Loading safetensors checkpoint shards:  84% Completed | 857/1024 [00:22<00:08, 19.09it/s]
Loading safetensors checkpoint shards:  84% Completed | 860/1024 [00:22<00:11, 13.81it/s]
Loading safetensors checkpoint shards:  84% Completed | 864/1024 [00:22<00:09, 17.04it/s]
Loading safetensors checkpoint shards:  85% Completed | 868/1024 [00:22<00:07, 20.38it/s]
Loading safetensors checkpoint shards:  85% Completed | 872/1024 [00:22<00:06, 23.75it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:22<00:05, 26.05it/s]
Loading safetensors checkpoint shards:  86% Completed | 880/1024 [00:22<00:05, 28.29it/s]
Loading safetensors checkpoint shards:  86% Completed | 884/1024 [00:23<00:04, 30.25it/s]
Loading safetensors checkpoint shards:  87% Completed | 888/1024 [00:23<00:04, 31.88it/s]
Loading safetensors checkpoint shards:  87% Completed | 892/1024 [00:23<00:04, 32.44it/s]
Loading safetensors checkpoint shards:  88% Completed | 896/1024 [00:23<00:03, 33.53it/s]
Loading safetensors checkpoint shards:  88% Completed | 900/1024 [00:23<00:03, 34.79it/s]
Loading safetensors checkpoint shards:  88% Completed | 905/1024 [00:23<00:03, 36.61it/s]
Loading safetensors checkpoint shards:  89% Completed | 909/1024 [00:23<00:03, 36.72it/s]
Loading safetensors checkpoint shards:  89% Completed | 913/1024 [00:23<00:03, 36.43it/s]
Loading safetensors checkpoint shards:  90% Completed | 918/1024 [00:23<00:02, 39.59it/s]
Loading safetensors checkpoint shards:  90% Completed | 923/1024 [00:24<00:02, 39.65it/s]
Loading safetensors checkpoint shards:  91% Completed | 928/1024 [00:24<00:02, 40.70it/s]
Loading safetensors checkpoint shards:  91% Completed | 933/1024 [00:24<00:02, 39.86it/s]
Loading safetensors checkpoint shards:  92% Completed | 938/1024 [00:24<00:02, 40.52it/s]
Loading safetensors checkpoint shards:  92% Completed | 943/1024 [00:24<00:01, 40.97it/s]
Loading safetensors checkpoint shards:  93% Completed | 948/1024 [00:24<00:01, 39.92it/s]
Loading safetensors checkpoint shards:  93% Completed | 953/1024 [00:24<00:01, 41.81it/s]
Loading safetensors checkpoint shards:  94% Completed | 958/1024 [00:24<00:01, 40.80it/s]
Loading safetensors checkpoint shards:  94% Completed | 963/1024 [00:25<00:01, 38.90it/s]
Loading safetensors checkpoint shards:  94% Completed | 967/1024 [00:25<00:01, 38.77it/s]
Loading safetensors checkpoint shards:  95% Completed | 971/1024 [00:25<00:01, 36.99it/s]
Loading safetensors checkpoint shards:  95% Completed | 976/1024 [00:25<00:01, 38.07it/s]
Loading safetensors checkpoint shards:  96% Completed | 981/1024 [00:25<00:01, 38.80it/s]
Loading safetensors checkpoint shards:  99% Completed | 1011/1024 [00:25<00:00, 105.94it/s]
Loading safetensors checkpoint shards: 100% Completed | 1023/1024 [00:25<00:00, 99.36it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 39.63it/s]

[2025-09-13 08:00:05 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 08:00:07 TP1] KV Cache is allocated. #tokens: 620313, KV size: 40.60 GB
[2025-09-13 08:00:07 TP3] KV Cache is allocated. #tokens: 620313, KV size: 40.60 GB
[2025-09-13 08:00:07 TP4] KV Cache is allocated. #tokens: 620313, KV size: 40.60 GB
[2025-09-13 08:00:07 TP5] KV Cache is allocated. #tokens: 620313, KV size: 40.60 GB
[2025-09-13 08:00:07 TP6] KV Cache is allocated. #tokens: 620313, KV size: 40.60 GB
[2025-09-13 08:00:07 TP7] KV Cache is allocated. #tokens: 620313, KV size: 40.60 GB
[2025-09-13 08:00:07 TP2] KV Cache is allocated. #tokens: 620313, KV size: 40.60 GB
[2025-09-13 08:00:07 TP0] KV Cache is allocated. #tokens: 620313, KV size: 40.60 GB
[2025-09-13 08:00:07 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 08:00:07 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 08:00:07 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.51 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 08:00:08 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:00:08 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
                                                                                                                                                                     [2025-09-13 08:00:08 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 08:00:08 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 08:00:09 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 08:00:09 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 08:00:09 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 08:00:09 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 08:00:09 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 24896.60it/s]
[2025-09-13 08:00:09 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:00:09 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 25402.32it/s]
[2025-09-13 08:00:10 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:00:10 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27071.67it/s]
[2025-09-13 08:00:10 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:00:10 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26565.65it/s]
[2025-09-13 08:00:11 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:00:11 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27181.40it/s]
[2025-09-13 08:00:12 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.20 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.75it/s][2025-09-13 08:00:15 TP4] Registering 984 cuda graph addresses
[2025-09-13 08:00:15 TP5] Registering 984 cuda graph addresses
[2025-09-13 08:00:15 TP6] Registering 984 cuda graph addresses
[2025-09-13 08:00:15 TP1] Registering 984 cuda graph addresses
[2025-09-13 08:00:15 TP2] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.20 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.12it/s]
[2025-09-13 08:00:15 TP3] Registering 984 cuda graph addresses
[2025-09-13 08:00:15 TP7] Registering 984 cuda graph addresses
[2025-09-13 08:00:15 TP0] Registering 984 cuda graph addresses
[2025-09-13 08:00:15 TP0] Capture cuda graph end. Time elapsed: 8.00 s. mem usage=0.39 GB. avail mem=17.17 GB.
[2025-09-13 08:00:15 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 08:00:15 TP0] Chunked prefix cache is turned on.
[2025-09-13 08:00:15 TP0] Init torch distributed begin.
[2025-09-13 08:00:15 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 08:00:15 TP0] Load weight begin. avail mem=17.17 GB
[2025-09-13 08:00:15 TP0] Detected fp8 checkpoint.
[2025-09-13 08:00:15 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 19/1024 [00:00<00:05, 182.30it/s]
Loading safetensors checkpoint shards:   4% Completed | 46/1024 [00:00<00:04, 232.45it/s]
Loading safetensors checkpoint shards:  10% Completed | 107/1024 [00:00<00:02, 400.36it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:00<00:01, 476.83it/s]
Loading safetensors checkpoint shards:  22% Completed | 225/1024 [00:00<00:01, 513.25it/s]
Loading safetensors checkpoint shards:  28% Completed | 285/1024 [00:00<00:01, 540.98it/s]
Loading safetensors checkpoint shards:  34% Completed | 345/1024 [00:00<00:01, 558.60it/s]
Loading safetensors checkpoint shards:  40% Completed | 407/1024 [00:00<00:01, 576.94it/s]
Loading safetensors checkpoint shards:  46% Completed | 469/1024 [00:00<00:00, 589.97it/s]
Loading safetensors checkpoint shards:  52% Completed | 533/1024 [00:01<00:00, 603.44it/s]
Loading safetensors checkpoint shards:  58% Completed | 597/1024 [00:01<00:00, 613.31it/s]
Loading safetensors checkpoint shards:  64% Completed | 659/1024 [00:01<00:00, 609.03it/s]
Loading safetensors checkpoint shards:  70% Completed | 720/1024 [00:01<00:00, 602.40it/s]
Loading safetensors checkpoint shards:  76% Completed | 781/1024 [00:01<00:00, 592.80it/s]
Loading safetensors checkpoint shards:  82% Completed | 841/1024 [00:01<00:00, 589.83it/s]
Loading safetensors checkpoint shards:  88% Completed | 901/1024 [00:01<00:00, 584.27it/s]
Loading safetensors checkpoint shards:  94% Completed | 960/1024 [00:01<00:00, 581.26it/s]
Loading safetensors checkpoint shards: 100% Completed | 1019/1024 [00:01<00:00, 404.23it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:01<00:00, 512.99it/s]

[2025-09-13 08:00:18 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.18 GB, mem usage=1.99 GB.
[2025-09-13 08:00:18 TP0] KV Cache is allocated. #tokens: 620313, KV size: 0.67 GB
[2025-09-13 08:00:18 TP6] KV Cache is allocated. #tokens: 620313, KV size: 0.67 GB
[2025-09-13 08:00:18 TP0] Memory pool end. avail mem=14.52 GB
[2025-09-13 08:00:18 TP4] KV Cache is allocated. #tokens: 620313, KV size: 0.67 GB
[2025-09-13 08:00:18 TP3] KV Cache is allocated. #tokens: 620313, KV size: 0.67 GB
[2025-09-13 08:00:18 TP5] KV Cache is allocated. #tokens: 620313, KV size: 0.67 GB
[2025-09-13 08:00:18 TP2] KV Cache is allocated. #tokens: 620313, KV size: 0.67 GB
[2025-09-13 08:00:18 TP1] KV Cache is allocated. #tokens: 620313, KV size: 0.67 GB
[2025-09-13 08:00:18 TP7] KV Cache is allocated. #tokens: 620313, KV size: 0.67 GB
[2025-09-13 08:00:18 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 08:00:18 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 08:00:18 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 08:00:18 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 08:00:18 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 08:00:18 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.14 GB
[2025-09-13 08:00:18 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 08:00:18 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.95 GB
Capturing batches (bs=1 avail_mem=14.46 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  3.13it/s][2025-09-13 08:00:24 TP6] Registering 120 cuda graph addresses
[2025-09-13 08:00:24 TP3] Registering 120 cuda graph addresses
[2025-09-13 08:00:24 TP4] Registering 120 cuda graph addresses
[2025-09-13 08:00:24 TP1] Registering 120 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.46 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.47it/s]
[2025-09-13 08:00:24 TP0] Registering 120 cuda graph addresses
[2025-09-13 08:00:24 TP2] Registering 120 cuda graph addresses
[2025-09-13 08:00:24 TP5] Registering 120 cuda graph addresses
[2025-09-13 08:00:24 TP7] Registering 120 cuda graph addresses
[2025-09-13 08:00:24 TP1] Capture draft cuda graph end. Time elapsed: 6.30 s. mem usage=0.49 GB. avail mem=14.42 GB.
[2025-09-13 08:00:24 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.42 GB
[2025-09-13 08:00:24 TP0] Capture draft cuda graph end. Time elapsed: 6.30 s. mem usage=0.49 GB. avail mem=14.46 GB.
[2025-09-13 08:00:24 TP5] Capture draft cuda graph end. Time elapsed: 6.29 s. mem usage=0.49 GB. avail mem=14.42 GB.
[2025-09-13 08:00:24 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.42 GB
[2025-09-13 08:00:24 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.46 GB
[2025-09-13 08:00:24 TP7] Capture draft cuda graph end. Time elapsed: 6.29 s. mem usage=0.49 GB. avail mem=14.65 GB.
[2025-09-13 08:00:24 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.65 GB
[2025-09-13 08:00:24 TP2] Capture draft cuda graph end. Time elapsed: 6.35 s. mem usage=0.49 GB. avail mem=14.42 GB.
[2025-09-13 08:00:24 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.42 GB
[2025-09-13 08:00:24 TP6] Capture draft cuda graph end. Time elapsed: 6.35 s. mem usage=0.49 GB. avail mem=14.42 GB.
[2025-09-13 08:00:24 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.42 GB
[2025-09-13 08:00:24 TP3] Capture draft cuda graph end. Time elapsed: 6.31 s. mem usage=0.49 GB. avail mem=14.42 GB.
[2025-09-13 08:00:24 TP4] Capture draft cuda graph end. Time elapsed: 6.35 s. mem usage=0.49 GB. avail mem=14.42 GB.
[2025-09-13 08:00:24 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.42 GB
[2025-09-13 08:00:24 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.42 GB
Capturing batches (bs=1 avail_mem=14.25 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:00<00:00, 29.74it/s][2025-09-13 08:00:25 TP4] Registering 24 cuda graph addresses
[2025-09-13 08:00:25 TP5] Registering 24 cuda graph addresses
[2025-09-13 08:00:25 TP6] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.25 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 29.01it/s]
[2025-09-13 08:00:25 TP7] Registering 24 cuda graph addresses
[2025-09-13 08:00:25 TP2] Registering 24 cuda graph addresses
[2025-09-13 08:00:25 TP1] Registering 24 cuda graph addresses
[2025-09-13 08:00:25 TP3] Registering 24 cuda graph addresses
[2025-09-13 08:00:25 TP0] Registering 24 cuda graph addresses
[2025-09-13 08:00:25 TP4] Capture draft extend cuda graph end. Time elapsed: 1.08 s. mem usage=0.20 GB. avail mem=14.21 GB.
[2025-09-13 08:00:25 TP3] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.20 GB. avail mem=14.21 GB.
[2025-09-13 08:00:25 TP2] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.20 GB. avail mem=14.21 GB.
[2025-09-13 08:00:25 TP7] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.20 GB. avail mem=14.45 GB.
[2025-09-13 08:00:25 TP6] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.20 GB. avail mem=14.21 GB.
[2025-09-13 08:00:25 TP1] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.20 GB. avail mem=14.21 GB.
[2025-09-13 08:00:25 TP0] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.20 GB. avail mem=14.25 GB.
[2025-09-13 08:00:25 TP5] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.20 GB. avail mem=14.21 GB.
[2025-09-13 08:00:25 TP0] max_total_num_tokens=620313, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.25 GB
[2025-09-13 08:00:26] INFO:     Started server process [399121]
[2025-09-13 08:00:26] INFO:     Waiting for application startup.
[2025-09-13 08:00:26] INFO:     Application startup complete.
[2025-09-13 08:00:26] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 08:00:27] INFO:     127.0.0.1:59034 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 08:00:27 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:00:27 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:00:27 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27824.66it/s]
[2025-09-13 08:00:28] INFO:     127.0.0.1:59048 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:28] The server is fired up and ready to roll!
[2025-09-13 08:00:36 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:00:37] INFO:     127.0.0.1:57204 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 08:00:37] INFO:     127.0.0.1:57216 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:37 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 08:00:39] INFO:     127.0.0.1:52452 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:39] INFO:     127.0.0.1:52466 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:39 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:00:39] INFO:     127.0.0.1:52478 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:39] INFO:     127.0.0.1:52482 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:39] INFO:     127.0.0.1:52484 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:39] INFO:     127.0.0.1:52494 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:39] INFO:     127.0.0.1:52500 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:39] INFO:     127.0.0.1:52512 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:39 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 08:00:39 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:00:39 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:00:39 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:00:39 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:00:39 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:00:39 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:00:39 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:00:39 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:00:39 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 08:00:40 TP0] Decode batch. #running-req: 8, #token: 14650, token usage: 0.02, accept len: 3.22, cuda graph: True, gen throughput (token/s): 51.20, #queue-req: 0, 
[2025-09-13 08:00:42 TP0] Decode batch. #running-req: 8, #token: 15966, token usage: 0.03, accept len: 4.11, cuda graph: True, gen throughput (token/s): 953.54, #queue-req: 0, 
 12%|████████████████▍                                                                                                                  | 1/8 [00:04<00:28,  4.07s/it][2025-09-13 08:00:43 TP0] Decode batch. #running-req: 7, #token: 16752, token usage: 0.03, accept len: 4.62, cuda graph: True, gen throughput (token/s): 1015.06, #queue-req: 0, 
 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 7/8 [00:05<00:00,  2.59it/s][2025-09-13 08:00:44 TP0] Decode batch. #running-req: 1, #token: 1425, token usage: 0.00, accept len: 3.77, cuda graph: True, gen throughput (token/s): 409.65, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.27it/s]
[2025-09-13 08:00:45] INFO:     127.0.0.1:52522 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.32      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4065      
Request throughput (req/s):              1.27      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         648.58    
Total token throughput (tok/s):          648.58    
Concurrency:                             6.53      
Accept length:                           4.01      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5154.34   
Median E2E Latency (ms):                 5160.79   
---------------Time to First Token----------------
Mean TTFT (ms):                          623.22    
Median TTFT (ms):                        735.28    
P99 TTFT (ms):                           735.76    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           8.87      
Median ITL (ms):                         5.87      
P95 ITL (ms):                            17.57     
P99 ITL (ms):                            34.81     
Max ITL (ms):                            740.77    
==================================================
[2025-09-13 08:00:45] INFO:     127.0.0.1:52524 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 08:00:45] INFO:     127.0.0.1:52538 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:45 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 08:00:46] INFO:     127.0.0.1:52544 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:46] INFO:     127.0.0.1:52558 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:46 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:00:46] INFO:     127.0.0.1:52564 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:46] INFO:     127.0.0.1:52580 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:46] INFO:     127.0.0.1:52584 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:46] INFO:     127.0.0.1:52588 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:46] INFO:     127.0.0.1:52604 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:46] INFO:     127.0.0.1:52608 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:46 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 08:00:47 TP0] Decode batch. #running-req: 8, #token: 14060, token usage: 0.02, accept len: 3.20, cuda graph: True, gen throughput (token/s): 111.95, #queue-req: 0, 
[2025-09-13 08:00:48 TP0] Decode batch. #running-req: 8, #token: 15176, token usage: 0.02, accept len: 3.49, cuda graph: True, gen throughput (token/s): 820.58, #queue-req: 0, 
[2025-09-13 08:00:50 TP0] Decode batch. #running-req: 8, #token: 16637, token usage: 0.03, accept len: 4.57, cuda graph: True, gen throughput (token/s): 1041.01, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:03<00:53,  3.59s/it][2025-09-13 08:00:50] INFO:     127.0.0.1:47926 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:50 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:28,  2.04s/it][2025-09-13 08:00:51] INFO:     127.0.0.1:47940 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:04<00:15,  1.21s/it][2025-09-13 08:00:51] INFO:     127.0.0.1:47942 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:51 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 08:00:51 TP0] Decode batch. #running-req: 8, #token: 10820, token usage: 0.02, accept len: 4.14, cuda graph: True, gen throughput (token/s): 681.00, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.10it/s][2025-09-13 08:00:51] INFO:     127.0.0.1:47948 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:51] INFO:     127.0.0.1:47962 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:52 TP0] Prefill batch. #new-seq: 2, #new-token: 2823, #cached-token: 1705, token usage: 0.02, #running-req: 6, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:05<00:05,  1.99it/s][2025-09-13 08:00:52] INFO:     127.0.0.1:47972 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:52 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:05<00:04,  2.10it/s][2025-09-13 08:00:52] INFO:     127.0.0.1:47974 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:52 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
[2025-09-13 08:00:53 TP0] Decode batch. #running-req: 8, #token: 10988, token usage: 0.02, accept len: 3.46, cuda graph: True, gen throughput (token/s): 604.75, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:07<00:05,  1.43it/s][2025-09-13 08:00:53] INFO:     127.0.0.1:47990 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:00:53 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 08:00:55 TP0] Decode batch. #running-req: 8, #token: 15667, token usage: 0.03, accept len: 3.63, cuda graph: True, gen throughput (token/s): 713.49, #queue-req: 0, 
 62%|████████████████████████████████████████████████████████████████████████████████▋                                                | 10/16 [00:09<00:05,  1.14it/s][2025-09-13 08:00:56 TP0] Decode batch. #running-req: 6, #token: 9919, token usage: 0.02, accept len: 4.47, cuda graph: True, gen throughput (token/s): 960.76, #queue-req: 0, 
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 15/16 [00:11<00:00,  2.62it/s][2025-09-13 08:00:57 TP0] Decode batch. #running-req: 1, #token: 3166, token usage: 0.01, accept len: 4.02, cuda graph: True, gen throughput (token/s): 462.10, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.38it/s]
[2025-09-13 08:00:58] INFO:     127.0.0.1:41652 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.61     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8061      
Request throughput (req/s):              1.38      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         705.34    
Total token throughput (tok/s):          705.34    
Concurrency:                             7.17      
Accept length:                           3.95      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5206.70   
Median E2E Latency (ms):                 5207.34   
---------------Time to First Token----------------
Mean TTFT (ms):                          257.84    
Median TTFT (ms):                        240.69    
P99 TTFT (ms):                           343.01    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.68      
Median ITL (ms):                         6.70      
P95 ITL (ms):                            32.04     
P99 ITL (ms):                            45.88     
Max ITL (ms):                            195.86    
==================================================
[2025-09-13 08:00:58] INFO:     127.0.0.1:41658 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=47: batch_size=8, steps=6, topk=4, num_draft_tokens=8, speed=113.76 token/s, step_time=34.74 ms
Start i=48: batch_size=8, steps=6, topk=4, num_draft_tokens=12
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 6 --speculative-eagle-topk 4 --speculative-num-draft-tokens 12 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 08:01:09.214000 404718 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:01:09.214000 404718 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
[2025-09-13 08:01:09] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=1028569152, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=6, speculative_eagle_topk=4, speculative_num_draft_tokens=12, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 08:01:09] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 08:01:18.279000 404926 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:01:18.279000 404926 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 08:01:18.464000 404923 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:01:18.464000 404923 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 08:01:18.490000 404929 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:01:18.490000 404929 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 08:01:18.687000 404925 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:01:18.687000 404925 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 08:01:18.689000 404930 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:01:18.689000 404930 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 08:01:18.708000 404928 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:01:18.708000 404928 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 08:01:18.782000 404924 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:01:18.782000 404924 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 08:01:18.785000 404931 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:01:18.785000 404931 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 08:01:18.842000 404927 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:01:18.842000 404927 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 08:01:19 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 08:01:19 TP0] Chunked prefix cache is turned on.
[2025-09-13 08:01:19 TP0] Init torch distributed begin.
`torch_dtype` is deprecated! Use `dtype` instead!
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 08:01:20 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 08:01:23 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 08:01:25 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 08:01:25 TP0] Detected fp8 checkpoint.
[2025-09-13 08:01:25 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 25/1024 [00:00<00:04, 240.15it/s]
Loading safetensors checkpoint shards:   5% Completed | 50/1024 [00:00<00:15, 61.44it/s]
Loading safetensors checkpoint shards:   6% Completed | 63/1024 [00:01<00:17, 53.50it/s]
Loading safetensors checkpoint shards:   7% Completed | 72/1024 [00:01<00:18, 50.67it/s]
Loading safetensors checkpoint shards:   8% Completed | 79/1024 [00:01<00:20, 47.13it/s]
Loading safetensors checkpoint shards:   8% Completed | 85/1024 [00:01<00:19, 47.16it/s]
Loading safetensors checkpoint shards:   9% Completed | 91/1024 [00:01<00:20, 46.36it/s]
Loading safetensors checkpoint shards:   9% Completed | 97/1024 [00:01<00:20, 44.81it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:01<00:20, 44.82it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:02<00:19, 45.91it/s]
Loading safetensors checkpoint shards:  11% Completed | 113/1024 [00:02<00:20, 45.03it/s]
Loading safetensors checkpoint shards:  12% Completed | 119/1024 [00:02<00:19, 46.41it/s]
Loading safetensors checkpoint shards:  12% Completed | 124/1024 [00:02<00:34, 26.11it/s]
Loading safetensors checkpoint shards:  13% Completed | 130/1024 [00:02<00:29, 30.70it/s]
Loading safetensors checkpoint shards:  13% Completed | 135/1024 [00:02<00:27, 32.68it/s]
Loading safetensors checkpoint shards:  14% Completed | 141/1024 [00:03<00:23, 37.49it/s]
Loading safetensors checkpoint shards:  14% Completed | 146/1024 [00:03<00:22, 39.39it/s]
Loading safetensors checkpoint shards:  15% Completed | 151/1024 [00:03<00:21, 41.30it/s]
Loading safetensors checkpoint shards:  15% Completed | 156/1024 [00:03<00:20, 41.51it/s]
Loading safetensors checkpoint shards:  16% Completed | 161/1024 [00:03<00:19, 43.43it/s]
Loading safetensors checkpoint shards:  16% Completed | 166/1024 [00:03<00:20, 42.17it/s]
Loading safetensors checkpoint shards:  17% Completed | 172/1024 [00:03<00:19, 44.32it/s]
Loading safetensors checkpoint shards:  17% Completed | 177/1024 [00:03<00:19, 44.19it/s]
Loading safetensors checkpoint shards:  18% Completed | 182/1024 [00:04<00:19, 44.26it/s]
Loading safetensors checkpoint shards:  18% Completed | 187/1024 [00:04<00:18, 44.31it/s]
Loading safetensors checkpoint shards:  19% Completed | 192/1024 [00:04<00:18, 44.61it/s]
Loading safetensors checkpoint shards:  19% Completed | 198/1024 [00:04<00:17, 47.15it/s]
Loading safetensors checkpoint shards:  20% Completed | 203/1024 [00:04<00:18, 45.13it/s]
Loading safetensors checkpoint shards:  20% Completed | 209/1024 [00:04<00:17, 46.88it/s]
Loading safetensors checkpoint shards:  21% Completed | 214/1024 [00:04<00:17, 46.12it/s]
Loading safetensors checkpoint shards:  21% Completed | 219/1024 [00:04<00:17, 45.90it/s]
Loading safetensors checkpoint shards:  22% Completed | 224/1024 [00:04<00:17, 45.27it/s]
Loading safetensors checkpoint shards:  22% Completed | 229/1024 [00:05<00:17, 45.33it/s]
Loading safetensors checkpoint shards:  23% Completed | 234/1024 [00:05<00:17, 45.12it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:05<00:16, 46.93it/s]
Loading safetensors checkpoint shards:  24% Completed | 245/1024 [00:05<00:16, 46.11it/s]
Loading safetensors checkpoint shards:  25% Completed | 251/1024 [00:05<00:16, 47.93it/s]
Loading safetensors checkpoint shards:  25% Completed | 256/1024 [00:05<00:16, 46.89it/s]
Loading safetensors checkpoint shards:  26% Completed | 262/1024 [00:05<00:15, 47.88it/s]
Loading safetensors checkpoint shards:  26% Completed | 267/1024 [00:05<00:16, 47.02it/s]
Loading safetensors checkpoint shards:  27% Completed | 273/1024 [00:05<00:15, 48.47it/s]
Loading safetensors checkpoint shards:  27% Completed | 278/1024 [00:06<00:16, 45.63it/s]
Loading safetensors checkpoint shards:  28% Completed | 284/1024 [00:06<00:15, 46.74it/s]
Loading safetensors checkpoint shards:  28% Completed | 289/1024 [00:06<00:16, 45.82it/s]
Loading safetensors checkpoint shards:  29% Completed | 294/1024 [00:06<00:15, 45.76it/s]
Loading safetensors checkpoint shards:  29% Completed | 299/1024 [00:06<00:16, 45.27it/s]
Loading safetensors checkpoint shards:  30% Completed | 305/1024 [00:06<00:15, 47.40it/s]
Loading safetensors checkpoint shards:  30% Completed | 310/1024 [00:06<00:15, 45.85it/s]
Loading safetensors checkpoint shards:  31% Completed | 316/1024 [00:06<00:14, 47.56it/s]
Loading safetensors checkpoint shards:  31% Completed | 321/1024 [00:07<00:15, 45.71it/s]
Loading safetensors checkpoint shards:  32% Completed | 326/1024 [00:07<00:28, 24.60it/s]
Loading safetensors checkpoint shards:  32% Completed | 331/1024 [00:07<00:24, 28.10it/s]
Loading safetensors checkpoint shards:  33% Completed | 336/1024 [00:07<00:21, 31.34it/s]
Loading safetensors checkpoint shards:  33% Completed | 342/1024 [00:07<00:19, 35.64it/s]
Loading safetensors checkpoint shards:  34% Completed | 347/1024 [00:07<00:18, 36.68it/s]
Loading safetensors checkpoint shards:  34% Completed | 352/1024 [00:08<00:16, 39.61it/s]
Loading safetensors checkpoint shards:  35% Completed | 357/1024 [00:08<00:16, 40.35it/s]
Loading safetensors checkpoint shards:  35% Completed | 362/1024 [00:08<00:15, 41.93it/s]
Loading safetensors checkpoint shards:  36% Completed | 367/1024 [00:08<00:15, 41.45it/s]
Loading safetensors checkpoint shards:  36% Completed | 372/1024 [00:08<00:15, 42.65it/s]
Loading safetensors checkpoint shards:  37% Completed | 377/1024 [00:08<00:16, 39.87it/s]
Loading safetensors checkpoint shards:  37% Completed | 382/1024 [00:08<00:15, 40.93it/s]
Loading safetensors checkpoint shards:  38% Completed | 387/1024 [00:08<00:16, 39.49it/s]
Loading safetensors checkpoint shards:  38% Completed | 392/1024 [00:09<00:16, 37.81it/s]
Loading safetensors checkpoint shards:  39% Completed | 397/1024 [00:09<00:15, 39.59it/s]
Loading safetensors checkpoint shards:  39% Completed | 402/1024 [00:09<00:16, 37.92it/s]
Loading safetensors checkpoint shards:  40% Completed | 407/1024 [00:09<00:15, 39.62it/s]
Loading safetensors checkpoint shards:  40% Completed | 412/1024 [00:09<00:15, 38.58it/s]
Loading safetensors checkpoint shards:  41% Completed | 417/1024 [00:09<00:15, 38.42it/s]
Loading safetensors checkpoint shards:  41% Completed | 421/1024 [00:09<00:15, 38.13it/s]
Loading safetensors checkpoint shards:  42% Completed | 425/1024 [00:09<00:16, 37.22it/s]
Loading safetensors checkpoint shards:  42% Completed | 430/1024 [00:10<00:15, 39.25it/s]
Loading safetensors checkpoint shards:  42% Completed | 434/1024 [00:10<00:15, 37.54it/s]
Loading safetensors checkpoint shards:  43% Completed | 439/1024 [00:10<00:15, 38.94it/s]
Loading safetensors checkpoint shards:  43% Completed | 443/1024 [00:10<00:15, 38.08it/s]
Loading safetensors checkpoint shards:  44% Completed | 447/1024 [00:10<00:15, 36.27it/s]
Loading safetensors checkpoint shards:  44% Completed | 452/1024 [00:10<00:15, 37.17it/s]
Loading safetensors checkpoint shards:  45% Completed | 456/1024 [00:10<00:15, 37.03it/s]
Loading safetensors checkpoint shards:  45% Completed | 461/1024 [00:10<00:14, 38.07it/s]
Loading safetensors checkpoint shards:  45% Completed | 465/1024 [00:10<00:15, 36.74it/s]
Loading safetensors checkpoint shards:  46% Completed | 469/1024 [00:11<00:15, 36.15it/s]
Loading safetensors checkpoint shards:  46% Completed | 474/1024 [00:11<00:13, 39.63it/s]
Loading safetensors checkpoint shards:  47% Completed | 478/1024 [00:11<00:14, 38.64it/s]
Loading safetensors checkpoint shards:  47% Completed | 483/1024 [00:11<00:13, 40.86it/s]
Loading safetensors checkpoint shards:  48% Completed | 488/1024 [00:11<00:13, 40.79it/s]
Loading safetensors checkpoint shards:  48% Completed | 493/1024 [00:11<00:12, 42.81it/s]
Loading safetensors checkpoint shards:  49% Completed | 498/1024 [00:11<00:11, 44.40it/s]
Loading safetensors checkpoint shards:  49% Completed | 503/1024 [00:11<00:12, 41.20it/s]
Loading safetensors checkpoint shards:  50% Completed | 508/1024 [00:11<00:12, 41.11it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:12<00:12, 40.32it/s]
Loading safetensors checkpoint shards:  51% Completed | 518/1024 [00:12<00:12, 41.74it/s]
Loading safetensors checkpoint shards:  51% Completed | 523/1024 [00:12<00:12, 39.17it/s]
Loading safetensors checkpoint shards:  52% Completed | 528/1024 [00:12<00:12, 40.78it/s]
Loading safetensors checkpoint shards:  52% Completed | 533/1024 [00:12<00:12, 39.51it/s]
Loading safetensors checkpoint shards:  53% Completed | 538/1024 [00:12<00:12, 39.71it/s]
Loading safetensors checkpoint shards:  53% Completed | 543/1024 [00:12<00:12, 38.83it/s]
Loading safetensors checkpoint shards:  53% Completed | 547/1024 [00:12<00:12, 38.40it/s]
Loading safetensors checkpoint shards:  54% Completed | 552/1024 [00:13<00:11, 39.50it/s]
Loading safetensors checkpoint shards:  54% Completed | 556/1024 [00:13<00:12, 38.56it/s]
Loading safetensors checkpoint shards:  55% Completed | 561/1024 [00:13<00:11, 39.17it/s]
Loading safetensors checkpoint shards:  55% Completed | 565/1024 [00:13<00:11, 38.72it/s]
Loading safetensors checkpoint shards:  56% Completed | 569/1024 [00:13<00:11, 38.65it/s]
Loading safetensors checkpoint shards:  56% Completed | 574/1024 [00:13<00:11, 39.10it/s]
Loading safetensors checkpoint shards:  56% Completed | 578/1024 [00:14<00:24, 18.51it/s]
Loading safetensors checkpoint shards:  57% Completed | 584/1024 [00:14<00:18, 24.00it/s]
Loading safetensors checkpoint shards:  57% Completed | 588/1024 [00:14<00:16, 26.53it/s]
Loading safetensors checkpoint shards:  58% Completed | 592/1024 [00:14<00:14, 28.83it/s]
Loading safetensors checkpoint shards:  58% Completed | 597/1024 [00:14<00:12, 33.09it/s]
Loading safetensors checkpoint shards:  59% Completed | 602/1024 [00:14<00:11, 35.61it/s]
Loading safetensors checkpoint shards:  59% Completed | 607/1024 [00:14<00:10, 38.31it/s]
Loading safetensors checkpoint shards:  60% Completed | 612/1024 [00:14<00:10, 39.56it/s]
Loading safetensors checkpoint shards:  60% Completed | 618/1024 [00:15<00:09, 42.43it/s]
Loading safetensors checkpoint shards:  61% Completed | 623/1024 [00:15<00:09, 43.06it/s]
Loading safetensors checkpoint shards:  61% Completed | 628/1024 [00:15<00:09, 43.94it/s]
Loading safetensors checkpoint shards:  62% Completed | 633/1024 [00:15<00:09, 41.87it/s]
Loading safetensors checkpoint shards:  62% Completed | 638/1024 [00:15<00:09, 42.60it/s]
Loading safetensors checkpoint shards:  63% Completed | 643/1024 [00:15<00:09, 41.77it/s]
Loading safetensors checkpoint shards:  63% Completed | 648/1024 [00:15<00:09, 39.97it/s]
Loading safetensors checkpoint shards:  64% Completed | 653/1024 [00:15<00:09, 40.01it/s]
Loading safetensors checkpoint shards:  64% Completed | 658/1024 [00:16<00:09, 40.02it/s]
Loading safetensors checkpoint shards:  65% Completed | 663/1024 [00:16<00:09, 38.07it/s]
Loading safetensors checkpoint shards:  65% Completed | 667/1024 [00:16<00:09, 38.02it/s]
Loading safetensors checkpoint shards:  66% Completed | 671/1024 [00:16<00:09, 38.23it/s]
Loading safetensors checkpoint shards:  66% Completed | 675/1024 [00:16<00:09, 38.57it/s]
Loading safetensors checkpoint shards:  66% Completed | 679/1024 [00:16<00:09, 37.06it/s]
Loading safetensors checkpoint shards:  67% Completed | 683/1024 [00:16<00:09, 37.37it/s]
Loading safetensors checkpoint shards:  67% Completed | 688/1024 [00:16<00:08, 38.37it/s]
Loading safetensors checkpoint shards:  68% Completed | 693/1024 [00:16<00:08, 40.63it/s]
Loading safetensors checkpoint shards:  68% Completed | 698/1024 [00:17<00:08, 40.45it/s]
Loading safetensors checkpoint shards:  69% Completed | 703/1024 [00:17<00:08, 39.34it/s]
Loading safetensors checkpoint shards:  69% Completed | 707/1024 [00:17<00:08, 39.21it/s]
Loading safetensors checkpoint shards:  69% Completed | 711/1024 [00:17<00:08, 38.71it/s]
Loading safetensors checkpoint shards:  70% Completed | 715/1024 [00:17<00:08, 38.41it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:17<00:08, 37.02it/s]
Loading safetensors checkpoint shards:  71% Completed | 723/1024 [00:17<00:08, 37.21it/s]
Loading safetensors checkpoint shards:  71% Completed | 727/1024 [00:17<00:08, 36.99it/s]
Loading safetensors checkpoint shards:  71% Completed | 731/1024 [00:18<00:08, 36.59it/s]
Loading safetensors checkpoint shards:  72% Completed | 735/1024 [00:18<00:08, 35.57it/s]
Loading safetensors checkpoint shards:  72% Completed | 739/1024 [00:18<00:07, 36.01it/s]
Loading safetensors checkpoint shards:  73% Completed | 743/1024 [00:18<00:07, 36.21it/s]
Loading safetensors checkpoint shards:  73% Completed | 747/1024 [00:18<00:07, 35.30it/s]
Loading safetensors checkpoint shards:  73% Completed | 751/1024 [00:18<00:07, 35.48it/s]
Loading safetensors checkpoint shards:  74% Completed | 755/1024 [00:18<00:07, 35.86it/s]
Loading safetensors checkpoint shards:  74% Completed | 759/1024 [00:18<00:07, 36.30it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:18<00:07, 36.55it/s]
Loading safetensors checkpoint shards:  75% Completed | 768/1024 [00:19<00:06, 38.12it/s]
Loading safetensors checkpoint shards:  75% Completed | 772/1024 [00:19<00:07, 35.07it/s]
Loading safetensors checkpoint shards:  76% Completed | 776/1024 [00:19<00:07, 35.09it/s]
Loading safetensors checkpoint shards:  76% Completed | 780/1024 [00:19<00:06, 35.47it/s]
Loading safetensors checkpoint shards:  77% Completed | 784/1024 [00:19<00:06, 35.60it/s]
Loading safetensors checkpoint shards:  77% Completed | 788/1024 [00:19<00:06, 35.07it/s]
Loading safetensors checkpoint shards:  77% Completed | 792/1024 [00:19<00:06, 35.06it/s]
Loading safetensors checkpoint shards:  78% Completed | 796/1024 [00:19<00:06, 35.48it/s]
Loading safetensors checkpoint shards:  78% Completed | 800/1024 [00:19<00:06, 35.49it/s]
Loading safetensors checkpoint shards:  79% Completed | 805/1024 [00:20<00:05, 36.79it/s]
Loading safetensors checkpoint shards:  79% Completed | 809/1024 [00:20<00:05, 36.62it/s]
Loading safetensors checkpoint shards:  79% Completed | 813/1024 [00:20<00:05, 36.39it/s]
Loading safetensors checkpoint shards:  80% Completed | 817/1024 [00:20<00:05, 35.18it/s]
Loading safetensors checkpoint shards:  80% Completed | 821/1024 [00:20<00:05, 34.94it/s]
Loading safetensors checkpoint shards:  81% Completed | 825/1024 [00:20<00:05, 35.82it/s]
Loading safetensors checkpoint shards:  81% Completed | 829/1024 [00:20<00:05, 35.86it/s]
Loading safetensors checkpoint shards:  81% Completed | 833/1024 [00:20<00:05, 36.71it/s]
Loading safetensors checkpoint shards:  82% Completed | 837/1024 [00:20<00:05, 37.17it/s]
Loading safetensors checkpoint shards:  82% Completed | 841/1024 [00:21<00:04, 37.12it/s]
Loading safetensors checkpoint shards:  83% Completed | 845/1024 [00:21<00:04, 36.67it/s]
Loading safetensors checkpoint shards:  83% Completed | 849/1024 [00:21<00:04, 36.58it/s]
Loading safetensors checkpoint shards:  83% Completed | 853/1024 [00:21<00:04, 37.40it/s]
Loading safetensors checkpoint shards:  84% Completed | 857/1024 [00:21<00:04, 36.46it/s]
Loading safetensors checkpoint shards:  84% Completed | 861/1024 [00:21<00:04, 36.49it/s]
Loading safetensors checkpoint shards:  85% Completed | 867/1024 [00:21<00:03, 41.53it/s]
Loading safetensors checkpoint shards:  85% Completed | 872/1024 [00:22<00:07, 19.39it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:22<00:06, 22.04it/s]
Loading safetensors checkpoint shards:  86% Completed | 881/1024 [00:22<00:05, 25.94it/s]
Loading safetensors checkpoint shards:  87% Completed | 886/1024 [00:22<00:04, 29.19it/s]
Loading safetensors checkpoint shards:  87% Completed | 890/1024 [00:22<00:04, 28.21it/s]
Loading safetensors checkpoint shards:  87% Completed | 894/1024 [00:22<00:04, 29.63it/s]
Loading safetensors checkpoint shards:  88% Completed | 898/1024 [00:23<00:03, 31.57it/s]
Loading safetensors checkpoint shards:  88% Completed | 902/1024 [00:23<00:03, 33.50it/s]
Loading safetensors checkpoint shards:  88% Completed | 906/1024 [00:23<00:03, 35.10it/s]
Loading safetensors checkpoint shards:  89% Completed | 910/1024 [00:23<00:03, 36.29it/s]
Loading safetensors checkpoint shards:  89% Completed | 915/1024 [00:23<00:02, 38.03it/s]
Loading safetensors checkpoint shards:  90% Completed | 919/1024 [00:23<00:02, 38.03it/s]
Loading safetensors checkpoint shards:  90% Completed | 923/1024 [00:23<00:02, 38.08it/s]
Loading safetensors checkpoint shards:  91% Completed | 927/1024 [00:23<00:02, 37.34it/s]
Loading safetensors checkpoint shards:  91% Completed | 931/1024 [00:23<00:02, 35.60it/s]
Loading safetensors checkpoint shards:  91% Completed | 935/1024 [00:23<00:02, 35.84it/s]
Loading safetensors checkpoint shards:  92% Completed | 939/1024 [00:24<00:02, 35.85it/s]
Loading safetensors checkpoint shards:  92% Completed | 943/1024 [00:24<00:02, 36.43it/s]
Loading safetensors checkpoint shards:  92% Completed | 947/1024 [00:24<00:02, 35.86it/s]
Loading safetensors checkpoint shards:  93% Completed | 951/1024 [00:24<00:02, 35.80it/s]
Loading safetensors checkpoint shards:  93% Completed | 955/1024 [00:24<00:01, 35.75it/s]
Loading safetensors checkpoint shards:  94% Completed | 959/1024 [00:24<00:01, 35.87it/s]
Loading safetensors checkpoint shards:  94% Completed | 963/1024 [00:24<00:01, 35.54it/s]
Loading safetensors checkpoint shards:  95% Completed | 968/1024 [00:24<00:01, 37.22it/s]
Loading safetensors checkpoint shards:  95% Completed | 972/1024 [00:25<00:01, 36.96it/s]
Loading safetensors checkpoint shards:  95% Completed | 977/1024 [00:25<00:01, 37.96it/s]
Loading safetensors checkpoint shards:  96% Completed | 982/1024 [00:25<00:01, 40.65it/s]
Loading safetensors checkpoint shards:  98% Completed | 1002/1024 [00:25<00:00, 82.38it/s]
Loading safetensors checkpoint shards:  99% Completed | 1011/1024 [00:25<00:00, 77.45it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 40.05it/s]

[2025-09-13 08:01:51 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 08:01:53 TP0] KV Cache is allocated. #tokens: 620345, KV size: 40.60 GB
[2025-09-13 08:01:53 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 08:01:53 TP1] KV Cache is allocated. #tokens: 620345, KV size: 40.60 GB
[2025-09-13 08:01:53 TP7] KV Cache is allocated. #tokens: 620345, KV size: 40.60 GB
[2025-09-13 08:01:53 TP3] KV Cache is allocated. #tokens: 620345, KV size: 40.60 GB
[2025-09-13 08:01:53 TP5] KV Cache is allocated. #tokens: 620345, KV size: 40.60 GB
[2025-09-13 08:01:53 TP6] KV Cache is allocated. #tokens: 620345, KV size: 40.60 GB
[2025-09-13 08:01:53 TP2] KV Cache is allocated. #tokens: 620345, KV size: 40.60 GB
[2025-09-13 08:01:53 TP4] KV Cache is allocated. #tokens: 620345, KV size: 40.60 GB
[2025-09-13 08:01:54 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 08:01:54 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.50 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 08:01:55 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:01:55 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 08:01:55 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 08:01:55 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 08:01:55 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 08:01:55 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 08:01:55 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 08:01:55 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 08:01:55 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26408.14it/s]
[2025-09-13 08:01:55 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:01:55 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27404.69it/s]
[2025-09-13 08:01:56 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:01:56 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28845.10it/s]
[2025-09-13 08:01:57 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:01:57 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28246.67it/s]
[2025-09-13 08:01:57 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:01:57 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 29244.62it/s]
[2025-09-13 08:01:58 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.16 GB):  88%|███████████████████████████████████████████████████████████████████████████▎          | 7/8 [00:06<00:00,  1.87it/s][2025-09-13 08:02:01 TP2] Registering 984 cuda graph addresses
[2025-09-13 08:02:01 TP5] Registering 984 cuda graph addresses
[2025-09-13 08:02:01 TP1] Registering 984 cuda graph addresses
Capturing batches (bs=1 avail_mem=17.16 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.16it/s]
[2025-09-13 08:02:01 TP6] Registering 984 cuda graph addresses
[2025-09-13 08:02:01 TP3] Registering 984 cuda graph addresses
[2025-09-13 08:02:01 TP4] Registering 984 cuda graph addresses
[2025-09-13 08:02:01 TP7] Registering 984 cuda graph addresses
[2025-09-13 08:02:01 TP0] Registering 984 cuda graph addresses
[2025-09-13 08:02:01 TP0] Capture cuda graph end. Time elapsed: 7.61 s. mem usage=0.43 GB. avail mem=17.14 GB.
[2025-09-13 08:02:01 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 08:02:01 TP0] Chunked prefix cache is turned on.
[2025-09-13 08:02:01 TP0] Init torch distributed begin.
[2025-09-13 08:02:01 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 08:02:01 TP0] Load weight begin. avail mem=17.14 GB
[2025-09-13 08:02:01 TP0] Detected fp8 checkpoint.
[2025-09-13 08:02:01 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 18/1024 [00:00<00:05, 171.97it/s]
Loading safetensors checkpoint shards:   4% Completed | 43/1024 [00:00<00:04, 215.06it/s]
Loading safetensors checkpoint shards:  11% Completed | 108/1024 [00:00<00:02, 408.04it/s]
Loading safetensors checkpoint shards:  17% Completed | 171/1024 [00:00<00:01, 493.51it/s]
Loading safetensors checkpoint shards:  23% Completed | 232/1024 [00:00<00:01, 534.02it/s]
Loading safetensors checkpoint shards:  29% Completed | 294/1024 [00:00<00:01, 562.47it/s]
Loading safetensors checkpoint shards:  35% Completed | 355/1024 [00:00<00:01, 576.19it/s]
Loading safetensors checkpoint shards:  41% Completed | 418/1024 [00:00<00:01, 590.21it/s]
Loading safetensors checkpoint shards:  47% Completed | 480/1024 [00:00<00:00, 597.26it/s]
Loading safetensors checkpoint shards:  53% Completed | 540/1024 [00:01<00:01, 469.20it/s]
Loading safetensors checkpoint shards:  58% Completed | 592/1024 [00:01<00:00, 439.71it/s]
Loading safetensors checkpoint shards:  64% Completed | 655/1024 [00:01<00:00, 485.75it/s]
Loading safetensors checkpoint shards:  70% Completed | 717/1024 [00:01<00:00, 519.04it/s]
Loading safetensors checkpoint shards:  76% Completed | 778/1024 [00:01<00:00, 542.01it/s]
Loading safetensors checkpoint shards:  82% Completed | 840/1024 [00:01<00:00, 561.25it/s]
Loading safetensors checkpoint shards:  88% Completed | 901/1024 [00:01<00:00, 573.60it/s]
Loading safetensors checkpoint shards:  94% Completed | 960/1024 [00:01<00:00, 571.72it/s]
Loading safetensors checkpoint shards:  99% Completed | 1018/1024 [00:02<00:00, 382.60it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 479.47it/s]

[2025-09-13 08:02:04 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.15 GB, mem usage=1.99 GB.
[2025-09-13 08:02:04 TP0] KV Cache is allocated. #tokens: 620345, KV size: 0.67 GB
[2025-09-13 08:02:04 TP0] Memory pool end. avail mem=14.48 GB
[2025-09-13 08:02:04 TP3] KV Cache is allocated. #tokens: 620345, KV size: 0.67 GB
[2025-09-13 08:02:04 TP2] KV Cache is allocated. #tokens: 620345, KV size: 0.67 GB
[2025-09-13 08:02:04 TP6] KV Cache is allocated. #tokens: 620345, KV size: 0.67 GB
[2025-09-13 08:02:04 TP1] KV Cache is allocated. #tokens: 620345, KV size: 0.67 GB
[2025-09-13 08:02:04 TP7] KV Cache is allocated. #tokens: 620345, KV size: 0.67 GB
[2025-09-13 08:02:04 TP4] KV Cache is allocated. #tokens: 620345, KV size: 0.67 GB
[2025-09-13 08:02:04 TP5] KV Cache is allocated. #tokens: 620345, KV size: 0.67 GB
[2025-09-13 08:02:04 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 08:02:04 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 08:02:04 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 08:02:04 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.91 GB
[2025-09-13 08:02:04 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 08:02:04 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 08:02:04 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.87 GB
[2025-09-13 08:02:04 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.11 GB
Capturing batches (bs=1 avail_mem=14.42 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:03<00:00,  2.73it/s][2025-09-13 08:02:11 TP7] Registering 120 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.42 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.32it/s]
[2025-09-13 08:02:11 TP3] Registering 120 cuda graph addresses
[2025-09-13 08:02:11 TP6] Registering 120 cuda graph addresses
[2025-09-13 08:02:11 TP0] Registering 120 cuda graph addresses
[2025-09-13 08:02:11 TP2] Registering 120 cuda graph addresses
[2025-09-13 08:02:11 TP1] Registering 120 cuda graph addresses
[2025-09-13 08:02:11 TP5] Registering 120 cuda graph addresses
[2025-09-13 08:02:11 TP4] Registering 120 cuda graph addresses
[2025-09-13 08:02:11 TP1] Capture draft cuda graph end. Time elapsed: 6.77 s. mem usage=0.49 GB. avail mem=14.38 GB.
[2025-09-13 08:02:11 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.38 GB
[2025-09-13 08:02:11 TP6] Capture draft cuda graph end. Time elapsed: 6.77 s. mem usage=0.49 GB. avail mem=14.38 GB.
[2025-09-13 08:02:11 TP5] Capture draft cuda graph end. Time elapsed: 6.77 s. mem usage=0.49 GB. avail mem=14.38 GB.
[2025-09-13 08:02:11 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.38 GB
[2025-09-13 08:02:11 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.38 GB
[2025-09-13 08:02:11 TP2] Capture draft cuda graph end. Time elapsed: 6.77 s. mem usage=0.49 GB. avail mem=14.38 GB.
[2025-09-13 08:02:11 TP4] Capture draft cuda graph end. Time elapsed: 6.77 s. mem usage=0.49 GB. avail mem=14.38 GB.
[2025-09-13 08:02:11 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.38 GB
[2025-09-13 08:02:11 TP0] Capture draft cuda graph end. Time elapsed: 6.77 s. mem usage=0.49 GB. avail mem=14.42 GB.
[2025-09-13 08:02:11 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.38 GB
[2025-09-13 08:02:11 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.42 GB
[2025-09-13 08:02:11 TP7] Capture draft cuda graph end. Time elapsed: 6.77 s. mem usage=0.49 GB. avail mem=14.62 GB.
[2025-09-13 08:02:11 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.62 GB
[2025-09-13 08:02:11 TP3] Capture draft cuda graph end. Time elapsed: 6.77 s. mem usage=0.49 GB. avail mem=14.38 GB.
[2025-09-13 08:02:11 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.38 GB
Capturing batches (bs=1 avail_mem=14.22 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 23.22it/s]
[2025-09-13 08:02:12 TP2] Registering 24 cuda graph addresses
[2025-09-13 08:02:12 TP0] Registering 24 cuda graph addresses
[2025-09-13 08:02:12 TP3] Registering 24 cuda graph addresses
[2025-09-13 08:02:12 TP1] Registering 24 cuda graph addresses
[2025-09-13 08:02:12 TP5] Registering 24 cuda graph addresses
[2025-09-13 08:02:12 TP6] Registering 24 cuda graph addresses
[2025-09-13 08:02:12 TP4] Registering 24 cuda graph addresses
[2025-09-13 08:02:12 TP7] Registering 24 cuda graph addresses
[2025-09-13 08:02:12 TP6] Capture draft extend cuda graph end. Time elapsed: 1.18 s. mem usage=0.21 GB. avail mem=14.18 GB.
[2025-09-13 08:02:12 TP4] Capture draft extend cuda graph end. Time elapsed: 1.18 s. mem usage=0.21 GB. avail mem=14.18 GB.
[2025-09-13 08:02:12 TP5] Capture draft extend cuda graph end. Time elapsed: 1.19 s. mem usage=0.21 GB. avail mem=14.18 GB.
[2025-09-13 08:02:12 TP1] Capture draft extend cuda graph end. Time elapsed: 1.19 s. mem usage=0.21 GB. avail mem=14.18 GB.
[2025-09-13 08:02:12 TP3] Capture draft extend cuda graph end. Time elapsed: 1.19 s. mem usage=0.21 GB. avail mem=14.18 GB.
[2025-09-13 08:02:12 TP7] Capture draft extend cuda graph end. Time elapsed: 1.19 s. mem usage=0.21 GB. avail mem=14.41 GB.
[2025-09-13 08:02:12 TP2] Capture draft extend cuda graph end. Time elapsed: 1.19 s. mem usage=0.21 GB. avail mem=14.18 GB.
[2025-09-13 08:02:12 TP0] Capture draft extend cuda graph end. Time elapsed: 1.19 s. mem usage=0.20 GB. avail mem=14.22 GB.
[2025-09-13 08:02:12 TP0] max_total_num_tokens=620345, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.22 GB
[2025-09-13 08:02:13] INFO:     Started server process [404718]
[2025-09-13 08:02:13] INFO:     Waiting for application startup.
[2025-09-13 08:02:13] INFO:     Application startup complete.
[2025-09-13 08:02:13] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 08:02:13] INFO:     127.0.0.1:55544 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 08:02:14] INFO:     127.0.0.1:55560 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 08:02:14 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:02:14 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:02:14 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28421.71it/s]
[2025-09-13 08:02:15] INFO:     127.0.0.1:55564 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:15] The server is fired up and ready to roll!
[2025-09-13 08:02:23 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:02:24] INFO:     127.0.0.1:47880 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 08:02:24] INFO:     127.0.0.1:47894 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:24 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 08:02:26] INFO:     127.0.0.1:47898 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:26] INFO:     127.0.0.1:47912 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:26 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:02:26] INFO:     127.0.0.1:47914 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:26] INFO:     127.0.0.1:47922 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:26] INFO:     127.0.0.1:47924 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:26] INFO:     127.0.0.1:47936 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:26] INFO:     127.0.0.1:47944 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:26] INFO:     127.0.0.1:47946 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:26 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 08:02:26 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:02:26 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:02:26 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:02:26 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:02:26 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:02:26 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:02:26 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:02:26 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:02:26 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 08:02:28 TP0] Decode batch. #running-req: 8, #token: 14706, token usage: 0.02, accept len: 3.46, cuda graph: True, gen throughput (token/s): 52.48, #queue-req: 0, 
[2025-09-13 08:02:29 TP0] Decode batch. #running-req: 8, #token: 16073, token usage: 0.03, accept len: 4.27, cuda graph: True, gen throughput (token/s): 917.01, #queue-req: 0, 
 12%|████████████████▍                                                                                                                  | 1/8 [00:04<00:32,  4.60s/it][2025-09-13 08:02:31 TP0] Decode batch. #running-req: 7, #token: 16742, token usage: 0.03, accept len: 4.08, cuda graph: True, gen throughput (token/s): 846.98, #queue-req: 0, 
 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 7/8 [00:06<00:00,  2.07it/s][2025-09-13 08:02:32 TP0] Decode batch. #running-req: 1, #token: 1483, token usage: 0.00, accept len: 3.94, cuda graph: True, gen throughput (token/s): 429.81, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.23it/s]
[2025-09-13 08:02:32] INFO:     127.0.0.1:47302 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  6.49      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4087      
Request throughput (req/s):              1.23      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         631.61    
Total token throughput (tok/s):          631.61    
Concurrency:                             6.85      
Accept length:                           3.97      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5550.88   
Median E2E Latency (ms):                 5522.82   
---------------Time to First Token----------------
Mean TTFT (ms):                          611.22    
Median TTFT (ms):                        725.54    
P99 TTFT (ms):                           726.08    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.67      
Median ITL (ms):                         7.19      
P95 ITL (ms):                            19.05     
P99 ITL (ms):                            37.64     
Max ITL (ms):                            746.25    
==================================================
[2025-09-13 08:02:32] INFO:     127.0.0.1:47308 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 08:02:32] INFO:     127.0.0.1:47310 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:32 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 08:02:34] INFO:     127.0.0.1:47326 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:34] INFO:     127.0.0.1:47340 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:34 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:02:34] INFO:     127.0.0.1:47350 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:34] INFO:     127.0.0.1:47356 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:34] INFO:     127.0.0.1:47362 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:34] INFO:     127.0.0.1:47366 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:34] INFO:     127.0.0.1:47382 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:34] INFO:     127.0.0.1:47398 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:34 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 08:02:35 TP0] Decode batch. #running-req: 8, #token: 14477, token usage: 0.02, accept len: 3.32, cuda graph: True, gen throughput (token/s): 240.63, #queue-req: 0, 
[2025-09-13 08:02:36 TP0] Decode batch. #running-req: 8, #token: 15811, token usage: 0.03, accept len: 4.17, cuda graph: True, gen throughput (token/s): 899.11, #queue-req: 0, 
[2025-09-13 08:02:38 TP0] Decode batch. #running-req: 8, #token: 17164, token usage: 0.03, accept len: 4.23, cuda graph: True, gen throughput (token/s): 902.51, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:00,  4.03s/it][2025-09-13 08:02:38] INFO:     127.0.0.1:50234 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:38 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:27,  1.99s/it][2025-09-13 08:02:38] INFO:     127.0.0.1:50244 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:38 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:17,  1.35s/it][2025-09-13 08:02:39] INFO:     127.0.0.1:50250 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:39 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 08:02:39] INFO:     127.0.0.1:50266 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:39 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:07,  1.40it/s][2025-09-13 08:02:39] INFO:     127.0.0.1:50280 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:39 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:06<00:06,  1.52it/s][2025-09-13 08:02:40] INFO:     127.0.0.1:50294 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:40 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 08:02:40 TP0] Decode batch. #running-req: 8, #token: 12795, token usage: 0.02, accept len: 3.94, cuda graph: True, gen throughput (token/s): 513.05, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:05,  1.72it/s][2025-09-13 08:02:40] INFO:     127.0.0.1:50304 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:40 TP0] Prefill batch. #new-seq: 1, #new-token: 1849, #cached-token: 875, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 50%|█████████████████████████████████████████████████████████████████                                                                 | 8/16 [00:06<00:04,  1.90it/s][2025-09-13 08:02:41] INFO:     127.0.0.1:50314 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:02:41 TP0] Prefill batch. #new-seq: 1, #new-token: 4161, #cached-token: 862, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 08:02:42 TP0] Decode batch. #running-req: 8, #token: 14998, token usage: 0.02, accept len: 3.56, cuda graph: True, gen throughput (token/s): 613.42, #queue-req: 0, 
 56%|█████████████████████████████████████████████████████████████████████████▏                                                        | 9/16 [00:09<00:07,  1.12s/it][2025-09-13 08:02:43 TP0] Decode batch. #running-req: 7, #token: 13994, token usage: 0.02, accept len: 4.79, cuda graph: True, gen throughput (token/s): 1009.68, #queue-req: 0, 
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                | 14/16 [00:10<00:00,  2.54it/s][2025-09-13 08:02:45 TP0] Decode batch. #running-req: 2, #token: 3684, token usage: 0.01, accept len: 4.66, cuda graph: True, gen throughput (token/s): 684.53, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.36it/s]
[2025-09-13 08:02:45] INFO:     127.0.0.1:50330 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.75     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8142      
Request throughput (req/s):              1.36      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         697.02    
Total token throughput (tok/s):          697.02    
Concurrency:                             7.25      
Accept length:                           4.06      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5327.90   
Median E2E Latency (ms):                 5204.22   
---------------Time to First Token----------------
Mean TTFT (ms):                          231.75    
Median TTFT (ms):                        273.23    
P99 TTFT (ms):                           278.84    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.97      
Median ITL (ms):                         6.31      
P95 ITL (ms):                            28.45     
P99 ITL (ms):                            53.21     
Max ITL (ms):                            272.56    
==================================================
[2025-09-13 08:02:46] INFO:     127.0.0.1:50346 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=48: batch_size=8, steps=6, topk=4, num_draft_tokens=12, speed=108.83 token/s, step_time=37.31 ms
devuser@7ed22f68dd76:/sgl-workspace/sglang$ python3 scripts/playground/bench_speculative.py --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --tp-size 8 --trust-remote-code --batch-size 8 --steps 3 --topk 1 --num_draft_tokens 3 --speculative-algorithm EAGLE --dataset-path /shared/junmingc/converted_prompts.txt
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 08:04:41.238000 410895 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:04:41.238000 410895 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
Loaded 180 prompts from /shared/junmingc/converted_prompts.txt
Start i=0: batch_size=8, steps=3, topk=1, num_draft_tokens=3
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-draft-tokens 3 --speculative-draft-model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --speculative-algorithm EAGLE --cuda-graph-max-bs 8 --mem-fraction-static 0.872 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 08:04:46.789000 411099 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:04:46.789000 411099 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
WARNING:sglang.srt.server_args:Overlap scheduler is disabled because of using eagle speculative decoding.
WARNING:sglang.srt.server_args:DeepSeek MTP does not require setting speculative_draft_model_path.
WARNING:sglang.srt.server_args:speculative_num_draft_tokens is adjusted to speculative_num_steps + 1 when speculative_eagle_topk == 1
[2025-09-13 08:04:47] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.872, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=350419993, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm='EAGLE', speculative_draft_model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', speculative_draft_model_revision=None, speculative_num_steps=3, speculative_eagle_topk=1, speculative_num_draft_tokens=4, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=True, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 08:04:47] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 08:04:55.750000 411400 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:04:55.750000 411400 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 08:04:56.007000 411403 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:04:56.007000 411403 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 08:04:56.267000 411402 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:04:56.267000 411402 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 08:04:56.315000 411405 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:04:56.315000 411405 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[2025-09-13 08:04:56 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 08:04:56 TP0] Chunked prefix cache is turned on.
[2025-09-13 08:04:56 TP0] Init torch distributed begin.
W0913 08:04:56.355000 411404 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:04:56.355000 411404 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 08:04:56.358000 411408 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:04:56.358000 411408 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 08:04:56.436000 411401 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:04:56.436000 411401 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 08:04:56.447000 411406 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:04:56.447000 411406 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 08:04:56.480000 411407 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:04:56.480000 411407 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 08:04:58 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 08:05:01 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 08:05:03 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 08:05:03 TP0] Detected fp8 checkpoint.
[2025-09-13 08:05:03 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 29/1024 [00:00<00:04, 240.74it/s]
Loading safetensors checkpoint shards:   5% Completed | 54/1024 [00:00<00:12, 79.32it/s]
Loading safetensors checkpoint shards:   7% Completed | 67/1024 [00:00<00:15, 61.43it/s]
Loading safetensors checkpoint shards:   7% Completed | 76/1024 [00:01<00:15, 61.90it/s]
Loading safetensors checkpoint shards:   8% Completed | 84/1024 [00:01<00:17, 52.55it/s]
Loading safetensors checkpoint shards:   9% Completed | 91/1024 [00:01<00:16, 55.32it/s]
Loading safetensors checkpoint shards:  10% Completed | 98/1024 [00:01<00:30, 30.72it/s]
Loading safetensors checkpoint shards:  10% Completed | 105/1024 [00:02<00:26, 35.23it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:24, 37.36it/s]
Loading safetensors checkpoint shards:  11% Completed | 117/1024 [00:02<00:22, 41.14it/s]
Loading safetensors checkpoint shards:  12% Completed | 123/1024 [00:02<00:21, 41.80it/s]
Loading safetensors checkpoint shards:  13% Completed | 129/1024 [00:02<00:20, 44.26it/s]
Loading safetensors checkpoint shards:  13% Completed | 135/1024 [00:02<00:19, 44.97it/s]
Loading safetensors checkpoint shards:  14% Completed | 142/1024 [00:02<00:17, 50.31it/s]
Loading safetensors checkpoint shards:  14% Completed | 148/1024 [00:02<00:17, 49.31it/s]
Loading safetensors checkpoint shards:  15% Completed | 155/1024 [00:03<00:16, 52.70it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:03<00:14, 58.42it/s]
Loading safetensors checkpoint shards:  17% Completed | 173/1024 [00:03<00:12, 66.16it/s]
Loading safetensors checkpoint shards:  18% Completed | 181/1024 [00:03<00:12, 69.34it/s]
Loading safetensors checkpoint shards:  19% Completed | 192/1024 [00:03<00:10, 78.84it/s]
Loading safetensors checkpoint shards:  20% Completed | 201/1024 [00:03<00:10, 80.97it/s]
Loading safetensors checkpoint shards:  21% Completed | 211/1024 [00:03<00:09, 86.15it/s]
Loading safetensors checkpoint shards:  21% Completed | 220/1024 [00:03<00:10, 76.34it/s]
Loading safetensors checkpoint shards:  22% Completed | 228/1024 [00:03<00:11, 68.65it/s]
Loading safetensors checkpoint shards:  23% Completed | 236/1024 [00:04<00:23, 33.57it/s]
Loading safetensors checkpoint shards:  24% Completed | 243/1024 [00:04<00:20, 37.75it/s]
Loading safetensors checkpoint shards:  25% Completed | 251/1024 [00:04<00:18, 42.25it/s]
Loading safetensors checkpoint shards:  25% Completed | 258/1024 [00:04<00:16, 47.10it/s]
Loading safetensors checkpoint shards:  26% Completed | 266/1024 [00:04<00:14, 52.56it/s]
Loading safetensors checkpoint shards:  27% Completed | 273/1024 [00:05<00:13, 54.76it/s]
Loading safetensors checkpoint shards:  27% Completed | 280/1024 [00:05<00:13, 57.21it/s]
Loading safetensors checkpoint shards:  28% Completed | 287/1024 [00:05<00:12, 56.76it/s]
Loading safetensors checkpoint shards:  29% Completed | 294/1024 [00:05<00:12, 57.20it/s]
Loading safetensors checkpoint shards:  29% Completed | 301/1024 [00:05<00:13, 54.94it/s]
Loading safetensors checkpoint shards:  30% Completed | 307/1024 [00:05<00:13, 54.46it/s]
Loading safetensors checkpoint shards:  31% Completed | 313/1024 [00:05<00:12, 55.08it/s]
Loading safetensors checkpoint shards:  31% Completed | 320/1024 [00:05<00:12, 57.97it/s]
Loading safetensors checkpoint shards:  32% Completed | 327/1024 [00:06<00:11, 58.93it/s]
Loading safetensors checkpoint shards:  33% Completed | 334/1024 [00:06<00:11, 60.33it/s]
Loading safetensors checkpoint shards:  33% Completed | 341/1024 [00:06<00:10, 62.62it/s]
Loading safetensors checkpoint shards:  34% Completed | 348/1024 [00:06<00:11, 57.36it/s]
Loading safetensors checkpoint shards:  35% Completed | 354/1024 [00:06<00:11, 56.35it/s]
Loading safetensors checkpoint shards:  35% Completed | 360/1024 [00:06<00:12, 54.75it/s]
Loading safetensors checkpoint shards:  36% Completed | 366/1024 [00:06<00:13, 49.27it/s]
Loading safetensors checkpoint shards:  36% Completed | 372/1024 [00:06<00:14, 46.54it/s]
Loading safetensors checkpoint shards:  37% Completed | 377/1024 [00:07<00:14, 44.16it/s]
Loading safetensors checkpoint shards:  37% Completed | 382/1024 [00:07<00:14, 44.61it/s]
Loading safetensors checkpoint shards:  38% Completed | 387/1024 [00:07<00:14, 43.67it/s]
Loading safetensors checkpoint shards:  38% Completed | 392/1024 [00:07<00:14, 43.77it/s]
Loading safetensors checkpoint shards:  39% Completed | 397/1024 [00:07<00:29, 20.96it/s]
Loading safetensors checkpoint shards:  39% Completed | 402/1024 [00:08<00:25, 24.33it/s]
Loading safetensors checkpoint shards:  40% Completed | 407/1024 [00:08<00:21, 28.65it/s]
Loading safetensors checkpoint shards:  40% Completed | 414/1024 [00:08<00:17, 35.33it/s]
Loading safetensors checkpoint shards:  41% Completed | 420/1024 [00:08<00:15, 38.81it/s]
Loading safetensors checkpoint shards:  42% Completed | 425/1024 [00:08<00:14, 40.00it/s]
Loading safetensors checkpoint shards:  42% Completed | 432/1024 [00:08<00:13, 44.27it/s]
Loading safetensors checkpoint shards:  43% Completed | 438/1024 [00:08<00:12, 47.27it/s]
Loading safetensors checkpoint shards:  43% Completed | 444/1024 [00:08<00:11, 48.59it/s]
Loading safetensors checkpoint shards:  44% Completed | 450/1024 [00:08<00:11, 49.16it/s]
Loading safetensors checkpoint shards:  45% Completed | 456/1024 [00:09<00:12, 45.18it/s]
Loading safetensors checkpoint shards:  45% Completed | 462/1024 [00:09<00:12, 46.64it/s]
Loading safetensors checkpoint shards:  46% Completed | 467/1024 [00:09<00:12, 43.27it/s]
Loading safetensors checkpoint shards:  46% Completed | 473/1024 [00:09<00:11, 46.02it/s]
Loading safetensors checkpoint shards:  47% Completed | 478/1024 [00:09<00:11, 45.63it/s]
Loading safetensors checkpoint shards:  47% Completed | 483/1024 [00:09<00:11, 45.52it/s]
Loading safetensors checkpoint shards:  48% Completed | 488/1024 [00:09<00:13, 40.81it/s]
Loading safetensors checkpoint shards:  48% Completed | 493/1024 [00:10<00:12, 42.45it/s]
Loading safetensors checkpoint shards:  49% Completed | 498/1024 [00:10<00:12, 41.47it/s]
Loading safetensors checkpoint shards:  49% Completed | 505/1024 [00:10<00:11, 46.67it/s]
Loading safetensors checkpoint shards:  50% Completed | 510/1024 [00:10<00:11, 45.55it/s]
Loading safetensors checkpoint shards:  50% Completed | 515/1024 [00:10<00:11, 45.93it/s]
Loading safetensors checkpoint shards:  51% Completed | 520/1024 [00:10<00:10, 46.14it/s]
Loading safetensors checkpoint shards:  51% Completed | 525/1024 [00:10<00:11, 45.34it/s]
Loading safetensors checkpoint shards:  52% Completed | 530/1024 [00:10<00:11, 44.78it/s]
Loading safetensors checkpoint shards:  52% Completed | 536/1024 [00:10<00:10, 46.58it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:11<00:10, 43.95it/s]
Loading safetensors checkpoint shards:  53% Completed | 546/1024 [00:11<00:11, 40.10it/s]
Loading safetensors checkpoint shards:  54% Completed | 551/1024 [00:11<00:11, 41.38it/s]
Loading safetensors checkpoint shards:  54% Completed | 556/1024 [00:11<00:11, 40.98it/s]
Loading safetensors checkpoint shards:  55% Completed | 561/1024 [00:11<00:11, 39.99it/s]
Loading safetensors checkpoint shards:  55% Completed | 566/1024 [00:11<00:11, 40.20it/s]
Loading safetensors checkpoint shards:  56% Completed | 571/1024 [00:11<00:10, 41.64it/s]
Loading safetensors checkpoint shards:  56% Completed | 576/1024 [00:11<00:10, 41.22it/s]
Loading safetensors checkpoint shards:  57% Completed | 581/1024 [00:12<00:10, 43.00it/s]
Loading safetensors checkpoint shards:  57% Completed | 586/1024 [00:12<00:10, 43.64it/s]
Loading safetensors checkpoint shards:  58% Completed | 591/1024 [00:12<00:10, 40.42it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:12<00:23, 17.93it/s]
Loading safetensors checkpoint shards:  59% Completed | 600/1024 [00:13<00:20, 20.39it/s]
Loading safetensors checkpoint shards:  59% Completed | 605/1024 [00:13<00:16, 24.69it/s]
Loading safetensors checkpoint shards:  59% Completed | 609/1024 [00:13<00:15, 26.74it/s]
Loading safetensors checkpoint shards:  60% Completed | 613/1024 [00:13<00:14, 29.14it/s]
Loading safetensors checkpoint shards:  60% Completed | 619/1024 [00:13<00:11, 34.33it/s]
Loading safetensors checkpoint shards:  61% Completed | 624/1024 [00:13<00:11, 35.29it/s]
Loading safetensors checkpoint shards:  61% Completed | 628/1024 [00:13<00:11, 35.58it/s]
Loading safetensors checkpoint shards:  62% Completed | 632/1024 [00:13<00:10, 36.16it/s]
Loading safetensors checkpoint shards:  62% Completed | 636/1024 [00:13<00:10, 36.02it/s]
Loading safetensors checkpoint shards:  62% Completed | 640/1024 [00:14<00:10, 35.68it/s]
Loading safetensors checkpoint shards:  63% Completed | 644/1024 [00:14<00:10, 36.73it/s]
Loading safetensors checkpoint shards:  63% Completed | 648/1024 [00:14<00:10, 37.27it/s]
Loading safetensors checkpoint shards:  64% Completed | 652/1024 [00:14<00:09, 37.82it/s]
Loading safetensors checkpoint shards:  64% Completed | 656/1024 [00:14<00:10, 35.57it/s]
Loading safetensors checkpoint shards:  64% Completed | 660/1024 [00:14<00:10, 35.28it/s]
Loading safetensors checkpoint shards:  65% Completed | 664/1024 [00:14<00:10, 35.17it/s]
Loading safetensors checkpoint shards:  65% Completed | 668/1024 [00:14<00:10, 34.91it/s]
Loading safetensors checkpoint shards:  66% Completed | 672/1024 [00:14<00:09, 35.92it/s]
Loading safetensors checkpoint shards:  66% Completed | 676/1024 [00:15<00:09, 36.03it/s]
Loading safetensors checkpoint shards:  66% Completed | 680/1024 [00:15<00:09, 36.91it/s]
Loading safetensors checkpoint shards:  67% Completed | 684/1024 [00:15<00:09, 37.14it/s]
Loading safetensors checkpoint shards:  67% Completed | 688/1024 [00:15<00:10, 32.19it/s]
Loading safetensors checkpoint shards:  68% Completed | 692/1024 [00:15<00:10, 31.25it/s]
Loading safetensors checkpoint shards:  68% Completed | 696/1024 [00:15<00:11, 28.13it/s]
Loading safetensors checkpoint shards:  68% Completed | 699/1024 [00:15<00:13, 24.42it/s]
Loading safetensors checkpoint shards:  69% Completed | 702/1024 [00:16<00:14, 22.74it/s]
Loading safetensors checkpoint shards:  69% Completed | 705/1024 [00:16<00:14, 22.16it/s]
Loading safetensors checkpoint shards:  69% Completed | 708/1024 [00:16<00:14, 22.26it/s]
Loading safetensors checkpoint shards:  69% Completed | 711/1024 [00:16<00:13, 23.87it/s]
Loading safetensors checkpoint shards:  70% Completed | 715/1024 [00:16<00:11, 26.25it/s]
Loading safetensors checkpoint shards:  70% Completed | 718/1024 [00:16<00:11, 25.78it/s]
Loading safetensors checkpoint shards:  70% Completed | 721/1024 [00:16<00:12, 24.11it/s]
Loading safetensors checkpoint shards:  71% Completed | 724/1024 [00:16<00:12, 24.78it/s]
Loading safetensors checkpoint shards:  71% Completed | 727/1024 [00:17<00:11, 25.31it/s]
Loading safetensors checkpoint shards:  71% Completed | 730/1024 [00:17<00:11, 25.69it/s]
Loading safetensors checkpoint shards:  72% Completed | 733/1024 [00:17<00:11, 25.87it/s]
Loading safetensors checkpoint shards:  72% Completed | 736/1024 [00:17<00:10, 26.28it/s]
Loading safetensors checkpoint shards:  72% Completed | 740/1024 [00:17<00:09, 29.55it/s]
Loading safetensors checkpoint shards:  73% Completed | 743/1024 [00:17<00:09, 29.59it/s]
Loading safetensors checkpoint shards:  73% Completed | 746/1024 [00:17<00:10, 27.70it/s]
Loading safetensors checkpoint shards:  73% Completed | 749/1024 [00:17<00:09, 28.23it/s]
Loading safetensors checkpoint shards:  73% Completed | 752/1024 [00:17<00:09, 27.90it/s]
Loading safetensors checkpoint shards:  74% Completed | 756/1024 [00:18<00:08, 30.14it/s]
Loading safetensors checkpoint shards:  74% Completed | 760/1024 [00:18<00:09, 27.08it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:18<00:09, 26.27it/s]
Loading safetensors checkpoint shards:  75% Completed | 766/1024 [00:18<00:09, 26.29it/s]
Loading safetensors checkpoint shards:  75% Completed | 769/1024 [00:18<00:09, 27.14it/s]
Loading safetensors checkpoint shards:  75% Completed | 773/1024 [00:18<00:08, 28.76it/s]
Loading safetensors checkpoint shards:  76% Completed | 777/1024 [00:18<00:08, 29.97it/s]
Loading safetensors checkpoint shards:  76% Completed | 781/1024 [00:18<00:07, 31.00it/s]
Loading safetensors checkpoint shards:  77% Completed | 785/1024 [00:19<00:07, 31.91it/s]
Loading safetensors checkpoint shards:  77% Completed | 789/1024 [00:19<00:08, 28.22it/s]
Loading safetensors checkpoint shards:  77% Completed | 792/1024 [00:19<00:08, 27.75it/s]
Loading safetensors checkpoint shards:  78% Completed | 795/1024 [00:19<00:08, 28.24it/s]
Loading safetensors checkpoint shards:  78% Completed | 798/1024 [00:19<00:08, 28.12it/s]
Loading safetensors checkpoint shards:  78% Completed | 802/1024 [00:19<00:07, 29.46it/s]
Loading safetensors checkpoint shards:  79% Completed | 806/1024 [00:19<00:07, 30.75it/s]
Loading safetensors checkpoint shards:  79% Completed | 810/1024 [00:19<00:06, 30.63it/s]
Loading safetensors checkpoint shards:  79% Completed | 814/1024 [00:20<00:16, 12.75it/s]
Loading safetensors checkpoint shards:  80% Completed | 818/1024 [00:20<00:13, 15.75it/s]
Loading safetensors checkpoint shards:  80% Completed | 822/1024 [00:20<00:10, 18.81it/s]
Loading safetensors checkpoint shards:  81% Completed | 826/1024 [00:21<00:08, 22.18it/s]
Loading safetensors checkpoint shards:  81% Completed | 830/1024 [00:21<00:07, 25.24it/s]
Loading safetensors checkpoint shards:  81% Completed | 834/1024 [00:21<00:06, 28.10it/s]
Loading safetensors checkpoint shards:  82% Completed | 838/1024 [00:21<00:06, 30.36it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:21<00:05, 32.18it/s]
Loading safetensors checkpoint shards:  83% Completed | 846/1024 [00:21<00:05, 32.61it/s]
Loading safetensors checkpoint shards:  83% Completed | 850/1024 [00:21<00:05, 33.43it/s]
Loading safetensors checkpoint shards:  83% Completed | 854/1024 [00:21<00:04, 34.27it/s]
Loading safetensors checkpoint shards:  84% Completed | 858/1024 [00:21<00:04, 34.38it/s]
Loading safetensors checkpoint shards:  84% Completed | 862/1024 [00:22<00:04, 34.93it/s]
Loading safetensors checkpoint shards:  85% Completed | 866/1024 [00:22<00:04, 35.27it/s]
Loading safetensors checkpoint shards:  85% Completed | 870/1024 [00:22<00:04, 35.40it/s]
Loading safetensors checkpoint shards:  85% Completed | 874/1024 [00:22<00:04, 35.05it/s]
Loading safetensors checkpoint shards:  86% Completed | 878/1024 [00:22<00:04, 35.18it/s]
Loading safetensors checkpoint shards:  86% Completed | 882/1024 [00:22<00:04, 35.44it/s]
Loading safetensors checkpoint shards:  87% Completed | 886/1024 [00:22<00:03, 35.73it/s]
Loading safetensors checkpoint shards:  87% Completed | 890/1024 [00:22<00:03, 35.73it/s]
Loading safetensors checkpoint shards:  87% Completed | 894/1024 [00:22<00:03, 36.01it/s]
Loading safetensors checkpoint shards:  88% Completed | 898/1024 [00:23<00:03, 36.38it/s]
Loading safetensors checkpoint shards:  88% Completed | 902/1024 [00:23<00:03, 36.85it/s]
Loading safetensors checkpoint shards:  88% Completed | 906/1024 [00:23<00:03, 37.20it/s]
Loading safetensors checkpoint shards:  89% Completed | 910/1024 [00:23<00:03, 37.21it/s]
Loading safetensors checkpoint shards:  89% Completed | 915/1024 [00:23<00:02, 38.27it/s]
Loading safetensors checkpoint shards:  90% Completed | 919/1024 [00:23<00:02, 38.36it/s]
Loading safetensors checkpoint shards:  90% Completed | 924/1024 [00:23<00:02, 39.59it/s]
Loading safetensors checkpoint shards:  91% Completed | 928/1024 [00:23<00:02, 39.64it/s]
Loading safetensors checkpoint shards:  91% Completed | 932/1024 [00:23<00:02, 39.00it/s]
Loading safetensors checkpoint shards:  91% Completed | 936/1024 [00:23<00:02, 38.79it/s]
Loading safetensors checkpoint shards:  92% Completed | 940/1024 [00:24<00:02, 38.23it/s]
Loading safetensors checkpoint shards:  92% Completed | 944/1024 [00:24<00:02, 37.31it/s]
Loading safetensors checkpoint shards:  93% Completed | 948/1024 [00:24<00:02, 36.17it/s]
Loading safetensors checkpoint shards:  93% Completed | 952/1024 [00:24<00:02, 35.98it/s]
Loading safetensors checkpoint shards:  93% Completed | 956/1024 [00:24<00:01, 36.18it/s]
Loading safetensors checkpoint shards:  94% Completed | 960/1024 [00:24<00:01, 36.51it/s]
Loading safetensors checkpoint shards:  94% Completed | 964/1024 [00:24<00:01, 34.77it/s]
Loading safetensors checkpoint shards:  95% Completed | 969/1024 [00:24<00:01, 35.91it/s]
Loading safetensors checkpoint shards:  95% Completed | 973/1024 [00:25<00:01, 36.11it/s]
Loading safetensors checkpoint shards:  96% Completed | 978/1024 [00:25<00:01, 38.33it/s]
Loading safetensors checkpoint shards:  96% Completed | 985/1024 [00:25<00:00, 46.46it/s]
Loading safetensors checkpoint shards:  99% Completed | 1012/1024 [00:25<00:00, 107.87it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 40.35it/s]
 
[2025-09-13 08:05:29 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 08:05:31 TP1] KV Cache is allocated. #tokens: 620113, KV size: 40.58 GB
[2025-09-13 08:05:31 TP5] KV Cache is allocated. #tokens: 620113, KV size: 40.58 GB
[2025-09-13 08:05:31 TP2] KV Cache is allocated. #tokens: 620113, KV size: 40.58 GB
[2025-09-13 08:05:31 TP0] KV Cache is allocated. #tokens: 620113, KV size: 40.58 GB
[2025-09-13 08:05:31 TP0] Memory pool end. avail mem=17.66 GB
[2025-09-13 08:05:31 TP3] KV Cache is allocated. #tokens: 620113, KV size: 40.58 GB
[2025-09-13 08:05:31 TP7] KV Cache is allocated. #tokens: 620113, KV size: 40.58 GB
[2025-09-13 08:05:31 TP4] KV Cache is allocated. #tokens: 620113, KV size: 40.58 GB
[2025-09-13 08:05:31 TP6] KV Cache is allocated. #tokens: 620113, KV size: 40.58 GB
[2025-09-13 08:05:32 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=17.56 GB
[2025-09-13 08:05:32 TP0] Capture cuda graph bs [1, 2, 3, 4, 5, 6, 7, 8]
Capturing batches (bs=8 avail_mem=17.53 GB):   0%|                                                                                              | 0/8 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 08:05:33 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:05:33 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     [2025-09-13 08:05:33 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 08:05:33 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 08:05:33 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 08:05:33 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 08:05:33 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 08:05:33 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 08:05:33 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26288.39it/s]
[2025-09-13 08:05:33 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:05:33 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27566.39it/s]
[2025-09-13 08:05:34 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:05:34 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28779.77it/s]
[2025-09-13 08:05:35 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:05:35 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27099.56it/s]
[2025-09-13 08:05:35 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:05:35 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28046.09it/s]
[2025-09-13 08:05:36 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=17.25 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.18it/s]
[2025-09-13 08:05:39 TP3] Registering 984 cuda graph addresses
[2025-09-13 08:05:39 TP4] Registering 984 cuda graph addresses
[2025-09-13 08:05:39 TP5] Registering 984 cuda graph addresses
[2025-09-13 08:05:39 TP6] Registering 984 cuda graph addresses
[2025-09-13 08:05:39 TP2] Registering 984 cuda graph addresses
[2025-09-13 08:05:39 TP1] Registering 984 cuda graph addresses
[2025-09-13 08:05:39 TP0] Registering 984 cuda graph addresses
[2025-09-13 08:05:39 TP7] Registering 984 cuda graph addresses
[2025-09-13 08:05:39 TP0] Capture cuda graph end. Time elapsed: 7.47 s. mem usage=0.34 GB. avail mem=17.23 GB.
[2025-09-13 08:05:39 TP0] MLA optimization is turned on. Use fa3 backend.
[2025-09-13 08:05:39 TP0] Chunked prefix cache is turned on.
[2025-09-13 08:05:39 TP0] Init torch distributed begin.
[2025-09-13 08:05:39 TP0] Init torch distributed ends. mem usage=0.00 GB
[2025-09-13 08:05:39 TP0] Load weight begin. avail mem=17.23 GB
[2025-09-13 08:05:39 TP0] Detected fp8 checkpoint.
[2025-09-13 08:05:39 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 20/1024 [00:00<00:05, 193.14it/s]
Loading safetensors checkpoint shards:   5% Completed | 47/1024 [00:00<00:04, 237.39it/s]
Loading safetensors checkpoint shards:  10% Completed | 106/1024 [00:00<00:02, 395.93it/s]
Loading safetensors checkpoint shards:  16% Completed | 167/1024 [00:00<00:01, 479.06it/s]
Loading safetensors checkpoint shards:  22% Completed | 228/1024 [00:00<00:01, 525.40it/s]
Loading safetensors checkpoint shards:  28% Completed | 290/1024 [00:00<00:01, 554.13it/s]
Loading safetensors checkpoint shards:  34% Completed | 352/1024 [00:00<00:01, 572.85it/s]
Loading safetensors checkpoint shards:  40% Completed | 414/1024 [00:00<00:01, 585.06it/s]
Loading safetensors checkpoint shards:  46% Completed | 476/1024 [00:00<00:00, 594.47it/s]
Loading safetensors checkpoint shards:  53% Completed | 538/1024 [00:01<00:00, 600.16it/s]
Loading safetensors checkpoint shards:  59% Completed | 600/1024 [00:01<00:00, 603.69it/s]
Loading safetensors checkpoint shards:  65% Completed | 661/1024 [00:01<00:00, 600.33it/s]
Loading safetensors checkpoint shards:  71% Completed | 722/1024 [00:01<00:00, 594.09it/s]
Loading safetensors checkpoint shards:  76% Completed | 782/1024 [00:01<00:00, 587.36it/s]
Loading safetensors checkpoint shards:  82% Completed | 841/1024 [00:01<00:00, 587.23it/s]
Loading safetensors checkpoint shards:  88% Completed | 900/1024 [00:01<00:00, 583.36it/s]
Loading safetensors checkpoint shards:  94% Completed | 959/1024 [00:01<00:00, 581.54it/s]
Loading safetensors checkpoint shards:  99% Completed | 1018/1024 [00:01<00:00, 403.64it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:02<00:00, 511.98it/s]

[2025-09-13 08:05:42 TP0] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=15.24 GB, mem usage=1.98 GB.
[2025-09-13 08:05:42 TP5] KV Cache is allocated. #tokens: 620113, KV size: 0.67 GB
[2025-09-13 08:05:42 TP6] KV Cache is allocated. #tokens: 620113, KV size: 0.67 GB
[2025-09-13 08:05:42 TP3] KV Cache is allocated. #tokens: 620113, KV size: 0.67 GB
[2025-09-13 08:05:42 TP1] KV Cache is allocated. #tokens: 620113, KV size: 0.67 GB
[2025-09-13 08:05:42 TP2] KV Cache is allocated. #tokens: 620113, KV size: 0.67 GB
[2025-09-13 08:05:42 TP4] KV Cache is allocated. #tokens: 620113, KV size: 0.67 GB
[2025-09-13 08:05:42 TP7] KV Cache is allocated. #tokens: 620113, KV size: 0.67 GB
[2025-09-13 08:05:42 TP0] KV Cache is allocated. #tokens: 620113, KV size: 0.67 GB
[2025-09-13 08:05:42 TP0] Memory pool end. avail mem=14.58 GB
[2025-09-13 08:05:42 TP0] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.01 GB
[2025-09-13 08:05:42 TP6] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.97 GB
[2025-09-13 08:05:42 TP2] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.97 GB
[2025-09-13 08:05:42 TP4] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.97 GB
[2025-09-13 08:05:42 TP7] Capture draft cuda graph begin. This can take up to several minutes. avail mem=15.20 GB
[2025-09-13 08:05:42 TP3] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.97 GB
[2025-09-13 08:05:42 TP1] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.97 GB
[2025-09-13 08:05:42 TP5] Capture draft cuda graph begin. This can take up to several minutes. avail mem=14.97 GB
Capturing batches (bs=1 avail_mem=14.83 GB):  62%|█████████████████████████████████████████████████████▊                                | 5/8 [00:01<00:00,  5.09it/s][2025-09-13 08:05:45 TP6] Registering 48 cuda graph addresses
[2025-09-13 08:05:45 TP1] Registering 48 cuda graph addresses
[2025-09-13 08:05:45 TP5] Registering 48 cuda graph addresses
[2025-09-13 08:05:45 TP2] Registering 48 cuda graph addresses
[2025-09-13 08:05:45 TP3] Registering 48 cuda graph addresses
[2025-09-13 08:05:45 TP7] Registering 48 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.83 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:02<00:00,  3.54it/s]
[2025-09-13 08:05:45 TP4] Registering 48 cuda graph addresses
[2025-09-13 08:05:45 TP0] Registering 48 cuda graph addresses
[2025-09-13 08:05:45 TP6] Capture draft cuda graph end. Time elapsed: 3.14 s. mem usage=0.18 GB. avail mem=14.79 GB.
[2025-09-13 08:05:45 TP0] Capture draft cuda graph end. Time elapsed: 3.14 s. mem usage=0.18 GB. avail mem=14.83 GB.
[2025-09-13 08:05:45 TP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.83 GB
[2025-09-13 08:05:45 TP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 08:05:45 TP5] Capture draft cuda graph end. Time elapsed: 3.14 s. mem usage=0.18 GB. avail mem=14.79 GB.
[2025-09-13 08:05:45 TP4] Capture draft cuda graph end. Time elapsed: 3.14 s. mem usage=0.18 GB. avail mem=14.79 GB.
[2025-09-13 08:05:45 TP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 08:05:45 TP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 08:05:45 TP3] Capture draft cuda graph end. Time elapsed: 3.14 s. mem usage=0.18 GB. avail mem=14.79 GB.
[2025-09-13 08:05:45 TP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 08:05:45 TP1] Capture draft cuda graph end. Time elapsed: 3.14 s. mem usage=0.18 GB. avail mem=14.79 GB.
[2025-09-13 08:05:45 TP7] Capture draft cuda graph end. Time elapsed: 3.14 s. mem usage=0.18 GB. avail mem=15.02 GB.
[2025-09-13 08:05:45 TP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
[2025-09-13 08:05:45 TP2] Capture draft cuda graph end. Time elapsed: 3.14 s. mem usage=0.18 GB. avail mem=14.79 GB.
[2025-09-13 08:05:45 TP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=15.02 GB
[2025-09-13 08:05:45 TP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=14.79 GB
Capturing batches (bs=1 avail_mem=14.66 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 6/8 [00:00<00:00, 58.98it/s][2025-09-13 08:05:46 TP2] Registering 24 cuda graph addresses
[2025-09-13 08:05:46 TP6] Registering 24 cuda graph addresses
[2025-09-13 08:05:46 TP3] Registering 24 cuda graph addresses
Capturing batches (bs=1 avail_mem=14.66 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 55.01it/s]
[2025-09-13 08:05:46 TP5] Registering 24 cuda graph addresses
[2025-09-13 08:05:46 TP7] Registering 24 cuda graph addresses
[2025-09-13 08:05:46 TP1] Registering 24 cuda graph addresses
[2025-09-13 08:05:46 TP0] Registering 24 cuda graph addresses
[2025-09-13 08:05:46 TP4] Registering 24 cuda graph addresses
[2025-09-13 08:05:46 TP4] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.17 GB. avail mem=14.62 GB.
[2025-09-13 08:05:46 TP2] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.17 GB. avail mem=14.62 GB.
[2025-09-13 08:05:46 TP6] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.17 GB. avail mem=14.62 GB.
[2025-09-13 08:05:46 TP7] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.17 GB. avail mem=14.85 GB.
[2025-09-13 08:05:46 TP5] Capture draft extend cuda graph end. Time elapsed: 1.10 s. mem usage=0.17 GB. avail mem=14.62 GB.
[2025-09-13 08:05:46 TP1] Capture draft extend cuda graph end. Time elapsed: 1.09 s. mem usage=0.17 GB. avail mem=14.62 GB.
[2025-09-13 08:05:46 TP3] Capture draft extend cuda graph end. Time elapsed: 1.10 s. mem usage=0.17 GB. avail mem=14.62 GB.
[2025-09-13 08:05:46 TP0] Capture draft extend cuda graph end. Time elapsed: 1.10 s. mem usage=0.17 GB. avail mem=14.66 GB.
[2025-09-13 08:05:46 TP0] max_total_num_tokens=620113, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=14.66 GB
[2025-09-13 08:05:47] INFO:     Started server process [411099]
[2025-09-13 08:05:47] INFO:     Waiting for application startup.
[2025-09-13 08:05:47] INFO:     Application startup complete.
[2025-09-13 08:05:47] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 08:05:48] INFO:     127.0.0.1:55562 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 08:05:48 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:05:48 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:05:48 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28548.47it/s]
[2025-09-13 08:05:49] INFO:     127.0.0.1:55576 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:05:49] The server is fired up and ready to roll!
[2025-09-13 08:05:51 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:05:52] INFO:     127.0.0.1:55592 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 08:05:52] INFO:     127.0.0.1:55608 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:05:52 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 08:05:54] INFO:     127.0.0.1:55618 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:05:54] INFO:     127.0.0.1:55630 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:05:54 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:05:54] INFO:     127.0.0.1:55636 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:05:54] INFO:     127.0.0.1:55640 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:05:54] INFO:     127.0.0.1:55650 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:05:54] INFO:     127.0.0.1:55656 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:05:54] INFO:     127.0.0.1:55658 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:05:54] INFO:     127.0.0.1:55668 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:05:54 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 08:05:54 TP0] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:05:54 TP1] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:05:54 TP6] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:05:54 TP4] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:05:54 TP2] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:05:54 TP5] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:05:54 TP3] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:05:54 TP7] length of new_indices: 2 != length of topk_p: 3, this should not happen
[2025-09-13 08:05:54 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 08:05:55 TP0] Decode batch. #running-req: 8, #token: 14473, token usage: 0.02, accept len: 2.64, cuda graph: True, gen throughput (token/s): 66.56, #queue-req: 0, 
[2025-09-13 08:05:56 TP0] Decode batch. #running-req: 8, #token: 15383, token usage: 0.02, accept len: 2.84, cuda graph: True, gen throughput (token/s): 837.56, #queue-req: 0, 
[2025-09-13 08:05:57 TP0] Decode batch. #running-req: 8, #token: 16344, token usage: 0.03, accept len: 3.00, cuda graph: True, gen throughput (token/s): 882.15, #queue-req: 0, 
[2025-09-13 08:05:58 TP0] Decode batch. #running-req: 8, #token: 17267, token usage: 0.03, accept len: 2.88, cuda graph: True, gen throughput (token/s): 846.53, #queue-req: 0, 
 62%|█████████████████████████████████████████████████████████████████████████████████▉                                                 | 5/8 [00:05<00:01,  1.61it/s][2025-09-13 08:05:59 TP0] Decode batch. #running-req: 3, #token: 2175, token usage: 0.00, accept len: 3.06, cuda graph: True, gen throughput (token/s): 718.60, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:05<00:00,  1.38it/s]
[2025-09-13 08:05:59] INFO:     127.0.0.1:58666 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  5.81      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4081      
Request throughput (req/s):              1.38      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         704.52    
Total token throughput (tok/s):          704.52    
Concurrency:                             7.49      
Accept length:                           2.89      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5441.61   
Median E2E Latency (ms):                 5507.10   
---------------Time to First Token----------------
Mean TTFT (ms):                          620.44    
Median TTFT (ms):                        738.34    
P99 TTFT (ms):                           738.97    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           9.43      
Median ITL (ms):                         6.87      
P95 ITL (ms):                            25.26     
P99 ITL (ms):                            27.53     
Max ITL (ms):                            646.86    
==================================================
[2025-09-13 08:05:59] INFO:     127.0.0.1:58674 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 08:05:59] INFO:     127.0.0.1:58690 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:05:59 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 08:06:01] INFO:     127.0.0.1:58700 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:06:01] INFO:     127.0.0.1:58710 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:06:01 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:06:01] INFO:     127.0.0.1:58724 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:06:01] INFO:     127.0.0.1:58726 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:06:01] INFO:     127.0.0.1:58736 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:06:01] INFO:     127.0.0.1:58746 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:06:01] INFO:     127.0.0.1:58762 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:06:01] INFO:     127.0.0.1:58764 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:06:01 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 08:06:02 TP0] Decode batch. #running-req: 8, #token: 14347, token usage: 0.02, accept len: 2.56, cuda graph: True, gen throughput (token/s): 209.39, #queue-req: 0, 
[2025-09-13 08:06:03 TP0] Decode batch. #running-req: 8, #token: 15277, token usage: 0.02, accept len: 2.91, cuda graph: True, gen throughput (token/s): 863.07, #queue-req: 0, 
[2025-09-13 08:06:04 TP0] Decode batch. #running-req: 8, #token: 16229, token usage: 0.03, accept len: 2.98, cuda graph: True, gen throughput (token/s): 868.72, #queue-req: 0, 
[2025-09-13 08:06:05 TP0] Decode batch. #running-req: 8, #token: 17143, token usage: 0.03, accept len: 2.86, cuda graph: True, gen throughput (token/s): 845.03, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:04<01:05,  4.39s/it][2025-09-13 08:06:05] INFO:     127.0.0.1:58778 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:06:05 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 12%|████████████████▎                                                                                                                 | 2/16 [00:04<00:28,  2.04s/it][2025-09-13 08:06:06] INFO:     127.0.0.1:58790 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:06:06 TP0] Prefill batch. #new-seq: 1, #new-token: 1997, #cached-token: 876, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 19%|████████████████████████▍                                                                                                         | 3/16 [00:05<00:17,  1.32s/it][2025-09-13 08:06:06] INFO:     127.0.0.1:58798 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:06:06 TP0] Prefill batch. #new-seq: 1, #new-token: 403, #cached-token: 885, token usage: 0.03, #running-req: 7, #queue-req: 0, 
 25%|████████████████████████████████▌                                                                                                 | 4/16 [00:05<00:10,  1.15it/s][2025-09-13 08:06:06] INFO:     127.0.0.1:58804 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:06:06 TP0] Prefill batch. #new-seq: 1, #new-token: 84, #cached-token: 857, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 08:06:07 TP0] Decode batch. #running-req: 8, #token: 13630, token usage: 0.02, accept len: 3.03, cuda graph: True, gen throughput (token/s): 592.45, #queue-req: 0, 
 31%|████████████████████████████████████████▋                                                                                         | 5/16 [00:05<00:07,  1.49it/s][2025-09-13 08:06:07] INFO:     127.0.0.1:58810 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:06:07 TP0] Prefill batch. #new-seq: 1, #new-token: 2739, #cached-token: 848, token usage: 0.02, #running-req: 7, #queue-req: 0, 
 38%|████████████████████████████████████████████████▊                                                                                 | 6/16 [00:06<00:05,  1.85it/s][2025-09-13 08:06:07] INFO:     127.0.0.1:58814 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:06:07 TP0] Prefill batch. #new-seq: 1, #new-token: 520, #cached-token: 876, token usage: 0.01, #running-req: 7, #queue-req: 0, 
 44%|████████████████████████████████████████████████████████▉                                                                         | 7/16 [00:06<00:04,  2.22it/s][2025-09-13 08:06:07] INFO:     127.0.0.1:58822 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:06:07] INFO:     127.0.0.1:58834 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:06:07 TP0] Prefill batch. #new-seq: 2, #new-token: 6010, #cached-token: 1737, token usage: 0.01, #running-req: 6, #queue-req: 0, 
[2025-09-13 08:06:08 TP0] Decode batch. #running-req: 8, #token: 14399, token usage: 0.02, accept len: 2.65, cuda graph: True, gen throughput (token/s): 500.78, #queue-req: 0, 
[2025-09-13 08:06:09 TP0] Decode batch. #running-req: 8, #token: 15313, token usage: 0.02, accept len: 2.86, cuda graph: True, gen throughput (token/s): 837.72, #queue-req: 0, 
[2025-09-13 08:06:10 TP0] Decode batch. #running-req: 8, #token: 16343, token usage: 0.03, accept len: 3.22, cuda graph: True, gen throughput (token/s): 942.72, #queue-req: 0, 
 56%|█████████████████████████████████████████████████████████████████████████▏                                                        | 9/16 [00:09<00:07,  1.07s/it][2025-09-13 08:06:11 TP0] Decode batch. #running-req: 7, #token: 14783, token usage: 0.02, accept len: 3.27, cuda graph: True, gen throughput (token/s): 912.55, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.42it/s]
[2025-09-13 08:06:12] INFO:     127.0.0.1:60394 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  11.31     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8140      
Request throughput (req/s):              1.42      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         724.53    
Total token throughput (tok/s):          724.53    
Concurrency:                             7.60      
Accept length:                           2.92      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   5367.81   
Median E2E Latency (ms):                 5231.03   
---------------Time to First Token----------------
Mean TTFT (ms):                          257.01    
Median TTFT (ms):                        325.57    
P99 TTFT (ms):                           330.57    
---------------Inter-Token Latency----------------
Mean ITL (ms):                           10.00     
Median ITL (ms):                         6.85      
P95 ITL (ms):                            26.93     
P99 ITL (ms):                            41.43     
Max ITL (ms):                            334.01    
==================================================
[2025-09-13 08:06:12] INFO:     127.0.0.1:60410 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=0: batch_size=8, steps=3, topk=1, num_draft_tokens=3, speed=107.55 token/s, step_time=27.18 ms
^[[Adevuser@7ed22f68dd76:/sgl-workspace/sglang$ python3 scripts/playground/bench_speculative.py --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --tp-size 8 --trust-remote-code --batch-size 8 steps 0 --topk 0 --num_draft_tokens 0 --dataset-path /shared/junmingc/converted_prompts.txt
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
usage: bench_speculative.py [-h] --model-path MODEL_PATH [--tokenizer-path TOKENIZER_PATH] [--tokenizer-mode {auto,slow}]
                            [--tokenizer-worker-num TOKENIZER_WORKER_NUM] [--skip-tokenizer-init]
                            [--load-format {auto,pt,safetensors,npcache,dummy,sharded_state,gguf,bitsandbytes,layered,remote}]
                            [--model-loader-extra-config MODEL_LOADER_EXTRA_CONFIG] [--trust-remote-code] [--context-length CONTEXT_LENGTH] [--is-embedding]
                            [--enable-multimodal] [--revision REVISION] [--model-impl MODEL_IMPL] [--host HOST] [--port PORT] [--skip-server-warmup]
                            [--warmups WARMUPS] [--nccl-port NCCL_PORT] [--dtype {auto,half,float16,bfloat16,float,float32}]
                            [--quantization {awq,fp8,gptq,marlin,gptq_marlin,awq_marlin,bitsandbytes,gguf,modelopt,modelopt_fp4,petit_nvfp4,w8a8_int8,w8a8_fp8,moe_wna16,qoq,w4afp8,mxfp4}]
                            [--quantization-param-path QUANTIZATION_PARAM_PATH] [--kv-cache-dtype {auto,fp8_e5m2,fp8_e4m3}]
                            [--mem-fraction-static MEM_FRACTION_STATIC] [--max-running-requests MAX_RUNNING_REQUESTS] [--max-queued-requests MAX_QUEUED_REQUESTS]
                            [--max-total-tokens MAX_TOTAL_TOKENS] [--chunked-prefill-size CHUNKED_PREFILL_SIZE] [--max-prefill-tokens MAX_PREFILL_TOKENS]
                            [--schedule-policy {lpm,random,fcfs,dfs-weight,lof}] [--schedule-conservativeness SCHEDULE_CONSERVATIVENESS] [--page-size PAGE_SIZE]
                            [--hybrid-kvcache-ratio [HYBRID_KVCACHE_RATIO]] [--swa-full-tokens-ratio SWA_FULL_TOKENS_RATIO] [--disable-hybrid-swa-memory]
                            [--device DEVICE] [--tensor-parallel-size TENSOR_PARALLEL_SIZE] [--pipeline-parallel-size PIPELINE_PARALLEL_SIZE]
                            [--max-micro-batch-size MAX_MICRO_BATCH_SIZE] [--stream-interval STREAM_INTERVAL] [--stream-output] [--random-seed RANDOM_SEED]
                            [--constrained-json-whitespace-pattern CONSTRAINED_JSON_WHITESPACE_PATTERN] [--watchdog-timeout WATCHDOG_TIMEOUT]
                            [--dist-timeout DIST_TIMEOUT] [--download-dir DOWNLOAD_DIR] [--base-gpu-id BASE_GPU_ID] [--gpu-id-step GPU_ID_STEP] [--sleep-on-idle]
                            [--log-level LOG_LEVEL] [--log-level-http LOG_LEVEL_HTTP] [--log-requests] [--log-requests-level {0,1,2,3}]
                            [--crash-dump-folder CRASH_DUMP_FOLDER] [--show-time-cost] [--enable-metrics] [--enable-metrics-for-all-schedulers]
                            [--bucket-time-to-first-token BUCKET_TIME_TO_FIRST_TOKEN [BUCKET_TIME_TO_FIRST_TOKEN ...]]
                            [--bucket-inter-token-latency BUCKET_INTER_TOKEN_LATENCY [BUCKET_INTER_TOKEN_LATENCY ...]]
                            [--bucket-e2e-request-latency BUCKET_E2E_REQUEST_LATENCY [BUCKET_E2E_REQUEST_LATENCY ...]] [--collect-tokens-histogram]
                            [--prompt-tokens-buckets PROMPT_TOKENS_BUCKETS [PROMPT_TOKENS_BUCKETS ...]]
                            [--generation-tokens-buckets GENERATION_TOKENS_BUCKETS [GENERATION_TOKENS_BUCKETS ...]]
                            [--gc-warning-threshold-secs GC_WARNING_THRESHOLD_SECS] [--decode-log-interval DECODE_LOG_INTERVAL]
                            [--enable-request-time-stats-logging] [--kv-events-config KV_EVENTS_CONFIG] [--api-key API_KEY] [--served-model-name SERVED_MODEL_NAME]
                            [--weight-version WEIGHT_VERSION] [--chat-template CHAT_TEMPLATE] [--completion-template COMPLETION_TEMPLATE]
                            [--file-storage-path FILE_STORAGE_PATH] [--enable-cache-report]
                            [--reasoning-parser {deepseek-r1,deepseek-v3,glm45,gpt-oss,kimi,qwen3,qwen3-thinking,step3}]
                            [--tool-call-parser {llama3,qwen25,mistral,deepseekv3,deepseekv31,pythonic,kimi_k2,qwen3_coder,glm45,step3,gpt-oss}]
                            [--tool-server TOOL_SERVER] [--data-parallel-size DATA_PARALLEL_SIZE]
                            [--load-balance-method {round_robin,shortest_queue,minimum_tokens}] [--prefill-round-robin-balance] [--dist-init-addr DIST_INIT_ADDR]
                            [--nnodes NNODES] [--node-rank NODE_RANK] [--json-model-override-args JSON_MODEL_OVERRIDE_ARGS]
                            [--preferred-sampling-params PREFERRED_SAMPLING_PARAMS] [--enable-lora] [--max-lora-rank MAX_LORA_RANK]
                            [--lora-target-modules [{q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj,qkv_proj,gate_up_proj,all} ...]]
                            [--lora-paths [LORA_PATHS ...]] [--max-loras-per-batch MAX_LORAS_PER_BATCH] [--max-loaded-loras MAX_LOADED_LORAS]
                            [--lora-backend LORA_BACKEND]
                            [--attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,hybrid_linear_attn,aiter,wave,intel_amx,ascend}]
                            [--prefill-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,hybrid_linear_attn,aiter,wave,intel_amx,ascend}]
                            [--decode-attention-backend {triton,torch_native,cutlass_mla,fa3,flashinfer,flashmla,trtllm_mla,trtllm_mha,dual_chunk_flash_attn,hybrid_linear_attn,aiter,wave,intel_amx,ascend}]
                            [--sampling-backend {flashinfer,pytorch}] [--grammar-backend {xgrammar,outlines,llguidance,none}]
                            [--mm-attention-backend {sdpa,fa3,triton_attn}] [--speculative-algorithm {EAGLE,EAGLE3,NEXTN,STANDALONE}]
                            [--speculative-draft-model-path SPECULATIVE_DRAFT_MODEL_PATH] [--speculative-draft-model-revision SPECULATIVE_DRAFT_MODEL_REVISION]
                            [--speculative-num-steps SPECULATIVE_NUM_STEPS] [--speculative-eagle-topk SPECULATIVE_EAGLE_TOPK]
                            [--speculative-num-draft-tokens SPECULATIVE_NUM_DRAFT_TOKENS]
                            [--speculative-accept-threshold-single SPECULATIVE_ACCEPT_THRESHOLD_SINGLE]
                            [--speculative-accept-threshold-acc SPECULATIVE_ACCEPT_THRESHOLD_ACC] [--speculative-token-map SPECULATIVE_TOKEN_MAP]
                            [--speculative-attention-mode {prefill,decode}] [--expert-parallel-size EXPERT_PARALLEL_SIZE] [--moe-a2a-backend {none,deepep}]
                            [--moe-runner-backend {auto,triton,triton_kernel,flashinfer_trtllm,flashinfer_cutlass,flashinfer_mxfp4}]
                            [--flashinfer-mxfp4-moe-precision {default,bf16}] [--enable-flashinfer-allreduce-fusion] [--deepep-mode {normal,low_latency,auto}]
                            [--ep-num-redundant-experts EP_NUM_REDUNDANT_EXPERTS] [--ep-dispatch-algorithm EP_DISPATCH_ALGORITHM]
                            [--init-expert-location INIT_EXPERT_LOCATION] [--enable-eplb] [--eplb-algorithm EPLB_ALGORITHM]
                            [--eplb-rebalance-num-iterations EPLB_REBALANCE_NUM_ITERATIONS] [--eplb-rebalance-layers-per-chunk EPLB_REBALANCE_LAYERS_PER_CHUNK]
                            [--eplb-min-rebalancing-utilization-threshold EPLB_MIN_REBALANCING_UTILIZATION_THRESHOLD]
                            [--expert-distribution-recorder-mode EXPERT_DISTRIBUTION_RECORDER_MODE]
                            [--expert-distribution-recorder-buffer-size EXPERT_DISTRIBUTION_RECORDER_BUFFER_SIZE] [--enable-expert-distribution-metrics]
                            [--deepep-config DEEPEP_CONFIG] [--moe-dense-tp-size MOE_DENSE_TP_SIZE] [--max-mamba-cache-size MAX_MAMBA_CACHE_SIZE]
                            [--mamba-ssm-dtype {float32,bfloat16}] [--enable-hierarchical-cache] [--hicache-ratio HICACHE_RATIO] [--hicache-size HICACHE_SIZE]
                            [--hicache-write-policy {write_back,write_through,write_through_selective}] [--hicache-io-backend {direct,kernel}]
                            [--hicache-mem-layout {layer_first,page_first}] [--hicache-storage-backend {file,mooncake,hf3fs,nixl}]
                            [--hicache-storage-prefetch-policy {best_effort,wait_complete,timeout}]
                            [--hicache-storage-backend-extra-config HICACHE_STORAGE_BACKEND_EXTRA_CONFIG] [--enable-lmcache] [--enable-double-sparsity]
                            [--ds-channel-config-path DS_CHANNEL_CONFIG_PATH] [--ds-heavy-channel-num DS_HEAVY_CHANNEL_NUM]
                            [--ds-heavy-token-num DS_HEAVY_TOKEN_NUM] [--ds-heavy-channel-type DS_HEAVY_CHANNEL_TYPE]
                            [--ds-sparse-decode-threshold DS_SPARSE_DECODE_THRESHOLD] [--cpu-offload-gb CPU_OFFLOAD_GB] [--offload-group-size OFFLOAD_GROUP_SIZE]
                            [--offload-num-in-group OFFLOAD_NUM_IN_GROUP] [--offload-prefetch-step OFFLOAD_PREFETCH_STEP] [--offload-mode OFFLOAD_MODE]
                            [--disable-radix-cache] [--cuda-graph-max-bs CUDA_GRAPH_MAX_BS] [--cuda-graph-bs CUDA_GRAPH_BS [CUDA_GRAPH_BS ...]]
                            [--disable-cuda-graph] [--disable-cuda-graph-padding] [--enable-profile-cuda-graph] [--enable-cudagraph-gc] [--enable-nccl-nvls]
                            [--enable-symm-mem] [--disable-flashinfer-cutlass-moe-fp4-allgather] [--enable-tokenizer-batch-encode] [--disable-outlines-disk-cache]
                            [--disable-custom-all-reduce] [--enable-mscclpp] [--disable-overlap-schedule] [--enable-mixed-chunk] [--enable-dp-attention]
                            [--enable-dp-lm-head] [--enable-two-batch-overlap] [--tbo-token-distribution-threshold TBO_TOKEN_DISTRIBUTION_THRESHOLD]
                            [--enable-torch-compile] [--torch-compile-max-bs TORCH_COMPILE_MAX_BS] [--torchao-config TORCHAO_CONFIG] [--enable-nan-detection]
                            [--enable-p2p-check] [--triton-attention-reduce-in-fp32] [--triton-attention-num-kv-splits TRITON_ATTENTION_NUM_KV_SPLITS]
                            [--num-continuous-decode-steps NUM_CONTINUOUS_DECODE_STEPS] [--delete-ckpt-after-loading] [--enable-memory-saver]
                            [--allow-auto-truncate] [--enable-custom-logit-processor] [--flashinfer-mla-disable-ragged] [--disable-shared-experts-fusion]
                            [--disable-chunked-prefix-cache] [--disable-fast-image-processor] [--enable-return-hidden-states]
                            [--scheduler-recv-interval SCHEDULER_RECV_INTERVAL] [--numa-node NUMA_NODE [NUMA_NODE ...]]
                            [--debug-tensor-dump-output-folder DEBUG_TENSOR_DUMP_OUTPUT_FOLDER] [--debug-tensor-dump-input-file DEBUG_TENSOR_DUMP_INPUT_FILE]
                            [--debug-tensor-dump-inject DEBUG_TENSOR_DUMP_INJECT] [--debug-tensor-dump-prefill-only] [--disaggregation-mode {null,prefill,decode}]
                            [--disaggregation-transfer-backend {mooncake,nixl,ascend,fake}] [--disaggregation-bootstrap-port DISAGGREGATION_BOOTSTRAP_PORT]
                            [--disaggregation-decode-tp DISAGGREGATION_DECODE_TP] [--disaggregation-decode-dp DISAGGREGATION_DECODE_DP]
                            [--disaggregation-prefill-pp DISAGGREGATION_PREFILL_PP] [--disaggregation-ib-device DISAGGREGATION_IB_DEVICE]
                            [--num-reserved-decode-tokens NUM_RESERVED_DECODE_TOKENS] [--custom-weight-loader [CUSTOM_WEIGHT_LOADER ...]]
                            [--weight-loader-disable-mmap] [--enable-pdmux] [--sm-group-num SM_GROUP_NUM] [--enable-ep-moe] [--enable-deepep-moe]
                            [--enable-flashinfer-cutlass-moe] [--enable-flashinfer-trtllm-moe] [--enable-triton-kernel-moe] [--enable-flashinfer-mxfp4-moe]
                            [--batch-size BATCH_SIZE [BATCH_SIZE ...]] [--steps STEPS [STEPS ...]] [--topk TOPK [TOPK ...]]
                            [--num_draft_tokens NUM_DRAFT_TOKENS [NUM_DRAFT_TOKENS ...]] [--num-prompts NUM_PROMPTS] [--start START] [--end END] [--output OUTPUT]
                            [--is-multimodal] [--dataset-path DATASET_PATH]
bench_speculative.py: error: unrecognized arguments: --8 steps 0
devuser@7ed22f68dd76:/sgl-workspace/sglang$ python3 scripts/playground/bench_speculative.py --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --tp-size 8 --trust-remote-code --batch-size 8 --steps 0 --topk 0 --num_draft_tokens 0 --dataset-path /shared/junmingc/converted_prompts.txt
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 08:07:06.957000 416833 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:07:06.957000 416833 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
Loaded 180 prompts from /shared/junmingc/converted_prompts.txt
Start i=0: batch_size=8, steps=0, topk=0, num_draft_tokens=0
Auto-configed device: cuda
command=python3 -m sglang.launch_server --model-path /host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/ --cuda-graph-max-bs 8 --mem-fraction-static 0.886 --tp-size 8 --max-running-requests 8 --trust-remote-code --device cuda --host 127.0.0.1 --port 20000
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
W0913 08:07:12.776000 417039 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:07:12.776000 417039 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[2025-09-13 08:07:13] server_args=ServerArgs(model_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_path='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='127.0.0.1', port=20000, skip_server_warmup=False, warmups=None, nccl_port=None, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', mem_fraction_static=0.886, max_running_requests=8, max_queued_requests=9223372036854775807, max_total_tokens=None, chunked_prefill_size=8192, max_prefill_tokens=16384, schedule_policy='fcfs', schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, device='cuda', tp_size=8, pp_size=1, max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=334608657, constrained_json_whitespace_pattern=None, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, gc_warning_threshold_secs=0.0, api_key=None, served_model_name='/host-shm/dsv3-agent-0723-7100-0819-1500-mtp-fp8/dsv3-agent-0723-7100-0819-1500-mtp-fp8/', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, dp_size=1, load_balance_method='round_robin', prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_backend='triton', attention_backend=None, decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, speculative_algorithm=None, speculative_draft_model_path=None, speculative_draft_model_revision=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm='static', init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', disable_radix_cache=False, cuda_graph_max_bs=8, cuda_graph_bs=None, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, torch_compile_max_bs=32, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, debug_tensor_dump_output_folder=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, debug_tensor_dump_prefill_only=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, num_reserved_decode_tokens=512, custom_weight_loader=[], weight_loader_disable_mmap=False, enable_pdmux=False, sm_group_num=3, max_mamba_cache_size=None, mamba_ssm_dtype='float32', enable_ep_moe=False, enable_deepep_moe=False, enable_flashinfer_cutlass_moe=False, enable_flashinfer_trtllm_moe=False, enable_triton_kernel_moe=False, enable_flashinfer_mxfp4_moe=False)
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 08:07:13] Using default HuggingFace chat template with detected content format: string
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 08:07:22.096000 417314 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:07:22.096000 417314 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 08:07:22.114000 417312 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:07:22.114000 417312 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 08:07:22.184000 417313 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:07:22.184000 417313 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 08:07:22.250000 417318 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:07:22.250000 417318 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
`torch_dtype` is deprecated! Use `dtype` instead!
W0913 08:07:22.439000 417316 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:07:22.439000 417316 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 08:07:22.466000 417319 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:07:22.466000 417319 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
W0913 08:07:22.564000 417317 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:07:22.564000 417317 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
All deep_gemm operations loaded successfully!
W0913 08:07:22.572000 417320 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:07:22.572000 417320 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0913 08:07:22.627000 417321 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0913 08:07:22.627000 417321 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-09-13 08:07:22 TP0] Attention backend not explicitly specified. Use fa3 backend by default.
[2025-09-13 08:07:22 TP0] Chunked prefix cache is turned on.
[2025-09-13 08:07:22 TP0] Init torch distributed begin.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 08:07:24 TP0] sglang is using nccl==2.27.3
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[2025-09-13 08:07:27 TP0] Init torch distributed ends. mem usage=1.24 GB
[2025-09-13 08:07:29 TP0] Load weight begin. avail mem=138.02 GB
[2025-09-13 08:07:29 TP0] Detected fp8 checkpoint.
[2025-09-13 08:07:29 TP0] Shared experts fusion optimization enabled.
Loading safetensors checkpoint shards:   0% Completed | 0/1024 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 23/1024 [00:00<00:04, 208.19it/s]
Loading safetensors checkpoint shards:   4% Completed | 44/1024 [00:00<00:13, 70.70it/s]
Loading safetensors checkpoint shards:   5% Completed | 56/1024 [00:00<00:14, 68.52it/s]
Loading safetensors checkpoint shards:   6% Completed | 66/1024 [00:00<00:15, 60.45it/s]
Loading safetensors checkpoint shards:   7% Completed | 74/1024 [00:01<00:17, 55.04it/s]
Loading safetensors checkpoint shards:   8% Completed | 81/1024 [00:01<00:18, 50.60it/s]
Loading safetensors checkpoint shards:   8% Completed | 87/1024 [00:01<00:21, 43.18it/s]
Loading safetensors checkpoint shards:   9% Completed | 92/1024 [00:01<00:24, 38.62it/s]
Loading safetensors checkpoint shards:   9% Completed | 97/1024 [00:01<00:22, 40.36it/s]
Loading safetensors checkpoint shards:  10% Completed | 102/1024 [00:02<00:38, 23.78it/s]
Loading safetensors checkpoint shards:  10% Completed | 106/1024 [00:02<00:35, 26.01it/s]
Loading safetensors checkpoint shards:  11% Completed | 111/1024 [00:02<00:31, 29.04it/s]
Loading safetensors checkpoint shards:  11% Completed | 117/1024 [00:02<00:26, 33.73it/s]
Loading safetensors checkpoint shards:  12% Completed | 122/1024 [00:02<00:24, 36.11it/s]
Loading safetensors checkpoint shards:  12% Completed | 128/1024 [00:02<00:22, 39.88it/s]
Loading safetensors checkpoint shards:  13% Completed | 133/1024 [00:03<00:22, 39.27it/s]
Loading safetensors checkpoint shards:  14% Completed | 139/1024 [00:03<00:20, 42.92it/s]
Loading safetensors checkpoint shards:  14% Completed | 144/1024 [00:03<00:20, 42.25it/s]
Loading safetensors checkpoint shards:  15% Completed | 149/1024 [00:03<00:20, 42.96it/s]
Loading safetensors checkpoint shards:  15% Completed | 154/1024 [00:03<00:20, 43.13it/s]
Loading safetensors checkpoint shards:  16% Completed | 159/1024 [00:03<00:19, 43.39it/s]
Loading safetensors checkpoint shards:  16% Completed | 164/1024 [00:03<00:19, 43.92it/s]
Loading safetensors checkpoint shards:  17% Completed | 169/1024 [00:03<00:19, 43.78it/s]
Loading safetensors checkpoint shards:  17% Completed | 175/1024 [00:03<00:18, 45.52it/s]
Loading safetensors checkpoint shards:  18% Completed | 180/1024 [00:04<00:19, 43.61it/s]
Loading safetensors checkpoint shards:  18% Completed | 185/1024 [00:04<00:18, 45.23it/s]
Loading safetensors checkpoint shards:  19% Completed | 190/1024 [00:04<00:18, 44.74it/s]
Loading safetensors checkpoint shards:  19% Completed | 195/1024 [00:04<00:18, 45.82it/s]
Loading safetensors checkpoint shards:  20% Completed | 200/1024 [00:04<00:18, 44.02it/s]
Loading safetensors checkpoint shards:  20% Completed | 205/1024 [00:04<00:18, 44.19it/s]
Loading safetensors checkpoint shards:  21% Completed | 210/1024 [00:04<00:18, 43.17it/s]
Loading safetensors checkpoint shards:  21% Completed | 215/1024 [00:04<00:18, 44.47it/s]
Loading safetensors checkpoint shards:  21% Completed | 220/1024 [00:04<00:19, 42.08it/s]
Loading safetensors checkpoint shards:  22% Completed | 225/1024 [00:05<00:19, 41.56it/s]
Loading safetensors checkpoint shards:  22% Completed | 230/1024 [00:05<00:19, 41.78it/s]
Loading safetensors checkpoint shards:  23% Completed | 235/1024 [00:05<00:19, 41.00it/s]
Loading safetensors checkpoint shards:  23% Completed | 240/1024 [00:05<00:18, 42.43it/s]
Loading safetensors checkpoint shards:  24% Completed | 245/1024 [00:05<00:18, 41.45it/s]
Loading safetensors checkpoint shards:  25% Completed | 251/1024 [00:05<00:18, 42.88it/s]
Loading safetensors checkpoint shards:  25% Completed | 256/1024 [00:05<00:18, 42.56it/s]
Loading safetensors checkpoint shards:  25% Completed | 261/1024 [00:05<00:17, 44.29it/s]
Loading safetensors checkpoint shards:  26% Completed | 266/1024 [00:06<00:17, 43.03it/s]
Loading safetensors checkpoint shards:  27% Completed | 272/1024 [00:06<00:16, 44.61it/s]
Loading safetensors checkpoint shards:  27% Completed | 277/1024 [00:06<00:17, 42.45it/s]
Loading safetensors checkpoint shards:  28% Completed | 282/1024 [00:06<00:16, 44.04it/s]
Loading safetensors checkpoint shards:  28% Completed | 287/1024 [00:06<00:17, 42.80it/s]
Loading safetensors checkpoint shards:  29% Completed | 292/1024 [00:06<00:17, 40.92it/s]
Loading safetensors checkpoint shards:  29% Completed | 297/1024 [00:06<00:17, 42.36it/s]
Loading safetensors checkpoint shards:  29% Completed | 302/1024 [00:06<00:17, 41.30it/s]
Loading safetensors checkpoint shards:  30% Completed | 307/1024 [00:07<00:34, 20.58it/s]
Loading safetensors checkpoint shards:  30% Completed | 311/1024 [00:07<00:30, 23.36it/s]
Loading safetensors checkpoint shards:  31% Completed | 316/1024 [00:07<00:25, 27.33it/s]
Loading safetensors checkpoint shards:  31% Completed | 320/1024 [00:07<00:23, 29.54it/s]
Loading safetensors checkpoint shards:  32% Completed | 324/1024 [00:07<00:22, 30.51it/s]
Loading safetensors checkpoint shards:  32% Completed | 329/1024 [00:07<00:20, 33.53it/s]
Loading safetensors checkpoint shards:  33% Completed | 333/1024 [00:08<00:20, 34.07it/s]
Loading safetensors checkpoint shards:  33% Completed | 338/1024 [00:08<00:19, 35.94it/s]
Loading safetensors checkpoint shards:  33% Completed | 342/1024 [00:08<00:18, 36.39it/s]
Loading safetensors checkpoint shards:  34% Completed | 346/1024 [00:08<00:19, 35.59it/s]
Loading safetensors checkpoint shards:  34% Completed | 351/1024 [00:08<00:17, 38.63it/s]
Loading safetensors checkpoint shards:  35% Completed | 355/1024 [00:08<00:17, 38.54it/s]
Loading safetensors checkpoint shards:  35% Completed | 360/1024 [00:08<00:16, 40.97it/s]
Loading safetensors checkpoint shards:  36% Completed | 365/1024 [00:08<00:16, 40.12it/s]
Loading safetensors checkpoint shards:  36% Completed | 370/1024 [00:09<00:16, 39.63it/s]
Loading safetensors checkpoint shards:  37% Completed | 376/1024 [00:09<00:14, 43.65it/s]
Loading safetensors checkpoint shards:  37% Completed | 381/1024 [00:09<00:15, 42.35it/s]
Loading safetensors checkpoint shards:  38% Completed | 387/1024 [00:09<00:13, 46.48it/s]
Loading safetensors checkpoint shards:  38% Completed | 392/1024 [00:09<00:13, 45.57it/s]
Loading safetensors checkpoint shards:  39% Completed | 398/1024 [00:09<00:12, 48.76it/s]
Loading safetensors checkpoint shards:  40% Completed | 405/1024 [00:09<00:11, 52.41it/s]
Loading safetensors checkpoint shards:  40% Completed | 412/1024 [00:09<00:11, 55.45it/s]
Loading safetensors checkpoint shards:  41% Completed | 418/1024 [00:09<00:10, 55.26it/s]
Loading safetensors checkpoint shards:  41% Completed | 424/1024 [00:10<00:11, 52.91it/s]
Loading safetensors checkpoint shards:  42% Completed | 430/1024 [00:10<00:12, 49.09it/s]
Loading safetensors checkpoint shards:  42% Completed | 435/1024 [00:10<00:13, 44.60it/s]
Loading safetensors checkpoint shards:  43% Completed | 440/1024 [00:10<00:13, 43.80it/s]
Loading safetensors checkpoint shards:  43% Completed | 445/1024 [00:10<00:14, 40.86it/s]
Loading safetensors checkpoint shards:  44% Completed | 450/1024 [00:10<00:14, 40.51it/s]
Loading safetensors checkpoint shards:  44% Completed | 455/1024 [00:10<00:15, 37.60it/s]
Loading safetensors checkpoint shards:  45% Completed | 460/1024 [00:10<00:14, 39.53it/s]
Loading safetensors checkpoint shards:  45% Completed | 465/1024 [00:11<00:15, 37.22it/s]
Loading safetensors checkpoint shards:  46% Completed | 469/1024 [00:11<00:15, 36.14it/s]
Loading safetensors checkpoint shards:  46% Completed | 475/1024 [00:11<00:13, 40.73it/s]
Loading safetensors checkpoint shards:  47% Completed | 480/1024 [00:11<00:14, 38.28it/s]
Loading safetensors checkpoint shards:  47% Completed | 484/1024 [00:11<00:14, 37.63it/s]
Loading safetensors checkpoint shards:  48% Completed | 488/1024 [00:11<00:16, 32.63it/s]
Loading safetensors checkpoint shards:  48% Completed | 492/1024 [00:11<00:15, 33.60it/s]
Loading safetensors checkpoint shards:  49% Completed | 498/1024 [00:12<00:13, 38.23it/s]
Loading safetensors checkpoint shards:  49% Completed | 503/1024 [00:12<00:13, 38.03it/s]
Loading safetensors checkpoint shards:  50% Completed | 507/1024 [00:12<00:27, 18.65it/s]
Loading safetensors checkpoint shards:  50% Completed | 513/1024 [00:12<00:21, 24.20it/s]
Loading safetensors checkpoint shards:  51% Completed | 519/1024 [00:12<00:16, 29.74it/s]
Loading safetensors checkpoint shards:  51% Completed | 524/1024 [00:13<00:15, 32.82it/s]
Loading safetensors checkpoint shards:  52% Completed | 530/1024 [00:13<00:13, 37.62it/s]
Loading safetensors checkpoint shards:  52% Completed | 535/1024 [00:13<00:12, 39.27it/s]
Loading safetensors checkpoint shards:  53% Completed | 541/1024 [00:13<00:11, 41.63it/s]
Loading safetensors checkpoint shards:  53% Completed | 547/1024 [00:13<00:10, 44.36it/s]
Loading safetensors checkpoint shards:  54% Completed | 553/1024 [00:13<00:09, 47.83it/s]
Loading safetensors checkpoint shards:  55% Completed | 559/1024 [00:13<00:09, 46.66it/s]
Loading safetensors checkpoint shards:  55% Completed | 564/1024 [00:13<00:11, 40.81it/s]
Loading safetensors checkpoint shards:  56% Completed | 569/1024 [00:14<00:11, 38.59it/s]
Loading safetensors checkpoint shards:  56% Completed | 574/1024 [00:14<00:11, 40.34it/s]
Loading safetensors checkpoint shards:  57% Completed | 579/1024 [00:14<00:10, 40.78it/s]
Loading safetensors checkpoint shards:  57% Completed | 585/1024 [00:14<00:09, 44.20it/s]
Loading safetensors checkpoint shards:  58% Completed | 590/1024 [00:14<00:09, 43.75it/s]
Loading safetensors checkpoint shards:  58% Completed | 596/1024 [00:14<00:09, 47.20it/s]
Loading safetensors checkpoint shards:  59% Completed | 602/1024 [00:14<00:08, 49.28it/s]
Loading safetensors checkpoint shards:  59% Completed | 607/1024 [00:14<00:08, 49.04it/s]
Loading safetensors checkpoint shards:  60% Completed | 612/1024 [00:14<00:08, 49.08it/s]
Loading safetensors checkpoint shards:  60% Completed | 618/1024 [00:15<00:07, 51.45it/s]
Loading safetensors checkpoint shards:  61% Completed | 624/1024 [00:15<00:07, 52.48it/s]
Loading safetensors checkpoint shards:  62% Completed | 630/1024 [00:15<00:08, 48.68it/s]
Loading safetensors checkpoint shards:  62% Completed | 635/1024 [00:15<00:08, 45.31it/s]
Loading safetensors checkpoint shards:  62% Completed | 640/1024 [00:15<00:09, 40.88it/s]
Loading safetensors checkpoint shards:  63% Completed | 645/1024 [00:15<00:10, 36.89it/s]
Loading safetensors checkpoint shards:  63% Completed | 649/1024 [00:15<00:10, 36.39it/s]
Loading safetensors checkpoint shards:  64% Completed | 653/1024 [00:15<00:10, 34.63it/s]
Loading safetensors checkpoint shards:  64% Completed | 657/1024 [00:16<00:10, 33.36it/s]
Loading safetensors checkpoint shards:  65% Completed | 661/1024 [00:16<00:14, 24.87it/s]
Loading safetensors checkpoint shards:  65% Completed | 664/1024 [00:16<00:14, 24.69it/s]
Loading safetensors checkpoint shards:  65% Completed | 667/1024 [00:16<00:14, 24.38it/s]
Loading safetensors checkpoint shards:  65% Completed | 670/1024 [00:16<00:14, 24.71it/s]
Loading safetensors checkpoint shards:  66% Completed | 673/1024 [00:16<00:14, 24.55it/s]
Loading safetensors checkpoint shards:  66% Completed | 676/1024 [00:17<00:14, 24.21it/s]
Loading safetensors checkpoint shards:  66% Completed | 679/1024 [00:17<00:13, 25.00it/s]
Loading safetensors checkpoint shards:  67% Completed | 682/1024 [00:17<00:13, 25.32it/s]
Loading safetensors checkpoint shards:  67% Completed | 686/1024 [00:17<00:11, 28.55it/s]
Loading safetensors checkpoint shards:  67% Completed | 690/1024 [00:17<00:10, 31.24it/s]
Loading safetensors checkpoint shards:  68% Completed | 695/1024 [00:17<00:09, 35.30it/s]
Loading safetensors checkpoint shards:  68% Completed | 699/1024 [00:17<00:08, 36.20it/s]
Loading safetensors checkpoint shards:  69% Completed | 703/1024 [00:17<00:08, 35.74it/s]
Loading safetensors checkpoint shards:  69% Completed | 707/1024 [00:17<00:08, 36.04it/s]
Loading safetensors checkpoint shards:  69% Completed | 711/1024 [00:18<00:08, 36.42it/s]
Loading safetensors checkpoint shards:  70% Completed | 715/1024 [00:18<00:08, 36.33it/s]
Loading safetensors checkpoint shards:  70% Completed | 719/1024 [00:18<00:08, 34.95it/s]
Loading safetensors checkpoint shards:  71% Completed | 723/1024 [00:18<00:21, 13.70it/s]
Loading safetensors checkpoint shards:  71% Completed | 727/1024 [00:19<00:17, 16.70it/s]
Loading safetensors checkpoint shards:  71% Completed | 731/1024 [00:19<00:14, 19.76it/s]
Loading safetensors checkpoint shards:  72% Completed | 735/1024 [00:19<00:12, 22.60it/s]
Loading safetensors checkpoint shards:  72% Completed | 739/1024 [00:19<00:11, 25.78it/s]
Loading safetensors checkpoint shards:  73% Completed | 745/1024 [00:19<00:08, 32.08it/s]
Loading safetensors checkpoint shards:  73% Completed | 750/1024 [00:19<00:07, 36.18it/s]
Loading safetensors checkpoint shards:  74% Completed | 757/1024 [00:19<00:06, 43.19it/s]
Loading safetensors checkpoint shards:  75% Completed | 763/1024 [00:19<00:05, 46.28it/s]
Loading safetensors checkpoint shards:  75% Completed | 769/1024 [00:19<00:05, 44.78it/s]
Loading safetensors checkpoint shards:  76% Completed | 774/1024 [00:20<00:05, 41.74it/s]
Loading safetensors checkpoint shards:  76% Completed | 779/1024 [00:20<00:05, 42.44it/s]
Loading safetensors checkpoint shards:  77% Completed | 785/1024 [00:20<00:05, 43.73it/s]
Loading safetensors checkpoint shards:  77% Completed | 790/1024 [00:20<00:06, 38.89it/s]
Loading safetensors checkpoint shards:  78% Completed | 795/1024 [00:20<00:06, 38.04it/s]
Loading safetensors checkpoint shards:  78% Completed | 799/1024 [00:20<00:05, 37.87it/s]
Loading safetensors checkpoint shards:  78% Completed | 803/1024 [00:20<00:05, 37.87it/s]
Loading safetensors checkpoint shards:  79% Completed | 809/1024 [00:20<00:04, 43.26it/s]
Loading safetensors checkpoint shards:  80% Completed | 815/1024 [00:21<00:04, 44.42it/s]
Loading safetensors checkpoint shards:  80% Completed | 820/1024 [00:21<00:04, 43.74it/s]
Loading safetensors checkpoint shards:  81% Completed | 825/1024 [00:21<00:04, 44.40it/s]
Loading safetensors checkpoint shards:  81% Completed | 831/1024 [00:21<00:04, 47.12it/s]
Loading safetensors checkpoint shards:  82% Completed | 836/1024 [00:21<00:03, 47.83it/s]
Loading safetensors checkpoint shards:  82% Completed | 842/1024 [00:21<00:03, 48.21it/s]
Loading safetensors checkpoint shards:  83% Completed | 847/1024 [00:21<00:03, 45.52it/s]
Loading safetensors checkpoint shards:  83% Completed | 852/1024 [00:21<00:03, 45.95it/s]
Loading safetensors checkpoint shards:  84% Completed | 858/1024 [00:22<00:03, 45.18it/s]
Loading safetensors checkpoint shards:  84% Completed | 864/1024 [00:22<00:03, 47.28it/s]
Loading safetensors checkpoint shards:  85% Completed | 870/1024 [00:22<00:03, 49.23it/s]
Loading safetensors checkpoint shards:  86% Completed | 876/1024 [00:22<00:02, 50.20it/s]
Loading safetensors checkpoint shards:  86% Completed | 882/1024 [00:22<00:02, 49.56it/s]
Loading safetensors checkpoint shards:  87% Completed | 887/1024 [00:22<00:02, 47.76it/s]
Loading safetensors checkpoint shards:  87% Completed | 892/1024 [00:22<00:02, 47.07it/s]
Loading safetensors checkpoint shards:  88% Completed | 897/1024 [00:22<00:02, 47.39it/s]
Loading safetensors checkpoint shards:  88% Completed | 902/1024 [00:22<00:02, 44.31it/s]
Loading safetensors checkpoint shards:  89% Completed | 907/1024 [00:23<00:02, 45.68it/s]
Loading safetensors checkpoint shards:  89% Completed | 913/1024 [00:23<00:02, 47.65it/s]
Loading safetensors checkpoint shards:  90% Completed | 918/1024 [00:23<00:02, 37.19it/s]
Loading safetensors checkpoint shards:  90% Completed | 923/1024 [00:23<00:02, 37.11it/s]
Loading safetensors checkpoint shards:  91% Completed | 929/1024 [00:23<00:02, 41.28it/s]
Loading safetensors checkpoint shards:  91% Completed | 936/1024 [00:23<00:01, 46.43it/s]
Loading safetensors checkpoint shards:  92% Completed | 944/1024 [00:23<00:01, 53.02it/s]
Loading safetensors checkpoint shards:  93% Completed | 952/1024 [00:23<00:01, 58.68it/s]
Loading safetensors checkpoint shards:  94% Completed | 960/1024 [00:24<00:02, 22.85it/s]
Loading safetensors checkpoint shards:  94% Completed | 966/1024 [00:24<00:02, 27.12it/s]
Loading safetensors checkpoint shards:  95% Completed | 971/1024 [00:24<00:01, 30.11it/s]
Loading safetensors checkpoint shards:  95% Completed | 977/1024 [00:25<00:01, 34.20it/s]
Loading safetensors checkpoint shards:  96% Completed | 983/1024 [00:25<00:01, 39.04it/s]
Loading safetensors checkpoint shards:  97% Completed | 992/1024 [00:25<00:00, 49.71it/s]
Loading safetensors checkpoint shards:  98% Completed | 1002/1024 [00:25<00:00, 59.67it/s]
Loading safetensors checkpoint shards:  99% Completed | 1011/1024 [00:25<00:00, 67.07it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 83.00it/s]
Loading safetensors checkpoint shards: 100% Completed | 1024/1024 [00:25<00:00, 39.98it/s]

[2025-09-13 08:07:56 TP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=58.29 GB, mem usage=79.73 GB.
[2025-09-13 08:07:57 TP4] KV Cache is allocated. #tokens: 649479, KV size: 42.51 GB
[2025-09-13 08:07:57 TP2] KV Cache is allocated. #tokens: 649479, KV size: 42.51 GB
[2025-09-13 08:07:57 TP3] KV Cache is allocated. #tokens: 649479, KV size: 42.51 GB
[2025-09-13 08:07:57 TP5] KV Cache is allocated. #tokens: 649479, KV size: 42.51 GB
[2025-09-13 08:07:57 TP6] KV Cache is allocated. #tokens: 649479, KV size: 42.51 GB
[2025-09-13 08:07:57 TP7] KV Cache is allocated. #tokens: 649479, KV size: 42.51 GB
[2025-09-13 08:07:57 TP1] KV Cache is allocated. #tokens: 649479, KV size: 42.51 GB
[2025-09-13 08:07:57 TP0] KV Cache is allocated. #tokens: 649479, KV size: 42.51 GB
[2025-09-13 08:07:57 TP0] Memory pool end. avail mem=15.75 GB
[2025-09-13 08:07:57 TP0] Capture cuda graph begin. This can take up to several minutes. avail mem=15.66 GB
[2025-09-13 08:07:57 TP0] Capture cuda graph bs [1, 2, 4, 8]
Capturing batches (bs=8 avail_mem=15.66 GB):   0%|                                                                                              | 0/4 [00:00<?, ?it/s]Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 08:07:58 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:07:58 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
                                                                                                                                                                     Warning: please use at least NVCC 12.9 for the best DeepGEMM performance                                                                     | 0/16384 [00:00<?, ?it/s]
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[2025-09-13 08:07:58 TP2] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 08:07:58 TP5] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 08:07:58 TP6] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 08:07:58 TP3] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 08:07:58 TP7] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
                                                                                                                                                                     [2025-09-13 08:07:58 TP4] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
[2025-09-13 08:07:58 TP1] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26174.33it/s]
[2025-09-13 08:07:59 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:07:59 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=3072, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 26209.58it/s]
[2025-09-13 08:07:59 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:07:59 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2048, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28379.40it/s]
[2025-09-13 08:08:00 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:08:00 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4608, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27549.44it/s]
[2025-09-13 08:08:00 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:08:00 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=2304, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 28381.86it/s]
[2025-09-13 08:08:01 TP0] Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Fallback to triton version 3.3.1 and use MoE kernel config from /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_3_1/E=257,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json. Performance might be sub-optimal!
Capturing batches (bs=1 avail_mem=15.54 GB):  75%|████████████████████████████████████████████████████████████████▌                     | 3/4 [00:05<00:01,  1.40s/it][2025-09-13 08:08:03 TP7] Registering 492 cuda graph addresses
[2025-09-13 08:08:03 TP6] Registering 492 cuda graph addresses
[2025-09-13 08:08:03 TP5] Registering 492 cuda graph addresses
[2025-09-13 08:08:03 TP4] Registering 492 cuda graph addresses
[2025-09-13 08:08:03 TP3] Registering 492 cuda graph addresses
Capturing batches (bs=1 avail_mem=15.54 GB): 100%|██████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.54s/it]
[2025-09-13 08:08:03 TP2] Registering 492 cuda graph addresses
[2025-09-13 08:08:03 TP1] Registering 492 cuda graph addresses
[2025-09-13 08:08:03 TP0] Registering 492 cuda graph addresses
[2025-09-13 08:08:04 TP0] Capture cuda graph end. Time elapsed: 6.83 s. mem usage=0.14 GB. avail mem=15.52 GB.
[2025-09-13 08:08:04 TP0] max_total_num_tokens=649479, chunked_prefill_size=8192, max_prefill_tokens=16384, max_running_requests=8, context_len=163840, available_gpu_mem=15.52 GB
[2025-09-13 08:08:04] INFO:     Started server process [417039]
[2025-09-13 08:08:04] INFO:     Waiting for application startup.
[2025-09-13 08:08:04] INFO:     Application startup complete.
[2025-09-13 08:08:04] INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)
[2025-09-13 08:08:05] INFO:     127.0.0.1:45602 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-09-13 08:08:05 TP0] Prefill batch. #new-seq: 1, #new-token: 7, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:08:06 TP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
[2025-09-13 08:08:06 TP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=4096, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
DeepGEMM warmup: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 16384/16384 [00:00<00:00, 27066.21it/s]
[2025-09-13 08:08:07] INFO:     127.0.0.1:45618 - "GET /health_generate HTTP/1.1" 503 Service Unavailable
[2025-09-13 08:08:08] INFO:     127.0.0.1:45610 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:08] The server is fired up and ready to roll!
[2025-09-13 08:08:17 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:08:18] INFO:     127.0.0.1:39728 - "GET /health_generate HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 08:08:18] INFO:     127.0.0.1:35216 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:18 TP0] Prefill batch. #new-seq: 1, #new-token: 4665, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:08:18 TP0] Decode batch. #running-req: 1, #token: 1, token usage: 0.00, cuda graph: True, gen throughput (token/s): 2.74, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                           | 0/8 [00:00<?, ?it/s][2025-09-13 08:08:19] INFO:     127.0.0.1:35232 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:19] INFO:     127.0.0.1:35244 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:19 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:08:20] INFO:     127.0.0.1:35256 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:20] INFO:     127.0.0.1:35264 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:20] INFO:     127.0.0.1:35274 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:20] INFO:     127.0.0.1:35288 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:20] INFO:     127.0.0.1:35298 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:20] INFO:     127.0.0.1:35314 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:20 TP0] Prefill batch. #new-seq: 3, #new-token: 8192, #cached-token: 2540, token usage: 0.01, #running-req: 1, #queue-req: 4, 
[2025-09-13 08:08:20 TP0] Prefill batch. #new-seq: 5, #new-token: 1189, #cached-token: 3538, token usage: 0.02, #running-req: 3, #queue-req: 0, 
[2025-09-13 08:08:21 TP0] Decode batch. #running-req: 8, #token: 14236, token usage: 0.02, cuda graph: True, gen throughput (token/s): 103.06, #queue-req: 0, 
[2025-09-13 08:08:22 TP0] Decode batch. #running-req: 8, #token: 14556, token usage: 0.02, cuda graph: True, gen throughput (token/s): 576.70, #queue-req: 0, 
[2025-09-13 08:08:23 TP0] Decode batch. #running-req: 8, #token: 14876, token usage: 0.02, cuda graph: True, gen throughput (token/s): 566.49, #queue-req: 0, 
[2025-09-13 08:08:23 TP0] Decode batch. #running-req: 8, #token: 15196, token usage: 0.02, cuda graph: True, gen throughput (token/s): 560.36, #queue-req: 0, 
[2025-09-13 08:08:24 TP0] Decode batch. #running-req: 8, #token: 15516, token usage: 0.02, cuda graph: True, gen throughput (token/s): 557.19, #queue-req: 0, 
[2025-09-13 08:08:24 TP0] Decode batch. #running-req: 8, #token: 15836, token usage: 0.02, cuda graph: True, gen throughput (token/s): 557.06, #queue-req: 0, 
[2025-09-13 08:08:25 TP0] Decode batch. #running-req: 8, #token: 16156, token usage: 0.02, cuda graph: True, gen throughput (token/s): 555.54, #queue-req: 0, 
[2025-09-13 08:08:25 TP0] Decode batch. #running-req: 8, #token: 16476, token usage: 0.03, cuda graph: True, gen throughput (token/s): 556.95, #queue-req: 0, 
[2025-09-13 08:08:26 TP0] Decode batch. #running-req: 8, #token: 16796, token usage: 0.03, cuda graph: True, gen throughput (token/s): 555.62, #queue-req: 0, 
[2025-09-13 08:08:27 TP0] Decode batch. #running-req: 8, #token: 17116, token usage: 0.03, cuda graph: True, gen throughput (token/s): 555.58, #queue-req: 0, 
[2025-09-13 08:08:27 TP0] Decode batch. #running-req: 8, #token: 17436, token usage: 0.03, cuda graph: True, gen throughput (token/s): 555.28, #queue-req: 0, 
[2025-09-13 08:08:28 TP0] Decode batch. #running-req: 8, #token: 17756, token usage: 0.03, cuda graph: True, gen throughput (token/s): 555.28, #queue-req: 0, 
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:08<00:00,  1.09s/it]
[2025-09-13 08:08:28] INFO:     127.0.0.1:49206 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     8         
Benchmark duration (s):                  8.75      
Total input tokens:                      0         
Total generated tokens:                  4096      
Total generated tokens (retokenized):    4088      
Request throughput (req/s):              0.91      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         467.87    
Total token throughput (tok/s):          467.87    
Concurrency:                             7.98      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   8737.15   
Median E2E Latency (ms):                 8738.91   
---------------Time to First Token----------------
Mean TTFT (ms):                          1215.36   
Median TTFT (ms):                        1451.26   
P99 TTFT (ms):                           1451.82   
---------------Inter-Token Latency----------------
Mean ITL (ms):                           14.72     
Median ITL (ms):                         14.36     
P95 ITL (ms):                            14.49     
P99 ITL (ms):                            14.53     
Max ITL (ms):                            1124.26   
==================================================
[2025-09-13 08:08:28] INFO:     127.0.0.1:49222 - "GET /get_server_info HTTP/1.1" 200 OK
Starting warmup with 1 sequences...
[2025-09-13 08:08:28] INFO:     127.0.0.1:49226 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:28 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:08:28 TP0] Decode batch. #running-req: 1, #token: 4673, token usage: 0.01, cuda graph: True, gen throughput (token/s): 398.01, #queue-req: 0, 
Warmup completed with 1 sequences. Starting main benchmark run...
  0%|                                                                                                                                          | 0/16 [00:00<?, ?it/s][2025-09-13 08:08:30] INFO:     127.0.0.1:49228 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:30] INFO:     127.0.0.1:49230 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:30 TP0] Prefill batch. #new-seq: 1, #new-token: 1, #cached-token: 4665, token usage: 0.01, #running-req: 0, #queue-req: 0, 
[2025-09-13 08:08:30] INFO:     127.0.0.1:49232 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:30] INFO:     127.0.0.1:49234 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:30] INFO:     127.0.0.1:49240 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:30] INFO:     127.0.0.1:49256 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:30] INFO:     127.0.0.1:49258 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:30] INFO:     127.0.0.1:49260 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:30 TP0] Prefill batch. #new-seq: 7, #new-token: 7, #cached-token: 15452, token usage: 0.02, #running-req: 1, #queue-req: 0, 
[2025-09-13 08:08:30 TP0] Decode batch. #running-req: 8, #token: 14036, token usage: 0.02, cuda graph: True, gen throughput (token/s): 72.09, #queue-req: 0, 
[2025-09-13 08:08:31 TP0] Decode batch. #running-req: 8, #token: 14356, token usage: 0.02, cuda graph: True, gen throughput (token/s): 583.02, #queue-req: 0, 
[2025-09-13 08:08:31 TP0] Decode batch. #running-req: 8, #token: 14676, token usage: 0.02, cuda graph: True, gen throughput (token/s): 576.73, #queue-req: 0, 
[2025-09-13 08:08:32 TP0] Decode batch. #running-req: 8, #token: 14996, token usage: 0.02, cuda graph: True, gen throughput (token/s): 566.89, #queue-req: 0, 
[2025-09-13 08:08:32 TP0] Decode batch. #running-req: 8, #token: 15316, token usage: 0.02, cuda graph: True, gen throughput (token/s): 562.41, #queue-req: 0, 
[2025-09-13 08:08:33 TP0] Decode batch. #running-req: 8, #token: 15636, token usage: 0.02, cuda graph: True, gen throughput (token/s): 560.43, #queue-req: 0, 
[2025-09-13 08:08:34 TP0] Decode batch. #running-req: 8, #token: 15956, token usage: 0.02, cuda graph: True, gen throughput (token/s): 558.40, #queue-req: 0, 
[2025-09-13 08:08:34 TP0] Decode batch. #running-req: 8, #token: 16276, token usage: 0.03, cuda graph: True, gen throughput (token/s): 559.46, #queue-req: 0, 
[2025-09-13 08:08:35 TP0] Decode batch. #running-req: 8, #token: 16596, token usage: 0.03, cuda graph: True, gen throughput (token/s): 556.53, #queue-req: 0, 
[2025-09-13 08:08:35 TP0] Decode batch. #running-req: 8, #token: 16916, token usage: 0.03, cuda graph: True, gen throughput (token/s): 556.31, #queue-req: 0, 
[2025-09-13 08:08:36 TP0] Decode batch. #running-req: 8, #token: 17236, token usage: 0.03, cuda graph: True, gen throughput (token/s): 555.25, #queue-req: 0, 
[2025-09-13 08:08:37 TP0] Decode batch. #running-req: 8, #token: 17556, token usage: 0.03, cuda graph: True, gen throughput (token/s): 555.64, #queue-req: 0, 
[2025-09-13 08:08:37 TP0] Decode batch. #running-req: 8, #token: 17876, token usage: 0.03, cuda graph: True, gen throughput (token/s): 555.05, #queue-req: 0, 
  6%|████████▏                                                                                                                         | 1/16 [00:07<01:54,  7.63s/it][2025-09-13 08:08:37] INFO:     127.0.0.1:49262 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:37 TP0] Prefill batch. #new-seq: 1, #new-token: 797, #cached-token: 847, token usage: 0.00, #running-req: 7, #queue-req: 0, 
[2025-09-13 08:08:37] INFO:     127.0.0.1:49278 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:37] INFO:     127.0.0.1:49290 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:37] INFO:     127.0.0.1:49298 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:37] INFO:     127.0.0.1:49314 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:37] INFO:     127.0.0.1:49322 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:37] INFO:     127.0.0.1:49328 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:37] INFO:     127.0.0.1:49336 - "POST /generate HTTP/1.1" 200 OK
[2025-09-13 08:08:37 TP0] Prefill batch. #new-seq: 7, #new-token: 8192, #cached-token: 6070, token usage: 0.00, #running-req: 1, #queue-req: 0, 
[2025-09-13 08:08:38 TP0] Prefill batch. #new-seq: 1, #new-token: 3570, #cached-token: 0, token usage: 0.02, #running-req: 7, #queue-req: 0, 
[2025-09-13 08:08:39 TP0] Decode batch. #running-req: 8, #token: 13624, token usage: 0.02, cuda graph: True, gen throughput (token/s): 139.82, #queue-req: 0, 
[2025-09-13 08:08:40 TP0] Decode batch. #running-req: 8, #token: 13944, token usage: 0.02, cuda graph: True, gen throughput (token/s): 570.23, #queue-req: 0, 
[2025-09-13 08:08:40 TP0] Decode batch. #running-req: 8, #token: 14264, token usage: 0.02, cuda graph: True, gen throughput (token/s): 562.87, #queue-req: 0, 
[2025-09-13 08:08:41 TP0] Decode batch. #running-req: 8, #token: 14584, token usage: 0.02, cuda graph: True, gen throughput (token/s): 561.76, #queue-req: 0, 
[2025-09-13 08:08:42 TP0] Decode batch. #running-req: 8, #token: 14904, token usage: 0.02, cuda graph: True, gen throughput (token/s): 561.23, #queue-req: 0, 
[2025-09-13 08:08:42 TP0] Decode batch. #running-req: 8, #token: 15224, token usage: 0.02, cuda graph: True, gen throughput (token/s): 559.99, #queue-req: 0, 
[2025-09-13 08:08:43 TP0] Decode batch. #running-req: 8, #token: 15544, token usage: 0.02, cuda graph: True, gen throughput (token/s): 560.49, #queue-req: 0, 
[2025-09-13 08:08:43 TP0] Decode batch. #running-req: 8, #token: 15864, token usage: 0.02, cuda graph: True, gen throughput (token/s): 559.18, #queue-req: 0, 
[2025-09-13 08:08:44 TP0] Decode batch. #running-req: 8, #token: 16184, token usage: 0.02, cuda graph: True, gen throughput (token/s): 558.80, #queue-req: 0, 
[2025-09-13 08:08:44 TP0] Decode batch. #running-req: 8, #token: 16504, token usage: 0.03, cuda graph: True, gen throughput (token/s): 558.75, #queue-req: 0, 
[2025-09-13 08:08:45 TP0] Decode batch. #running-req: 8, #token: 16824, token usage: 0.03, cuda graph: True, gen throughput (token/s): 557.99, #queue-req: 0, 
[2025-09-13 08:08:46 TP0] Decode batch. #running-req: 8, #token: 17144, token usage: 0.03, cuda graph: True, gen throughput (token/s): 557.34, #queue-req: 0, 
[2025-09-13 08:08:46 TP0] Decode batch. #running-req: 8, #token: 17464, token usage: 0.03, cuda graph: True, gen throughput (token/s): 557.57, #queue-req: 0, 
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:16<00:00,  1.04s/it]
[2025-09-13 08:08:46] INFO:     127.0.0.1:47964 - "GET /get_server_info HTTP/1.1" 200 OK

============ Serving Benchmark Result ============
Backend:                                 sglang    
Traffic request rate:                    inf       
Max request concurrency:                 8         
Successful requests:                     16        
Benchmark duration (s):                  16.64     
Total input tokens:                      0         
Total generated tokens:                  8192      
Total generated tokens (retokenized):    8065      
Request throughput (req/s):              0.96      
Input token throughput (tok/s):          0.00      
Output token throughput (tok/s):         492.20    
Total token throughput (tok/s):          492.20    
Concurrency:                             7.99      
----------------End-to-End Latency----------------
Mean E2E Latency (ms):                   8312.97   
Median E2E Latency (ms):                 8314.02   
---------------Time to First Token----------------
Mean TTFT (ms):                          898.85    
Median TTFT (ms):                        382.34    
P99 TTFT (ms):                           1688.93   
---------------Inter-Token Latency----------------
Mean ITL (ms):                           14.51     
Median ITL (ms):                         14.29     
P95 ITL (ms):                            14.48     
P99 ITL (ms):                            14.64     
Max ITL (ms):                            1260.65   
==================================================
[2025-09-13 08:08:46] INFO:     127.0.0.1:47972 - "GET /get_server_info HTTP/1.1" 200 OK
Finish i=0: batch_size=8, steps=0, topk=0, num_draft_tokens=0, speed=70.27 token/s, step_time=14.23 ms
devuser@7ed22f68dd76:/sgl-workspace/sglang$ 
