name: Auto Tune Kernels

permissions:
  contents: write

on:
  workflow_dispatch:
    inputs:
      model:
        description: 'Model name/path to auto-tune.'
        required: false
        type: string
        default: 'Qwen/Qwen3-30B-A3B-Instruct-2507'
      tp_size:
        description: 'Tensor parallel size.'
        required: false
        type: string
        default: '8'
      ep_size:
        description: 'Expert parallel size.'
        required: false
        type: string
        default: '8'
      batch_sizes:
        description: 'Space-separated batch sizes (e.g. "1 2 4 8"). Leave empty for defaults.'
        required: false
        type: string
        default: ''
      create_pr:
        description: 'Create a PR with tuned configs (true/false).'
        required: false
        type: string
        default: 'false'
      runner:
        description: "Runner label to use (e.g. 4-gpu-a10). Use 'all' to run the full matrix."
        required: false
        type: string
        default: 'all'

env:
  CONFIG_DIR: python/sglang/srt/layers/moe/fused_moe_triton/configs

jobs:
  auto-tune-matrix:
    if: github.repository == 'sgl-project/sglang'
    strategy:
      fail-fast: false
      matrix:
        runner: ${{ fromJSON(inputs.runner == 'all' && '["4-gpu-b200","4-gpu-gb200","4-gpu-h100","8-gpu-b200","8-gpu-h20","8-gpu-h200"]' || format('["{0}"]', inputs.runner)) }}
    runs-on: ${{ matrix.runner }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          bash scripts/ci/ci_install_dependency.sh
          pip install ray

      - name: Restore checkpoint cache
        uses: actions/cache@v4
        with:
          path: ~/.sglang/auto_tune_checkpoints/
          key: auto-tune-${{ matrix.runner }}-${{ inputs.model }}-tp${{ inputs.tp_size }}-ep${{ inputs.ep_size }}

      - name: Run auto tune
        run: |
          args=(--model "${{ inputs.model }}" --tp-size "${{ inputs.tp_size }}" --ep-size "${{ inputs.ep_size }}")
          args+=(--output-dir "${{ env.CONFIG_DIR }}")
          args+=(--resume --checkpoint-dir ~/.sglang/auto_tune_checkpoints/)
          if [[ -n "${{ inputs.batch_sizes }}" ]]; then
            args+=(--batch-sizes ${{ inputs.batch_sizes }})
          fi
          python3 -m sglang.auto_tune "${args[@]}"

      - name: Upload tuned configs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: tuned-configs-${{ matrix.runner }}
          path: ${{ env.CONFIG_DIR }}/**
          if-no-files-found: warn

  commit-configs:
    if: github.repository == 'sgl-project/sglang' && inputs.create_pr == 'true'
    needs: auto-tune-matrix
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download tuned configs
        uses: actions/download-artifact@v4
        with:
          pattern: tuned-configs-*
          path: ${{ env.CONFIG_DIR }}
          merge-multiple: true

      - name: Create PR with tuned configs
        uses: peter-evans/create-pull-request@v6
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: "Auto-tune fused MoE configs (all runners)"
          title: "Auto-tuned fused MoE configs"
          body: |
            Auto-tuned fused MoE Triton configs aggregated from all runners.

            Trigger: `${{ github.workflow }} (#${{ github.run_number }})`, run_id `${{ github.run_id }}`.
          branch: auto-tune/configs-${{ github.ref_name }}-${{ github.run_id }}
          delete-branch: true
          add-paths: |
            ${{ env.CONFIG_DIR }}/**
