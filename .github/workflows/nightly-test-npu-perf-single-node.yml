name: 'e2e nightly test single-node (Ascend NPU)'

on:
  workflow_call:
    inputs:
      runner:
        required: true
        type: string
        default: linux-aarch64-a3-16
      test_config_name:
        required: true
        type: string
        description: test config name
      test_case:
        required: true
        type: string
        description: path of test case file
      image:
        required: false
        type: string
        description: image for pods
        default: "swr.cn-southwest-2.myhuaweicloud.com/base_image/dockerhub/lmsysorg/sglang:v0.5.6-ascend-a3"
      install_sglang_from_source:
        required: false
        type: boolean
        default: true
        description: use sglang from source code or from docker image

concurrency:
  group: ascend-nightly-performance-singlenode-${{ github.workflow_ref }}-${{ github.ref }}--${{ inputs.test_config_name }}
  cancel-in-progress: true

jobs:
  e2e:
    name: ${{ inputs.test_config_name }}
    runs-on: ${{ inputs.runner }}
    container:
      image: ${{ inputs.image }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check npu info
        run: |
          npu-smi info

      - name: Run test
        timeout-minutes: 300
        env:
          SGLANG_USE_MODELSCOPE: true
          HF_ENDPOINT: https://hf-mirror.com
          SGLANG_IS_IN_CI: true
        run: |
          sglang_source_path=$(pwd)
          echo "Source code path: ${sglang_source_path}"

          # prepare for output data
          current_date=$(date +%Y%m%d)
          test_data_output_path=/root/.cache/tests/output/perf/${current_date}
          mkdir -p ${test_data_output_path}

          test_case=${{ inputs.test_case }}
          tc_name=${test_case##*/}
          tc_name=${tc_name%.*}
          export METRICS_DATA_FILE=${test_data_output_path}/${tc_name}.txt
          echo "Metrics file: ${METRICS_DATA_FILE}"

          # speed up by using infra cache services
          CACHING_URL="cache-service.nginx-pypi-cache.svc.cluster.local"
          sed -Ei "s@(ports|archive).ubuntu.com@${CACHING_URL}:8081@g" /etc/apt/sources.list
          pip config set global.index-url http://${CACHING_URL}/pypi/simple
          pip config set global.extra-index-url "https://pypi.tuna.tsinghua.edu.cn/simple"
          pip config set global.trusted-host "${CACHING_URL} pypi.tuna.tsinghua.edu.cn"

          # copy required file from our daily cache
          cp ~/.cache/modelscope/hub/datasets/otavia/ShareGPT_Vicuna_unfiltered/ShareGPT_V3_unfiltered_cleaned_split.json /tmp
          # copy download through proxy
          curl -o /tmp/test.jsonl -L https://gh-proxy.test.osinfra.cn/https://raw.githubusercontent.com/openai/grade-school-math/master/grade_school_math/data/test.jsonl

          echo performance | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
          sysctl -w vm.swappiness=0
          sysctl -w kernel.numa_balancing=0
          sysctl -w kernel.sched_migration_cost_ns=50000

          # export SGLANG_SET_CPU_AFFINITY=1

          install_sglang_from_source=${{ inputs.install_sglang_from_source }}
          if [ "$install_sglang_from_source" = "true" ] || [ "$install_sglang_from_source" = "True" ];then
            echo "Install sglang from source"
            commit_id=${{ github.sha }}
            echo "commit id: ${commit_id}" > ${test_data_output_path}/commit_id
            export PYTHONPATH=${sglang_source_path}/python:$PYTHONPATH
          else
            echo "Use sglang from image: ${{ inputs.image }}"
          fi

          # Set environment of cann
          . /usr/local/Ascend/cann/set_env.sh
          . /usr/local/Ascend/nnal/atb/set_env.sh

          echo "Running test case ${test_case}"
          python3 -u ${test_case}
          echo "Finished test case ${test_case}"

          plog_path="/root/ascend/log/debug/plog"
          if [ -d "$plog_path" ];then
            echo "Plog files found. Begin to backup them."
            target_plog_path="/root/.cache/tests/logs/plog/${tc_name}/${HOSTNAME}"
            rm -rf ${target_plog_path}
            mkdir -p ${target_plog_path}
            cp ${plog_path}/* ${target_plog_path}
          fi
