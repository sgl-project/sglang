# Copied and adapted from: https://github.com/hao-ai-lab/FastVideo

import asyncio
import base64
import subprocess
import time
import unittest
from pathlib import Path

from openai import OpenAI

from sglang.multimodal_gen.runtime.utils.common import kill_process_tree
from sglang.multimodal_gen.test.test_utils import is_mp4, is_png, wait_for_port


def wait_for_video_completion(client, video_id, timeout=300, check_interval=3):
    start = time.time()
    video = client.videos.retrieve(video_id)

    while video.status not in ("completed", "failed"):
        time.sleep(check_interval)
        video = client.videos.retrieve(video_id)
        assert time.time() - start < timeout, "video generate timeout"

    return video


class TestVideoHttpServer(unittest.TestCase):
    model_name = "Wan-AI/Wan2.1-T2V-1.3B-Diffusers"
    timeout = 120
    extra_args = []

    def _create_wait_and_download(
        self, client: OpenAI, prompt: str, size: str
    ) -> bytes:

        video = client.videos.create(prompt=prompt, size=size)
        video_id = video.id
        self.assertEqual(video.status, "queued")

        video = wait_for_video_completion(client, video_id, timeout=self.timeout)
        self.assertEqual(video.status, "completed", "video generate failed")

        response = client.videos.download_content(
            video_id=video_id,
        )
        content = response.read()
        return content

    @classmethod
    def setUpClass(cls):
        cls.base_command = [
            "sglang",
            "serve",
            "--model-path",
            f"{cls.model_name}",
            "--port",
            "30010",
        ]

        process = subprocess.Popen(
            cls.base_command + cls.extra_args,
            # stdout=subprocess.PIPE,
            # stderr=subprocess.PIPE,
            text=True,
            bufsize=1,
        )
        cls.pid = process.pid
        wait_for_port(host="127.0.0.1", port=30010)

    @classmethod
    def tearDownClass(cls):
        kill_process_tree(cls.pid)

    def test_http_server_basic(self):
        client = OpenAI(
            api_key="sk-proj-1234567890", base_url="http://localhost:30010/v1"
        )
        content = self._create_wait_and_download(
            client, "A calico cat playing a piano on stage", "832x480"
        )
        self.assertTrue(is_mp4(content))

    def test_concurrent_requests(self):
        client = OpenAI(
            api_key="sk-proj-1234567890", base_url="http://localhost:30010/v1"
        )

        num_requests = 2

        async def generate_and_check_video(prompt, size):
            content = await asyncio.to_thread(
                self._create_wait_and_download, client, prompt, size
            )
            self.assertTrue(is_mp4(content))

        async def send_concurrent_requests():
            tasks = [
                generate_and_check_video(
                    "A dog playing a piano on stage",
                    "832x480",
                )
                for _ in range(num_requests)
            ]
            await asyncio.gather(*tasks)

        asyncio.run(send_concurrent_requests())


class TestFastWan2_1HttpServer(TestVideoHttpServer):
    model_name = "FastVideo/FastWan2.1-T2V-1.3B-Diffusers"
    extra_args = [
        "--attention-backend",
        "video_sparse_attn",
    ]


class TestFastWan2_2HttpServer(TestVideoHttpServer):
    model_name = "FastVideo/FastWan2.2-TI2V-5B-FullAttn-Diffusers"


# class TestImage2VideoHttpServer(unittest.TestCase):
#     model_name = "Wan-AI/Wan2.2-I2V-A14B-Diffusers"
#     timeout = 1200
#     extra_args = []

#     def _create_wait_and_download(
#         self, client: OpenAI, prompt: str, size: str
#     ) -> bytes:

#         image_path = "/root/sgl-diffusion/image_input.png"
#         image_path = Path(image_path)
#         video = client.videos.create(prompt=prompt,
#                                     input_reference=image_path,
#                                     size=size,
#                                     seconds=10,
#                                     extra_body={"fps": 16, "num_frames": 125})
#                                     # TODO: Some combinations of num_frames and fps may cause errors and need further investigation.
#         video_id = video.id
#         self.assertEqual(video.status, "queued")

# video = wait_for_video_completion(client, video_id, timeout=self.timeout)
# self.assertEqual(video.status, "completed", "video generate failed")

#         response = client.videos.download_content(
#             video_id=video_id,
#         )
#         content = response.read()
#         return content

#     @classmethod
#     def setUpClass(cls):
#         cls.base_command = [
#             "sgl-diffusion",
#             "serve",
#             "--model-path",
#             f"{cls.model_name}",
#             "--port",
#             "30010",
#         ]

#         process = subprocess.Popen(
#             cls.base_command + cls.extra_args,
#             # stdout=subprocess.PIPE,
#             # stderr=subprocess.PIPE,
#             text=True,
#             bufsize=1,
#         )
#         cls.pid = process.pid
#         wait_for_port(host="127.0.0.1", port=30010)

#     @classmethod
#     def tearDownClass(cls):
#         kill_process_tree(cls.pid)

#     def test_http_server_basic(self):
#         client = OpenAI(
#             api_key="sk-proj-1234567890", base_url="http://localhost:30010/v1"
#         )
#         content = self._create_wait_and_download(
#             client, "A girl is fighting a monster.", "832x480"
#         )
#         self.assertTrue(is_mp4(content))

#     def test_concurrent_requests(self):
#         client = OpenAI(
#             api_key="sk-proj-1234567890", base_url="http://localhost:30010/v1"
#         )

#         num_requests = 2

#         async def generate_and_check_video(prompt, size):
#             content = await asyncio.to_thread(
#                 self._create_wait_and_download, client, prompt, size
#             )
#             self.assertTrue(is_mp4(content))

#         async def send_concurrent_requests():
#             tasks = [
#                 generate_and_check_video(
#                     "A dog playing a piano on stage",
#                     "832x480",
#                 )
#                 for _ in range(num_requests)
#             ]
#             await asyncio.gather(*tasks)

#         asyncio.run(send_concurrent_requests())


class TestImageHttpServer(unittest.TestCase):

    def _create_wait_and_download(
        self, client: OpenAI, prompt: str, size: str
    ) -> bytes:
        img = client.images.generate(
            model="gpt-image-1",
            prompt=prompt,
            n=1,
            size=size,
            response_format="b64_json",
            output_format="png",
        )
        image_bytes = base64.b64decode(img.data[0].b64_json)
        return image_bytes

    @classmethod
    def setUpClass(cls):
        cls.base_command = [
            "sglang",
            "serve",
            "--model-path",
            "Qwen/Qwen-Image",
            "--port",
            "30020",
        ]

        process = subprocess.Popen(
            cls.base_command,
            # stdout=subprocess.PIPE,
            # stderr=subprocess.PIPE,
            text=True,
            bufsize=1,
        )
        cls.pid = process.pid
        wait_for_port(host="127.0.0.1", port=30020)

    @classmethod
    def tearDownClass(cls):
        kill_process_tree(cls.pid)

    def test_http_server_basic(self):
        client = OpenAI(
            api_key="sk-proj-1234567890", base_url="http://localhost:30020/v1"
        )
        content = self._create_wait_and_download(
            client, "A calico cat playing a piano on stage", "832x480"
        )
        self.assertTrue(is_png(content))

    def test_concurrent_requests(self):
        client = OpenAI(
            api_key="sk-proj-1234567890", base_url="http://localhost:30020/v1"
        )

        num_requests = 2

        async def generate_and_check_image(prompt, size):
            content = await asyncio.to_thread(
                self._create_wait_and_download, client, prompt, size
            )
            self.assertTrue(is_png(content))

        async def send_concurrent_requests():
            tasks = [
                generate_and_check_image(
                    "A dog playing a piano on stage",
                    "832x480",
                )
                for _ in range(num_requests)
            ]
            await asyncio.gather(*tasks)

        asyncio.run(send_concurrent_requests())


if __name__ == "__main__":
    # del TestPerformÂ·anceBase
    unittest.main()
