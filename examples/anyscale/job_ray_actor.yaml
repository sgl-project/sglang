# Anyscale Job Configuration for Multi-Node SGLang with Ray Actor Backend
# This job tests the unified Ray actor scheduler launching that automatically
# discovers GPU nodes and creates per-node placement groups.
#
# Configuration: TP=8 across 2 nodes (4 GPUs per node)
# Total: 1 head node + 2 worker nodes = 3 nodes (12 GPUs available, 8 used)
#
# Submit with: anyscale job submit -f examples/anyscale/job_ray_actor.yaml

name: sglang-multinode-ray-actor-tp8

cloud:

# Compute configuration
compute_config:
  # Head node configuration
  head_node:
    instance_type: g5.12xlarge  # 4x A10G GPUs
    
  # Worker nodes configuration  
  worker_nodes:
    - instance_type: g5.12xlarge  # 4x A10G GPUs
      min_nodes: 2
      max_nodes: 2

# Build from Dockerfile (path relative to working_dir)
containerfile: examples/anyscale/Dockerfile

# Working directory (will be uploaded - use repo root to include local sglang source)
working_dir: .

# Entrypoint script
# Handles package compatibility fixes for Ray actor backend:
# 1. Fix packages on HEAD node (runs here in entrypoint)
# 2. Fix packages on WORKER nodes (via Ray remote tasks)
# 3. Then run the driver
#
# Why fixes can't just be pip install in entrypoint:
# - Entrypoint ONLY runs on head node
# - Worker nodes use Docker image directly, never run entrypoint
# - Must use Ray remote tasks to fix packages on workers
entrypoint: |
  set -e

  echo "=========================================="
  echo "SGLang Ray Actor Backend Setup"
  echo "=========================================="

  # ----------------------------------------------
  # Step 1: Fix packages on HEAD node
  # ----------------------------------------------
  echo ""
  echo "Step 1: Fixing packages on HEAD node..."

  # Fix NumPy < 2.0 (prevents scipy/sklearn/torchvision import errors)
  echo "  Installing numpy<2.0..."
  pip install --no-cache-dir -q "numpy>=1.26.0,<2.0"

  # Keep flashinfer 0.6.1 (matches Dockerfile) - version check bypassed via env var

  # Reinstall sgl-kernel from PyPI (force reinstall to pick up correct GPU arch)
  echo "  Reinstalling sgl-kernel..."
  pip install --no-cache-dir -q sgl-kernel --force-reinstall

  echo "  Head node packages fixed."

  # ----------------------------------------------
  # Step 2: Fix packages on ALL WORKER nodes
  # ----------------------------------------------
  echo ""
  echo "Step 2: Fixing packages on WORKER nodes via Ray..."

  # Run script to fix packages on all worker nodes via Ray remote tasks
  # This must run BEFORE importing sglang (which triggers sgl_kernel import)
  python examples/anyscale/fix_worker_packages.py

  # ----------------------------------------------
  # Step 3: Replace sglang with local version on HEAD node (dev only)
  # (Worker nodes are handled in Step 2 via fix_worker_packages.py)
  # ----------------------------------------------
  echo ""
  echo "Step 3: Replacing sglang.srt with local version on HEAD node..."
  SGLANG_INSTALL_PATH=$(python -c "import sglang; import os; print(os.path.dirname(sglang.__file__))")
  echo "  Installed: $SGLANG_INSTALL_PATH"
  echo "  Local: python/sglang/srt"
  rm -rf "$SGLANG_INSTALL_PATH/srt"
  cp -r python/sglang/srt "$SGLANG_INSTALL_PATH/srt"
  echo "  Done."

  # ----------------------------------------------
  # Step 4: Run the driver
  # ----------------------------------------------
  echo ""
  echo "Step 4: Running driver..."
  echo "=========================================="
  python examples/anyscale/driver_ray_actor.py --tp 8 --skip-package-fix

# Environment variables
env_vars:
  NCCL_DEBUG: INFO
  NCCL_IB_DISABLE: "0"
  NCCL_NET_GDR_LEVEL: "2"
  # Prevent Ray from overwriting CUDA_VISIBLE_DEVICES
  RAY_EXPERIMENTAL_NOSET_CUDA_VISIBLE_DEVICES: "1"
  # Skip flashinfer version check (use 0.6.1 from Dockerfile instead of 0.6.2)
  SGLANG_SKIP_SGL_KERNEL_VERSION_CHECK: "1"

# Job configuration
max_retries: 0
