# Usage: save your github_token in github_token.txt
# docker build --secret id=github_token,src=github_token.txt  -t sglang:xpu_u2410 -f  Dockerfile.xpu --no-cache .


# default base image
ARG BASE_IMAGE="pytorch_xpu_base:ubuntu2410_20250410"

FROM $BASE_IMAGE AS base
USER root

# Set environment variables

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHON_VERSION=3.10

# Set maintainer label
LABEL maintainer="zhaoqiong.zheng@intel.com"

# Install Miniforge & PyTorch/Triton & build vllm/SGlang from source
RUN --mount=type=secret,id=github_token \
    cd /root && \
    echo ${PYTHON_VERSION} | sed 's/\.//g' > /tmp/version.txt && \
    export PYTHON_VERSION_STRING=$(cat /tmp/version.txt) && \
    . /miniforge3/bin/activate && \
    conda activate py${PYTHON_VERSION_STRING} && \
    TEMP_DIR=$(mktemp -d) && \
    echo "Downloading Triton wheels..." && \
    WORKFLOW_ID=$(curl -s -H "Authorization: token $(cat /run/secrets/github_token)"  \
      "https://api.github.com/repos/intel/intel-xpu-backend-for-triton/actions/workflows" \
      | jq -r '.workflows[] | select(.name == "Triton wheels") | .id') && \
    echo "WORKFLOW_ID=${WORKFLOW_ID}" && \
    RUN_ID=$(curl -s -H "Authorization: token $(cat /run/secrets/github_token)" \
        "https://api.github.com/repos/intel/intel-xpu-backend-for-triton/actions/workflows/${WORKFLOW_ID}/runs?status=completed&conclusion=success&per_page=1" \
        | jq -r '.workflow_runs[0].id') && \
    echo "RUN_ID=${RUN_ID}" && \
    ARTIFACT_TEMPLATE="wheels-pytorch-py${PYTHON_VERSION}*" && \
    REGEX_PATTERN=$(echo "$ARTIFACT_TEMPLATE" | sed 's/\*/.*/g') && \
    ARTIFACT_NAME=$(curl -s -H "Authorization: token $(cat /run/secrets/github_token)"  \
        "https://api.github.com/repos/intel/intel-xpu-backend-for-triton/actions/runs/$RUN_ID/artifacts" | \
        jq -r --arg regex "^${REGEX_PATTERN}$" \
    '(.artifacts // [])[] | select(.name | test($regex)) | .name') && \
    echo "ARTIFACT_NAME=${ARTIFACT_NAME}" && \
    LATEST_ARTIFACT_URL=$(curl -s -H "Authorization: token $(cat /run/secrets/github_token)"  \
        "https://api.github.com/repos/intel/intel-xpu-backend-for-triton/actions/runs/$RUN_ID/artifacts" | \
        jq -r ".artifacts[] | select(.name == \"$ARTIFACT_NAME\") | .archive_download_url") && \
    echo "LATEST_ARTIFACT_URL=${LATEST_ARTIFACT_URL}" && \
    curl -L -H "Authorization: token $(cat /run/secrets/github_token)" -C - \
        --retry 5 \
        -o $ARTIFACT_NAME.zip $LATEST_ARTIFACT_URL && \
    unzip -t $ARTIFACT_NAME.zip && \ 
    unzip $ARTIFACT_NAME.zip -d $TEMP_DIR && \
    echo  "Installing Triton wheels..." && \
    pip install $TEMP_DIR/*.whl --root-user-action=ignore && \
    rm -rf $TEMP_DIR && \
    # Install vllm from source
    cd /root && \
    . /opt/intel/oneapi/setvars.sh && \
    echo "Building vllm/sglang from source ..." && \
    git clone https://github.com/zhuyuhua-v/vllm.git && \
    cd vllm && \
    git checkout yuhua/deepseek && \
    pip install setuptools_scm --root-user-action=ignore && \
    pip install setuptools==75.6.0 packaging==24.2 --root-user-action=ignore && \
    VLLM_TARGET_DEVICE=xpu python setup.py install && \
    # Install SGlang from source 
    cd /root && \
    git clone --branch deepseek-xpu-distribute --single-branch https://github.com/cboss6/sglang.git && \
    cd sglang && \
    pip install -e "python[all_xpu]" --root-user-action=ignore && \
    # Install required packages for sglang workloads
    pip install msgspec blake3 py-cpuinfo compressed_tensors gguf partial_json_parser einops --root-user-action=ignore && \
    conda install libsqlite=3.48.0 -y && \
    echo ". /miniforge3/bin/activate; conda activate py${PYTHON_VERSION_STRING}; . /opt/intel/oneapi/setvars.sh; cd /root/" >> /root/.bashrc;
    

# Set the default shell to bash
SHELL ["bash", "-c"]
CMD ["bash", "-c", "source /root/.bashrc && exec bash"]
