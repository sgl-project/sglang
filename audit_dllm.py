import os
import glob
import asyncio
import re
from openai import AsyncOpenAI

# ================= âš¡ï¸ é…ç½®åŒºåŸŸ =================
# 1. å¡«å…¥ä½ ä¹‹å‰éªŒè¯æˆåŠŸçš„é…ç½®
REMOTE_HOST = "https://api.agentify.top/v1" 
API_KEY = "sk-MzagDUFUavhiE1ieVOHk5V1KAy7eXF0ZXfnn6IkPRwb9185P"
MODEL_NAME = "openai/gpt-oss-120b" 

# å¹¶å‘é™åˆ¶ (é˜²æ­¢ API 429)
CONCURRENCY_LIMIT = 5

client = AsyncOpenAI(base_url=REMOTE_HOST, api_key=API_KEY)

# ================= ğŸ§  æ ¸å¿ƒå®¡è®¡é€»è¾‘ =================

async def audit_file(sem, file_path):
    async with sem:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                code = f.read()
        except: return None

        # 1. é¢„ç­›: åªçœ‹åŒ…å« Diffusion/LLaDA å…³é”®è¯çš„æ–‡ä»¶
        if not re.search(r"(llada|diffusion|denoise|mask|block|tp_rank)", code, re.IGNORECASE):
            return None

        print(f"ğŸ§ª æ­£åœ¨å®¡è®¡ dLLM æ ¸å¿ƒä»£ç : {file_path}")

        # 2. é«˜ç»´ Prompt: æ³¨å…¥ LLaDA å’Œ åˆ†å¸ƒå¼å¹¶è¡Œçš„å…ˆéªŒçŸ¥è¯†
        prompt = f"""
        You are an AI Math & Systems Architect auditing the new LLaDA (Large Language Diffusion with Masking) implementation in SGLang.
        
        Target File: {file_path}
        
        **Context**: LLaDA is a Masked Diffusion Model. Unlike Auto-Regressive models, it generates blocks of tokens in parallel using a **Rectangular Attention Mask** (Bidirectional). It requires iterative denoising (re-masking).
        
        **Your Goal**: Find Logic Bugs that break mathematical correctness or distributed consistency.
        
        **Focus Areas**:
        
        1.  **Attention Mask Logic**:
            - Does the code correctly implement the Rectangular Mask for Block Diffusion? 
            - If it reuses the Causal Mask (Triangular) from standard LLMs, THIS IS A BUG.
            
        2.  **Tensor Parallel (TP) Randomness Sync**:
            - LLaDA relies on random masking ratio `t ~ U(0, 1)`.
            - In TP mode, `torch.rand` or `torch.randn` MUST use a synchronized generator seed across all GPUs.
            - If `torch.rand()` is called without handling TP rank synchronization, outputs will diverge. THIS IS A CRITICAL BUG.
            
        3.  **KV Cache Indexing**:
            - Block diffusion writes to non-contiguous slots or overwrites existing slots during re-masking.
            - Check if `paged_attention` indices are calculated correctly. Are we appending when we should be overwriting?
            
        4.  **Numerical Stability**:
            - Look for division by `std` or `sigma`. Is there an epsilon (`+ 1e-6`) to prevent NaN?
            - Check for `exp()` or `log()` on potentially zero/negative values in the noise scheduler.

        **Output Format**:
        - If SAFE: Output only "SAFE".
        - If RISKY:
        [Severity: HIGH/CRITICAL]
        [Line Number]
        [Issue Description]
        [Mathematical/Code Fix Suggestion]
        """

        try:
            res = await client.chat.completions.create(
                model=MODEL_NAME,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1, # æä½æ¸©åº¦ï¼Œæ•°å­¦å®¹ä¸å¾—å¹»è§‰
            )
            return (file_path, res.choices[0].message.content)
        except Exception as e:
            return (file_path, f"API ERROR: {str(e)}")

async def main():
    report_file = "DLLM_AUDIT_REPORT.md"
    
    # ğŸ¯ ç›®æ ‡é”å®šï¼šSGLang çš„ Python æ¨¡å‹å®šä¹‰ç›®å½•
    target_files = set()
    
    # ç­–ç•¥ A: æ‰«æ models ç›®å½• (å¯»æ‰¾ llada.py)
    target_files.update(glob.glob("python/sglang/srt/models/**/*llada*.py", recursive=True))
    target_files.update(glob.glob("python/sglang/srt/models/**/*diffusion*.py", recursive=True))
    
    # ç­–ç•¥ B: æ‰«æ layers ç›®å½• (å¯»æ‰¾ attention mask å®ç°)
    target_files.update(glob.glob("python/sglang/srt/layers/**/*.py", recursive=True))
    
    # ç­–ç•¥ C: æ‰«æ scheduler (å¯»æ‰¾ diffusion scheduler)
    target_files.update(glob.glob("python/sglang/srt/managers/**/*.py", recursive=True))

    target_files = list(target_files)
    print(f"ğŸš€ å¼€å§‹å®¡è®¡ dLLM ç›¸å…³ä»£ç  ({len(target_files)} files)...")

    sem = asyncio.Semaphore(CONCURRENCY_LIMIT)
    tasks = [audit_file(sem, f) for f in target_files]
    
    # æ˜¾ç¤ºè¿›åº¦
    results = await asyncio.gather(*tasks)
    
    with open(report_file, "w", encoding="utf-8") as f:
        f.write("# SGLang dLLM (LLaDA) Security & Logic Audit\n\n")
        
        hit_count = 0
        for item in results:
            if item and "SAFE" not in item[1] and "API ERROR" not in item[1]:
                path, content = item
                hit_count += 1
                print(f"ğŸ”¥ [æ½œåœ¨é€»è¾‘æ¼æ´] {path}")
                f.write(f"## ğŸ“‚ {path}\n{content}\n\n---\n")
                f.flush()

    print(f"\nâœ… å®¡è®¡å®Œæˆï¼å…±å‘ç° {hit_count} ä¸ªæ½œåœ¨é—®é¢˜ã€‚")
    print(f"ğŸ‘‰ è¯·æŸ¥çœ‹æŠ¥å‘Š: {report_file}")

if __name__ == "__main__":
    asyncio.run(main())