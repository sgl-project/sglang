//! Golden tests for the multimodal processing pipeline.
//!
//! These tests verify that the `MultiModalPipeline` correctly:
//! 1. Selects the appropriate processor based on model_id
//! 2. Processes images through the correct processor
//! 3. Produces outputs matching the SGLang Python processor outputs
//!
//! This validates that our Rust implementation matches SGLang's Python implementation.
//!
//! Pipeline golden outputs are in:
//! - `tests/fixtures/golden_pipeline/{model}/{scenario}/golden.npz`
//! - `tests/fixtures/golden_pipeline/{model}/{scenario}/metadata.json`
//!
//! Note: Qwen2-VL/Qwen3-VL golden data is stored in 2D patch format,
//! not raw 4D pixel values. The tests handle this by using the processor's
//! `reshape_to_patches()` method before comparison.
//!
//! ## Running These Tests
//!
//! These tests are **ignored by default** because they require:
//! - Golden test fixtures generated by `scripts/generate_pipeline_golden.py`
//! - More compute/memory than typical CI runners
//!
//! To run locally:
//! ```bash
//! # First generate golden fixtures
//! python scripts/generate_pipeline_golden.py
//!
//! # Then run the ignored tests
//! cargo test --test pipeline_golden_tests -- --ignored
//! ```
//!
//! In CI, these run in the `router-grpc-response-api-tests` job which has
//! GPU resources and SGLang dependencies available.

use std::{
    fs::File,
    io::Read,
    path::{Path, PathBuf},
    sync::Arc,
    time::Duration,
};

use image::DynamicImage;
use ndarray::ArrayD;
use reqwest::Client;
use sgl_model_gateway::multimodal::{
    vision::{image_processor::ModelSpecificValue, PreProcessorConfig, Qwen2VLProcessor},
    MediaConnector, MediaConnectorConfig, MultiModalPipeline, PipelineConfig,
};

/// Load golden pixel_values from npz (returns dynamic array)
fn load_golden_pixel_values(path: &Path) -> ArrayD<f32> {
    let file = File::open(path).expect("Failed to open golden npz");
    let mut npz = npyz::npz::NpzArchive::new(file).expect("Failed to parse npz");

    let reader = npz
        .by_name("pixel_values")
        .expect("Failed to read npz")
        .expect("No pixel_values");

    let shape: Vec<usize> = reader.shape().iter().map(|&s| s as usize).collect();
    let data: Vec<f32> = reader.into_vec().expect("Failed to read array");

    ArrayD::from_shape_vec(ndarray::IxDyn(&shape), data).expect("Shape conversion failed")
}

/// Load Qwen2-VL golden data (2D patches format)
fn load_golden_qwen2_vl_patches(path: &Path) -> (Vec<f32>, (usize, usize)) {
    let file = File::open(path).expect("Failed to open golden npz");
    let mut npz = npyz::npz::NpzArchive::new(file).expect("Failed to parse npz");

    let reader = npz
        .by_name("pixel_values")
        .expect("Failed to read npz")
        .expect("No pixel_values");

    let shape = reader.shape().to_vec();
    assert_eq!(shape.len(), 2, "Expected 2D tensor for Qwen2-VL patches");

    let data: Vec<f32> = reader.into_vec().expect("Failed to read array");
    (data, (shape[0] as usize, shape[1] as usize))
}

/// Load image_grid_thw from npz file
fn load_golden_grid_thw(path: &Path) -> Vec<u32> {
    let file = File::open(path).expect("Failed to open golden file");
    let mut npz = npyz::npz::NpzArchive::new(file).expect("Failed to parse npz");

    let reader = npz
        .by_name("image_grid_thw")
        .expect("Failed to read npz")
        .expect("No image_grid_thw");

    let data: Vec<i64> = reader.into_vec().expect("Failed to read array");
    data.into_iter().map(|v| v as u32).collect()
}

/// Load num_tokens from npz file
fn load_golden_num_tokens(path: &Path) -> usize {
    let file = File::open(path).expect("Failed to open golden file");
    let mut npz = npyz::npz::NpzArchive::new(file).expect("Failed to parse npz");

    let reader = npz
        .by_name("num_tokens")
        .expect("Failed to read npz")
        .expect("No num_tokens");

    let data: Vec<i64> = reader.into_vec().expect("Failed to read array");
    data[0] as usize
}

/// Load preprocessor config if available
fn load_config(path: &Path) -> Option<PreProcessorConfig> {
    if path.exists() {
        let mut file = File::open(path).ok()?;
        let mut contents = String::new();
        file.read_to_string(&mut contents).ok()?;
        PreProcessorConfig::from_json(&contents).ok()
    } else {
        None
    }
}

/// Load a test image
fn load_test_image(name: &str) -> DynamicImage {
    let path = PathBuf::from(format!("tests/fixtures/images/{}.jpg", name));
    image::open(&path).unwrap_or_else(|_| panic!("Failed to load test image: {}", name))
}

/// Compare two dynamic tensors and return max absolute difference
fn max_diff(a: &ArrayD<f32>, b: &ArrayD<f32>) -> f32 {
    assert_eq!(
        a.shape(),
        b.shape(),
        "Shape mismatch: {:?} vs {:?}",
        a.shape(),
        b.shape()
    );
    (a - b).mapv(|v| v.abs()).fold(0.0f32, |acc, &v| acc.max(v))
}

/// Create a pipeline for testing
fn create_test_pipeline() -> MultiModalPipeline {
    let client = Client::builder()
        .timeout(Duration::from_secs(10))
        .build()
        .expect("Failed to create client");

    let config = MediaConnectorConfig {
        allowed_domains: None,
        allowed_local_media_path: Some(PathBuf::from(".")),
        fetch_timeout: Duration::from_secs(10),
    };

    let connector = MediaConnector::new(client, config).expect("Failed to create connector");
    MultiModalPipeline::new(Arc::new(connector))
}

// ============================================================================
// Pipeline Processor Selection Tests
// ============================================================================

#[test]
#[ignore]
fn test_pipeline_has_llava_processor() {
    let pipeline = create_test_pipeline();

    // Various LLaVA model ID patterns should find a processor
    assert!(pipeline.has_processor("llava-hf/llava-1.5-7b-hf"));
    assert!(pipeline.has_processor("liuhaotian/llava-v1.5-7b"));
    assert!(pipeline.has_processor("llava-hf/llava-v1.6-mistral-7b-hf"));

    // Verify it's the right processor
    let processor = pipeline.get_processor("llava-hf/llava-1.5-7b-hf").unwrap();
    assert_eq!(processor.model_name(), "llava");
}

#[test]
#[ignore]
fn test_pipeline_has_qwen_processors() {
    let pipeline = create_test_pipeline();

    // Qwen2-VL
    assert!(pipeline.has_processor("Qwen/Qwen2-VL-7B-Instruct"));
    let p = pipeline.get_processor("Qwen/Qwen2-VL-7B-Instruct").unwrap();
    assert_eq!(p.model_name(), "qwen2-vl");

    // Qwen2.5-VL (uses same processor as Qwen2-VL)
    assert!(pipeline.has_processor("Qwen/Qwen2.5-VL-7B-Instruct"));

    // Qwen3-VL
    assert!(pipeline.has_processor("Qwen/Qwen3-VL-8B-Instruct"));
    let p = pipeline.get_processor("Qwen/Qwen3-VL-8B-Instruct").unwrap();
    assert_eq!(p.model_name(), "qwen3-vl");
}

#[test]
#[ignore]
fn test_pipeline_has_phi_processors() {
    let pipeline = create_test_pipeline();

    // Phi3-Vision
    assert!(pipeline.has_processor("microsoft/Phi-3-vision-128k-instruct"));
    let p = pipeline
        .get_processor("microsoft/Phi-3-vision-128k-instruct")
        .unwrap();
    assert_eq!(p.model_name(), "phi3-vision");

    // Phi4-Vision
    assert!(pipeline.has_processor("microsoft/phi-4-vision"));
    let p = pipeline.get_processor("microsoft/phi-4-vision").unwrap();
    assert_eq!(p.model_name(), "phi4-vision");
}

#[test]
#[ignore]
fn test_pipeline_has_llama4_processor() {
    let pipeline = create_test_pipeline();

    assert!(pipeline.has_processor("meta-llama/Llama-4-Scout-17B"));
    assert!(pipeline.has_processor("llama4-vision"));

    let p = pipeline.get_processor("llama4-vision").unwrap();
    assert_eq!(p.model_name(), "llama4-vision");
}

#[test]
#[ignore]
fn test_pipeline_has_pixtral_processor() {
    let pipeline = create_test_pipeline();

    assert!(pipeline.has_processor("mistralai/Pixtral-12B-2409"));
    assert!(pipeline.has_processor("pixtral-12b"));

    let p = pipeline.get_processor("pixtral-12b").unwrap();
    assert_eq!(p.model_name(), "pixtral");
}

#[test]
#[ignore]
fn test_pipeline_no_processor_for_unknown_model() {
    let pipeline = create_test_pipeline();

    assert!(!pipeline.has_processor("unknown-model/foo"));
    assert!(pipeline.get_processor("unknown-model/foo").is_none());
}

// ============================================================================
// Pipeline Processing Tests (using existing golden data)
// ============================================================================

/// Map image name to scenario name for golden_pipeline directory
fn image_to_scenario(image_name: &str) -> &str {
    match image_name {
        "square" => "single_square",
        "wide" => "single_wide",
        "tall" => "single_tall",
        "small" => "single_small",
        other => other,
    }
}

/// Test that pipeline processing matches SGLang Python processor output
fn run_pipeline_test(
    model_id: &str,
    golden_dir: &str,
    image_name: &str,
    config_file: Option<&str>,
    tolerance: f32,
) {
    let scenario = image_to_scenario(image_name);
    let golden_path = PathBuf::from(format!(
        "tests/fixtures/golden_pipeline/{}/{}/golden.npz",
        golden_dir, scenario
    ));

    if !golden_path.exists() {
        eprintln!("Skipping test: golden data not found at {:?}", golden_path);
        return;
    }

    // Load golden data
    let golden_pixels = load_golden_pixel_values(&golden_path);

    // Load config if specified - configs are in metadata.json now
    let config_path = config_file.map(|f| {
        PathBuf::from(format!(
            "tests/fixtures/golden_pipeline/{}/{}/{}",
            golden_dir, scenario, f
        ))
    });
    let preproc_config = config_path.and_then(|p| load_config(&p));

    // Load test image
    let image = load_test_image(image_name);

    // Create pipeline and process
    let pipeline = create_test_pipeline();

    assert!(
        pipeline.has_processor(model_id),
        "No processor for model_id: {}",
        model_id
    );

    let mut config = PipelineConfig::new(model_id);
    if let Some(pc) = preproc_config {
        config = config.with_preprocessor_config(pc);
    }

    // Process single image
    let result = pipeline
        .process_images(&[image], &config)
        .expect("Pipeline processing failed");

    // Compare pixel_values (shapes may differ - golden might be flattened)
    let result_pixels = &result.preprocessed.pixel_values;

    // Check if shapes match or if we need to compare flattened
    if golden_pixels.shape() == result_pixels.shape() {
        let diff = max_diff(&golden_pixels, result_pixels);
        println!(
            "Pipeline test {}/{}: shape {:?}, max_diff = {:.6}",
            model_id,
            image_name,
            result_pixels.shape(),
            diff
        );
        assert!(
            diff < tolerance,
            "pixel_values max_diff {} exceeds tolerance {} for {}/{}",
            diff,
            tolerance,
            model_id,
            image_name
        );
    } else {
        // Shapes differ - compare total elements and some statistics
        let golden_flat: Vec<f32> = golden_pixels.iter().cloned().collect();
        let result_flat: Vec<f32> = result_pixels.iter().cloned().collect();

        assert_eq!(
            golden_flat.len(),
            result_flat.len(),
            "Total element count mismatch for {}/{}: golden {} vs result {}",
            model_id,
            image_name,
            golden_flat.len(),
            result_flat.len()
        );

        let diff: f32 = golden_flat
            .iter()
            .zip(result_flat.iter())
            .map(|(a, b)| (a - b).abs())
            .fold(0.0f32, |acc, v| acc.max(v));

        println!(
            "Pipeline test {}/{}: golden shape {:?}, result shape {:?}, max_diff = {:.6}",
            model_id,
            image_name,
            golden_pixels.shape(),
            result_pixels.shape(),
            diff
        );

        assert!(
            diff < tolerance,
            "pixel_values max_diff {} exceeds tolerance {} for {}/{}",
            diff,
            tolerance,
            model_id,
            image_name
        );
    }
}

// ============================================================================
// LLaVA Pipeline Golden Tests
// ============================================================================

#[test]
#[ignore]
fn test_pipeline_llava_square() {
    run_pipeline_test(
        "llava-hf/llava-1.5-7b-hf",
        "llava",
        "square",
        Some("preprocessor_config.json"),
        0.01,
    );
}

#[test]
#[ignore]
fn test_pipeline_llava_wide() {
    run_pipeline_test(
        "llava-hf/llava-1.5-7b-hf",
        "llava",
        "wide",
        Some("preprocessor_config.json"),
        0.01,
    );
}

#[test]
#[ignore]
fn test_pipeline_llava_tall() {
    run_pipeline_test(
        "llava-hf/llava-1.5-7b-hf",
        "llava",
        "tall",
        Some("preprocessor_config.json"),
        0.01,
    );
}

// ============================================================================
// Qwen2-VL Pipeline Golden Tests
// ============================================================================

/// Specialized test for Qwen2-VL that handles patch format conversion.
///
/// Qwen2-VL golden data is stored as 2D patches (num_patches, patch_features),
/// not as 4D pixel values. We need to reshape our output to match.
fn run_qwen2_vl_pipeline_test(model_id: &str, image_name: &str, tolerance: f32) {
    let scenario = image_to_scenario(image_name);
    let golden_dir = PathBuf::from(format!(
        "tests/fixtures/golden_pipeline/qwen2_vl/{}",
        scenario
    ));
    let npz_path = golden_dir.join("golden.npz");

    if !npz_path.exists() {
        eprintln!("Skipping test: golden data not found at {:?}", npz_path);
        return;
    }

    // Load golden data (2D patch format)
    let (golden_pixels, golden_shape) = load_golden_qwen2_vl_patches(&npz_path);
    let golden_grid_thw = load_golden_grid_thw(&npz_path);
    let golden_num_tokens = load_golden_num_tokens(&npz_path);

    // Load test image
    let image = load_test_image(image_name);

    // Create pipeline and process
    let pipeline = create_test_pipeline();

    assert!(
        pipeline.has_processor(model_id),
        "No processor for model_id: {}",
        model_id
    );

    let config = PipelineConfig::new(model_id);

    // Process single image
    let result = pipeline
        .process_images(&[image], &config)
        .expect("Pipeline processing failed");

    // Extract image_grid_thw from result
    let rust_grid_thw = match result.preprocessed.model_specific.get("image_grid_thw") {
        Some(ModelSpecificValue::UintTensor { data, shape }) => {
            assert_eq!(shape, &[1, 3], "Expected shape [1, 3] for single image");
            data.clone()
        }
        _ => panic!("Expected image_grid_thw in model_specific"),
    };

    // Compare grid dimensions
    println!(
        "Pipeline qwen2_vl - {} - Grid T H W: golden={:?}, rust={:?}",
        image_name, golden_grid_thw, rust_grid_thw
    );
    assert_eq!(
        golden_grid_thw, rust_grid_thw,
        "image_grid_thw mismatch for {}",
        image_name
    );

    // Compare token counts
    let rust_num_tokens = result.preprocessed.num_img_tokens[0];
    println!(
        "Pipeline qwen2_vl - {} - Tokens: golden={}, rust={}",
        image_name, golden_num_tokens, rust_num_tokens
    );
    assert_eq!(
        golden_num_tokens, rust_num_tokens,
        "num_tokens mismatch for {}",
        image_name
    );

    // Reshape our output to patch format for comparison
    let preproc_config = PreProcessorConfig::default();
    let processor = Qwen2VLProcessor::from_preprocessor_config(&preproc_config);
    let result_pixels = &result.preprocessed.pixel_values;

    // Extract dimensions
    let grid_t = rust_grid_thw[0] as usize;
    let grid_h = rust_grid_thw[1] as usize;
    let grid_w = rust_grid_thw[2] as usize;

    // Convert ArrayD to Array4 for reshaping
    let tensor_4d = result_pixels
        .clone()
        .into_dimensionality::<ndarray::Ix4>()
        .expect("Expected 4D tensor");

    // Remove batch dimension to get [C, H, W]
    let tensor_3d = tensor_4d.index_axis(ndarray::Axis(0), 0).to_owned();

    // Reshape to patches format
    let rust_patches = processor.reshape_to_patches(&tensor_3d, grid_t, grid_h, grid_w);

    // Verify shapes match
    let expected_num_patches = grid_t * grid_h * grid_w;
    let patch_size = preproc_config.get_patch_size(14);
    let temporal_patch_size = preproc_config.temporal_patch_size.unwrap_or(2);
    let expected_patch_features = 3 * temporal_patch_size * patch_size * patch_size;

    println!(
        "Pipeline qwen2_vl - {} - Patch shape: golden={:?}, rust=({}, {})",
        image_name, golden_shape, expected_num_patches, expected_patch_features
    );
    assert_eq!(
        golden_shape,
        (expected_num_patches, expected_patch_features),
        "Patch shape mismatch"
    );
    assert_eq!(
        rust_patches.len(),
        expected_num_patches * expected_patch_features,
        "Rust patches total size mismatch"
    );

    // Compare pixel values
    let max_diff: f32 = golden_pixels
        .iter()
        .zip(rust_patches.iter())
        .map(|(a, b)| (a - b).abs())
        .fold(0.0f32, |acc, v| acc.max(v));

    println!(
        "Pipeline qwen2_vl - {} - Max pixel diff: {:.6}",
        image_name, max_diff
    );
    assert!(
        max_diff < tolerance,
        "Max pixel difference {} exceeds tolerance {} for {}",
        max_diff,
        tolerance,
        image_name
    );
}

#[test]
#[ignore]
fn test_pipeline_qwen2_vl_square() {
    run_qwen2_vl_pipeline_test("Qwen/Qwen2-VL-7B-Instruct", "square", 0.01);
}

#[test]
#[ignore]
fn test_pipeline_qwen2_vl_wide() {
    run_qwen2_vl_pipeline_test("Qwen/Qwen2-VL-7B-Instruct", "wide", 0.01);
}

#[test]
#[ignore]
fn test_pipeline_qwen2_vl_tall() {
    run_qwen2_vl_pipeline_test("Qwen/Qwen2-VL-7B-Instruct", "tall", 0.01);
}

// ============================================================================
// Qwen3-VL Pipeline Golden Tests
// ============================================================================

/// Specialized test for Qwen3-VL (same patch format as Qwen2-VL but different config)
fn run_qwen3_vl_pipeline_test(model_id: &str, image_name: &str, tolerance: f32) {
    let scenario = image_to_scenario(image_name);
    let golden_dir = PathBuf::from(format!(
        "tests/fixtures/golden_pipeline/qwen3_vl/{}",
        scenario
    ));
    let npz_path = golden_dir.join("golden.npz");

    if !npz_path.exists() {
        eprintln!("Skipping test: golden data not found at {:?}", npz_path);
        return;
    }

    // Load golden data (2D patch format)
    let (golden_pixels, golden_shape) = load_golden_qwen2_vl_patches(&npz_path);
    let golden_grid_thw = load_golden_grid_thw(&npz_path);
    let golden_num_tokens = load_golden_num_tokens(&npz_path);

    // Load test image
    let image = load_test_image(image_name);

    // Create pipeline and process
    let pipeline = create_test_pipeline();

    assert!(
        pipeline.has_processor(model_id),
        "No processor for model_id: {}",
        model_id
    );

    let config = PipelineConfig::new(model_id);

    let result = pipeline
        .process_images(&[image], &config)
        .expect("Pipeline processing failed");

    // Extract image_grid_thw from result
    let rust_grid_thw = match result.preprocessed.model_specific.get("image_grid_thw") {
        Some(ModelSpecificValue::UintTensor { data, shape }) => {
            assert_eq!(shape, &[1, 3], "Expected shape [1, 3] for single image");
            data.clone()
        }
        _ => panic!("Expected image_grid_thw in model_specific"),
    };

    // Compare grid dimensions
    println!(
        "Pipeline qwen3_vl - {} - Grid T H W: golden={:?}, rust={:?}",
        image_name, golden_grid_thw, rust_grid_thw
    );
    assert_eq!(
        golden_grid_thw, rust_grid_thw,
        "image_grid_thw mismatch for {}",
        image_name
    );

    // Compare token counts
    let rust_num_tokens = result.preprocessed.num_img_tokens[0];
    println!(
        "Pipeline qwen3_vl - {} - Tokens: golden={}, rust={}",
        image_name, golden_num_tokens, rust_num_tokens
    );
    assert_eq!(
        golden_num_tokens, rust_num_tokens,
        "num_tokens mismatch for {}",
        image_name
    );

    // Reshape our output to patch format for comparison
    // Import Qwen3VLProcessor for reshape
    use sgl_model_gateway::multimodal::vision::Qwen3VLProcessor;
    let preproc_config = PreProcessorConfig::default();
    let processor = Qwen3VLProcessor::from_preprocessor_config(&preproc_config);
    let result_pixels = &result.preprocessed.pixel_values;

    let grid_t = rust_grid_thw[0] as usize;
    let grid_h = rust_grid_thw[1] as usize;
    let grid_w = rust_grid_thw[2] as usize;

    let tensor_4d = result_pixels
        .clone()
        .into_dimensionality::<ndarray::Ix4>()
        .expect("Expected 4D tensor");

    let tensor_3d = tensor_4d.index_axis(ndarray::Axis(0), 0).to_owned();

    let rust_patches = processor.reshape_to_patches(&tensor_3d, grid_t, grid_h, grid_w);

    // Verify shapes match
    let expected_num_patches = grid_t * grid_h * grid_w;
    let patch_size = preproc_config.get_patch_size(16); // Qwen3 uses 16
    let temporal_patch_size = preproc_config.temporal_patch_size.unwrap_or(2);
    let expected_patch_features = 3 * temporal_patch_size * patch_size * patch_size;

    println!(
        "Pipeline qwen3_vl - {} - Patch shape: golden={:?}, rust=({}, {})",
        image_name, golden_shape, expected_num_patches, expected_patch_features
    );
    assert_eq!(
        golden_shape,
        (expected_num_patches, expected_patch_features),
        "Patch shape mismatch"
    );

    // Compare pixel values
    let max_diff: f32 = golden_pixels
        .iter()
        .zip(rust_patches.iter())
        .map(|(a, b)| (a - b).abs())
        .fold(0.0f32, |acc, v| acc.max(v));

    println!(
        "Pipeline qwen3_vl - {} - Max pixel diff: {:.6}",
        image_name, max_diff
    );
    assert!(
        max_diff < tolerance,
        "Max pixel difference {} exceeds tolerance {} for {}",
        max_diff,
        tolerance,
        image_name
    );
}

#[test]
#[ignore]
fn test_pipeline_qwen3_vl_square() {
    run_qwen3_vl_pipeline_test("Qwen/Qwen3-VL-8B-Instruct", "square", 0.01);
}

#[test]
#[ignore]
fn test_pipeline_qwen3_vl_wide() {
    run_qwen3_vl_pipeline_test("Qwen/Qwen3-VL-8B-Instruct", "wide", 0.01);
}

#[test]
#[ignore]
fn test_pipeline_qwen3_vl_tall() {
    run_qwen3_vl_pipeline_test("Qwen/Qwen3-VL-8B-Instruct", "tall", 0.01);
}

// ============================================================================
// Phi3-Vision Pipeline Golden Tests
// ============================================================================

/// Test for Phi3-Vision (5D output with tiles)
fn run_phi3_vision_pipeline_test(model_id: &str, image_name: &str, tolerance: f32) {
    let scenario = image_to_scenario(image_name);
    let golden_dir = PathBuf::from(format!(
        "tests/fixtures/golden_pipeline/phi3_vision/{}",
        scenario
    ));
    let npz_path = golden_dir.join("golden.npz");

    if !npz_path.exists() {
        eprintln!("Skipping test: golden data not found at {:?}", npz_path);
        return;
    }

    // Load golden pixel_values (5D)
    let golden_pixels = load_golden_pixel_values(&npz_path);

    // Load test image
    let image = load_test_image(image_name);

    // Create pipeline and process
    let pipeline = create_test_pipeline();

    assert!(
        pipeline.has_processor(model_id),
        "No processor for model_id: {}",
        model_id
    );

    let config = PipelineConfig::new(model_id);

    let result = pipeline
        .process_images(&[image], &config)
        .expect("Pipeline processing failed");

    let result_pixels = &result.preprocessed.pixel_values;

    // Compare shapes
    println!(
        "Pipeline phi3_vision - {} - Shape: golden={:?}, rust={:?}",
        image_name,
        golden_pixels.shape(),
        result_pixels.shape()
    );

    assert_eq!(
        golden_pixels.shape(),
        result_pixels.shape(),
        "Shape mismatch for phi3_vision/{}",
        image_name
    );

    // Compare pixel values
    let diff = max_diff(&golden_pixels, result_pixels);
    println!(
        "Pipeline phi3_vision - {} - Max pixel diff: {:.6}",
        image_name, diff
    );
    assert!(
        diff < tolerance,
        "Max pixel difference {} exceeds tolerance {} for phi3_vision/{}",
        diff,
        tolerance,
        image_name
    );
}

#[test]
#[ignore]
fn test_pipeline_phi3_vision_square() {
    run_phi3_vision_pipeline_test("microsoft/Phi-3-vision-128k-instruct", "square", 0.08);
}

#[test]
#[ignore]
fn test_pipeline_phi3_vision_wide() {
    run_phi3_vision_pipeline_test("microsoft/Phi-3-vision-128k-instruct", "wide", 0.08);
}

#[test]
#[ignore]
fn test_pipeline_phi3_vision_tall() {
    run_phi3_vision_pipeline_test("microsoft/Phi-3-vision-128k-instruct", "tall", 0.08);
}

// ============================================================================
// Phi4-Vision Pipeline Golden Tests
// ============================================================================

/// Test for Phi4-Vision (5D output with tiles + attention mask)
fn run_phi4_vision_pipeline_test(model_id: &str, image_name: &str, tolerance: f32) {
    let scenario = image_to_scenario(image_name);
    let golden_dir = PathBuf::from(format!(
        "tests/fixtures/golden_pipeline/phi4_vision/{}",
        scenario
    ));
    let npz_path = golden_dir.join("golden.npz");

    if !npz_path.exists() {
        eprintln!("Skipping test: golden data not found at {:?}", npz_path);
        return;
    }

    // Load golden pixel_values (5D)
    let golden_pixels = load_golden_pixel_values(&npz_path);

    // Load test image
    let image = load_test_image(image_name);

    // Create pipeline and process
    let pipeline = create_test_pipeline();

    assert!(
        pipeline.has_processor(model_id),
        "No processor for model_id: {}",
        model_id
    );

    let config = PipelineConfig::new(model_id);

    let result = pipeline
        .process_images(&[image], &config)
        .expect("Pipeline processing failed");

    let result_pixels = &result.preprocessed.pixel_values;

    // Compare shapes
    println!(
        "Pipeline phi4_vision - {} - Shape: golden={:?}, rust={:?}",
        image_name,
        golden_pixels.shape(),
        result_pixels.shape()
    );

    assert_eq!(
        golden_pixels.shape(),
        result_pixels.shape(),
        "Shape mismatch for phi4_vision/{}",
        image_name
    );

    // Compare pixel values
    let diff = max_diff(&golden_pixels, result_pixels);
    println!(
        "Pipeline phi4_vision - {} - Max pixel diff: {:.6}",
        image_name, diff
    );
    assert!(
        diff < tolerance,
        "Max pixel difference {} exceeds tolerance {} for phi4_vision/{}",
        diff,
        tolerance,
        image_name
    );
}

#[test]
#[ignore]
fn test_pipeline_phi4_vision_square() {
    run_phi4_vision_pipeline_test("microsoft/phi-4-vision", "square", 0.05);
}

#[test]
#[ignore]
fn test_pipeline_phi4_vision_wide() {
    run_phi4_vision_pipeline_test("microsoft/phi-4-vision", "wide", 0.05);
}

#[test]
#[ignore]
fn test_pipeline_phi4_vision_tall() {
    run_phi4_vision_pipeline_test("microsoft/phi-4-vision", "tall", 0.05);
}

// ============================================================================
// LLaMA4-Vision Pipeline Golden Tests
// ============================================================================

/// Test for LLaMA4-Vision (tile-based output)
fn run_llama4_vision_pipeline_test(model_id: &str, image_name: &str, tolerance: f32) {
    let scenario = image_to_scenario(image_name);
    let golden_dir = PathBuf::from(format!(
        "tests/fixtures/golden_pipeline/llama4_vision/{}",
        scenario
    ));
    let npz_path = golden_dir.join("golden.npz");

    if !npz_path.exists() {
        eprintln!("Skipping test: golden data not found at {:?}", npz_path);
        return;
    }

    // Load golden pixel_values (4D: [num_tiles, C, H, W] - no batch dim in golden)
    let golden_pixels = load_golden_pixel_values(&npz_path);

    // Load test image
    let image = load_test_image(image_name);

    // Create pipeline and process
    let pipeline = create_test_pipeline();

    assert!(
        pipeline.has_processor(model_id),
        "No processor for model_id: {}",
        model_id
    );

    let config = PipelineConfig::new(model_id);

    let result = pipeline
        .process_images(&[image], &config)
        .expect("Pipeline processing failed");

    let result_pixels = &result.preprocessed.pixel_values;

    // LLaMA4 golden is [num_tiles, C, H, W], rust is [B, num_tiles, C, H, W]
    // Need to compare with batch dimension removed from rust output
    println!(
        "Pipeline llama4_vision - {} - Shape: golden={:?}, rust={:?}",
        image_name,
        golden_pixels.shape(),
        result_pixels.shape()
    );

    // Handle shape comparison - rust output has batch dimension
    if result_pixels.ndim() == 5 && golden_pixels.ndim() == 4 {
        // Remove batch dimension from rust output for comparison
        let result_5d = result_pixels
            .clone()
            .into_dimensionality::<ndarray::Ix5>()
            .expect("Expected 5D tensor");
        let result_4d = result_5d.index_axis(ndarray::Axis(0), 0);

        // Compare only the valid tiles (golden may have fewer tiles)
        let golden_tiles = golden_pixels.shape()[0];
        let rust_tiles = result_4d.shape()[0];

        println!(
            "Pipeline llama4_vision - {} - Tiles: golden={}, rust={}",
            image_name, golden_tiles, rust_tiles
        );

        // Compare tile by tile
        let min_tiles = golden_tiles.min(rust_tiles);
        let mut max_diff_val = 0.0f32;

        for t in 0..min_tiles {
            let golden_tile = golden_pixels.index_axis(ndarray::Axis(0), t);
            let rust_tile = result_4d.index_axis(ndarray::Axis(0), t);

            let tile_diff: f32 = golden_tile
                .iter()
                .zip(rust_tile.iter())
                .map(|(a, b)| (a - b).abs())
                .fold(0.0f32, |acc, v| acc.max(v));

            max_diff_val = max_diff_val.max(tile_diff);
        }

        println!(
            "Pipeline llama4_vision - {} - Max pixel diff: {:.6}",
            image_name, max_diff_val
        );
        assert!(
            max_diff_val < tolerance,
            "Max pixel difference {} exceeds tolerance {} for llama4_vision/{}",
            max_diff_val,
            tolerance,
            image_name
        );
    } else {
        // Direct comparison if shapes match
        let diff = max_diff(&golden_pixels, result_pixels);
        println!(
            "Pipeline llama4_vision - {} - Max pixel diff: {:.6}",
            image_name, diff
        );
        assert!(
            diff < tolerance,
            "Max pixel difference {} exceeds tolerance {} for llama4_vision/{}",
            diff,
            tolerance,
            image_name
        );
    }
}

#[test]
#[ignore]
fn test_pipeline_llama4_vision_square() {
    run_llama4_vision_pipeline_test("meta-llama/Llama-4-Scout-17B", "square", 0.03);
}

#[test]
#[ignore]
fn test_pipeline_llama4_vision_wide() {
    run_llama4_vision_pipeline_test("meta-llama/Llama-4-Scout-17B", "wide", 0.03);
}

#[test]
#[ignore]
fn test_pipeline_llama4_vision_tall() {
    run_llama4_vision_pipeline_test("meta-llama/Llama-4-Scout-17B", "tall", 0.03);
}

// ============================================================================
// Pixtral Pipeline Golden Tests
// ============================================================================

#[test]
#[ignore]
fn test_pipeline_pixtral_square() {
    run_pipeline_test(
        "mistralai/Pixtral-12B-2409",
        "pixtral",
        "square",
        Some("preprocessor_config.json"),
        0.05,
    );
}

#[test]
#[ignore]
fn test_pipeline_pixtral_wide() {
    run_pipeline_test(
        "mistralai/Pixtral-12B-2409",
        "pixtral",
        "wide",
        Some("preprocessor_config.json"),
        0.05,
    );
}

#[test]
#[ignore]
fn test_pipeline_pixtral_tall() {
    run_pipeline_test(
        "mistralai/Pixtral-12B-2409",
        "pixtral",
        "tall",
        Some("preprocessor_config.json"),
        0.05,
    );
}

// ============================================================================
// Pipeline Result Accessors Tests
// ============================================================================

#[test]
#[ignore]
fn test_pipeline_result_accessors() {
    let pipeline = create_test_pipeline();

    // Load a test image
    let image = load_test_image("square");

    let config = PipelineConfig::new("llava-hf/llava-1.5-7b-hf");
    let result = pipeline
        .process_images(&[image], &config)
        .expect("Processing failed");

    // Test accessors
    assert_eq!(result.image_count(), 1);
    assert!(!result.is_empty());
    assert!(!result.num_tokens().is_empty());
    assert!(result.total_tokens() > 0);
    assert_eq!(result.original_sizes().len(), 1);
    assert_eq!(result.processed_sizes().len(), 1);
    assert_eq!(result.modalities.len(), 1);
}

#[test]
#[ignore]
fn test_pipeline_batch_processing() {
    let pipeline = create_test_pipeline();

    // Load multiple test images
    let images = vec![
        load_test_image("square"),
        load_test_image("wide"),
        load_test_image("tall"),
    ];

    let config = PipelineConfig::new("llava-hf/llava-1.5-7b-hf");
    let result = pipeline
        .process_images(&images, &config)
        .expect("Processing failed");

    // Verify batch processing
    assert_eq!(result.image_count(), 3);
    assert_eq!(result.num_tokens().len(), 3);
    assert_eq!(result.original_sizes().len(), 3);
    assert_eq!(result.modalities.len(), 3);
}
