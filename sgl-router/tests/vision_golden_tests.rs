//! Golden tests for vision processors.
//!
//! These tests compare Rust preprocessor output against golden outputs
//! generated by HuggingFace transformers to ensure pixel-perfect compatibility.
//!
//! Two modes are tested:
//! - `llava/` - Standard CLIP processing (llava-hf/* models, no expand-to-square)
//! - `llava_pad/` - Expand-to-square mode (liuhaotian/llava-* models, image_aspect_ratio=pad)
//!
//! To regenerate golden outputs:
//! ```bash
//! python scripts/generate_vision_golden.py
//! ```

use std::{fs::File, io::Read, path::Path};

use ndarray::Array4;
use sgl_model_gateway::multimodal::vision::{
    ImagePreProcessor, LlavaProcessor, PreProcessorConfig,
};

/// Load a numpy .npz file and extract pixel_values
fn load_golden_npz(path: &Path) -> Array4<f32> {
    let file = File::open(path).expect("Failed to open golden file");
    let mut npz = npyz::npz::NpzArchive::new(file).expect("Failed to parse npz");

    // Read pixel_values array (npz stores arrays without .npy extension in the lookup)
    let reader = npz
        .by_name("pixel_values")
        .expect("Failed to read npz")
        .expect("No pixel_values");

    // Get shape from npy header
    let shape = reader.shape().to_vec();
    assert_eq!(shape.len(), 4, "Expected 4D tensor [B, C, H, W]");

    // Read data as f32 vec
    let data: Vec<f32> = reader.into_vec().expect("Failed to read array");

    // Convert to Array4
    Array4::from_shape_vec(
        (
            shape[0] as usize,
            shape[1] as usize,
            shape[2] as usize,
            shape[3] as usize,
        ),
        data,
    )
    .expect("Shape conversion failed")
}

/// Load preprocessor config from JSON
fn load_config(path: &Path) -> PreProcessorConfig {
    let mut file = File::open(path).expect("Failed to open config");
    let mut contents = String::new();
    file.read_to_string(&mut contents)
        .expect("Failed to read config");
    PreProcessorConfig::from_json(&contents).expect("Failed to parse config")
}

/// Compare two tensors and return max absolute difference
fn max_diff(a: &Array4<f32>, b: &Array4<f32>) -> f32 {
    assert_eq!(a.shape(), b.shape(), "Shape mismatch");
    (a - b).mapv(|v| v.abs()).fold(0.0f32, |acc, &v| acc.max(v))
}

/// Run a golden test for a specific mode and image.
///
/// # Arguments
/// * `mode` - Either "llava" (standard CLIP) or "llava_pad" (expand-to-square mode)
/// * `image_name` - Name of the test image (e.g., "square", "tall", "wide", "small")
fn run_golden_test(mode: &str, image_name: &str) {
    let golden_dir = Path::new("tests/fixtures/golden").join(mode);
    let image_path = Path::new("tests/fixtures/images").join(format!("{}.jpg", image_name));

    if !golden_dir.exists() || !image_path.exists() {
        eprintln!(
            "Golden test fixtures for {}/{} not found, skipping test",
            mode, image_name
        );
        eprintln!("Run: python scripts/generate_vision_golden.py");
        return;
    }

    let golden = load_golden_npz(&golden_dir.join(format!("golden_{}.npz", image_name)));
    let config = load_config(&golden_dir.join("preprocessor_config.json"));

    let image = image::open(&image_path).expect("Failed to open image");

    let processor: Box<dyn ImagePreProcessor> = match mode {
        "llava" => Box::new(LlavaProcessor::new()),
        "llava_pad" => Box::new(LlavaProcessor::new_with_pad()),
        _ => panic!("Unknown test mode: {}", mode),
    };

    let result = processor
        .preprocess(&[image], &config)
        .expect("Processing failed");

    let diff = max_diff(&golden, &result.pixel_values);
    println!(
        "{} - {} image - Max difference: {:.6}",
        mode, image_name, diff
    );
    println!("Golden shape: {:?}", golden.shape());
    println!("Rust shape: {:?}", result.pixel_values.shape());

    // Allow tolerance for floating point and interpolation algorithm differences
    assert!(
        diff < 0.02,
        "Max difference {} exceeds tolerance 0.02",
        diff
    );
}

// ============================================================================
// Standard CLIP mode tests (llava-hf/* models, no expand-to-square)
// ============================================================================

#[test]
fn test_llava_golden_square() {
    run_golden_test("llava", "square");
}

#[test]
fn test_llava_golden_tall() {
    run_golden_test("llava", "tall");
}

#[test]
fn test_llava_golden_wide() {
    run_golden_test("llava", "wide");
}

#[test]
fn test_llava_golden_small() {
    run_golden_test("llava", "small");
}

// ============================================================================
// Pad mode tests (liuhaotian/llava-* models, image_aspect_ratio=pad)
// ============================================================================

#[test]
fn test_llava_pad_golden_square() {
    run_golden_test("llava_pad", "square");
}

#[test]
fn test_llava_pad_golden_tall() {
    run_golden_test("llava_pad", "tall");
}

#[test]
fn test_llava_pad_golden_wide() {
    run_golden_test("llava_pad", "wide");
}

#[test]
fn test_llava_pad_golden_small() {
    run_golden_test("llava_pad", "small");
}

// ============================================================================
// Token count tests
// ============================================================================

#[test]
fn test_llava_token_count() {
    let golden_dir = Path::new("tests/fixtures/golden/llava");

    if !golden_dir.exists() {
        eprintln!("Golden test fixtures not found, skipping test");
        return;
    }

    let config = load_config(&golden_dir.join("preprocessor_config.json"));
    let processor = LlavaProcessor::new();

    // LLaVA 1.5 with 336x336 and patch_size=14: (336/14)^2 = 576 tokens
    let tokens = processor.calculate_num_tokens(336, 336, &config);
    assert_eq!(
        tokens, 576,
        "Expected 576 tokens for 336x336 with patch_size=14"
    );
}
