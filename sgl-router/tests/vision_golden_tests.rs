//! Golden tests for vision processors.
//!
//! These tests compare Rust preprocessor output against golden outputs
//! generated by HuggingFace transformers to ensure pixel-perfect compatibility.
//!
//! Modes tested:
//! - `llava/` - Standard CLIP processing (llava-hf/* models, no expand-to-square)
//! - `llava_pad/` - Expand-to-square mode (liuhaotian/llava-* models, image_aspect_ratio=pad)
//! - `qwen2_vl/` - Dynamic resolution with smart resize (Qwen/Qwen2-VL-* models)
//!
//! To regenerate golden outputs:
//! ```bash
//! python scripts/generate_vision_golden.py
//! ```

use std::{fs::File, io::Read, path::Path};

use ndarray::Array4;
use sgl_model_gateway::multimodal::vision::{
    image_processor::ModelSpecificValue, ImagePreProcessor, LlavaProcessor, PreProcessorConfig,
    Qwen2VLProcessor,
};

/// Load a numpy .npz file and extract pixel_values
fn load_golden_npz(path: &Path) -> Array4<f32> {
    let file = File::open(path).expect("Failed to open golden file");
    let mut npz = npyz::npz::NpzArchive::new(file).expect("Failed to parse npz");

    // Read pixel_values array (npz stores arrays without .npy extension in the lookup)
    let reader = npz
        .by_name("pixel_values")
        .expect("Failed to read npz")
        .expect("No pixel_values");

    // Get shape from npy header
    let shape = reader.shape().to_vec();
    assert_eq!(shape.len(), 4, "Expected 4D tensor [B, C, H, W]");

    // Read data as f32 vec
    let data: Vec<f32> = reader.into_vec().expect("Failed to read array");

    // Convert to Array4
    Array4::from_shape_vec(
        (
            shape[0] as usize,
            shape[1] as usize,
            shape[2] as usize,
            shape[3] as usize,
        ),
        data,
    )
    .expect("Shape conversion failed")
}

/// Load preprocessor config from JSON
fn load_config(path: &Path) -> PreProcessorConfig {
    let mut file = File::open(path).expect("Failed to open config");
    let mut contents = String::new();
    file.read_to_string(&mut contents)
        .expect("Failed to read config");
    PreProcessorConfig::from_json(&contents).expect("Failed to parse config")
}

/// Compare two tensors and return max absolute difference
fn max_diff(a: &Array4<f32>, b: &Array4<f32>) -> f32 {
    assert_eq!(a.shape(), b.shape(), "Shape mismatch");
    (a - b).mapv(|v| v.abs()).fold(0.0f32, |acc, &v| acc.max(v))
}

/// Load image_grid_thw from npz file
fn load_golden_grid_thw(path: &Path) -> Vec<u32> {
    let file = File::open(path).expect("Failed to open golden file");
    let mut npz = npyz::npz::NpzArchive::new(file).expect("Failed to parse npz");

    let reader = npz
        .by_name("image_grid_thw")
        .expect("Failed to read npz")
        .expect("No image_grid_thw");

    // Shape not needed, data is flat
    let _shape = reader.shape();

    // Read data as i64 vec (numpy default for int)
    let data: Vec<i64> = reader.into_vec().expect("Failed to read array");

    // Convert to u32
    data.into_iter().map(|v| v as u32).collect()
}

/// Load num_tokens from npz file
fn load_golden_num_tokens(path: &Path) -> usize {
    let file = File::open(path).expect("Failed to open golden file");
    let mut npz = npyz::npz::NpzArchive::new(file).expect("Failed to parse npz");

    let reader = npz
        .by_name("num_tokens")
        .expect("Failed to read npz")
        .expect("No num_tokens");

    // Read single value as i64
    let data: Vec<i64> = reader.into_vec().expect("Failed to read array");
    data[0] as usize
}

/// Run a golden test for a specific mode and image.
///
/// # Arguments
/// * `mode` - Either "llava" (standard CLIP) or "llava_pad" (expand-to-square mode)
/// * `image_name` - Name of the test image (e.g., "square", "tall", "wide", "small")
fn run_golden_test(mode: &str, image_name: &str) {
    let golden_dir = Path::new("tests/fixtures/golden").join(mode);
    let image_path = Path::new("tests/fixtures/images").join(format!("{}.jpg", image_name));

    if !golden_dir.exists() || !image_path.exists() {
        eprintln!(
            "Golden test fixtures for {}/{} not found, skipping test",
            mode, image_name
        );
        eprintln!("Run: python scripts/generate_vision_golden.py");
        return;
    }

    let golden = load_golden_npz(&golden_dir.join(format!("golden_{}.npz", image_name)));
    let config = load_config(&golden_dir.join("preprocessor_config.json"));

    let image = image::open(&image_path).expect("Failed to open image");

    let processor: Box<dyn ImagePreProcessor> = match mode {
        "llava" => Box::new(LlavaProcessor::new()),
        "llava_pad" => Box::new(LlavaProcessor::new_with_pad()),
        _ => panic!("Unknown test mode: {}", mode),
    };

    let result = processor
        .preprocess(&[image], &config)
        .expect("Processing failed");

    let diff = max_diff(&golden, &result.pixel_values);
    println!(
        "{} - {} image - Max difference: {:.6}",
        mode, image_name, diff
    );
    println!("Golden shape: {:?}", golden.shape());
    println!("Rust shape: {:?}", result.pixel_values.shape());

    // Allow tolerance for floating point and interpolation algorithm differences
    assert!(
        diff < 0.02,
        "Max difference {} exceeds tolerance 0.02",
        diff
    );
}

// ============================================================================
// Standard CLIP mode tests (llava-hf/* models, no expand-to-square)
// ============================================================================

#[test]
fn test_llava_golden_square() {
    run_golden_test("llava", "square");
}

#[test]
fn test_llava_golden_tall() {
    run_golden_test("llava", "tall");
}

#[test]
fn test_llava_golden_wide() {
    run_golden_test("llava", "wide");
}

#[test]
fn test_llava_golden_small() {
    run_golden_test("llava", "small");
}

// ============================================================================
// Pad mode tests (liuhaotian/llava-* models, image_aspect_ratio=pad)
// ============================================================================

#[test]
fn test_llava_pad_golden_square() {
    run_golden_test("llava_pad", "square");
}

#[test]
fn test_llava_pad_golden_tall() {
    run_golden_test("llava_pad", "tall");
}

#[test]
fn test_llava_pad_golden_wide() {
    run_golden_test("llava_pad", "wide");
}

#[test]
fn test_llava_pad_golden_small() {
    run_golden_test("llava_pad", "small");
}

// ============================================================================
// Token count tests
// ============================================================================

#[test]
fn test_llava_token_count() {
    let golden_dir = Path::new("tests/fixtures/golden/llava");

    if !golden_dir.exists() {
        eprintln!("Golden test fixtures not found, skipping test");
        return;
    }

    let config = load_config(&golden_dir.join("preprocessor_config.json"));
    let processor = LlavaProcessor::new();

    // LLaVA 1.5 with 336x336 and patch_size=14: (336/14)^2 = 576 tokens
    let tokens = processor.calculate_num_tokens(336, 336, &config);
    assert_eq!(
        tokens, 576,
        "Expected 576 tokens for 336x336 with patch_size=14"
    );
}

// ============================================================================
// Qwen2-VL tests
// ============================================================================

/// Load flattened pixel values from Qwen2-VL npz file.
/// Returns (data, shape) where shape is (num_patches, patch_features).
fn load_golden_qwen2_vl_pixels(path: &Path) -> (Vec<f32>, (usize, usize)) {
    let file = File::open(path).expect("Failed to open golden file");
    let mut npz = npyz::npz::NpzArchive::new(file).expect("Failed to parse npz");

    let reader = npz
        .by_name("pixel_values")
        .expect("Failed to read npz")
        .expect("No pixel_values");

    let shape = reader.shape().to_vec();
    assert_eq!(shape.len(), 2, "Expected 2D tensor for Qwen2-VL patches");

    let data: Vec<f32> = reader.into_vec().expect("Failed to read array");
    (data, (shape[0] as usize, shape[1] as usize))
}

/// Run a Qwen2-VL golden test for a specific image.
///
/// This test validates:
/// 1. image_grid_thw matches the HuggingFace output
/// 2. num_tokens calculation is correct
/// 3. Pixel values match after reshaping to patch format
fn run_qwen2_vl_golden_test(image_name: &str) {
    let golden_dir = Path::new("tests/fixtures/golden/qwen2_vl");
    let image_path = Path::new("tests/fixtures/images").join(format!("{}.jpg", image_name));

    if !golden_dir.exists() || !image_path.exists() {
        eprintln!(
            "Golden test fixtures for qwen2_vl/{} not found, skipping test",
            image_name
        );
        eprintln!("Run: python scripts/generate_vision_golden.py --model qwen2_vl");
        return;
    }

    let npz_path = golden_dir.join(format!("golden_{}.npz", image_name));
    let config = load_config(&golden_dir.join("preprocessor_config.json"));

    // Load golden values
    let golden_grid_thw = load_golden_grid_thw(&npz_path);
    let golden_num_tokens = load_golden_num_tokens(&npz_path);
    let (golden_pixels, golden_shape) = load_golden_qwen2_vl_pixels(&npz_path);

    // Process image with our Rust processor
    let image = image::open(&image_path).expect("Failed to open image");
    let processor = Qwen2VLProcessor::from_preprocessor_config(&config);
    let result = processor
        .preprocess(&[image], &config)
        .expect("Processing failed");

    // Extract image_grid_thw from result
    let rust_grid_thw = match result.model_specific.get("image_grid_thw") {
        Some(ModelSpecificValue::UintTensor { data, shape }) => {
            assert_eq!(shape, &[1, 3], "Expected shape [1, 3] for single image");
            data.clone()
        }
        _ => panic!("Expected image_grid_thw in model_specific"),
    };

    // Compare grid dimensions
    println!(
        "qwen2_vl - {} image - Grid T H W: golden={:?}, rust={:?}",
        image_name, golden_grid_thw, rust_grid_thw
    );
    assert_eq!(
        golden_grid_thw, rust_grid_thw,
        "image_grid_thw mismatch for {}",
        image_name
    );

    // Compare token counts
    let rust_num_tokens = result.num_img_tokens[0];
    println!(
        "qwen2_vl - {} image - Tokens: golden={}, rust={}",
        image_name, golden_num_tokens, rust_num_tokens
    );
    assert_eq!(
        golden_num_tokens, rust_num_tokens,
        "num_tokens mismatch for {}",
        image_name
    );

    // Compare pixel values by reshaping our output to patch format
    let grid_t = rust_grid_thw[0] as usize;
    let grid_h = rust_grid_thw[1] as usize;
    let grid_w = rust_grid_thw[2] as usize;

    // Get the tensor for the first image (batch index 0)
    let pixel_values = &result.pixel_values;
    let tensor_3d = pixel_values.index_axis(ndarray::Axis(0), 0).to_owned();

    // Reshape to patches format
    let rust_patches = processor.reshape_to_patches(&tensor_3d, grid_t, grid_h, grid_w);

    // Verify shapes match
    let expected_num_patches = grid_t * grid_h * grid_w;
    let patch_size = config.patch_size.unwrap_or(14);
    let temporal_patch_size = config.temporal_patch_size.unwrap_or(2);
    let expected_patch_features = 3 * temporal_patch_size * patch_size * patch_size;

    println!(
        "qwen2_vl - {} image - Patch shape: golden={:?}, rust=({}, {})",
        image_name, golden_shape, expected_num_patches, expected_patch_features
    );
    assert_eq!(
        golden_shape,
        (expected_num_patches, expected_patch_features),
        "Patch shape mismatch"
    );
    assert_eq!(
        rust_patches.len(),
        expected_num_patches * expected_patch_features,
        "Rust patches size mismatch"
    );

    // Compare pixel values
    let max_diff = rust_patches
        .iter()
        .zip(golden_pixels.iter())
        .map(|(r, g)| (r - g).abs())
        .fold(0.0f32, f32::max);

    println!(
        "qwen2_vl - {} image - Max pixel diff: {:.6}",
        image_name, max_diff
    );

    // Allow tolerance for floating point and interpolation differences
    assert!(
        max_diff < 0.02,
        "Max pixel difference {} exceeds tolerance 0.02 for {}",
        max_diff,
        image_name
    );
}

#[test]
fn test_qwen2_vl_golden_square() {
    run_qwen2_vl_golden_test("square");
}

#[test]
fn test_qwen2_vl_golden_tall() {
    run_qwen2_vl_golden_test("tall");
}

#[test]
fn test_qwen2_vl_golden_wide() {
    run_qwen2_vl_golden_test("wide");
}

#[test]
fn test_qwen2_vl_golden_small() {
    run_qwen2_vl_golden_test("small");
}
